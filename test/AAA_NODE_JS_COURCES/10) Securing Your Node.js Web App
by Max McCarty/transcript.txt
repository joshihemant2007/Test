Since its creation in 2009, Node.js has seen exponential growth in its community of users and the applications they are building. With the drive towards a connected society, the need for web applications has never been greater. Yet, despite the push to connect the world as we know it, businesses of all sizes fall victim to data breaches everyday. The security risks that a Node.js based web application face are no different than any other web application. This course, Securing Your Node.js Web App, will empower you with both the understanding of various web based security risks and how to apply the proper mitigation in your Node.js web application. First, you'll learn about implementing proper authentication and session management. Next, you'll explore how to protect your MongoDB database from injection attacks and how to handle untrusted data - a key player in many of the risks you'll look at. Finally, you'll wrap up by learning how to control application and user authorization to key access areas and the benefits of serving our application over HTTPS. By the end of this course, you'll be on your way to building a significantly more secure Node.js web application.

Course Overview
Course Overview
Hi everyone. My name is Max McCarty, and welcome to my course, Securing Your Node. js Application. I'm a software engineer in Pittsburgh, Pennsylvania, and host of the Lock Me Down Podcast. Since its creation in 2009, Node. js has seen exponential growth in its community of users and the applications they are building. In the drive towards a connected society, the need for web applications has never been greater. Even companies such as Wall Street Journal, eBay, GoDaddy, Microsoft, and Ancestry. com have embraced Node for various needs. Yet despite the push to connect the world as we know it, businesses of all sizes fall victim to data breaches every day. With over 5000 data breaches reported since 2005, we clearly still have a problem, which brings us to why we are here. Web application security isn't going anywhere, and it isn't getting any easier to securely host user personal and financial information. In this course, not only will we implement the code to mitigate major security threats our web application will face, but also introduce you to a number of security testing tools along the way. We'll be tackling areas such as implementing proper authentication and session management, protecting our MongoDB database from injection attacks, and how to handle untrusted data, a key player in many of the risks we'll be looking at. Also, how to control application user authorization to key access areas, and the benefits of serving our application over HTTPS. By the end of this course, you'll be on your way to building a significantly more secure Node. js web application, because someone or some company's application will be the next victim of a data breach. The question is, will it be yours? I really enjoyed building this course, and I hope you'll enjoy watching it.

Introduction to Hackers Hall
Introduction to Hackers Hall
Hi, this is Max McCarty, and I wanted to take the opportunity to introduce you to the application we're going to be using extensively over this entire course. Hacker's Hall is a site dedicated to an interactive timeline of company data breaches and infamous hackers of the digital age. It's a site that I am currently running locally, and you will be able to as well with the demos provided with each module. The timeline provides a number of ways that we can interact with the events and hackers that have plagued history over the years. Navigating the timeline, we can view the details on items or related items. We can even filter the timeline by date, or through the search feature. Its other feature is the ability to allow authenticated users to cast their vote for most catastrophic data breach or infamous hacker, and view the results of those that have voted. We can also perform some of the standard authentication actions such as registering as a new user and logging in. And later in this course, we'll see some additional features come to life with user profile updates and administration features such as viewing the site users and deletion of a user. But the biggest feature the site provides is what isn't seen, and that is the extensive security holes and weaknesses that abound, and it's through these security deficiencies that we will use to exploit, test, and mitigate with the tools and techniques in this course.

Proper User Authentication
Overview
Hi, this is Max, and in this module, we're going to look at one of the most popular web application features, which is authentication. It's almost impossible to go to any web application and not find some feature that requires authentication. Even Johnny Apple Cider Recipes requires you to login just to rate their recipes. But despite our technological advances and the monolithic library of different frameworks and strategies for building web applications, there is still a huge knowledge gap in understanding how to implement proper and secure authentication measures. We witness this knowledge gap every year when we see data breaches that show companies and developers are still using broken authentication measures, whether it's storing passwords in plain text or using insecure hashing algorithms. There is even further evidence of this fact that OWASP top ten list of web application security risks has broken authentication at the number 2 spot. We're going to implement a number of security measures that layer on top of each other, a security in depth approach for implementing a proper authentication system, starting with proper password storage, and also the missing ingredient, which is password strength requirements, and finally, brute-force safeguards. So let's get started.

The Problem with Password Storage
Every year we see a slew of news articles regarding company data breaches where information on thousands and millions of users are leaked. The most common and highly-prized data across these different data breaches is user credentials. If they're so highly prized, why are they so easily exploited? Well, in many cases user passwords are stored in plain text or an insecure or inadequate hashing algorithm was used. Or maybe the passwords were encrypted and the private key was compromised. Unfortunately, users tend to use the same username/password combination for multiple sites, so when one site exposes a user's credentials, it's very possible it can be used elsewhere. So how should passwords be stored? A couple of the options that you might have come up with is using a cryptographic hash or encryption. So what is the difference between the two? When we talk about encryption, it is a two-way operation. We can take plain text using a private key, and encrypt that to a non-human-readable format. But with the right key, we can turn around, decrypt that information back to the original text. The difference with a hash, is that they are a one-way operation. With a hash value of the plain text, it's impossible to run it back through the hashing algorithm to produce the original text. So why is this important? Another caveat of cryptographic hashes is that with the same parameters and input, it would generate the same hash. So when it comes to a user attempting to login, and submitting a password guess, we don't need to compare that password guess to the original password, we only need to run the submitted password guess through the same hashing algorithm, and verify it is equivalent to the hash that we have stored. Alternatively, if we had encrypted the password, and our database of user's passwords had been compromised along with the private key for decrypting, there wouldn't be any problem for acquiring passwords for users in our system. So what cryptographic hash function do we use? MD5, or maybe one of the SHA groups? Well, for many of these they are found to be flawed, flaws that in many cases can be exploited. But the most damaging reason is because these hashing algorithms have been made to be fast, and while speed might be a beneficial factor for rendering a web page, it is not a beneficial factor when it comes to password storage. Because hashing algorithms are a one-way process, attempting to determine a user's password requires making guesses, and running those guesses through the same algorithm until a match is found. With the speed of computer hardware constantly improving, and the ability to run operations in parallel, the ability to generate and compare possible matches grows exponentially. Here we can see where a physical computer that was assembled could generate, in some cases, billions of hashes per second, which could then be compared to the original hash. Combined with the case of a password having a low-grade password strength, you can see it wouldn't be hard to find a matching password to a user's account when using one of these fast or flawed hashing algorithms. So if we're going to store user passwords as a cryptographic hash, and hash algorithms are generally made for the purpose of speed, then what do we need to add to our hashing algorithm to generate the security and durability that's needed? If we can slow down the hashing algorithm, then we can directly impose restrictions despite the computer's capabilities or parallel operations. With these two ingredients, we would have what is better known as a Key Derivation Function. In our case, we're going to use a Key Derivation Function by the name of bcrypt. Bcrypt is speed's kryptonite. The key to bcrypt, as well as other derivation functions, is that they superimpose a time constraint by not just hashing the contents once, but numerous times, and for most key derivation functions, the recommended number of hashing rounds are approximately 80, 000 or more. That number can vary, and it also can increase with time as computer hardware gets faster. So why is this important and beneficial to us? For someone to generate a match to a stored password hash, they would not only have to know precisely how many rounds of hashing had occurred, but they would also be constrained by the time required to iterate that number of rounds.

Introduction to Bcrypt
We're on the Node Package Management site, specifically for the bcrypt package, and this would be a good time to point out the importance of vetting any Node package you install on your application, especially when we're talking about libraries that handle some type of security aspect, such as password hashing. It's very hard to get every aspect of whatever mechanism is being implemented correct, but it's very easy to slip up and introduce some type of flaw. So the importance of finding a library that has had a lot of public exposure, that has been around for some period of time, has had a chance to be vetted by the public for any vulnerabilities to be resolved. Now bcrypt has been in publication for quite a number of years. You can see here that it's being downloaded in excess of 340, 000 times per month. They have a number of contributors, and it has a high exposure to the public for finding any possible vulnerabilities within the library itself. So we'll first start off by just taking a quick look at how the application is storing passwords now. I'll go ahead and just register a new account, put in any old password, and then we'll move over here to a Mongo terminal, connect to our database, and then run a quick query for that particular user. And we see right there under password it has stored our password, that I had typed in to store, so we're just storing passwords in plain text currently. So let's do something about that.

Implementing Bcrypt
So the very first thing we want to do is pull the bcrypt Node package into our application, and we'll go ahead and install that, and we'll specify this specific application with the save flag. The other thing we want to do is specify a very specific version, the most latest stable version. And I'll go ahead and minimize this terminal window, and we can see here that, indeed, it's dropped the bcrypt package in our dependencies inside of our package. json file, but this would be a good time to point out another Node Package Management tip. You'll see in your package. json file in your application or other applications, that a lot of times a package version is prefixed with either the carrot or tilde symbol. Now, that is basically specifying to the Node Package Management system a certain amount of leniency on what minor or major version they are allowed to update to. So in the case that you were to do a global update on all your packages, NPM is going to have a certain amount of leniency to what package version or minor version it can update a package to. The problem with that is when you're dealing with a library that handles some type of sensitive security matter, such as the library that hashes your passwords within your application, if a new minor or major version rolls out that introduces some security vulnerability, you're not going to know that, and the application will be updated to that latest minor or major version, depending on what you had specified as the prefix to that version. So, in most cases, if not all, you want to stick with a specific version of a package you're going to use, until you have a chance to vet that other latest minor or major version to make sure that there isn't any problems with it before you update to it. Now the next thing we want to do is actually put bcrypt to use hashing passwords, new user accounts that get registered within your application, and being able to do the comparison for when somebody is logging in and they've submitted some password guess. So the very next thing we want to do is actually put bcrypt to use hashing passwords for new registered users, as well as doing the comparison when somebody is trying to login. Now I'm going to switch over to our schemas. js file, and what this is is that our application is using Mongoose. Mongoose is an object modeling tool that allows us to introduce schemas to what is otherwise a schema-less database, which is Mongo, MongoDB. Now you don't have to use Mongoose within your application, but it makes a convenient place for me to be able to specify what is important to you, and that is using bcrypt to hash users' passwords. So the first thing I'm going to do is go ahead and import bcrypt into this file, and we'll come down here, and what I'm going to do is paste in a particular function, and what it is is Mongoose allows you to generate a hook into certain functions that it's going to carry out, in this case we're going to specify a hook that should be fired right before the save method for a new user is created. And what's important to you is actually implementation of using bcrypt to hash this new user's password. So in this case we specify bcrypt's hash method. We've given it the password of this new user, followed by how many rounds. Now this isn't rounds as in only 16. 5 times is it going to try go hash the password. For bcrypt, it's actually 2 to the power of that number, so in this case, it's 2 to the power of 16. 5, which is going to generate roughly a little over 92, 000 rounds of hashing for this password. Once we have generated that hash, we're going to specify and we're going to assign that hash to this new user's password. So when a new user registers, they submit the password they want to use, bcrypt is going to hash that 92, 000 rounds of hashing, and we're going to assign it to this new user's password, and then Mongoose Save method will fire for saving this new user. And we can see that by going ahead and firing up our application I went ahead and deleted that old user. We can go ahead and create them again. We'll just give it the same password, which was nothing more than just password. We'll jump back over to our Mongo terminal, and we'll do another lookup for that particular user. And indeed, we can see here, that it's actually created a password that is the hash of the password I submitted, which was nothing more than the word password. So that's only handling one scenario where we're hashing the password of a newly-created user within our system. The other part that we need to handle is when a user is attempting to login, and we need to compare their submitted password to what we have on file, which currently now is just a hash. I'm going to jump back over here to our authenticationRoutes, which as you probably are aware with express you can specify routes that are going to be handled by your API. In this case, we have our loginRoute, where we will receive any requests for our users attempting to login. And we're just doing an async call on this particular user we've looked up, and we have received, and we're calling passwordIsValid on that user, and submitting the password that was submitted by somebody who was trying to login. If we look over at the implementation of this passwordIsValid method, back on our schemas file for Mongoose, we have an instance method here, passwordIsValid where we have a found user, and we currently are just comparing originally the plain text password that we were storing to the password that was submitted, and if it's a match then we'll let them login. What I'm going to do here is replace this with an updated version that's using bcrypt to compare the password to what now is a hash that we're storing of the user's password. So what this is going to do is call the Compare method from the bcrypt library, and submit both passwords, the one that's on file and the one that was submitted, and we'll get back results in our callback method, that we can return whether or not it was a success or not. Now if we switch back, so if we fire back up our application, and we attempt to log in with the new user we just created, we should be able to find that now it can compare and log us in as that user, because back in, and I'll go ahead and minimize this, our passwordIsValid method, it's going to run the submitted password guess through the same number of rounds of hashing to see if it comes up with the very same hash results stored on file for this particular user. One last thing to point out is the importance of how we're utilizing bcrypt. Now you might not be using Mongoose, and that's not important. Wherever you're generating new users in your system or having users log in, you're going to utilize bcrypt in the same way for hashing passwords of newly-registered users, or users logging in in the case that you need to compare their submitted password to what's on file, nothing changes there. In our case, we have a convenient place that we can store that logic when we're using Mongoose.

Password Strength, the Missing Ingredient
In 2015, /. put out their annual Most Popular Passwords list, which is a list comprised from user account information acquired from data breaches. And you can see from this short top five results from that list, that the most popular passwords are generally easy-to-remember, and easy-to-implement passwords. I think most of us, if maybe not all of us, have been guilty for using very simple passwords such as these, or something similar, in the past. So what is the significance of this with implementing a secure authentication system? I think the best answer to that question is giving you a demonstration. Over on the Gibson Research Corporation site is a "Search Space" calculator, as they call it. The best way to describe it is using the metaphor they do, and that is, your password is basically a needle in a haystack. For those not familiar with that adage, it just means something that's very hard to find. It's not impossible, so in this case, how hard is your password, your needle, to be found in the haystack of possible passwords. We can see here they have the ability to put in a password, and what it does, first of all, it's not a password strength meter, but it will be able to give you a good measure of how long it would take, in a number of different situations, to be able to come up with the correct guess of what your password is. For example, if I just throw in the simple password as the password in this case, it's eight characters, all lowercase, what this "Search Space" calculator shows is giving you different scenarios of how that password might be attempted to be cracked in the case of an online attack where somebody is submitting password guesses to your API, or in the case all the way down to a compromised database which contains users' passwords, and they're doing an offline fast attack on those passwords, or in the case where they have ramped it up and they have the hardware to conduct what they're calling as a Massive Cracking Array Scenario of being able to throw upwards of 100 trillion guesses per second against those passwords. The word password, in this case, that we submitted, is showing that in two thousandths of a percent of a second they can come up with the correct guess, or even 2 seconds for a slower offline attempt to guess what that password is. Maybe we'll up the ante, and we'll add a few more digits to this, 13 characters in all. In the case where they are throwing everything they have, the kitchen sink and everything with it, to crack this password, they're still looking at a little under 3 weeks to come up with a 13-character password. Now what if we change this out and put in something a little different? Something very simple I think is easy to remember is 22 characters. Now look at the difference in how long it would take, anywhere from an online to an offline scenario, 2. 94 thousand trillion centuries, I mean that's a number I'm not sure I can actually wrap my head around. But the point is, how long it would take someone, even with accelerated hardware in an offline scenario to come up with the proper number of rounds of guessing before they came up with your guess. Now why is this important, and what does this mean? Well, going back to our list that we saw earlier, and we see passwords like 123456, the word password, and then we look back at something like you're expecting somebody to remember, let's say, something wacky, a lot of different types of requirements, and they come up with some crazy password. Do you think it would be easy for somebody to remember this password? Or do you think they would never tell me the odds, would be an easier password to remember. Not only is it easier to remember, but never tell me the odds is just easier to type. So when we're talking about some crazy password that somebody is expected to remember because of the requirements for it, it makes you realize why they might have put in 123456 or the word password to begin with. So when we're talking about password strength requirements, it's a challenge. It is both technical, as well as a training challenge to the users for your application. So whatever requirements for user passwords you're going to enforce on your application, is going to have a direct relation to the security of users within your application. As I've mentioned a number of times before, security is always a multi-layer approach. We're layering different security measures one on top of the other, with the assumption that an attacker can bypass some number of measures, maybe to the point where they've compromised and acquired your database. How easy are you going to make it for them to crack your users' passwords? If you put in a great hashing algorithm, but then you're only enforcing an 8-character low-grade password strength, in this case, they might have less than 2 thousandths of a second before they figured out the password for that user. So let's look at how we can implement requirements for passwords within our application.

Enforcing Validation Rules with Express-validator
Express-validator is a Node package that allows you to specify specific rules to validate data that comes in on either the request body, or as URL parameters, or the query string, because as you well know, any data that comes into your API that is outside of your control, has a high probability of being harmful to your system. We can use express-validator to specify the rules for an instance of the shape of the data for a new user. So let's see how we can put that to use. So back here in our application like we did before, we'll go ahead and install directly into our application the express-validator package, and we'll specify, in this case, the most latest version, and we can validate that, indeed, it has installed that version of the express-validator package within our package. json file. The next thing we're going to want to do is pull in that express-validator library in our server, our Express server in this case, and use it as middleware, and according to their documentation we need to specify it right after the body parser, so we will initialize it here. And I'm going to go ahead and minimize this terminal window for a little more room. Now before we go writing rules that we want to apply to some data that we're pulling in on our API, let's go look at exactly where we might use it. So I'm going to switch over here to our authenticationRoutes, which is our router for handling any authentication specific routes, such as where our user would submit for a new registered user. And we see here that we're just decomposing a number of fields off the request body, and checking if that user exists, and then if not, throwing that information into a new user and calling Save. Obviously, any of that information could be potentially harmful to our system, and we would want to run that information through our rules to validate it meets our requirements, so how can we go about that? So, ultimately, what we actually want it something that looks more like this, I'm going to go ahead and paste in this chunk of code, that basically shows there is a checkBody method off the request where we're passing in some object, in this case called a registrationSchema. Then we can call requestValidationErrors method off the request to see what errors might have been returned from the checkBody method. And then we're returning if there is any errors back to the caller, in this case our client. So this registrationSchema is going to be our rules that specify exactly what shape that data should be in. We'll start by going over here and creating a new folder, Directory, and we'll call it just validationSchemas. Actually, let's just call it validation for right now. And we will throw in there a new file called validationSchemas. So I'm going to go ahead and just paste in this body of our registrationSchema, which defines the rules and the schema for two fields that we care bout in this case for right now, email and password. Nothing fancy, it's just specifying that they're required, that it's a legitimate email, that the password has a minimum number of characters, and we can specify the error message in the case that those requirements are not met. So now I am going to come back over to our authenticationRoutes file and I'll go ahead and import that registrationSchema. And we already had pasted in the code here for providing that to the checkBody method, which will use that schema to validate the email and password field that's coming in off the request body. Now currently, if I flip back over to our validationSchema file, our registrationSchema doesn't have any really hard rules for the data, other than we're requiring a 12-character minimum for the password being submitted, these fields are required. We could take it a little extra step further and drop in a required shape to our password, for example. With the matches field we can specify our RegEx expression that would validate that the characters would have any number of upper and lowercase, as well as numbers, other than just the 12-character minimum. We can also come in here and drop in some additional requirements that at least one of these special characters, and I also see that I'm missing a requirement of at least one or more of those characters as well. So we can see this in action if we come over here and fire up our application. Back here on our application we'll go ahead and try to register. We'll just give it any old password. And we see that our error messages that we were returning back are indicating that our attempt to register that user, the submitted email and password for this new registration is not meeting the requirements that we specified in our registrationSchema. Back over here, we can see that those same error messages are being returned, in this case, for the password. So you can see here there is a slew of different options we have for ensuring that data submitted to our application conforms to the rules and the requirements that we specify. But this is only part 1. Let's look at a second step we can apply to help ensure the validity of the data we are introducing to our application by looking at requirements we can specify at the database level.

Enforcing Validation at the Database level with Mongoose
So back over here in our application in our schema file where we have defined Mongoose schemas to apply to our Mongo database, I wanted to take this opportunity to point out that we can apply an additional layer of validation before we're going off and saving that data. So maybe it's met the requirements that we have specified for that incoming data that has been submitted to our API, we're ready to save that data. Right now I just have a very simple user schema defined that has a couple of requirements for certain fields, and what they should be, String, Date, that really comes into play for ensuring what that data type should be in the case of a String or a Date or a Number or so forth. But what we can do is we can spice this up and add some additional logic here. So I'm going to go ahead and just replace our current define UserSchema with something a little more spiced up. You can see here that we have added those same additional requirements for password and email, very similar to what we had over here for our validationSchema that express-validator is using. Therefore, if we can be consistent with the rules and requirements that we specify for the shape of the data that's coming to our application, less chance for errors or issues, especially related to security, that might show up. So in this case I am specifying that when I want to create a user and save that user off to Mongo, that Mongoose will actually ensure that the data I am providing to the Mongo database fits the requirements that I specified for my application. So this is just another layer and requirement we can put on our application to ensure the validity of that data that's coming in. So we looked at a small example how we can enforce requirements and regulations on the data that we're bringing in externally into our application. Now let's take a look at how we can implement brute-force safeguards in our authentication system.

Brute-force Safeguards
Not every application is the same, and its requirements especially, nor is everybody that visits your application a legitimate user. A lot of the individuals that will be interacting with your application are going to be an attacker that's trying to carry out some nefarious action, usually in the form of a brute-force action against your application to find out where your weak points are. So what can be do about making those brute-force attempts against your application harder for someone that is attempting to find that weak point? Well, there's another question that we have to ask ourselves and we have to determine. See, the antithesis of security is convenience, so the first thing you have to determine is what convenience to your users are you willing to compromise for added security to your application. That's not always the case, but a lot of times they have some type of a quality to introducing additional security measures might compromise the convenience that your users experience on your application. So let's take a look at what we can do for different scenarios.

Brute-force Mitigation with Delayed Responses
Remember back here in our Gibson Research Search Space calculator? One of the scenarios they had was the Online Attack Scenario where they're assuming someone is able to throw a thousand guesses per second against your application. That is a brute force attack against your application. And there are some small things that we can do to help make that harder for individuals to take advantage of. It's just like bcrypt enforces and superimposes a time constraint by running the hashing of a password through n number of rounds, we can do the same thing with just some very small steps. Back in our application, specifically in our loginRoute handler, we have a body of work that's doing quite a few different things. So before I go and add to this body of work, let me just point out that having everything in one place is not good programming practices, as you probably know, but for the sake of this course and being able to make it more understood and the concepts followed, instead of having you jump around into additional files and areas within the application, I've decided to keep everything in one location, but generally we would split out validation of data, and error handling, and user creation into different areas that specifically handle those specific tasks. That being said, I'm going to go ahead and drop in this new function within our handler, and it's a function that all it does is superimpose, in this case, a 1 second delay. We then can go ahead and just update the logic that would use that, that will take advantage of that function in any response that's returned, whether it is a failed response or the successfully logged in, they'll be superimposed a 1 second delay before they get that response. Now for the legitimate user, they're not going to really notice that, but someone who is flooding your API with thousands of requests per second, that's going to take a toll on their success. But maybe a delay is not enough. Maybe your application has more requirements for what you do with failed attempts. So let's look at another scenario.

Tracking Failed Logins
We just got through looking at how we can impose a simple 1 second delay on login attempts that will help slow down brute-force logins against our application without necessarily negatively affecting legitimate users. But maybe your situation requires a much harsher action to take place when legitimate users fail to login. Unfortunately, we can't just implement the logic to lock out a user for a duration after so many failed attempts. We would be imposing into our application the possibility of a Denial of Service attack by brute-force login attempts locking out legitimate users after they failed to login. So we have to have a way to be able to uniquely identify login attempts into our system, and be able to track those login attempts. So what we're going to do is capture login attempts and store them in our MongoDB, and be able to attempt to uniquely identify those logins. So the first thing I'm going to do here is paste in a new schema for tracking logins, and we're going to call it loginSchema. So the key fields on this schema that I want to point out is the identityKey which will be some type of unique string that we can attempt to track login attempts, failed attempts, which is simply where we'll track the number of failed login attempts, and our timeout for tracking when they will be able to log back in. With our login schema defined, and we're able to capture unique logins, the next thing I wanted to define is some static methods on the schema that we can utilize during the authentication process. So the first thing I'm going to do is go ahead and paste in some static methods that we can then cover and take a little closer look at. Most of these should be self-explanatory, but let's look at the details. This first one "canAuthenticate", basically is checking whether or not the current login attempt can proceed. Have they reached the number of failed attempts, or in the case that they were currently under a timeout, has that timeout expired? Can we remove it and allow them to continue? If not, we're going to return that they can't. The next static method is failedLoginAttempt. Basically, we want to be able to capture and log to our logins table any failed attempts by this particular login. Finally, the "successfulLoginAttempt", basically we're cleaning up after ourselves in the case that a user has successfully logged in, and maybe they had previously failed to login in the past. So let's see how we can put these static methods to use. Before we can actually start calling on these specific static methods, we need to define the model that would be able to serve up this schema. So I'm going to go ahead into our model factory and drop in the function that will return the models that are bound to this schema. With our function to give us the model that's bound to that schema, we can come back over here to our authenticationRoutes, and we can make the necessary changes to our login handler that will allow us to be able to check and capture failed login attempts. So what I'm going to do is go ahead and replace our login logic currently with an updated version, taking advantage of those static methods to be to track login attempts, and then we'll go over those details. So with the updated version, starting here at line 88, we can see that we are generating our identityKey that we talked about earlier. Now the key that we're using is a concatenation of the email and the IP address on the request. Now this is probably a good time to point out that the information on a request coming into our API, a lot of it can be spoofed by an attacker. Somebody that is trying to make brute-force attempts on our application can change things such as header information, IP addresses, things of those sort. So the science of coming up with a unique key is never going to be perfect, and in this case, for simplicity reasons, I kept just a concatenation of an email and IP address, but there is a lot of different types of device fingerprinting that you can look into of trying to find a unique way and a unique key that you can use for identifying the logins. The rest of this doesn't change, it's just how you want to be able to formulate that unique identityKey. So with those updates made, we can see here that we're still continuing with the same procedures we were doing before, and validating that the information on that request is good, and that we can proceed, and eventually we'll come in here and call canAuthenticate and pass in that identityKey. If there is currently a lockout on that account, we're just going to return and not continue with the authentication process, and return a status of 500. But everything is checking out, and we continue on with our normal login procedure. If they provided a faulty password, and it's been a failed attempt to login, we will call the failedLoginAttempt static method and pass in that identityKey so that we can capture that. However, if it's a legitimate user with a legitimate password, and they have successfully logged in, we're going to call the successfulLoginAttempt static method, passing in that identityKey, so that we can clean up in the case that they've failed in the past. A couple of the things I just wanted to point out real quick. Back over on our schemas, specifically under our "canAuthenticate" static method, I'm using a 1 minute timeout. Your requirements might be different, so you need to evaluate and know exactly what kind of time restriction you want to impose, and how many. In this case, I'm simply enforcing a static 5 attempts before I'm locking their account for 1 minute. Now there is one glaring issue that you might have picked up on, that affects both our delayed response that we put in earlier, as well as this failed login tracking that we're doing here. There's a hint, and it's one of the fields that we had implemented in our loginSchema. The problem is that despite all these attempts to track legitimate logins, as well as delaying and slowing down brute force login attempts against our application, is the case where an attacker is performing parallel attacks against our system, but there's something we can do about that, and we're going to take a look at that next.

Mitigating Parallel Brute-force Attacks
So far we've implemented a delay, as well as a lockout mechanism, but attackers will maximize our attempts and run attacks in parallel. And this really thwarts our attempts to some degree, especially when it comes to delays. They can get around that by firing numerous attempts, maybe for the same account. But we can usher in something to help against that, and that is progress tracking. So you might have noticed in the loginSchema that I defined earlier, there was an inProgress field that I set as a Boolean. What I'm going to do is come down here and add one more additional static method called inProgress. So we've been able to identify logins coming into our system, and we're tracking them with an identityKey. So this inProgress static method will allow us to check if a current login for the same identity is already in place, and if there is, we don't want to continue with the one that's being conducted for that same login. So let's see how we can put this inProgress static method to use. So I'm going to switch back over to our authenticationRoutes, and still here, in our login handler, I'm going to paste in a chunk of code here that will allow us to check whether or not that identified login attmept is already in progress, and we'll call that inProgress static method and pass in that identityKey, and this will help us to thwart parallel attempts on the same account by the same identity. There is, however, one small change we need to make in order for this work. I'm going to switch back over here to our schemas file, and point out that, as we saw in our inProgress method, we are updating any existing entity with this identityKey and setting the inProgress field to true. But in the case that they failed to login, we want to set that inProgress to false. So I'm going to update our failedLoginAttempt method here with a new version that's simply setting that inProgress field back to false in the case that they aren't able to login. We know that we're already handling the successful login scenario, because we're completely removing this entity from the logins table if they successfully login. So we have been able to easily put in a delay against brute force login attempts, and also a legitimate way that way we can track users' logins, and impose a lockout for some period of time without affecting legitimate users and imposing a Denial of Service scenario on legitimate users. We've also been able to bypass brute force parallel attacks by tracking those unique logins as well.

Transport Layer Security
We can never talk about implementing proper authentication measures without talking about one of the most important elements when it comes to secure authentication, and that is the use of Transport Layer Security. We'll be talking more extensively about TLS in an upcoming module, but it's important to point out the relevance of TLS with authentication. See, the HTTP protocol is the protocol we think about when generally transmitting data across the web. However, when we need to transport sensitive data securely, we do it via HTTP over TLS, otherwise referred to as HTTPS. User credentials is obviously very sensitive data and should only ever be transmitted using HTTPS, but why is that? We have to understand that all transmissions using the standard HTTP protocol is public. All communications are transparent over HTTP, all data is wide open, whether we're talking about a wired or wireless scenario such as a coffee shop, anyone with the means can easily intercept the transmitted data. If it's over HTTP, the information within those transmissions is also transparent and assessable. Therefore, when we're talking about a public API, we can't keep that information from being intercepted. We can keep it from being disclosed by encrypting the transmissions itself. We do that by utilizing the Transport Layer Security when using HTTPS, which leads us to the golden rule, and that is that the entire authentication process must occur over HTTPS. That starts with the serving of our login forms all the way to the submission of our user credentials. Now if you are serving your entire site over HTTPS, that's not much of a problem, but if you have segregated areas within your application, where some is not being handled by HTTPS, then it's an absolute must and necessary to know that you have to start with the loading, the serving of those authentication forms, and the submission of the credentials that a user submitted have to be done over HTTPS.

Summary
In this module, we had a chance to look at some important areas of authentication within our applications. Those areas include ensuring that we are storing user credentials securely using a highly-trusted and vetted key derivation function such as bcrypt, how we can increase the security of those stored password hashes by enforcing adequate levels of user password requirements, as well as ways we can implement mitigations to protect our application from authentication-related brute force attacks. And finally, the importance of understanding that when it comes to authentication, an absolute uncompromising requirement is that your entire authentication process, starting with loading of authentication forms to the submission of user credentials, must be done over HTTPS.

Session Management
Overview
Hi, this is Max, and in this module we're going to be looking at how we can implement secure sessions within our application. As you know, the HTTP protocol is a stateless protocol. Each communication to the server is seen as an isolated individual request. Therefore, each request must contain enough information for the request to be handled properly by the server. But it's very common to need to persist application state from one request to another. A very common scenario would be knowing that a user has already authenticated with your application. A very unfriendly user experience would be requiring a user to log in for every request that required authentication. It's a very popular and long-running mechanism to track an authenticated user in your application through the use of sessions, and persisting some type of session identification on each request, so that we can track an existing session between requests. If we're using sessions to track and authenticate a user in our system, then session-related information, such as a session ID, becomes a very sensitive and vital piece of information that we must protect. So in this module, we're going to be looking at a number of different steps, starting with protecting the Session ID, and making it less obvious to what we're using as our session management system on our backend. Also, time-limited sessions, so we can limit the exposure and minimize the window of an attacker's opportunity, making sure that we don't recycle used sessions when a user successfully authenticates, and securing our session cookies with the HTTPOnly flag to limit their access. Again, since we can identify session cookies as sensitive data, using Transport Layer Security to secure session ID is vital, as in the case of the HTTPOnly flag, using the secure flag on our Session cookies so that they aren't accidentally leaked over a non-secure communication. Finally, the importance and consideration of re-authentication on key access areas of your application. As we've mentioned before, we're also going to be taking a layered approach to our session security. There won't be just one mitigation that we will apply, but a number of different mitigations that will help secure our session information for a number of different scenarios. So let's get started.

The Problem with Session ID's
As we know, sessions allow us to persist some type of application state between requests to our API, such as in the case of tracking that a user has authenticated with our application. In order to associate an existing session for a user from request to request, we provide a session ID on every response. This session ID, or if you will, token, is a highly-prized piece of information. It's equivalent to someone's Social Security card or driver's license, which contains a driver's license number or Social Security number, IDs that will allow someone that needs to know the ability to look up additional information about that person. The last thing that you want to do is provide that sensitive data to someone that you wouldn't want to have that information.

Protecting the Session ID
There are a number of session-related Node packages that we can use, but a popular one that has been around and maintained is express-session. By default, it's configured to use in-memory storage for tracking created sessions, however, there is a number of different session stores that can be utilized to persist sessions. Currently, our app is using connect-mongo, which is a popular Node package that will persist sessions to your MongoDB database. For the most part we'll be making changes to our implementation of express-sessions. While it's paramount to use highly-vetted and maintained Node packages when it comes to any area of your application, especially sensitive security areas such as authentication and session management, the points that we'll be covering in this module, aren't exclusive to any Node package. Now reconnaissance is the first step an attacker will use for finding a weak point into your application. If an attacker can identify certain mechanisms, frameworks or libraries, that you're using within your application, and knows of vulnerabilities within those libraries and framework, they can use it to exploit security holes within your application. To show you what I mean about identifying libraries and frameworks based on information that the application serves up that would allow an attacker to do reconnaissance and find out that information, let's take a look at what those session IDs that are provided to the application currently. So I'm going to go ahead and open up a new window here. I'm going to bring up the Chrome Developer tools and throw in our site address, and pull that up. And to give us a little bit more room, I'm going to expand this. And I come down here and click on the original request. We'll see here that under the request headers there is a cookie that has been provided that the browser will use for all subsequent requests back to the site. So clicking on here under the Cookies tab, we can see more clearly that there is a cookie with the name connect. sid, and this is the naming convention provided by our session and our Session Store Node packages that would allow somebody to identify that we are using those specific packages. To show you what I mean about the ability for an attacker to conduct reconnaissance and gather information about your application based on the information that your application provides, able to identify libraries or frameworks you're using, some of which might have vulnerabilities that they can exploit. I have Fiddler here open. Now Fiddler is a great web debugging proxy. We can capture all the web traffic with this application. It's going to play our Man in the Middle scenario, as it wouldn't be any different than if someone was sniffing the network traffic on an internal network or listening to the web traffic on a wireless network at a coffee shop. This is exactly what they would see as well. So what I'm going to do is I'm going to flip over to Chrome, and we'll load up our site, and once that comes up, let's flip back over to Fiddler, and we can see the traffic that it's captured. I'm going to click on this initial one, which is our original request to the root domain. And over on the right, we can see request and response information related to that request and the response that came back. I'm going to pull up this window so we can see a little bit more information and a little clearer, and you can see here that one of the response headers was a set cookie response, and specifically to set the cookie with the name connect. sid. Now connect. sid is a specific name provided by the Session Management Node packages we are using. Now in a case that it had a vulnerability in it, any attacker who's doing their reconnaissance, would be able to pick up on that and be able to know what session management system we are using on our backend, and might be able to use that to their advantage. So what we'll want to do is generalize the session ID identifier so it would make it harder for someone to know what session management system we are actually using. So let's see how we can do that. So we're here in our sessionManagementConfig file, and this is just a segregated part of the application that we do our session management setup for our application. You can see here that we're bringing in the "express-session" package, as well as the "connect-mongo", which allows us to persist sessions to our MongoDB database. So the first thing we're doing is initializing the express-session by providing it an options object with a number of different properties. But in this case, what we care about is generalizing our session ID to make it less obvious as to what session management system we are using. So what I'm going to do is go ahead and provide an additional property to this options object with the name of name. And in name, we can give it what we want our session ID to be, so I'm going to name it just simply "id". Now when we run our application, we'll see that instead of it saying connect. sid as it did before, it will say id, instead, making it more general and harder for somebody to discern what type of management system for our sessions we are using, or specifically what type of libraries or packages. So with those changes to our application, I have gone ahead and started our application backup over on the same test we did before, and we'll use Fiddler to capture all of our web traffic. So what I'm going to do is I'm going to flip over to Chrome here, and I cleared out the cookies from our previous session, and I'm just going to refresh our application once more, and once that finishes loading come back go Fiddler, and we'll see what traffic we've captured. So going to our initial request to the root of the application, we'll see here that in the response from our initial request that instead of setting a cookie with the name of connect. sid, we're now setting a cookie with the name of just id. So that generalizes our session ID and makes it a lot harder for any attacker who is doing reconnaissance on our application to discern exactly what session management mechanism we are using on our backend. So with that small change, but significant change, let's now see what we can do about reducing the window of opportunity that an attacker might have in compromising our user sessions.

Time-limited Sessions
The next thing that I want to take a look at is how long we make the session available. As mentioned numerous times, security is a multi-layer approach. You never know what scenario might play out and put your user sessions at risk. For example, a user logs onto a public computer, but they forget to log off your application when they're done, and that has put themselves up for the opportunity of session hijacking. Someone sits down at the same computer, ultimately is able to act on behalf of that user, as if they were that user. So we need some way to limit that risk and reduce the chance of it being exploited and that session becoming hijacked. In our application, I mentioned we're using the connect-mongo Node package, which allows us to persist sessions to our MongoDB database, and the default for the time to live for a session in our connect-mongo Node package is 14 days. That's quite a long time. That might be a sufficient time for your application's requirements, but if that isn't, and you would like to reduce the window of opportunity, such as the scenario I just mentioned a moment ago, what we can do is specifically state how long we want that time to live. And I will do that by adding an additional options property for when we initialize our Mongo Store for persisting sessions to our MongoDB database. I'm going to add a property with the name of TTL, and I'm going to give it a time period, for example, of one day. We'll do that by just specifying the number of hours, by minutes, multiplied by seconds, that will specify to the Mongo Store that we want our sessions only to exist for one day. That might be too much still, and maybe we want to reduce this down to just 1 hour. We can do that, though, easily by just stating the time to live. You should specify time to live sessions especially for tracking authenticated users should not go on forever, and we should limit that window of opportunity in the case that a session was hijacked, or somebody did forget to log off your application at a public computer, or something along those lines. Again, you might not use the connect-mongo Node package, maybe you're using Redis. Most other session stores allow you to set a time to live, and it's important that you do so, and specify it to your application's requirements. Now one small little additional bonus I want to throw out there is, in addition to the time to live for session, we could also limit the lifetime of the cookie who transports the session ID. We can do that by specifying the maxAge property for our cookie, and giving it a value in milliseconds, say in this case if I wanted to make it 1 hour. Now this is great, this is one extra little bonus that we can add to the configuration of how long those sessions are valid, by providing a time to live of the transport piece, and that's the cookie that's transporting that session ID, but I want to point out that that's nowhere near as important as setting the time to live for the session itself. Now everyone's application requirements are going to be different, and persisting a long session might not be a risk to your users. You need to evaluate your application's requirements to know exactly where a balance can be struck between user convenience and security. I will take a quick moment to point out that it's towards the end of this module we'll take a look at another tactic we can use to add additional user convenience without compromising security when we talk about reauthorization for key areas of our application.

Session Fixation
If you are generating a session for every visitor to your application, and you are allowing that visitor to retain the same session ID after they have authenticated, you are recycling that session and opening yourself for what is referred to as a session fixation attack. Essentially, if an unauthenticated user's session had been compromised for any number of ways that is possible, and fallen into the hands of someone who can operate as that same user, when the legitimate user authenticates, by allowing them to retain the same session, the attacker who has obtained this session can now also find that they are now operating under the elevated privileges of the legitimate user just as well. We can fix that easily by regenerating a completely new session when a user logs in. So in the case of a compromised session, once that same user authenticates and receives a new session, the compromised session will be of no additional use for the attacker. Let's see how we can regenerate a new session within our application.

Regenerating Sessions on Authentication
So back in our sessionManagement file where we are configuring session management within our application, I have opted to extend the function constructor prototype of the session by adding a login method. In this way, I simply can store information which gets persisted to our MongoDB persisted session. Right now, all we're doing is persisting some metadata about the user, such as first name, last name, email. We can come over to our authenticationRoutes, specifically our login handler, and we can see where we are calling this login method off of the session, once, and only after the user has successfully authenticated. Because of this, the login method is a good place for our application that we can ensure that the session associated with this user can be regenerated after they have successfully logged in. So I'm going to come back to our sessionManagement file, and I'm going to update this login method's body with an updated version. And in this case, all we're doing is calling the regenerated method provided by the express-session session object. Once it has regenerated a new session, the previous session and ID will no longer be associated, and this authenticated user will be operating under a fresh new session. Now with this in place, we can completely avoid session fixation attacks on our application's user sessions. Now up to this point, we have been focusing on the session itself, but there is another part of the equation that you're probably familiar with, and that is the mechanism used to transport the session ID on request and response, so let's take a look at that specifically.

The Problem with Session Cookies
So what is the use of session cookies? Up to this point, we've talked about persisting the session ID on responses, so that we can track application state between a user's requests, but the mechanism that we use to transport that ID from response to request is a cookie, and if the cookies are going to be responsible for transporting the session ID, then it would be of value to use to secure that cookie as much as possible. But there are a few important points that we should point out regarding our application and our server when we're talking about securing our session cookies. When it comes to serving our application to the client, I like to think about the client portion similar to the demilitarized zone between North and South Korea, for example. It's an area that is unpredictable and uncontrolled, military skirmishes between the countries can break out at any time, and it's definitely an area you enter at your own risk. The portion that we are in control of is only the server. When it comes to transporting the session ID on a response, it is the server that would only ever need access to the session ID. Now back to our identity card scenario from earlier, while we would provide it to entities that we trust, if that identity was to fall into the wrong hands, it could be a case of identity theft, and an attacker could assume the identity of possibly an authenticated user in our system. One way that this easily could be accomplished is through other web-related risks such as cross-site scripts that would have access to the cookies. But this could be easily mitigated with a simple flag that we add to the cookie header. We can easily notify the browser using the HttpOnly flag, that the cookie is not accessible by anyone but the browser, who will provide that cookie automatically on future requests. It basically states that only an HTTP request has access to the cookie. No script of any type will have the ability to access it. Any script will perceive that cookie as just not existing.

Protecting Session Cookies with the HTTPOnly Flag
So in our sessions options object, we are specifying some options related to our cookie, and then we can see here that we are specifying the httpOnly property to false, which will translate to express-session not applying the HttpOnly flag to our cookie header. So with our application loaded, I've gone ahead and cleared out the cookies from previous sessions, and I have the Chrome Developer tools opened here. I'm just going to expand them so we can see a little bit better. We're going to go ahead and refresh this particular URL so we can capture those requests being made. And we'll come up here to the original request, and we can see the response included a cookie with the name of id, and we can see the value here. But we can see over here on the right-hand side, that there is no indication that the httpOnly flag was set for this cookie, or consequently, just like a client-side script could, we can come over her and just run a simple line of JavaScript that will extract the values of our cookie that we are interested in, our session cookie, and we can see that we can access the value of that session cookie, just like any client-side script could. So let's do something about that. It's actually quite an easy fix. So back here in our sessionManagementConfiguration file, we're going to update our httpOnly property for our cookie to true, and then we can come back over here, fire up our application, and see what kind of impact that'll have in relation to what we just saw in being able to access the values of our session cookie. So back on our application, we're just going to go ahead and refresh it, and capture our request, and select our original request that we're making here. And this time, again we see that a cookie has been provided on a response with the name of id, but over on the right we can see that there is an indication now that the HttpOnly flag has been set for this cookie. And consequently, we can come back over to our Console and run an even broader request for the cookies, and see what value it returns now. And indeed, the browser is not going to serve up any of the contents of our session cookies.

Using Transport Layer Security to Secure Session Cookies
As you recall, the HttpOnly flag only protects our cookies from client-side scripts. It doesn't protect us from anyone sniffing the network traffic and acquiring the information being passed. However, Transport Layer Security can resolve that vulnerability for us. Let's look at what I mean by that. We saw in the last section how we could easily see the contents of our session cookie when we were sniffing the network traffic just like any Man in the Middle could perform. This time, however, we're going to load up our site over HTTPS instead, and we'll see what we can see in the way of traffic. Now nothing has changed, we're still using Fiddler as our web proxy so that we can capture our web traffic. I'm going to come over here to Chrome and issue a request simply by refreshing the page. Once that's done refreshing, I'll come back to Fiddler here, and we'll see what we can see in the way of traffic this time. Now instead of seeing an actual host, all we see is it listing Tunnel to. Now if I drill into this, we can see that all that Fiddler is seeing is that there is a handshake and an encrypted communication that is going on. Fortunately, Fiddler can't see exactly what is being sent, nor can it see exactly where it's going, other than a host that is listed, but that does not necessarily mean that's the intended target. So not only are we able to not see the contents of our session cookie, we are also not able to see any of the communication that is being established between the client and the server, because it is completely encrypted. Now there's still one problem with accessing our session cookie that TLS is not able to help us with, one other additional measure we have to take in order to secure those cookies. Let's see what that is.

The Problem with Mixed Content
Earlier we saw how the HttpOnly flag would restrict client scripts from being able to access the contents of our session cookies, but it still requires Transport Layer Security to secure the session cookie content from, say, the Man in the Middle attack, who would otherwise still be able to sniff and observe the network traffic, which brings me to my next question. On a secure page, what happens when a resource is loaded over HTTP? Mixed content is a warning you might see on sites whose HTTPS setup is not optimal. It's a scenario where the page or site is being loaded over HTTPS, but there's a resource within that page that is attempting to load over the insecure HTTP protocol. So what kind of problem would that pose when it comes to our session cookies? The browser automatically takes it upon itself to provide cookies on all requests, and the Transport Layer Security can help secure the contents of our session cookies. But when we have a mixed protocol request, such as requesting an image over HTTP, the browser would again also provide our session cookies on those requests as well, but this time, they're not protected by the encrypted communication being provided over HTTPS, and once again, we could easily leak the session information within our session cookie on those insecure requests. Now browsers are getting better with self-imposed security in certain circumstances, but we can take one more additive measure with our session cookies to ensure that if there is a mixed resource that was inadvertently loaded over HTTP, instead of HTTPS, the browser would know not to send our sensitive cookies in the open. We can do this using the secure cookie flag. So let's see how easy it actually is to set that flag.

Protecting Session Cookies with the Secure Flag
Back in our application, specifically in the sessionManagementConfiguration file, where we've been making our session configuration changes, you saw earlier where we had the httpOnly and the secure properties for our cookie object, and we recently updated the httpOnly property to true. And you can see clearly here that we've set the secure flag to false, or it currently is set to false. You probably already know what we're going to do here is we're going to update the secure property value to true. And that will ensure that the secure flag is set on our cookie. Now we can see this in action by simply firing up our application and taking a look at the state of that cookie that is provided on that response. So we're back on our site, and I'm going to go ahead and bring up the Chrome Developer tools. And to capture the network traffic using the Developer tools, I'm going to issue a request by refreshing the page. Down here I can select our original request, and we can take a look at the response headers specifically, to see that we're missing something here in this case, and that is there is no set cookie for our session cookie, and that is because there is not a secure communication being established between the client and our server. So our session cookies, which have been marked as secure, are not going to be transmitted. In the case that there was mixed content, and we were loading this page over HTTPS, and requests were being made to other resources which were not secure, Chrome does take additional measures of just not loading that content over the insecure communication, but not every browser does, so by marking our cookie with the secure flag, we can assure that the browser is not going to go off and send our session cookies along with that insecure request. Later on in this course, when we talk about Transport Layer Security more in depth, we'll see how content security policy reports allows us to monitor for mixed content on our site.

Re-authorization on Key Access Areas
When it comes to user session management, what is one thing you think these companies have in common? If you said they use re-authentication measures in key access areas of their application, you would be right. I put this under the session management area, as it really relates to a user's ongoing authentication session with your application. We know that we use sessions to help persist and authenticate a user without the unfriendly user experience of forcing a user to authenticate for every area or action of our application that requires an authenticated user. But in the case that a user session has been hijacked, and an attacker has assumed their identity, maybe from something as simple as a legitimate user forgetting to log off your application on a public computer, we can still maintain a layer of protection for that user by requiring them to re-authenticate for those key access areas on our site, such as changing passwords, checking order details, or updating profile information. Re-authentication is one security measure that will help us continue to protect a user even when all other user session security measures have been compromised.

Summary
So we covered quite a bit when it comes to securing our application sessions and implementing secure session management. Each mitigation helps secure our users from certain session-based attacks such as session hijacking, that might open them up for being impersonated by an attacker, such as obscuring the session management mechanism by generalizing the session ID, limiting the life of the time to live of our session, making sure we generate a new session when users successfully authenticate, securing the session cookie from access by client-side scripts through the HTTPOnly flag, securing the contents of those session cookies through the use of Transport Layer Security, by using the secure flag ensuring that we don't hand off session cookies through an insecure request, and finally, having users re-authenticate on key access areas of our application as an additive measure.

Securing MongoDB from Injection Attacks
Overview
Hi, this is Max, and in this module we'll be looking at database-related injection attacks, and what we can do to prevent a number of potential threats to the security of our application ranging from data manipulation, leaking application information, to Denial of Service attacks. The origins of database injection attacks have been one of the longest-running web risks around. OWASP has ranked injection flaws as the number one web risk for the last two releases of their top 10 most critical web application security list. In this module, we're going to specifically look at the infamous SQL injection attacks. We'll also look at injection demonstrates using Burp Suite, and look at what injection attack means for NoSQL databases, and injection vulnerabilities with popular NoSQL database, MongoDB, which we're using in our application. Also, MongoDB and the risk of JavaScript expressions and what that means. And finally, what application-level mitigations we can use to secure our database from injection attacks. So let get started.

SQL Injection Attacks
Before jumping into the technical jargon, I think the best way to convey the underpinnings of an injection attack is through a quick analogy. Imagine it's the year 2025, and most cars on the road have been replaced with autonomous, you know, self-driving versions of your favorite car. It's New York City, and the taxi capital of the world, and you hail a cab. Upon hailing a taxi cab through your mobile device, you're requested to provide the car with some information, such as a destination address and a time you need to arrive there by, and the number of people in your party. Maybe that's so they can distribute the cost among everyone. For the first piece of required data, you input a simple address such as 300 Main St. But that's not all, you also include with the address 300 Main St, as part of your address, the words, and cost is $0. 00 then return to garage. So the autonomous car proceeds to take you to 300 Main St for a total cost of 0. 00, and proceeds to drive itself back to the garage. Clearly the car was requesting information that should have been in the simple form of data, but instead you provided information in the form of instructions, instructions that ends up in having the car carry out your instructions, and overriding any other instructions it might normally carry out. Essentially, this is the basis for an injection attack. A system has an interpreter, which receives and parses information. If that information is more than just data, and also contains instructions, those instructions are also executed. Not only is injection attacks the most critical web security risk, but because of the combined popularity of relational database and the SQL language, SQL injection attacks have been identified as the most prevalent of injection attacks, allowing for attackers to carry out attacks on website databases that can result in manipulating stored data, leaking confidential information, or granting access to unauthorized people. The components of a SQL injection is made up of two ingredients, the query itself and the information that is provided as part of the query. Imagine a search field on a product page that would allow you to input a value for a product you want to search on. On the server-side, the user search term is simply injected into the query that is formulated to be executed against the database. So instead of a search term being submitted, such as Flash Light, someone submits the search term as Flash light; update products set name = 'All your bases are belong to us'. This value is the untrusted search terms which are then concatenated with the query SELECT* FROM Products WHERE Name =. In the end, SQL will end up seeing something like this instead. It will execute the query up to the semi-colon, where it will terminate the query and run the next part, update products set name = 'All your bases are belong to us'. And the end result will be that all the products in the database products table will have a new name. This can easily be rectified with parameterized queries where we can use parameters to specify what SQL should treat as data, therefore allowing us to compartmentalize all malicious information such as instructions that have been appended to data, ensuring those instructions aren't executed as instructions, and instead are seen as simply data. There are other supported mitigations, such as data validation and the use of principle of last privilege, but parameterized queries is the key component to mitigating SQL injection attacks. An injection attack could have been far worse than our example with more far-reaching results to what the injection would have done, but this example gives you can idea of what an injection attack can be capable of. Most likely you have heard of SQL injection attacks, but in our application we're not using a relational database, but a NoSQL database. In many ways, they share much of the same type of risk, but unfortunately don't provide the same mitigations, as most, if not all, NoSQL-based databases don't support parameterized queries, at least at the database level.

Injection Demonstration with Burp
This is Burp Suite. It's a security testing suite of different security-related tools for testing our web applications, and at its center is a proxy, much like we saw earlier in the course when we were looking at Fiddler. But the proxy is there primarily for you to intercept requests that you then can direct over to a specific security testing tool to perform various actions, such as analysis or scanning or re-engineering payloads before sending on to, say, the target that that request was originally intended for, and a host of other different options that we can use. What I want to show you with Burp Suite is how we can utilize it to conduct both automatic and manual injection attacks against a specific part of our application. Depending on your PC and browser of choice, will vary the setup process slightly, but the premise is that we can set up Burp to intercept traffic, which is, by default, set up out-of-the-box. We can see under the Proxy tab here, if we go under Options, that indeed it's set up to be running and listening on our local interface for a specific port. Now all of these settings are the default settings, and are generally set up correctly out-of-the-box, depending on your circumstances, might need to be augmented, For the most part, you don't have to change anything with Burp Suite for it to be ready to listen for any incoming requests. The only other part is to configure your browser to go through Burp Suite's proxy. So I'm going to flip back over here to Chrome, and in our Settings in Chrome, we can go down to our advanced settings, and then bring up our proxy settings, and see specifically in here that we want to turn on the Web Proxy for, in this case, just standard HTTP requests. When we turn that on, we can come back over to Burp Suite, and under our Proxy Intercept tab, we can turn on Intercept, which by default is generally on, and we can use this to turn it on or turn it off depending on what we want. Now for now I'm going to turn it off until we're ready to intercept some traffic. There is one piece of information I want to show you about our application. Back over in our application, there is a feature for our timeline where we can modify the date range of events that are showing up in our timeline. On the backend, our server will use those provided dates to query for timeline events that fit within that range. There's one caveat. Currently in our database we contain timeline events that are marked to be hidden or not, and we are currently only serving up timeline events that are marked as not being hidden. We'll look at the specifics of that current query for timeline events later in this course, but for now it's not relevant. What is relevant is how many items that are available that are not hidden. For now, I am outputting the number of served up timeline items when loading the timeline page. So I'm going to click Refresh here on our site, and then I'm going to switch over to our IDE, and we can see here in the IDE that I'm using, which is WebStorm, that I can output to the console the number of timeline items that were retrieved, which is 59. So keeping those pieces of information in mind, let's switch back to Burp Suite and see if we can't intercept a request that we make to our timeline API for our application. The first thing I want to do here in Burp Suite, is actually turn on so that it is intercepting requests that are being made. So I'm going to click here on the Intercept is off to make it Intercept is on, and then switch over to our browser where we can issue a request by changing the values of our current timeline dateRange. Now in order to trigger an actual API call, I need to change it from the original date, but we actually don't want to change the original date to change the number of timeline events being rendered, so for now I'm just going to change it from 2011 to 2010, just to issue a request. Really what I care about is I want to keep it the same as the original date range, so I'm going to set it back to 2011. If we come back to our Burp Suite, it's going to have intercepted some requests that we don't care about, so for this first one I'm just going to drop it. This next one we can actually see that it's the original change to the timeline to set it back to 2010. That's another one we don't care about. This next one is the actual trigger to the API with the original dateRange. Now to just be absolutely clear, we got rid of those other requests, we dropped those other requests, because we just want to focus on this particular call to our timeline API with the specific dateRange that was the default date Range that our site loads up with. We don't want to change anything, we just want to re-issue that request so we can intercept it here and do something with it. For example, we can kick this request over to an active scanner, and have it scan this specific URL. What I can do is just simply click on here and choose do an active scan. And over here in our scanner, under our scanning queue, we can see that it has a particular operation undergoing for this api/timeline API. And what I specifically wanted to show you here is what Burp Suite is sending to our API. So in order to do that, I'm going to reissue this same scan it's doing, and we'll flip over to our server and see what kind of requests are being made. I've turned on to output the payload that's being sent to our server, so I'm just going to say Scan Again. Now I'm just going to expand our terminal window here in our IDE that we're using, and we can see that there is a number of requests coming in, and the payloads are being outputted here to our terminal window, and what I wanted to show you specifically is that if we come up here and look at all the different payloads that's been submitted by Burp Suite, we can see that they contain various different types of data. It doesn't know exactly what your backend is, or the environment that you're running it in, or your database, so it's going to submit different types of payload that might be vulnerable to different scenarios. But, specifically, I just wanted to show you the different types of injection attacks that Burp will attempt to apply to some particular endpoint URL within your application. But what I really wanted to show you is how we can conduct a manual injection attack. So I'm going to flip back over to Burp Suite, and in our case we're going to kick this request over to the Repeater, so I'll right-click and choose Send to Repeater, and we can come up to the Repeater tab. The repeater is just what it sounds like. We can use it to re-issue the request or only after we've augmented the request headers, or possibly the payload, and changing the payload s exactly what we want to do here. We can make the assumption that an attacker will easily assume there's some type of query on the backend using these startDate and endDate parameters. An assumption that we can make about any attacker is that they might want to check for the ability to inject and run JavaScript on our backend. So what I'm going to do is come up here to the Params tab, and we can see the different parameters that are being submitted on our request to our timeline API. Now I'm just going to choose the startDate parameter, and I am going to add some additional information in here. It's going to sound a little quirky, and we'll find out later why that is, but I'm going to add a double-quote, a single-quote, and a close parentheses followed by a semi-colon, the words return true, another semi-colon, then a close bracket, a plus sign, and two forward slashes. Now that sounds a little quirky, and we'll see in the next section after this of this module why that is, but let's go ahead and send this request off and see what kind of response we get. So with that request sent, let's flip back over to our IDE, and if you recall, we were outputting 59 different timeline items when loading up the timeline. And without changing the timeline start and end dates, and by adding a simple variation to that startDate parameter value, let's see what the results are. I assume you know where we're going with this. So flipping over to our IDE, we can see here that it's now outputting the number of timeline items retrieved as being 62, instead of the original 59. And we can also see that above that for the start and end times, we can see that it also contains that information we injected in the payload of the startDate. So I'm going to flip back over to Burp Suite again, and we can see over here under the response window that we have got a response back. Now what I want to show you here is if I search for the value hidden, the value of true, let's see what we find. Well I can see there's one here. If I scroll up, I can see there's at least two other ones here. So we can see here that we're not only outputting timeline items where their value for the hidden field is set to false, but we're also outputting any timeline items that were set to be hidden. Now, of course, an expected response would be that we know what we are looking for, and we know what value to include in the payload to get these results. But these results, the differences in the results based on submitted payloads, are not hard for any attacker doing reconnaissance to find or disclose. But before we look for a remedy, let's look at the cause and how it applies to our application. Before we close out, I wanted to show you a little bit about how easy it is for somebody who knows what they're doing, an attacker that is doing reconnaissance on an application. Now a lot of applications don't completely handle errors properly, so in this case I've taken off the breaks for our application, and I'm allowing errors to propagate back to the caller of our API. So I'm back here in our Repeater, in Burp Suite, and I'm going to go back under our Params tab, and I'm going to, again, start adding information to our startDate parameter and see what kind of errors that might be able to be indicators to us of what we can do with our requests. So just starting off with adding part of our original information, like the quote, single quote, and close parentheses. If I just issue this request, it gives us an error message that IC is a MongoError. And I can see here that it's failed to call a particular method, and this might lead me down a path of making additional additives to our injected values, maybe closing out that particular statement. And issuing again I get nothing. But what if I came in here and started adding, like we did before, return true, and now I'm getting additional information as talking about a syntax error. So maybe I'm on to something here about what kind of statement an expression that is being evaluated in the Mongo engine, as again, we can see here it's still a MongoError. But if I continue down this path, maybe I will hit something. I'm going to close out this statement, and try it again. Nothing. But if I come in here and add some additional, like I'm going to close out the entire function, I can see here that it's starting to tell me I'm missing a semi-colon. So you can see where this is going. I can eventually start putting together the right injected values to propagate new or other unexpected results from this API. But before we look for a remedy, let's look at the cause and how it applies to our application.

NoSQL and the Risk of Injection Attacks
NoSQL databases, which a lot of people misconstrue for simply meaning no SQL or not SQL, but it also means not only SQL. Many of the SQL databases support procedural languages as opposed to the declarative languages such as structured query language or SQL. But some can actually support structured query languages as well. NoSQL databases have been around since the 1960s, but have steadily grown in popularity over the last number of years, and continue to gain a lot of attention, with more and more companies reaching for NoSQL databases for its plethora of advantages for different scenarios. One of the hurdles relational databases have faced have been horizontal scalability, forcing administrators to turn to vertical scaling as a first approach. The onslaught of big data related fields have also found NoSQL to be great candidates for their flexibility and, in some ways, better performance. But in the end, cost is also a major driving factor for the use of NoSQL databases. We just went over what makes up an SQL injection attack on an SQL-based database. So does that mean that NoSQL databases are free and clear of injection attacks? Unfortunately, it doesn't. As a matter of fact, many can, and have made the argument that NoSQL databases are more susceptible to injection attacks, but why is that? We saw how SQL-based databases can more easily combat injection attacks at the database level from within the database engine with the use of parameterized queries. Unfortunately, that is not a capability of NoSQL databases, which are heavily dependent on the drivers that are developed to facilitate the NoSQL API calls, and it is here at which time that the injected information is parsed or evaluated, and puts the database vulnerability of unexpected instructions being executed. Furthermore, to interface with a NoSQL database's API, the API calls are based on the application's language or a specific convention such as JSON or XML or binary JSON. Nosql-databases. org lists over 225 different NoSQL types of databases. Because there isn't a common language between them, protecting and testing requires knowledge specific to the database, syntax, data model, and presumably application programming language. However, MongoDB is one of, if not the most popular, of the NoSQL databases which we are using within our application. So we are going to concentrate on how we can avoid injection vulnerabilities within our MongoDB database from within our application.

MongoDB Injection Attacks
When talking about injection attacks, MongoDB has one major component going for it. As a document database, MongoDB stores information as JSON documents, which provides support for all the primary data types. However, MongoDB takes it one step further and represents those JSON documents in binary encoded format called BSON, or binary JSON. This also provides support for additional data types, but it also provides a better way to protect itself from a traditional injection attack because of how special characters are encoded. However, we aren't out of the free and clear of injection attacks through the use of BSON, or we wouldn't be talking about protecting our MongoDB database from injection attacks. What MongoDB does provide is that certain operations allow for the ability to run arbitrary JavaScript expressions. Remember back to our SQL injection components. Arbitrary SQL statements could be executed within a query by the structured query language itself where we had an appended semi-colon update products set name equal to a string, which was 'All your bases belong to us', and this was injected information being provided to the overall query. Take a look at this MongoDB query, db. products. find, where this. name == some user input. Look familiar? That is because the underlying premise is similar. In this case, user input can contain an arbitrary JavaScript expression that can inflict Denial of Service attacks or cost sensitive data leakage like we saw in the Burp Suite demonstrated. But prior to MongoDB version 2. 4, you could have easily removed data or worse, because you had access to global shell functions such as DB. One of the primary vulnerabilities with MongoDB is its ability to run JavaScript expressions. MongoDB has three primary operations that allow for the execution of JavaScript expressions, which are the $where operator, and map-reduce, and a group command. We'll look at the main one of the these, the $where operator, believed to be the most laxed, and warned by MongoDB documentation to be avoided because of its performance issues. We'll also look at how we can use application level mitigation such as user input validation to stop potential threats before they are executed against our database. Finally, at the end, we'll briefly look at how we can completely disable the execution of JavaScript within our database altogether.

MongoDB and the Risk of JavaScript Expressions
We saw with the Burp Suite demonstration that we were able to get the application to cough up hidden timeline items. We're going to dive into that scenario and look at specifically what was allowing that to occur. In our application, specifically in the route handler for timeline-related requests, we have a route for getting all timeline items. This route also handles if there is startDate or endDate parameters provided to the route. But what might jump out is that our query is made up of the special MongoDB keyword and operation $where. As I mentioned in the last section, this operator allows us to pass JavaScript expressions that will be carried out. This expression can be in the form of a string, as we currently have right now, or as a function. Currently I'm creating a query object that will eventually be passed to the find method. I prime it with a statement that it should find all timeline items where, hidden, is false. If by chance there are start and end dates provided as parameters, I am updating the where property of the query object with a new value, and that value is a function that will contain the JavaScript expression we want to evaluate, which it looks for timeline items within the start and end dates, and also where they are not hidden. However, as we saw in Burp Suite's demonstration, we can augment the parameter values with our own injected JavaScript, and see that we can directly impact the outcome. What we see here is a string passed into the $where operator that will be evaluated by the MongoDB engine. and the JavaScript executed. In our case, our injected values were closing out the execution of the first parameter, startDate, and then closing out the entire rest of the JavaScript expression by commenting out the remainder, but not before it returned true. And since the $where operator actually applies the JavaScript expression to every document within the collection, which is the reason for having poor performance, by returning true in our injected value we automatically evaluated that every document it looked at should be returned as part of the results, whether or not that document was hidden or not. In order to fix this, we're going to completely get rid of using an operator that is going to let arbitrary JavaScript be executed. I'm going to paste in a replacement code that circumvents this specific vulnerability, so I'm going to go ahead and highlight this entire try catch block of code, paste in a new block of code. As MongoDB documentation will point out, there generally is always a better alternative than the use of the $where statement, and in this case we have utilized the greater than or equal and the lesser than or equal operators to return values that are within our date range, and simply passing in the query property of hidden set to false, to ensure that only documents matching that value will be returned. So when you are looking to incorporate some detailed query, as best as possible avoid operators or commands that will allow for arbitrary JavaScript expressions. With the changes in place, we can go back to Burp Suite and issue the same malicious request, and see what our results will be. So I have started up our application, which is running, and I have come back over here to Burp Suite, and I am going to reissue this particular request. We've intercepted the same request to augment and acquire the timeline items with the date range like we did before in the demonstration. I'm going to send this request over to the Repeater like we did before, and back in our Repeater, just as before, we're going to click on the Params tab, and I'm going to add the value to the startDate. In this case it really wouldn't matter which parameter we added it to, but in this case I'm going to do just like we did before, and I'm going to paste in the value that we had injected in our startDate parameter. Then, as before, I'm going to click go to issue this request, but instead of getting the results we got before, instead the API is returning us an error, which says there was an error retrieving timeline items. Now, we could have just returned an empty array that there was no information to be returned, and not give any evidence that an error actually occurred. This is a dependence on your application, but in this case I wanted to show you that we are no longer returning that query of disclosing hidden timeline items. But what about the ability to stop it from ever attempting to execute against our MongoDB database? Well in the next part of this module, we'll look at how we can incorporate input validation as additional security mitigations, again, using that layered security in-depth approach. One last point on the execution of JavaScript expressions. When we run our MongoDB server, mongod, we can provide it a configuration file that contains settings specific to how we want our MongoDB server to be run. One of those settings under the Security section is the javascriptEnabled setting. This security-specific setting allows us to enable or disable the execution of JavaScript expressions within our MongoDB engine. By setting this value to false in our configuration file, we can turn off the ability to execute JavaScript expressions completely. Then, upon running our MongoDB server, mongod, as you probably are well aware, and provide path of your configuration file in the config switch, that file will contain your javascriptEnabled setting, and if you set that to false you can eliminate the ability for JavaScript expressions to be run in your MongoDB database. This would be one of those recommendations to lockdown, to, in this case, turn off JavaScript expressions, unless you are absolutely certain there is no other way to carry out your queries, or a particular query, without a JavaScript expression. Wait until you actually have it, and harden the security by turning it off by default.

Handling Untrusted Data
Once again, a security in-depth, multi-layer approach can help further ensure our security concerns around injection attacks. We can use mitigations like user input validation that we saw earlier in the course for mitigating malicious user input. Let's go back to our express-validator and put it to good use. We know that our route is being provided with a startDate and an endDate query string parameters, values that we can't trust. Even though the application we are setting those vales on the frontend to legitimate values, there's no stopping someone from augmenting those values however they like, whether through the application or by submitting directly to the API. Knowing this, we'll again turn to creating a validation scheme to run those parameters against, and validate them before we actually pass them onto our MongoDB database. So I'm going to come back over here to our validationSchema. js file, where we had originally created our registration and loginSchema to validate values passed in from those forms. Now we don't need anything elaborate, so I'm going to go ahead and paste a new schema down here at the bottom called timeLineRangeSchema. And it's pretty straightforward. We denote the two properties we want to check along with the isDate property set to true. The isDate, just like some of the other properties that we saw earlier like notEmpty or isEmail, are part of the validator. js Node package that the express-validator package uses. So by setting isDate set to true, it knows that it should run these properties against that function. Same goes with the notEmpty, which we currently have set to false, because our API doesn't always receive startDate or endDate query string parameters. We could also, if we like, add a custom error message as we have done in the past to override the default message. For now, we'll just leave it as it is. Back over in our timelineRoute handler, we'll update this to pull in that validationSchema. So I'm going to come up here to our imports, and I'm just going to import that timelineRangeSchema from validation, and from the validationSchemas. js file. Now to put this validation scheme to use, I'm going to come down here into this if block, where we are doing something with the startDate and endDate if we did receive one. I'm going to paste in a block of code here that will be familiar from the previous time that we used express-validator, that will take the timelineRangeSchema, and provide it to the checkQuery method. And it will run our timelineRangeSchema validation checks against those properties that we had defined, which is startDate and endDate. As before, if there are validation errors, we will get that back in our errors constant, and if so, we'll go ahead and return that back to the requester. Again, like we saw when we were covering authentication, there is a lot going on in this route. This is definitely not the best organized, and it's not pragmatic, but for the sake of following along in this course, I've kept these validations here in the route handler. So with our validation checks in place, which will evaluate these query string parameters before we ever submit them to our MongoDB database, let's go ahead and fire up our application and go back to Burp Suite and see what we see with our results with our injected parameter values. So we have our application running again, and I'm back here in Burp Suite. I've taken the liberty to issue an API call to our timeline with the same timeline date ranges as we saw before, And as before, I'm going to kick this request that we've intercepted over to our Repeater, can come over to our Repeater, and for our parameters, under the parameters tab, all I'm going to do just to make this very clear and concise, is replace these values with illegitimate values for our application. I'll plug in our injected values that we used before, just to see the errors that come back, and I'll issue this request back to our API just like before, by clicking on Go. And over here in our response we see that there is an array of objects which are the express-validator errors that it serves up, and in this case it's showing that there is a startDate and an endDate parameters that had a particular error, and it shows the error, as well as what was submitted. Now, again, like I mentioned before, we could have replaced this with a very vague error message that would come back from our API and not return such specific errors as we do in here, but for the sake of demonstration I wanted to show you what it could serve up based on the fact that we are intercepting and validating the startDate and endDate parameters before we're ever submitting it to MongoDB and having that malicious code be run. So as you can see, we've implemented a multi-layer approach by not using operators such as the $where operator that will allow us to run JavaScript expressions, but we also have implemented, at the application level, a mitigation of validating user input before we ever submit that on to our MongoDB database.

Summary
This was a very interesting area to discuss. Most likely, a majority of you have come across or heard of SQL injection attacks. Most likely you have even heard of the growing interest in the use of NoSQL-based databases for web or big-data-based applications. But there is a lot of misleading thoughts among users of NoSQL databases, that because many of these databases don't support structured query language, or SQL, they aren't at risk of injection type attacks, which we just clearly saw is not the case. After a primer on SQL injection attacks, we got to see firs- hand what a NoSQL injection attack using Burp Suite really looks like, and the threat that injection attacks pose to NoSQL databases. We also got to see why NoSQL databases are at risk of injection attacks, and how there isn't a silver bullet for all NoSQL databases due to the varying implementations, language support, and conventions, along with the specifics around MongoDB and what makes them vulnerable to injection attacks. And finally, how removing or limiting the ability to execute JavaScript expressions along with input validations, can eliminate the threat of injection attacks on our MongoDB database. But the underlying factor for the existence of injection attacks comes from the ingredient of untrusted data. Anytime there is the potential for dynamic data to be introduced to our application from outside our control, our application and environment is at risk if it isn't properly handled and treated for what it is, which is untrusted data. In the next module, we're going to look further at what the threat of untrusted data means, and some of the ways we can mitigate threats that can come because of mishandled external data.

Handling Untrusted Data
Overview
Throughout this course, we have come across the terms untrusted data, but what does it actually mean? Is it only input that users submit on a form from your web application? And at what point does data actually become untrusted, and how do we identify it? Once you've identified it, how should you handle it? We'll answer all of these questions in this module, which has been set aside as a specific module to look at what actually constitute as untrusted data. Most developers have a reasonable idea of what is untrusted data, but don't always know how to identify it, besides the most blatant forms of it. Specifically, we'll look at Fuzzing input with OWASP Zed Attack Proxy, and rules that we can apply to identify untrusted data. You've identified untrusted data, but when and where is the most logical place to handle it. We'll also look at the difference between two common approaches when it comes to handling untrusted data, whitelist versus blacklist. Also, we'll look at a few different methods to use for processing the untrusted data we have identified, to either stop it from moving forward or defang any malicious element of the data. Finally, why sanitizing may not be such a sanitary solution. So let's get started.

Fuzzing Data with Zed Attack Proxy
Before jumping right into all the details of defining what is untrusted data, where and how to handle it, let's take a look at how someone with malicious intent might attach your application by providing unexpected data. This is OWASP Zed Attack Proxy, or ZAP, for short, and how you'll hear me referring to it most of the time going forward. Much like we saw with Burp Suite, it provides a number of different features from an active scan against an endpoint for a wide number of vulnerabilities or manual attack features such as the Fuzzer, which is the feature we're going to use here. The Fuzzer allows us to bombard an endpoint with expected parameters, but unexpected values. Will those values cause the system to crash, or possibly cough up some system information through unexpected errors or possibly worse with data manipulation, such as in the form of an injection attack on a database, like we saw in the module on MongoDB injection attacks. Now the ZAP proxy, is a proxy much in the same way that we saw with Burp Suite or Fiddler, but I don't currently have it initialized to pick up traffic for sites that I interact with. So first thing I'm going to do is I'm going to flip over to Chrome, and I'm going to configure all the traffic, standard HTTP traffic, to go through that proxy. Now I'll just mention that your configuration is going to be different. I happen to be using a Mac version 10. 12, the Sierra, and I'm working with Chrome. You could be working in a different browser, different OS, but the concept is going to be the same, it's just your steps and settings and views will look different possibly. So if I come down to Settings, scroll down here to the advanced settings, and then further scroll down until I get to the proxy settings, I can turn on all HTTP traffic to route through this local proxy for ZAP. And by turning that on and applying it, I'm going to be back here in the ZAP window, but what I actually want to do is come back over to Chrome, and I want to register a new user. So what I want to do is click on Register to get to the registration from, because we want to register a new user. It doesn't really matter who it is, so for now I'm just going to put in Bruce, Leroy, for any fans out there, and a very easy bruce@leroy. com for an email address, and how about show--nuf for a password, and we'll register this new user. Now I'm going to flip back over to ZAP, and we'll see here under Sites that indeed it did capture that request for our registration. If I come down here under API, user, we can see the actual POST request, and if I come over here to the right and click on Request, we can actually see the request headers along with the payload in this bottom window of the values I submitted. So in order to use the technique of fuzzing, I'm going to right-click in this bottom window where it shows the payload we had submitted to get a context menu, and I'm going to choose the Fuzz option here. And what this allows us to do, like I mentioned earlier, is submit expected or unexpected payloads for one or more different parameters to a specific endpoint, in this case under Fuzz Locations on the right. I'm going to go ahead and get rid of this initial payload that it's automatically defaulted here, so we can start anew. What we want to do is we want to specify what value we want this Fuzzer to fuzz with different payloads, and I can do that by highlighting a particular value. Now I don't want to go crazy and submit a bunch of different parameters, I'm just going to use the email in this case for the demonstration purposes that we want to fuzz. I can assume that if a site is using an email address as a primary username, that it probably needs to be unique. So I'm going to fuzz the email value by selecting it and then coming over here to the right and clicking Add. This will bring up the Payloads window and allow me to specify what payloads I want the Fuzzer to submit for this particular value, and we can see the value field here shows the email address we selected. If I click Add here, we can get a window that will allow us to select preloaded payloads that we can use. In this case, I'll come up here to the Type dropdown and I'm going to choose File Fuzzers. And down under the jbrofuzz category, I can see there's a laundry list of different categories, different types of payloads I can submit. Now not all of these are going to be relevant to every scenario. For example, we have the HTTP headers I'm probably not going to want to be try to submit HTTP headers in the place of my email field, but what I can do is select a number of different relative payloads. For example, the Exploits has a list of different payloads such as a Format String Payload or an Integer Overload, or Long String of aaa's that we can see down here that when you select them they're added to the Payload Preview window, and you can see here we have the long string of aaa's that literally is a long string of a's. So I'm going to select this Exploits, and I'm also going to come down here and select our SQL Injection category, which has a number of different SQL-related injection attacks, whether it's Microsoft or MySQL or Oracle. And we can select this, and we can see here that it's going to add those different SQL injection payloads to our list of payloads we want to submit. And for each one of the values within this payload, the Fuzzer will submit an individual request. So I'm going to go ahead and hit Add, I think that is enough payloads for right now just for demonstrating how this works, and clicking OK this will add that list of payloads to the Fuzz Locations. And when I'm ready I can click the Start Fuzzer, and it will kick off a request for each one of those values within those payloads, and it will list those requests in the bottom window of our main ZAP window. So I'm going to come down here and click Start Fuzzer, and we can see this just ran pretty quickly, and I'll just drag this window up here so we can see it a little better. And over here on the right we can see all those different payloads that are listed there, and the state of what was sent back. If I select any one of these, I'm going to drag this window back down a little bit so we can see it a little bit better, we can see that it gave us a response of a 409, that this actual email of this SQL injection attack was allowed to be registered and submitted as an email address, and it was matched to an already-submitted request. Not only that, but this gets into and heads down the path of talking about cross-site scripting, which we'll come back to when we get to the module on cross-site scripting. If we come over here to our application, we can see a number of coughed-up application exceptions that occur that weren't handled, based on different values that were submitted, and we can start to see here some of the users that were created with the values that were submitted, and in this case it looks like we're seeing all the different long string of a's that were submitted, and that was one long string of a's. So we can see here that there is a number of different errors, if we come back down here to the bottom, that our application is coughing up. Now, depending on the application scenario, will those errors reveal insider information about the application to an attacker? Will it make the application crash hard and bring it down? Or will it allow an attacker to manipulate data in the application database or just reveal some of the vulnerabilities that exist for that site? And that is one of the benefits and the nice aspects of fuzzing your application, such as the Fuzzer feature in OWASP ZAP Proxy, where we can submit unexpected values at an endpoint to see how it behaves. Does it respond with appropriate error message? Does it respond without coughing up details or causing the system to crash or showing vulnerabilities within the application? In the end, we're still talking about untrusted data, but as obvious as it might sound, and knowing what untrusted data is, how easy really is it to identify various untrusted data that your application encounters, and that's what we're going to look at next.

Identifying Untrusted Data
Because untrusted data is such a key player, and one of the underlying premises for a number of different web-related vulnerabilities, as well as the difficulties in identifying the less obvious cases of untrusted data, I thought it worth dedicating a module strictly to identifying and handling untrusted data in our applications. In a number of modules throughout this course, such as authentication, securing MongoDB from injection attacks, as well as in an upcoming module on cross-site scripting, we have seen examples of how to handle specific cases of untrusted data, so it's worth noting that there is an importance to being able to identify what information your application can and cannot trust. Let's start off with a few questions to see how confident you are about your ability to identify untrusted data. I'll throw up a softball to start. User input values from a form on your client-side web application, say, a registration form for a new user to your website, trusted or untrusted? Hopefully you said untrusted. This would be one of, if not the most easily identifiable data that we can automatically assume is possibly malicious, and cannot be trusted. We know without a doubt that the information is being provided to us from someone else. How about the user agent header on an HTTP request which identifies the application and device being used, such as a mobile version of Chrome on a Samsung tablet or Mozilla Firefox on a Mac, trusted or untrusted? This starts to get a bit more tricky. It's easy to believe that because this type of information being provided on the HTTP Request is handled by the agent, such as a browser, but in reality it easily can be provided and augmented to be whatever the requester wants it to be, whether it's fictitious or true. How about the value you stored in a hidden field on a web page, that you specifically injected server-side before serving it to the user's browser, trusted or untrusted? At face value, information provided in a hidden field cannot be trusted, even if you are providing it yourself and its originating server-side. How about data from your database, values you might load to configure the state of your web server or application, trusted or untrusted? The database is in your control. It sits behind your firewall. What isn't there to be trusted. But the truth is it can't be fully trusted. When you toss in the ability for external sources, such as users to save arbitrary information to the database through, say, profile information, application preferences, images, comments, or how about the insider threats, such as a rogue database administrator who can provide unexpected information to a database. It's easy to see how the database, once believed to be completely safe, might not be so safe after all. So if you answered trusted to any of these questions, chances are maybe you aren't as sure about what can or can't be trusted. So that spurs the question, how can we identify untrusted data? The question can actually be answered easier than it might appear. We'll do so with a few rules that you can apply to data to know how it should be treated. Rule #1: Any data that is explicitly being supplied from an external source can be identified as untrusted. You can start off by asking yourself, where is that information coming from. Not only is this covering the most obvious cases, such as user-provided information in a form or values in a search field, but you can use this question to identify data that sometimes is right under our nose, yet is easily missed. For example, more and more frameworks handle the heavy lifting of some of the more mundane actions. Browsers and client frameworks can facilitate constructing the HTTP request that our backend web servers are listening for. It's commonplace for developers to fall for the notion that the HTTP request is safe, because they didn't have to construct it in their client's application, therefore, it's a typical out-of-sight, out-of-mind. but in truth, HTTP request headers contain information such as user agent, IP address, and metadata about the information in the request, such as the Mime type. It can be anything that the requester wants it to be. Rule #2: If the data has crossed a trust boundary, then it can be assumed to be untrusted data. Imagine a castle with surrounding moat or wall, and the moat or wall can be visualized as the castle's trust boundary. Anything inside can possibly be trusted to a certain extent. For a web application, a very small surrounding area could be viewed as our trust boundary, such as the immediate resources tied to our web server, such as configuration files or possibly static files stored locally, as a few examples. An ideal solution might be a website that only ever accepts Get requests and only serves static resources from its direct storage that it controls locally. But generally, in this day and age, that's not the type of applications we're building. Therefore, we can look at any resource outside our immediate control as potentially untrusted, such as the components of an HTTP request, an external service, or an API that we acquire information from, but also can include internal boundaries, such as to an internal web server. To help evaluate this rule, you can ask the question of what path has this data travelled. For example, the hidden field that you provided on a served-up web page, you can't trust that data for face value, it requires that the hidden field have a certain level of integrity, such as being encrypted or a message authentication code element that allows you to verify the value hasn't been tampered with when you receive it back. Rule #3: Be cognitive of who has access to the data. This encompasses both the human element, such as developers or DBAs, all the way to service components, such as internal services that are providing information information to a database, for example, that your application shares. Now I'm not talking about running around believing everyone is out to sabotage your application, but being mindful of the origins of data that your application is using to operate, in order to evaluate what level of scrutiny that data should undergo. The insider threat is a key player in data breaches today. Some are unaware participants, victims to, say, a phishing attack, whose compromised machine allows an attacker to gain access. Sometimes it's a shared resource, such as an internal service, that is compromised itself that might provide malicious data. These are not out of the ordinary, or edge cases, but legitimate issue that arise in data breaches all of the time. When working with any data within your application, applying these three rules and asking the associated question for a rule, and making no assumptions about the data, will help you shore up holes in your application. So you've identified untrusted data within your application. When and where should you do something about it? When should you handle it? Where should you handle? That's what we're going to talk about next.

Where and When to Handle Untrusted Data
Identifying untrusted data can be a lot easier when you know the questions to ask. No longer does ignorance blind us when we know what to look for in identifying data that has the potential to be malicious. But when it comes to identifying exactly where we need to run untrusted data through the appropriate processes, it's not as definitive. Why is that? Every application is different, and every application's architecture is different, and the number of sources of information that provide data to an application is also different, but what we do have is a simple rule that we can follow that will help us define a starting place as an appropriate place to start handling untrusted data that we have identified, along with a multi-step approach that we can apply to address untrusted data. We can use the example of a stronghold, such as the White House, for example, the home of the United States President. To gain access, there are checkpoints on the outside perimeter that you have to clear before having access to the immediate grounds. But before you're sipping tea with the White House china, you have to deal with another checkpoint at the house itself before you can gain entrance to the house. If you were there actually to visit with the president, there would be yet additional checkpoints that you'd have to clear before you're up close and personal with the president. When we're talking about a person with malicious intent, the threat to the president grows larger with every checkpoint they clear, gaining closer and closer proximity to the president. Now how does this apply to our application? Take our database, for example. In the case where we might be taking in external data to build a query to run against our database, if the external data is targeting the database, the closer it reaches it, the bigger the threat. The data is first encountered when it's received by our server framework, who processes the incoming request, and it moves through a pipeline of middleware until it finally reaches the distant route handler. Finally, after being processed by the route handler and incorporated into a query, that query could eventually be passed on to the database engine to be executed. The bottom line is, a simple rule that we can follow, Keep untrusted data as far away from critical systems as possible. This might seem like a no-brainer, an obvious choice, but in practice this can be easily missed. For example, it is easy to assume that handling untrusted data, such as user input at the intended target route handler, would be the obvious choice, but what if those same steps of handling untrusted data can be moved up the pipeline and addressed well before it reaches even the route handler itself? Later in this module, that's exactly what we'll do. We'll look at how we can move the handling of untrusted data upstream, and further away from critical systems such as our database. While our rule helps us address untrusted data as early in the pipeline to keep potentially malicious data as far away from critical systems, if we assume this is enough, we can be in for a big surprise, as attackers get more crafty with their malicious payloads. Just as we saw with the multi-checkpoint analogy, we can also use the same multi-step approach when it comes to addressing the when and where to address untrusted data, which should sound exactly like I've been mentioning many times throughout this course, security is a multi-layer security in-depth approach. We have already seen earlier, when implementing user input validation for authentication, how a multi-layer defense of input validation can help us not rely on a single point to catch malicious payloads. Therefore, while we try to handle untrusted data as far away from critical systems, assuming the worst, and that multi-checkpoints are required, gives us additional fortitude that we will catch malicious data before it's too late.

Whitelist Versus Blacklist Approaches
It's very possible you have heard of a whitelist or blacklist, which are terms that describe two different approaches that various untrusted data handling techniques might use. Take, for instances, if we were validating the user's color preference, and we run the submitted color value against a list of known bad values such as, does it contain script tag, or does it contain numbers or special characters. This is the practice of using a blacklist. The problem with this approach is that we could never be 100% certain we are checking for every possible bad value. The list of values would constantly be changing and growing with newly discovered crafty values by attackers. In addition, not only is it easy to miss, or not account for values you never fathomed or encountered, but it naturally lends to a maintenance nightmare. On the flip side, validating that same user's color preference value against a list of known acceptable values that we control, gives us a certainty that we wouldn't inadvertently allow a malicious color value through our validation. For example, validating a user's color choice against only letters, or only alphanumeric values, this list wouldn't change unless we want to start allowing for additional values to be accepted, no matter what crafty input value was provided. I can't say that we should never us a blacklist approach, since every scenario, library, and environment is different, but at all costs, it should be a last resort, and only after it has been determined that a whitelist approach is not possible.

Validating Untrusted Data
Earlier in the course on protecting our MongoDB from injection attack, we got to see an example of handling untrusted data by validating the submitted start and end date range for our application's timeline items. In addition, we also saw a similar approach by creating a validation schema for validating the input values of a registered new user. It's easy to apply the rules we discussed on how to identify untrusted data to see that the input values for our registering new user would apply to our first rule, which is any data that is explicitly being supplied from an external source, which user-supplied values to our registration form fits that description. Originally, here in the route handler for registering new users, is where we were applying our registration validation schema against the incoming request parameters by calling the check body method, and providing it the schema definition. But looking at our rule for when to handle untrusted data, is it possible that we could handle this data earlier in the pipeline before it ever reaches the route handler itself? Whether you use an express or another Node. js web service framework, if we can intercept this request and process the untrusted data in a middleware function, it can give us the possibility of moving it further up the chain, and further away from critical systems. For now, the first thing I'm going to do is just remove our previous check and validation against the incoming parameters for a new user registering, and then I'm going to come over here to our Configurations folder, and I'm just going to ca a new file. We're going to just call it validationSchemaConfig. js. In here I'm going to paste in a block of code that will be middleware for our express server that requests will filter through, that we can examine afterwards. So this is the same code, essentially, that we originally had in our registration route handler. The only difference from the original, there is a simple check for a match to the route that has been requested before enforcing the validation against the data. As a reminder, we'll come over here to our validationSchema. js file that retains all of our different validation schemas that we passed to express-validator at the various times, and we can see, as a refresher, the validation schema we had defined for our registration form, which contains rules for the email, password, firstName and lastName parameters. Therefore, back over here at our new validationSchemaConfig. js file, other than that small check to match to the route that is being requested, we're going to do the same validation against the request body parameters when we call checkBody on the request object, and provide the registrationSchema object which contains all of these rules. If the parameters are valid, we can call next, which will then propagate this request onto the next middleware in the pipeline. If not, it breaks the request out of the pipeline and returns a response with a particular error. Now, the last thing we need to do is wire up this middleware to our entire express pipeline. So I'm going to open up our server. js file, and over here I'm going to import that function we just defined in our validationSchemaConfig file, and I'm just going to paste in the import, and then I am going to invoke that function and pass in our express app. And that's all it takes to wire in our new middleware that would do the validation for our registration parameters. Now coming back over to our validationSchemaConfig file where we just define this middleware to do the validation, there's a few caveats to consider. Using middleware like this means that every request will go through this check and balance, as opposed to our original setup, where only if it matched the route handler would that route be invoked and handle the request. For the sake of simplicity, I kept the code as simple as possible, with only employing a simple check on the request. url to see if we should continue with running the request parameters through if the _____ url was a match. There are more elegant ways to do conditional checks, but keep this in mind, as every evaluation adds overhead to the processing of a request, and if not handled properly, could cause poor performance. With that said, we have now moved the validation upstream in the pipeline, and handled untrusted data for our registration of a new user before we ever hit the route handler, to satisfy our rule of keeping the handling of untrusted data as far away from the critical system as possible. But if you recall our approach to handling untrusted data should be in the form of the security in-depth, multi-layer approach. So if you recall, when we implemented the registration validation, we also incorporated validation at another layer before the data is shuffled off to the MongoDB database, by implementing the same validation rules in our Mongoose schema for our user. So if I come over to our schemas. js file in our data_access directory. so as a refresher, here in our schemas. js file we can see the UserSchema, which defines many of the same validation rules we just imposed directly on the input values we intercepted in our middleware. Therefore, to wrap up, we're handling validation of untrusted data as early as possible, starting way up the pipeline, but also employing multiple layers of validation with yet another check using Mongoose schemas before it's ushered off as a new record to our MongoDB database. But validation is usually an all or nothing proposition. Let's talk about another option that is contextual based handling of untrusted data that, used properly, the process known as escaping can defang and remove the malicious aspects of data so that we can continue to use it.

Escaping Untrusted Data
In an upcoming module on cross-site scripting, we'll be looking at the process known as escaping more in depth, and exactly how we can use it to remove the threat of data with malicious intent. For now, because of the general topic of untrusted data, I wanted to briefly mention it since it falls in line with a method of dealing with untrusted data. Jeff Williams, with Contrast Security, I think has the best description for what escaping is. It is also known as output encoding, and it is a technique used to ensure that characters are treated as data, not as characters that are relevant to the Interpreters parser. Escaping simply lets the interpreter know that the data is not intended to be executed, and therefore prevents attacks from working. If you watched the module on MongoDB injection attacks, the core component of that definition should sound familiar, ensuring that the information is treated as data, ensuring the information doesn't potentially contain instructions that are executed. When we think about the course of a user interacting with our application, there are many different pillars that make up the user's experience, such as the HTML that structures the client application, the CSS that beautifies what the user sees, and the JavaScript that enhances the user's experience, all the way to the server environment and database that is serving up the content to begin with. Each one of these areas operate under their own unique context, where their own specific interpreter can parse information related to their environment. Whether that is the browser's Interpreter parsing HTML and CSS or the execution of a query in the context of the database engine, each context has a specific interpreter performing the execution of parsing the information it has been provided. When that information that is being parsed goes beyond being simple data and contains instructions that the interpreter understands, the interpreter will carry out those instructions. Escaping, then, is the process of turning special characters that are relevant to a specific interpreter, and changing them into values that will ensure that the interpreter only see it as data, and not instructions after all. A perfect example to illustrate the point is the case where we want to allow users to submit legitimate HTML syntax as a part of a comment on a blog post, which we'll display just as they typed it. What you don't want is the browser's interpreter to attempt to parse the HTML the user supplied as HTML, but rather display the values as text. The caveat is that the escape rules that are applied to information to ensure it is only treated as data is unique for each context the data is being parsed in. So the escaping rules that apply in a JavaScript context are different than the escaping rules applied to an HTML context. Getting the escaping rules wrong, or applying the wrong rules in the wrong context, opens us up for a number of different risks, predominantly the risk of cross-site scripting. For now, understand that this is yet another method for dealing with untrusted data, but we'll look at using this method when we get to dealing with cross-site scripting.

Why Sanitizing Isn't So Sanitary
Application security isn't easy. If it was, we wouldn't see the repeated company data breaches and a constant race to keep up with attackers. Therefore, it's not uncommon to run across misleading or incorrect information when it comes to application security. One of those that is regularly seen is the promotion or the loose use of the term sanitizing as a means of handling untrusted data. Sanitization, or sanitizing untrusted data is nearly the opposite of invalidating and rejecting malicious data. Instead, sanitizing attempts to defang the malicious aspect of data in order to preserve some aspect or core component of the original value. Unfortunately, the core concept of sanitizing is, in itself, a blacklist approach. The sanitizing process attempts to sanitize the data by removing known values to be potentially malicious. Sanitizing, also, is highly bound to the context in which it is currently operating under. For example, sanitizing data intended for a database will be different than an HTML context. However, again, as we saw with the blacklist approach, being able to stay up with all the potential unsafe values and remove them, is a recipe for disaster. Instead, choosing to outright reject a value because it contains values that are determined to be unsafe, will always be a more safe and vastly easier to manage approach to sanitizing. However, in typical developer parlance, we can't say never, as there are exceptions, such as we'll see when it comes to dealing with threats of cross-site scripting. But if we can prefer other methods to sanitizing, we have a stronger chance of avoiding sticky situations.

Summary
Untrusted data is an ingredient that is a key player, not only for a vast number of web security risks, but the leading security risk that web applications have to protect against. OWASP Zed Attack Proxy's Fuzzer feature, showed us how easy it is for someone to bombard our endpoints with unexpected data that can be malicious, in a long list of different ways, to our system. But with a few rules to help us, we can identify what data constitutes as untrusted data so we no longer have to assume it's safe. By dealing with untrusted data as far from critical systems as possible, and applying a multi-layer approach, we can know when and where to address untrusted data properly. When dealing with untrusted data, if at all possible, we found out why using a whitelist over a blacklist approach is much safer and requires far less maintenance. We also got to see how data validation and escaping are primary candidates to addressing untrusted data. And finally, with a few exceptions, prefer a data rejection approach of handling untrusted data over sanitizing, if at all possible, due to the blacklist nature of sanitizing. Assume the worst, plan for the best, is a security approach that won't leave you vulnerable when our security lets us down. Even the best applications have weaknesses, but if we assume that our defenses can't be penetrated, leaves us vulnerable if it was to happen. We have seen how multiple layers of security through various layers of your application addressing the same threat can help fortify our position when it comes to mitigating specific threats. Another layer of security is ensuring that we have the proper access controls in place for various components of our application, so we aren't handing over the entire control of our systems to the first breach of our defenses. In the next module, we'll look at the concept of accessing controls, of how we can minimize the window of opportunity for an attacker.

Access Controls
Overview
Welcome back. I'm Max, and up until now, when addressing specific security threats our web applications face, we have seen how we can deploy similar mitigations at multiple checkpoints to further fortify our applications' overall security. Taking the opportunity, then, to hammer out the overall theme that our application security must be a multi-layer, security in-depth approach, we are going to look at a standalone security measure that will provide a security blanket effect to a number of critical areas of our application. Just as we saw that untrusted data plays a key role with a number of different security risks, the antithesis is a security measure we can use to severely reduce the attack footprint of our application. In this module, we're going to look at the concept of employing access controls to various areas of our application. Controlling what level of access critical systems, routines, and users can operate under when carrying out actions within our application. In detail, we'll be looking at the underlying principle of Least Privilege, and how adhering to this principle as a pillar to access control can help save us when other security measures and mitigations fail, and the problem with database access, and how we can apply the principle of least privilege when working within our MongoDB database. What role-based access control really is, and how to deploy function-level access controls to key areas of our application. And finally, making you aware of the function-level control gotchas and misconfigurations that can occur if you're not careful. So let's get started.

Principle of Least Privilege
Principle of Least Privilege is a set of words that developers might have encountered at some point in their career. The original term, principle of least privilege, is attributed to Jerome Saltzer from a publication in the Communication ACM monthly journal. Very simply, the principle of least privilege is the idea that only the very minimal and absolute necessary rights, permissions or access, is granted in order for an entity to perform their job or task. For example, a user doesn't have to have read and write access to a file when they only need to view the contents. Nor does a critical system need to be able to create tables in a relational database if all it ever needs to do is insert, update, or delete records. As we move through the different sections of this module and look at how to deploy access controls to critical areas of our application, we will be doing so under the definition of principle of least privilege, only providing the necessary or minimal access that critical systems or users will need to perform their job or task. But this wasn't called the rule of least privilege or the concept of least privilege, there is an underlying meaning to the use of the word principle in our principle of least privilege, meaning fundamental truth or fundamental basis for something. The principle of least privilege is a core behavior that we follow when applying access of any kind in our application, only ever providing the most minimal access, and nothing more. But it is easy to have a narrow view of this principle and think that it only applies to the production version of our application. How many applications have you worked on where one of the last backlogged items listed is that single line of hardening application security or where the database user you're operating under during the development of the application is the root administrator, but why is that? Because it's convenient, right? I would argue that the principle of least privilege can be a foundation behavior for how we administrate access controls within our application, but can also be a foundation behavior to the various development lifecycles an application undergoes. Too often, when we get to that hardening application security backlog item, there has been no collective list of areas that need to be addressed or access that needs to be restricted. And with the inclusion of multiple groups working on an application, such as architects, developers, and testers that are all responsible of various areas of the application, the ability to keep straight the number of security areas that need to be addressed can be an organizational nightmare. We are usually scrambling to recall what are those areas or access, and unless there is thorough security testing in place to find those holes, how many of those security areas are going to be missed or forgotten? Therefore, while the underlying meaning for the principle of least privilege has to do with how we go about administrating access for users, or interaction by critical systems, just remember that it can start with how access is granted during the various application development lifecycles as well.

The Problem with Database Access
I would be willing to bet that if you are a developer, the vast majority of applications that you have worked with that required relying on a database of some type, have operated using a single login for that database. If that is true, then the level of access to the database by your application would, at a minimum, be determined by the highest level of access required by any one particular area. Think about that. If only half of your interactions with your database required more than the ability to query for information, the other half of those database interactions by your application would have elevated privileges beyond what was required. So, what's the big deal? Despite our efforts to implement proper security, sometimes unforeseen security holes arise that are not known until they are compromised, even after extensive testing or because of a system outside of our control due to a weakness in a third-party component. And if attackers were to gain access to an area or routine of our application that operated under elevated privileges, they could potentially have the ability to carry out actions of consequences that we never anticipated. Having only the minimal amount of access that database interactions require, could be the difference in the attackers' goals being successful or not. Let's see how we can reduce our database access footprint in our application.

Overview of MongoDB Access Control
Now this is not a course on administrating MongoDB, however, what I do want to show you is an example how we can supply minimal database access to a function-level area of our application. On the mongodb. com website, for their documentation, it goes into great detail of how we can enable that on our MongoDB server, mongod. To start, I want to ensure that clients that interact with the MongoDB server, mongod, have to authenticate, and I can do that by specifying the auth command option or through the security. authorization setting in the mongod configuration file. Now when clients attempt to interact with the database, they will be required to authenticate, and the permissions associated with their account that they use to authenticate, will dictate their capabilities. In addition, on the mongodb. com site under the documentation, you can find information about specifying the roles that users belong to. MongoDB has both built-in roles, as well as the ability to create your own custom roles. The role can also target specific resources, such as a collection within a database, where you can specify the role only applies to a specific resource. What I have done is determine what access I would need at various function levels within my application, and define roles very specific to those interactions. For example, most interactions within our application can be distilled down to two primary actions, the ability to query for information, and inserting a new record. There are cases that we'll see later on in this course, where we need to be able to remove a user. In MongoDB, I created very specific roles that target a specific collection with a very limited access. An example would be a role that would allow inserting and creating indexes on a user collection, then created a user that would be assigned that role. When authenticating to mongod as that user, they would only be able to insert new documents and create relative indexes on the users' collection, and nothing else. With those pieces in place, let's take a look at how we can put it to work.

Implementing MongoDB Access Control
Our application allows a user to vote for an infamous hacker or a company data breach. The route handler here in our eventVoteRoutes. js file is responsible for handling the casting of that vote. We have a number of different operations, though, that have to occur, such as verifying the timeline eventId exists, and looking up the authenticated user, and casting the vote in the eventVote collection. In each of these operations, there is a different set of permissions along with different targeted collections, querying for the user in the user collection, and a timeline event in the timeline item collection, as well as inserting a vote in the eventVote collection. As we've talked about extensively earlier in this course, we are using the object-relational manager, mongoose, for defining schemas based on the collections in our MongoDB database. We can see those schemas, as we have in the past, under data_access directory for the schemas. js file, which defines different schemas for different collections in our MongoDB database. But when it comes to interacting with MongoDB through mongoose, we have to acquire a model, and we have our modelFactory. js file, which has different functions defined for serving up a model, which is tied directly to a connection in our MongoDB database. So to limit this connection, I've set it up so that my functions that provide a model take arguments that will help point to what account this specific connection to the database would need. So back over in the eventVoteRoutes, we have a specific scenario, and to keep it as straightforward as possible, the identifier just happens to coincide with the name of the collection, along with an additional identifier to specify the required action, such as to create or to query. Now, going back over to our modelFactory. js file, we can see how this comes into play. Here we take in those parameters, and load a config file that specifies the proper credentials based on the parameter values that were supplied. Then the MongoDB connection that is established is going to be limited to the collection and the permissions of that specific account. The modelFactory relies on a connection provider. js file, which we can open and see here, whose sole purpose is to asynchronously provide a MongoDB connection, which will be based on the credentials it has provided for that connection. So coming back over to our eventVoteRoute. js, which handles the casting of that vote, in the end, the model that's returned from these specific functions to acquire a model, where we provide a specific targeted resource identifier and action identifier, when they end limit whatever actions this route handler will be attempting to perform, in the case to query for a user or query for a specific timeline event, or in the end to add a new eventVote record for a particular casted vote. In the end, the operations here, that the models will conduct, will be extremely limited to both the resources they can interact with, as well as the actions they can perform. So in a worst-case scenario, if an attacker was to circumvent security that we had in place, and was to gain access to this logic of our application, they are going to be limited to the access that's been provided to the database operations. No longer are we operating under a single administrator account for the entire application, which would have allowed any attacker to perform any number of operations. Now we have limited and reduced the surface area, by limiting and reducing the accounts in which these database operations are operating under. Working with limited database connections, we started getting into function-level access when we're talking about controlled database access within our route handler. There are other ways to abstract the connections. For example, I mentioned a number of times in this course, that generally we wouldn't want to keep all of the application logic in our route handler, but it makes it easier for you to follow along. Therefore, if we were to properly export these operations to their own responsibility, we could load the specific models needed, rather than requiring the operation to know what access to request. But there are other function-level access controls that would directly impact the ability to carry out application-level actions, and that is where we're going to look next.

Role Based Access Control
There are a number of different access control methods that are utilized for different systems and their needs, like identity-based access controls, or mandatory/discretionary access controls, and role-based access controls, just to name a few. The last one is the one we're going to look at, and I wanted to take a minute to show the basic approach to the role-based method. The workflow of role-based access control is to assign users of the system to a role, such as a user being assigned to the role of content Manager in a system. Instead of having individual permissions, such as the right to read, and add, and delete content assigned directly to the user, we instead assign those more granular rights permissions to the role. Just like the role of a captain in a police department has different responsibilities than the role of a traffic officer, these roles that are assigned to a user encapsulate the permissions that the user can operate under. Therefore, an area of our application that might allow a user to perform a number of actions that might be closely related, instead of checking each individual right, we might simply check they are part of the role that has all those granular permissions. That isn't always the case, role permissions can change, and it's common to need to verify that a role has a specific permission, which we'll see both options when we look at an implementation in our application. A benefit of the hierarchal approach of permissions, as in the case of role-based access controls, is the ability to manage permission a lot easier, especially in a complex system with a large number of users and actions that require varying levels of access. With that simple overview, let's see what that looks like in our application.

Function Level Controls (with RBAC)
We started with looking at controlling operational access to a critical system, our database. By implementing accounts that adhere to the principle of least privilege, we could restrict the attack surface just by restricting the accounts access of our application's interaction with the database. These areas of our application are functional components that each have responsibilities of their own. It's a common need to implement access controls around these areas, whether that is creating new users in our system or publishing an article or deleting a user. It's absolutely necessary to conduct the right set of operations to verify the requesting user has access to carry out the actions they want to perform. Currently on our site, I can access the administrations page that shows the current list of users. And furthermore, I can also delete a user without restriction. I'm currently not logged on either, but I have free reign to conduct actions that clearly should be restricted, and we're going to look at how we can implement function-level action controls to restrict the specific actions, such as being able to view all the current users of the application, or delete users at free will. Here is our route for serving up a page of users depending on the page submitted, but before we want to serve our users up, we want to validate this current user that's making the request has the required permissions. As we saw in the previous section with an overview of role-based access control, each user in our system has been assigned roles such as user and admin, just to keep it simple. Let me open up the file that shows what that looks like. So over here under data_access we have a rolePermissionsFactory, which simply serves up an array of different roles with their assigned permissions. The list is provided to the logic that conducts the validation of a user to a role, and roles to permissions, and we'll look at that logic here in a moment. So, going back over to our adminRoutes. js file, which as I mentioned before, defines a number of admin-related routes that we want to handle, what we want to do is do the access control check to verify the current user making the request has the access for the intended request, as in this case, to request a certain page of users from our application. What I want to do is define a middleware that will run prior to this get request, so I'm going to come up here and before our get request function that handles the actual serving up of those users, I am going to use the all method and define a function here, just like before, that takes a request, a response, and the next middleware that's to occur, and in the body here I'm going to paste in the actual logic that does the validation. Hopefully it's easy to follow. For the sake of simplicity, I have shuffled off the heavy lifting of loading the user that is making the request. We get enough of that information from the session to be able to acquire the user, and load up the additional information that the session doesn't know about. But that's not the important part here. Once we have a user, making sure that the user that is making the request has the valid access is what's important. After loading the user from the database, the role-based access control does the validation of the user, based on arguments we provide, and reading it for the plain English it is, should give us some clue as the goal in which it states, check(user), is("admin"), can ("list users"). In plain English, we are setting the user as the context that we want to validate has the role of admin, and that the role of admin has the permission list users, because in this particular next middleware, which is our route handler for the request to get a page of users, is exactly what we're wanting to do, list the users of our application. The implementation and logic that sits behind these checks is over in our rbac. js file, which basically allows us to specify the context we want to check, in this case user, and provide some functions that we can utilize to validate this particular user as part of a role, as well as if we want to take the extra step of validating that role has a specific permission that we care about using the can function. But we don't have to always, in this case, just as a demonstration, have to verify the role has a particular permission if it's something that we don't care about. You might be, in your application's requirement, sure that a role has the valid permissions, or maybe you're not using any permissions behind and you're just validating a user as part of a particular role. In that case, back over in our admin routes, we could have easily just stated that we just wanted to check the user is currently part of the admin role. In this case, I can provide a callback function that after it checks whether that user is part of the admin role will provide the results. And we can see that depending on the return results, that we will return a 401 unauthorized, or possibly call the next middleware by calling next, if they are a valid user part of the role that we care about, which will then continue on to the route handler, the one that is actually going to provide the logic for serving up a page of users. Just like we did with this route for viewing users, we can also implement the necessary validation to validate the user can also delete. So if I come down here to our route that's specifically set up to handle a delete request for a specific user, I'm going to go ahead and also paste in the entire function, like we did above, and utilize the all method, and again, define middleware that will validate and check this specific user is part of the admin role, and that the admin role has the permission of remove user, which is what the body of work that the delete route handler will perform. And, again, we can see here that if they are not part of the required admin role, or that the admin role does not contain the permission "remove users", we're going to return a 401 HTTP response back to the requester, or in the case that they are, we're going to call next, which will then send the request on through to the next middleware in the pipeline, which will happen to be our delete request for handling the deletion of the requested user. So let's fire up our application and go back and see what kind of impact these changes have. Back over at our site, the application is running, and I'm currently not logged in as a user, and I've taken the liberty to implement the necessary client-side checks for the links to the Admin page. But because I'm not logged in, and the client-side checks are in place, I don't have the menu option to go to the Admin page. Even if I tried to go directly to the /admin/users page, it will simply redirect me to the home page when it validates that I don't have access. But if I log in with a user that does, such as max@lockmedown. com, and the password, and login, I now have the Admin link, which then I select, I can see the users. I can also attempt to delete a user, and successfully be able to remove them. Everyone's application needs are going to be different. What level of validation needs to be conducted, and to what extent, but as common as it is to require implementing function-level access controls to key access areas of your application, it is also easy to either outright miss implementing proper access controls in key areas, or misconfiguring the access control, and that is exactly what we're going to look at next.

Server-side Function Level Control Failure
We saw how we could implement function-level controls to key areas of our application, but there are a few function-level misconfigurations that can get you in hot water fast. One of the biggest security holes developers will fall into is the illusion that their client application they have served to the requester is still under their control. They believe that they can implement the most sophisticated access controls on the client side, and be satisfied that a clever attacker couldn't outwit their validation checks. This falls under what we talked about earlier in the module on untrusted data that our information has crossed a trust boundary. The truth is that the client is completely out of our control, and we can't trust any validation done on the client side. Sure, we can implement user-friendly checks to make the user experience as great as possible, but the golden rule is, all validation must occur on the server. No matter what you do on the client side, at the end of the day, those access control checks must be done server-side. Without getting entrenched in the details of the checks being done on the client side, which is not relevant to this particular course, we are doing some service-level validation of a particular user that is logged in, supposedly, and we have acquired a list of roles that they belong to from the login logic. When attempting to display information, such as the list of users, we can run specific validations to check whether this logged-in authenticated user is part of a role that's required. But before we display any information, or even navigate to that particular page, we actually conduct on the server side the access control validation for that specific user that they can do the action they are requesting to carry out. so no matter what you are doing on the client side, and whatever clever constructs to validate the user that is currently logged in, it's absolutely imperative that you validate the access controls for that specific user on the server side. But that's only one particular issue. Let's look at what happens in the case of access controls that are misconfigured, which is what we're going to look at next.

Access Control Misconfiguration
Misconfiguration is another problem that easily can occur with frameworks, such as express. js or any other framework that allows you to hook into routines in the pipeline. A typical pipeline works just as you might imagine, where it will carry out operations in the order that they were defined. I'm in the failure. js file, which is a constructed route specifically to demonstrate how easy this is to occur. Here is a router that is similarly set up to the administration router that we saw in the previous section on implementing function-level access controls for our different admin routes. We have defined a router for the specific path, api/admin/users. We have defined specific handlers for get requests to view all users, and delete requests to remove a particular user. We have also defined a get request at the beginning that should validate the requesting user is an administrator, and that is part of the admin role. But out of these, can you spot the problem in this particular scenario? Though we have listed access control checks at the beginning of the chain for this route, we have specified as the get method, which is only for get requests. So for any incoming route request with the delete verb would not be funneled through the middleware to validate the requesting user is an admin, or if they are even logged in. So anybody could essentially delete the entire list of users in our database. But by changing this to use the all method, instead of get, for example, by changing this to all, we can define that any request coming in for this route will be filtered through this specific middleware. Earlier in the course, we saw how we could leverage the express pipeline by creating middleware to validate untrusted data before it reached the actual intended route handler. However, when you toss in a large number of access control requirements, along with many cooks in the kitchen, in the form of teams of developers, it's easy for critical operations to get lost in the weeds. Therefore, I want to point out something that can be an important balancing act that you will need to determine with your applications' needs, requirements, and environment. Even though we moved the untrusted data higher up the pipeline, when it comes to access controls, it would be wise to ensure that they are fired right before the intended route handler. It could also be argued that depending on the gravity of the key area, and the complexity of the access control, that it actually occur in the beginning of the intended target handler. In the end, when it comes to function-level access control failures, such as with the lack of server-side checks and misconfigurations, as we saw in the last couple of sections, it's going to require an ample and thorough amount of testing. From smaller unit tests, all the way to penetration testing tools such as we've seen with Burp Suite and Zed Attack Proxy, to ensure that we haven't missed any loopholes in our logic and implementation. And that penetration testing, depending on, again, the complexity and gravity of your application might need to be conducted by teams or companies that are specifically set up with the necessary skills to do the thorough and proper security testing that is required for your application.

Summary
Access controls are a natural feature of today's dynamic web applications, and yet it is an area that is easy to get wrong. Many times, applications will fall short of implementing proper access controls because they fail to follow the principle of least privilege when it comes to function-level controls or access to critical systems. We've seen how the principle of least privilege is a security pillar that will go a long way in helping up shore up shortcomings in our application security. We also got to see how applying that principle to our interactions, with critical systems such as our applications database, but access to critical systems are not the only function-level controls we need to be aware of. We saw how role-based access controls can help us implement the proper function-level access to areas of our application, along with the function-level control failures that are easy to miss if you are not aware and fully testing your application. But there is still one more area we want to look at, that like many other areas that's we've covered in this course, also has a high level of risk, and ranks in the top echelon of web-related threats applications need to protect against, and that is cross-site scripting.

Defending Against Cross-site Scripting (XSS)
Overview
Welcome back. This is Max, and earlier in this course we took a heavy look at the concept of untrusted data, rules to help evaluate whether data is untrusted, and steps we can take to protect our application. In this module, we are going to look at an application security risk listed as the number 3 most serious risk by OWASP in their top ten list of application security risks, a threat to web applications whose foundation is based on the impact of untrusted data. Cross-site scripting is a risk that has threatened web applications for a long time, mainly because it is one of the more complicated and complex risks to mitigate. Furthermore, depending on your application's client-side architecture and the prevalence of DOM manipulation, it can be challenging to try and mitigate after the vulnerability already exists. If you watched the module on untrusted data, there will be some familiar concepts and mitigation approaches, but we'll specifically be looking at what a native cross-site scripting vulnerability in our application looks like, and how we can leverage tools such as Netsparker to help discover them, and also the anatomy of cross-site scripting attacks. We'll also look at three different types of cross-site scripting attacks, and how we can use a number of application configurations to help mitigate the threat of cross-site scripting attacks. And finally, a look at a number of different approaches we can use to handle untrusted data when it comes to cross-site scripting vulnerabilities.

Demo: Cross-site Scripting
In the module on session management, we saw the importance of protecting our user sessions. As we saw, hijacking a user session is the equivalent to identity theft, providing a way for an attacker to assume another user's identity on the site. The lack of protecting users from a session hijacking, and the way we handle untrusted data, leaves the door wide open for threats such as cross-site scripting. There are a number of cross-site scripting vulnerabilities on this site, but for now I wanted to demonstrate one particular exploit. On our application's timeline, we have a search feature that will allow us to supply a value that we want to search the names of timeline events that match that search term. We can put in the terms, for example, bank, to search for events that match that name. We could then choose to select one of these events that it has found to go specifically to that event. When we do put in the value, for example, bank, on the resulting page we'll see that our search terms are displayed at the top so we know they are being echoed back to us. We can see that our URL consists of a query string parameter that also contains the search terms we provided. Whoop-dee-doo, right? Well, for now just keep those items in mind. If you've never heard of a phishing attack, you probably are aware that email can be easily forged, and most people watching this have at some point received an email that appeared to be from a legitimate site that you are even familiar with, maybe it's a banking site or a commerce website that you might even have done business with in the past. The email looks so legit, that the from field even states it's from the legitimate site. Now, you received this newsletter from lockmedown. com, a site that you regularly visit and even get updates by receiving newsletters from them. Everything looks legit, there's new articles that have been published on the site, even new podcasts that have been released on the lockmedown. com podcast. There's even an update about a particular site that you have visited and have an account on, HackersHall. com. So you click on the associated link, and wham, your identity has just been compromised. Now what we are specifically looking at is just a simple popup window that happens to be showing the contents of your own authenticated session cookie that's on the HackersHall. com site, Instead of popping up a window with the contents of your session cookie, this could have quietly have been sent off to another site that was set up specifically to harvest session cookies by an attacker. But I wanted to explicitly show you what actually could be going on behind the scenes. Now this isn't the only cross-site scripting vulnerability on this site, but this particular case is what is referred to as a reflective cross-site scripting attack. The vulnerability is injected on a request, and reflected by the server back to the intended victim's browser. But before we dive into the details about cross-site scripting and the different forms it takes, and how we can combat it, let's look at a tool that can help discover these specific vulnerabilities in your site.

Identifying XSS with Netsparker
Up to this point, we have looked at how we can utilize a number of security testing tools such as Burp Suite, Zed's Attack Proxy, and even Fiddler's proxy, which isn't necessarily for security testing, but still makes a rather good one. I wanted to take the time to show you yet another tool that we can help bring vulnerabilities to the surface, which is Netsparker. Netsparker is very much the same in that it takes a high-level approach of positioning itself, and then begin able to launch a slew of different attacks at a targeted site. I'm unsure if they have plans for other operating systems, but for now it's strictly a Windows-based application. With Netsparker, we're going to take a slightly different approach. We're going to issue a very targeted attack, which we can do by starting a manual scan. We'll provide a specific URL to test, which we know is one that we are allowing users' input to be embedded into the URL, at which time we can choose a list of configured attacks or we can create a custom configuration by clicking on the ellipses, and defining a set of security checks, as well as a number of other configurable parameters. For now, I've already create a custom XSS configuration, which is pretty simple in its approach. It will attack the predefined URL I provided with its own defined cross-site scripting attacks. We can, in each predefined list of security groups, that on the right has their containing list of security checks that whey will perform. So, for example, I can choose Cross-site Scripting and see the number of different attacks that it will make against the site that we specify, or cross-site Scripting DOM-based attacks. With that, we'll go ahead and kick off our scan, and we'll reconvene here in a minute once it is done. With the scan complete, we can see that it has found an issue with this path, specifically it has found a cross-site scripting vulnerability in the timeline search path. Now Netsparker provides a general overview of the vulnerability, and how it can be remedied from a very general standpoint. You can also look over the specifics of how Netsparker exploited the vulnerability in the HTTP request and Response tab, which shows the details and the payload parameters that it provided. Unfortunately, what it can't do is tell you the specific requirement for a specific instance of a cross-site scripting vulnerability in your site. It doesn't know the underlying client-side implementation, the framework, or code that has made the vulnerability possible, so that is what we're going to look at next.

Anatomy of Cross-site Scripting Attack
Over and over throughout this course, you have heard about the ability for information to be processed as simple data or instructions. Whether we're talking about SQL Injection attacks, processing JavaScript expressions in a NoSQL database like MongoDB, or a number of various client-side code context, the way information is processed is the underlying theme for a number of critical web security risks. Again, this same theme resurfaces with cross-site scripting attacks. How information is handled, whether it is interpreted as data or instructions that it carries out. In the module on untrusted data, when we talked about the approach for handling untrusted data called escaping, or also known as output encoding, we learned about different code contexts. These code contexts such as HTML, CSS, URLs, and JavaScript, just to name a few, take the center stage when we're talking about cross-site scripting. It all comes down to how information is processed within those different code contexts. For example, we saw a demonstration on how we could inject scripts into a URL that got processed and fired a JavaScript alert message only after it acquired the cookies from the browser, all the while attempting to render an HTML element. That happened to be an example of what I refer to as reflective cross-site scripting, but we'll get into the different types in the upcoming sections. For now, it came down to how the information was treated when it was parsed. In all cases of a cross-site scripting vulnerability, when the HTML or JavaScript parser, or any other context parser receives untrusted information that contains instructions rather than simple data, it processes that information, and it ends up carrying out those instructions. So if the parser receives simple data, then the underlying results is the expected behavior, such as displaying the alphanumeric text that is entered in a search field, and those search terms being displayed on a page with the search results. That would be expected behavior. But when the information contains instructions to render an HTML anchor tag, that when clicked would usher the current authenticated users' sessions to an attackers site, this would probably not be the expected results of that information. Therefore, if the underlying premise of cross-site scripting vulnerabilities is that a parser receives untrusted information that happens to contain instructions, and it executed those instructions, then we can simply conclude that the underlying remedy is to ensure that an HTML parser or a JavaScript parser, or any other context parser, always treats untrusted information as data, no matter what instructions it actually contains. It sounds pretty simple, right? Well, unfortunately, as I mentioned at the beginning of this module, it's one of the most complex and complicated threats to mitigate, and there's a reason for that, and we'll start with the first reason and look at the different types of cross-site scripting risks we need to be aware of.

Reflective Cross-site Scripting
I don't think this specific version of cross-site scripting vulnerabilities requires a whole bunch more detail, as we've already gotten to see a demonstration of it at the beginning of this module, but for completeness, it's exactly what its name implies. The malicious information originates on the client and is part of the payload of a request. The server processes that request, ends up reflecting the malicious information back to the client where the malicious code is executed in a specific context. A clear example was the demonstration we saw where a phishing attack could be carried out on a victim that contains a well-crafted URL. A victim clicks on the link, which results in the request being processed by the server, and the information being reflected back to the user. The instructions that were embedded in the URL could do more than just steal a site's cookies, but garnish them access to the system. As more and more companies' security was hardening from the outside at the turn of the century and on, more clever approaches have been put together for an attack to gain access. Though not the only approach, a common approach is a collaborative approach of using a cross-site scripting vulnerability on a site, and the gullibility factor of humans to gain access to the network through the compromised system. But there is another type of cross-site scripting attack that might not require so much involuntary support by a specific user, and that's what we're going to look at next.

Persistent Cross-site Scripting
Unlike how we saw a required involuntary buy-in by the victim for a reflective cross-site scripting attack, where they had to conscientiously click on a provided link that was embedded in an email, persisted cross-site scripting can affect everyone who views the page that consists of a persistent cross-site scripting vulnerability, possibly resulting in a wider net of victims. To demonstrate, back on our site I'm currently logged in as a standard user, no one of any type of importance, and we have the capability of updating our profile, details such as First Name, Last Name or Display Name. Now if we were updating items such as password or email address, we would definitely require the user to re-authenticate, but in this case we're not going to do that for these non-influential fields. Currently I don't have a Display Name, so let's give it one. We could easily give it something like Peter, but that's not as much fun, and I've been wanting to gain access to the site as an administrator. So I'm going to paste in a lengthy text that's more than the intended value that the developers had in mind. So I'll just come in and paste in and update that. Now we can see that it updated my welcome message up above, but I'm not interested in hacking myself, so let's see how this would play out. So I'm going to log out as this user for now. And now, if an administrator was to come along and log in, and add their password, now let's navigate to the list of users on this site that the admin has access to, and see what the added value for the Peter Parker account does. Now if I navigate down here to that particular account, we see that all it did was really put in a button here that looks like we can view this specific user. Now if I click this user, it's navigating us away from the site, and if we look up here in the bar, it's just trying to go to Google, but appending the cookie contents for that particular admin's session ID in the query string, cookie. But this could have easily, instead of being sent to Google, which is of no value now, could have been sent to some other maliciously set-up site to harvest those cookies. Now clearly this malicious data had to be stored somewhere that it could be retrieved when it was needed for the information on the served page. This is the underlying difference between reflective and persisted cross-site scripting attacks. The malicious data is persisted to some type of storage where it can be retrieved. Now in this particular case, I made it very explicit, but generally speaking, the administrator would not even need to know what actually had occurred when this page has rendered the script executed, and those cookies are sent off to the site of the attacker who has set that site up to harvest those cookies. And it wouldn't be as explicit as defining a button here that we click on, but I wanted to do that so you can explicitly see what could occur. A common scenario that one would hear about is the case where a site allows users to add comments to a page, and a request for that page would also serve up the comments that were added for that page. If the comment that was stored contained a malicious script, everyone visiting the page that would render those comments would be a victim to the attack. Now reflective and persisted cross-site scripting are enough types of attacks to handle. There's yet another case of cross-site scripting attacks to deal with, and we're going to look at that one next.

DOM Based Cross-site Scripting
Now we're back in our application, specifically in the sessionsManagementConfig. js file where we configure how we want our application's user session cookies to be configured. And if you recall from the module on session management, one of the primary goals of an attacker hijacking a user session cookie is for identity theft, allowing that attacker to operate as somebody else. I also alluded then that one of the primary ways that an attacker can go about acquiring the user sessions is through the threat of cross-site scripting. If you didn't have the opportunity to watch that module, I would highly recommend it. It goes into depth of how to configure your user sessions and associated cookies for the best protection within your application. Now for the sake of completeness on the topic of cross-site scripting, we can completely protect our user session cookies from cross-site scripting attacks with a simple configuration, setting the cookies httpOnly flag, and this will ensure that the browser will not allow any type of script to access the contents of the cookie. So even if there was a cross-site scripting vulnerability on the site, accessing the contents of the cookie by a script, specifically a malicious one that's been injected by user input, would not have access to the contents of that cookie.

Introduction to Content Security Policies
When we talk about reflective or persistent cross-site scripting, we saw how a malicious payload could be reflected from the server, such as in a malicious link, or served from storage where it already exists. But in both cases, the malicious code is executed in a specific context such as an HTML context, and rendered to the DOM. These two cross-site scripting attacks were even more prevalent when websites generally used to handle all the HTML construction server side. However, with the growing use of single page applications and APIs for acquiring the data the application needs to operate, web applications have seen a growing increase in another cross-site scripting attack. DOM-based cross-site scripting can be hard to grasp, the difference between the previous two versions depending on your source of information. But essentially, how many of you have written web applications that might use either vanilla JavaScript or a popular library such as jQuery to manipulate DOM elements directly on an already-rendered page, with information based on the user input that would drive the user experience. If that user input is not properly handled, your application would essentially be open to DOM-based cross-site scripting attacks. Another characteristic of DOM-based cross-site scripting attacks is the difficultly of identifying the attack. Take, for instance, how a full HTML page might get constructed and provided to the browser for rendering in the client, and a persisted malicious link that was constructed from user input was injected into the page, server-side. We could detect that from analysis on the returned response from the server to see that the page contains the malicious script. But in the case of a DOM-based cross-site scripting attack, the page will not have changed on the response. And it's not until the browser is rendering the page, and through a DOM-manipulation process utilize the malicious user input, that the exploit would become evident, such as in the case where information in the URL is used to generate links, URL components that the user could provide that would have unexpected values and execute behaviors that were unforeseen, as in the case where a victim who was provided a link ends up coughing up sensitive data, such as in the case of a reflective cross-site scripting attack. In the end, cross-site scripting attacks is an exploit where untrusted data was not properly handled, and unexpected side effects occur at the expense of the victim, such as the case of session hijacking, stealing sensitive data, or even worse, such as the ability to provide gateways to attackers to gain complete access to a system. When it comes to mitigating cross-site scripting vulnerabilities, we can start with the easiest and most broad approach, and that is through configuration. So let's look at the first configuration change we can make in our application to help combat this threat.

Implementing Content Security Policies
No matter where it originates, no matter what its target consists of, the type of attack or the goal of a cross-site scripting attack, there are a few common components. The execution is always in the client. Though obvious, but worth mentioning, is that it's in the form of a script, as the name of the threat suggest. That being said, Content Security Policy is an HTTP header we can use to dictate exactly what resource can be loaded on our site, from where it can be loaded from, and under what protocol. One of the Content Security Policy header's purpose is to combat cross-site scripting attacks. We can provide the header on any particular, or on all responses, to control what scripts are allowed within our application. Despite its primary use of defending against cross-site scripting attacks, we'll see it again as a promising mitigation for protecting against mixed content on a web page. We can use the Content Security Policy header to control a laundry list of different sources such as style sheets and images, audio and video, form actions and embedded resources, as well as scripts, which is what really interests us. The header itself is composed of directives, and the values that are assignable to a directive. In this example, we can dictate that only scripts can be loaded by our domain. There are a number of various directives as we had seen, as well as default source, which allows us to dictate what should be the setting for all directives that we didn't explicitly define. So in the case that an attacker was to exploit a cross-site scripting vulnerability, specifying the download of a script from another source, the loading of that script would be blocked. So let's look at an implementation.

Enabling Cross-site Scripting Protection Filter
Truth be told, one of the reasons I was able to carry out the reflexive cross-site scripting attack against our site that we demonstrated, was because I turned off a native browser filter in Chrome, that helps protect against reflective cross-site scripting attacks. I hesitate to mention that, because not all browsers are equal, and nor should we rely on the browser to automatically protect against these specific cross-site scripting attacks. But we can help take a small step in notifying any browsers or older browsers that might not automatically implement a cross-site scripting filter, such as how Chrome automatically does, as well as some of the other mainstream browsers. We can provide it another response HTTP header, the X-XSS-PROTECTION header. With the value set to 1;mode=block, we can give the browser a heads up of our requested information. Specifically, what we are stating here is that we want to turn on the cross-site scripting filter denoted with the number 1, but we also want it to not render the page, we want it to block the rendering of the page. We could have just specified 1, and allowed the browser in some cases to actually try to sanitize the response URL that contains the malicious script payload, but in this case we want to instruct the browser to completely block the rendering of the page. But unlike Content Security Policy headers, and the helmet Node package, which is not turned on by default, providing the X-XSS protection header is, by default, if you just enable helmet. So back in our application, let's go ahead and open up our responseHeaderConfig. js file, which is where we defined our Content Security Policy headers through the helmet Node package. As I mentioned back in that section, helmet comes with a number of security features that are enabled by default. One of them that is not enabled by default is the contentSecurityPolicy, which is why we have defined it specifically here. But we could enable all the default security features of helmet just by simply invoking the function that helmet returns to us, just like so. Unfortunately, one of the security features that gets enabled by enabling the entire helmet Node package is to instruct the browser not to do MIME type sniffing. What does that mean? Well, basically, if you recall from the beginning of this course, I informed you that the application itself is riddled with a number of security risks, weaknesses, and different security holes, one of them being that we don't provide content type headers on responses. So it's up to the browser to try to determine through MIME-type sniffing, determine what kind of content they are receiving, and that leaves open yet another door for attackers to try to compromise our application. So if we allow helmet to instruct the browser not to perform MIME type sniffing, what it will end up doing is just rendering our HTML page as plain text, and that's definitely what we don't want. But we're getting ahead of ourselves, and that's an issue that we'll look at in a future course. Therefore, just as with the Content Security Policy middleware helmet, we can, instead of just invoking all of the security features helmet, we would just invoke, in this case, the xssFilter to show you explicitly what part of the helmet collection of middleware will provide the X-XSS PROTECTION header to the browser. Now just to reiterate, a lot of the modern browsers and big-name browsers like Chrome, and IE, and Firefox, and Opera, do provide cross-site scripting filtering mainly for reflective types of cross-site scripting attacks. This isn't going to benefit for those that are using modern day browsers, but if somebody was to connect with an older browser that does not have that filtering turned on by default, this is where this header will come into play. Now there is one other configuration we can make with our application that will go a long way, and it's one that we already talked about when we discussed session management. But let's look at it again, just to understand the significance.

Cookies Protection
When it comes to specifying response HTTP headers that pertains to security, I'm going to look to one of the better known and trusted middleware Node packages by the name of helmet. We'll see an example of implementing similar headers without the user of a third-party Node package, in the next module on script transport security, but for now, helmet is one of those Node packages you absolutely should use right out of the gate. It has excellent documentation that covers a number of different security aspects, and it's actually a collection of other smaller security-specific middleware, and without any configuration, just enabling the helmet Node package in your application will implement a number of security hardening by default that your application could use. Unfortunately, one of the middleware that is not part of the default settings is the Content Security Policies, and this is primarily because of the lack of having consistency about the headers across the major browsers. Therefore, helmet gives a few different options for tackling this inconsistency issue by allowing helmet to do either agent sniffing to determine the agent, and thus the version of the headers that it should provide, or by dumping all possible headers and covering any number of different browsers. In the end, what we want to do is provide our own configuration middleware that will enable helmet and set up the Content Security Policy and configuration for helmet. So I'm going to come over here into our configurations directory, and I'm going to create a new file, and we'll just name it responseHeaderConfig. js. But before we go and dump in the code that we want to wire up helmet, we need to first install helmet into our application. So I'm going to come down to our terminal window. Now we'll just type in npm install ---save ---save-exact helmet, with a specific version of 3. 1. 0, which is currently, at the time of this recording, the most latest version, and we'll install helmet. With that complete, I'm going to go ahead and minimize this window so we have a little more room to work. With that complete, I'll go ahead and paste in that block of code that will configure helmet in our Content Security Policy middleware. And now we can look at this in more detail. Here we are setting the default source directive to none, to the value of none. And right off the bat, no matter what directives we don't explicitly define, will be covered with this default source directive, followed by a number of other directives that state basically that all scripts, all style sheets, images, fonts, connected sources such as Ajax and Web Socket sources, can only be loaded from our domain. The few exceptions is that we have included also the fonts. gstaic. com as an allowable source for fonts, and fonst. googleapi. com for style sheets. With those in place, we need to wire it up in our server so this middleware will be utilized in the express pipeline. So over in our server. js file, I will import this new configuration file with import responseHeaderConfig from our configurations directory from that specific file. And then I will come down here and invoke that function that it returns, and pass in our express app, and that's all it'll take to utilize and implement that middleware that we have implemented here in the responseHeaderConfig file into our express pipeline. So with that in place, let's go ahead and fire up our application and let's see what this looks like. So back on our site, I'm going to go ahead and bring up the Chrome Developer tools, and we're just going to go ahead and refresh the page so that we can reissue the request and capture the network traffic for that. We're under the Network tab here in the Chrome Developer tools, and I'm just going to issue that refresh, and we'll see these requests that come in, and we'll scroll up here to the initial request for hackershall. com. And under the headers, I'll just pull this up a little bit, so we can see it a little bit better, we can see that, indeed, on the response headers there is a Content Security Policy, and it defines all the directives and the values we set for those directives here in this header. But if you noticed, there was a particular error, let's go over to the console and see what that is, and it says that it refused to load the script from code. jquery. com, and it was the minified jquery file version 2. 2. 3. This says that it has violated the directive we set, which currently for the script source directive is only set to "self", and "unsafe-inline". So we did not define that our application was allowed to pull in scripts from code. jquery. com. This is an example of how we have blocked any external script from being loaded, since this was not a specifically specified domain in our configuration for our Content Security Policies. Now we can take this particular domain, and we can add that to our script. So I'm going to jump back over to our application, and up here in our script source directive we can simply add an additional source that is allowable, because this is more or less a whitelist, and specify http://code. jquery. com. Now I'll restart up our application, and we can see how that will rectify the issue of loading a script that we allow form an external source. Okay, so back over to our site, bringing up the Chrome Developer tools, I'll just refresh one more time, and we'll see that we aren't getting those errors about the code. jquery. com site and not being able to load that specific external resource. So we can easily add that external source that would define part of our white list of what external allowable sources can be loaded through our Content Security Policies. And that is a one very potent configuration change that we can make in our application through the use of Content Security Policies to create an application-wide security impact against cross-site scripting. There is another web server configuration that we can utilize to help us protect against reflective cross-site scripting that helmet can also help us with, and that's what we're going to look at next.

Escaping Untrusted Data
In the module on handling untrusted data, we already got a good overview and introduction to what is escaping, or also referred to as output encoding, so if you haven't seen that module, I would highly recommend circling back. But building on that, what we want to be able to do is filter our user-provided untrusted data through a filter that would escape or encode the user input. Then in our HTML context we can ensure that the parser will only ever evaluate the information it receives in regards to the user-provided input as data, and not instructions. We're going to use a Node package from the developers at Yahoo called xss-filters. Its primary focus is on HTML, and URL encoding, and has an extensive API for varying specific sub-contexts such as HTML attributes and HTML comments, as well as URL components. It is also being actively maintained, and an active vetting community and high amount of use for vetting security issues within the package itself. Now I'm going to switch over to our adminRoutes. js file and our adminRoute for displaying pages of users simply dumps the list of users in the JSON output that we send back to the client. As a simple example, we know that users can provide their own information for specific fields, and make updates to their profile, as in the case of the user's display name, which was the crux of how the user embedded a link that would extract the logged-in administration session cookies that we saw earlier in the demonstration. That was a very explicit example that didn't have to be so blatant, and could have been kept under wraps so that the admin wouldn't even know that their session cookie had been extracted and sent off to an external site set up by the attacker. However, I wanted to demonstrate both the ability to acquire the session cookie, as well as the ability to manipulate the DOM with user-provided data. Now before we can use the xss-filters package we need to install it, so I'm going to come down here to my terminal window, and we'll just say npm install ---save, --save-exact, and say the package name at the most current version of this recording, which is 1. 2. 7, and we'll install this package. With that installed, I'm going to go ahead and close the terminal window, and the other thing we want to do is come up here and import that Node package, say import xssFilters from xss-filters, and now we can use it. So what I'm going to do is I'm going to come down here and I am going to replace some code here, and paste in a chunk of code that we can look at in detail. Let's scroll down here a little bit better for a better view. So essentially what we're going to do is take the array of users returned from our MongoDB query, and for each piece of data that is user-provided, we want to run it through the inHTMLData function. In the end, we're going to have an array of user objects that have these fields encoded, specifically in this case we are strictly using the inHTMLData method of the xss-filters API since this user information is being inserted into the HTML, and contains user-provided information. The end result will take our user-provided HTML that was used in the demonstration, and in turn, turn it into an escaped string. The xss-filters package makes a point to only escape the minimal amount necessary and not every HTML escapable character. And the end result is different than what we originally saw. As a refresher, what we originally saw when we logged in as an administrator and came to our list of users and went specifically to the user that we were using here, as an example, they had listed a View button rendered for where would be their display name, which is different when we actually apply the escaping of that user input, which let's look at the end results now that we're doing that. But instead, the end results after escaping that data look way different, so after logging back in behind those filters to escape the user input, we can come back over to our test subject and look at the input that they're providing and what it actually turns out to be. And we can see here that actually it is just showing up as a string, as just information, data, that was provided to the parser. And if we dig into this, we can see here that actually it's just viewing that user-provided input as a string, and not implementing it as an actual HTML element. Now you might be wondering, why are you doing the escaping on the output of the data before sending it to the client, or within the client before it's actually displayed? Why not perform this on the input before it's handled, persisted to the database or storage? And that's a good question, and I'll give you four good reasons. One, it's a great chance of avoiding scenarios where the data is double-encoded. Developers work under assumptions, maybe, that the data still needs to be properly escaped. It also helps avoid data loss. Truncation can occur simply because escape data is larger, more agile, with how the data is used. Application requirements change, and if the data is already encoded, you might limit your capabilities on what is done with the data, because it's already in a state of being escaped. It's also less prone to errors. Because of the potential of double-encoding and related issues, handling the escaping of data on the output rather than handling it on the incoming of data can help avoid unnecessary errors. So make sure you handle escaping of data prior to using, rather than prior to persisting it to storage. Finally, with the advancement of single-page applications in web development, a number of popular frameworks help aid in fighting against cross-site scripting. Frameworks such as React and Angular. js, the Node template engine, Jade, or ASP. NET's Razor template engine, take extensive steps in ensuring data escaped before being rendered to the DOM. For example, React explicitly makes you jump through hoops to take the guard rails off so you don't inexplicitly output raw untrusted data to the DOM by utilizing its API method called dangerously setting inner HTML. Angular is similar in having to also use explicit directives for accomplishing the same thing. But this only escaping, and escaping isn't always what we want to do, so let's look at a couple other options.

Sanitizing and Validation of Untrusted Data
So we have briefly talked about using the process of escaping of untrusted data with Node packages such as XSS filters, to turn potentially unsafe characters provided by a user into harmless data. Unfortunately, there are certain contexts or sub-contexts that are just not safe enough to simply escape user-provided input, or frankly, we just don't want to, and we have to rely on different techniques such as sanitizing or validation. I alluded to sanitizing in the module on handling untrusted data. Most of the time, sanitization takes a different approach with the data than escaping. Instead of encoding the data into a different format, sanitizing removes the characters all together. So if you have user input, such as this anchor tag that could be potentially unsafe, you could strip it down to the safe portion of the input. There aren't too many Node packages really to choose from when it comes to sanitizing, but one that has been around for a while and has an active community of developers is the NPM package XSS. One noticeable difference about this package is while the notion of sanitizing is generally a blacklist approach where it compares data to a list of characters that needs to be removed, the XSS package actually allows you to specify a whitelist of HTML tags and their attributes that are allowable. Anything outside of that range is automatically removed. But personally, I think sanitization is risky, and assuring that there isn't some crafty string that an attacker submitted isn't going to find a way to bypass a match, can be a major challenge. Therefore, I would throw out there, maybe it's something you need to think hard about. If you want to attempt to keep a user-submitted data, but you want to ensure that values, such as HTML elements or other unsafe characters are not present, then why don't you just ensure that the user abides by your rules, and validate the data, and ensure it only contains values you accept. You can do that through the process of data validation. But we've covered this topic of data validation extensively in the module on handling untrusted data. So if you want to see how to implement validation checks for user-provided data, check out that module. Finally, we have only looked at one small scenario of escaping untrusted data for one particular HTML context. There are a number of other contexts that we mentioned earlier in this module, such as a CSS context, a JavaScript or a URL, as well as sub-contexts such as an HTML attribute or an HTML comment. Each of these contexts and sub-contexts have their own rules of how the untrusted data has to be escaped. Unfortunately, we could put together a course strictly on the rules that govern exactly how data for each of these specific contexts are escaped. OWASP has put together a fairly comprehensible list of rules that you can follow for each scenario, whether inserting user-provided data in a CSS property, or HTML in a comment or attribute. The only thing you need to recognize is simply this: If you are inserting user-provided data into one of these contexts or sub-contexts, and you aren't performing data validation to reject the data outright, then you need to find the rule that applies to that scenario to see how it needs to be escaped. Finally, we only saw a simple example of escaping data before delivering it on the response payload. But depending on the scenario and the context, the escaping most likely will need to be done on the frontend client, prior to displaying the data or the use of the data as in the case of handling untrusted data in a JavaScript context.

Summary
On the surface, it's easy to understand that the risk of cross-site scripting comes down to simply the ability for untrusted data to execute scripts or manipulated or trusted scripts to perform unexpected actions. Unfortunately, the complexity of cross-site scripting is in the mitigation because of the various contexts that have different rules of how the data has to be properly handled. Over the course of this module, we got to see first-hand what an exploit of a cross-site scripting vulnerability looks like. We also got to see how tools such as Netsparker can help us detect potential cross-site scripting vulnerabilities in our application. With an overview of the anatomy of cross-site scripting attacks, we got a chance to look over the three various cross-site scripting attacks that we need to protect against. We also got to see how we can implement configuration changes to our application to apply application-wide mitigations such as the use of content Security Policies and other HTTP headers, along with protecting our cookies from the outcome of a cross-site scripting attack. Finally, the look at the technique of escaping or outputting coding, sanitizing, and validation can be used as different ways to handle untrusted data and avoid cross-site scripting vulnerabilities in our site. The last topic we're going to look at is one that can provide a number of significant security benefits to our application and its users through the use of Transport Layer Security. We're serving our application over HTTPS, so let's check that out next.

Securing Your Connection
Overview
Hi, this is Max, and in this module we'll be looking at how to keep your secrets secret. Encrypted communications is one way that a number of web-related risks can be mitigated. Transport Layer Security is just the answer to implementing a secure and encrypted communication between clients and your server. Specifically, we'll be looking at what is better known as acronym soup, of TLS, SSL, and HTTPS, acronyms that cause much confusion. Also, the benefits of Transport Layer Security, and how we can implement and establish a secure server in our application. We'll also look at a common misnomer about TLS configuration and login forms. In addition, we'll look at some supportive security measures with the use of a couple HTTP headers, such as HTTP Strict Transport Security and Content Security Policies. So let's get started.

Acronym Soup: TLS, SSL, and HTTPS
Throughout this course, Transport Layer Security has come up a number of times as a mitigation, part of the solution to solving different particular web-related risks, such as mitigating the ability for someone to eavesdrop on sensitive data, such as submitting user credentials during authentication, and preventing session hijacking. Although these two mitigations are specific Man-in-the-Middle-related attacks, TLS mitigates against other Man in the Middle attacks, such as DNS spoofing or cache poisoning. Essentially anyone in the middle has been blocked from reading, changing, or even redirecting that encrypted traffic. But the whole process and all the moving components that are involved with establishing secure and encrypted communications between clients and your server is not necessarily an easy-to-comprehend subject. To make matters worse, the industry hasn't necessarily made it any easier with the litany of acronyms, TLS, SSL, HTTPS, many of which seem to be talking about the same thing. Therefore, I thought it would be beneficial just to clear up the air with just a quick overview of what each of these pertinent terms mean, and where they fit in the big picture. Netscape originally developed the Secure Socket Layer protocol, SSL, and officially received a patent for it back in 1997. However, the internet engineering task force, IETF, will take over maintenance and improvement of that protocol in 1999. When they released an updated version of SSL, they decided to rename it from Secure Socket Layer to Transport Layer Security to disassociate it from Netscape, and they ended up releasing what we know of as TLS version 1. 0. In addition, instead of only representing a socket connection as the SSL protocol did, Transport Layer Security represents any secure bidirectional tunnel for arbitrary data. Simply put, HTTPS is a special name given to the use of the HTTP protocol over an established Transport Layer Security tunnel, or TLS tunnel. HTTPS is not its own protocol, but the secure use of the HTTP protocol provided by the TLS tunnel. Therefore, conceptually, SSL and TLS represent the same thing. While technically, TLS is an improved version of SSL, and technically SSL is not recommended as a protocol, the community and related documentation have used these two terms interchangeably, and HTTPS is simply denoting the use of the HTTP protocol over an established TLS tunnel. So hopefully that clears up some of the confusion.

The Importance of TLS
One of the most recognized features of the use of Transport Layer Security is the ability for it to encrypt the communication tunnel through which data is being exchanged. What that means for us is any data that has been marked as sensitive can be safely and securely exchanged between the client and our server, and as we saw, eliminating the ability for any Man in the Middle to read or even redirect the contents of the encrypted traffic. But in addition to the benefits of an encrypted communication, TLS contains a few other important benefits. It provides validation that the website you are attempting to communicate with is who they say they are. Early in the handshake that goes on between the server and the client, for example, the browser, the server provides their certificate, but how valuable is that certificate if the certificate cannot be validated. If a browser or PC could come preloaded with a copy of every available websites' SSL certificate, but that would be inefficient on so many levels, therefore, the chain of trust flows up to a higher authority, a certificate authority, and it is the certificate of the certificate authority which you trust. Therefore, in a simplified version, daring the handshake to establish a secure connection, you are able to use the certificate of the certificate authority to validate the certificate from the server you are communicating with. With the validity of the server, and the established encrypted communication, TLS also provides message integrity, integrity of the information being exchanged by computing and appropriate message authentication code for each received message to ensure that the message has not been tampered with during transit. So you can see, Transport Layer Security really encompasses keeping sensitive application and client information confidential and away from unauthorized parties. It also provides validation of who we are communicating with, and integrity of the information we receive.

Setting up a Secure Server
Because of the single-threaded nature of Node, establishing a TLS connection is expensive, and handling an infinite number of TLS handshakes by your express, or comparable Node server, would most likely prove damaging to the performance of your application. Therefore, use the right tool for the job, and use an appropriate server for establishing TLS handshakes and secure communications to your application. But this isn't a course on Nginx or Apache, so for the completeness we'll look at how we can easily set up our server to handle HTTPS requests, and later how to handle redirects, appropriately. Back in our application, specifically in our server. js file, we're going to accomplish two goals. We're going to set up a server to serve our application over HTTPS, and also redirect any requests to our application on port 80 over to our server handling our application on port 443, which is the default port used for HTTPS traffic. So to start, we're going to bring in a few libraries, starting with Node's own file system. So I will simply import from "fs", which is the Node file system library. We're also going to bring in the HTTPS Node library for setting up our HTTPS server. I'll import HTTPS from "https". Now in order to create our HTTPS server, we need to be able to provide it the private key and the certificate that it will use for communicating securely with a client, such as a browser. Now over here under the data directory I have two files, the hackershall. crt, which is our actual SSL certificate, and hackershall. key, which is our private key. Back in our server. js file, we'll use the fs library, the file system library from Node, to read in the contents of those files into an object, and I'm going to paste in some code here, which is our options object, and we'll read the contents of the key into a property called key and the contents of our certificate into a property called cert. And we'll see here in a moment how we'll provide this options object to our HTTPS server to use. Now I'm going to slide down here to the bottom where we're actually creating and listening on our standard HTTP server. App is our express server, listen is just a shorthand for express, which is in the background creating an HTTP Server, and listening on whatever port you provide. In this case, the insecure port constant is assigned to port 80. Now we're no longer going to be listening to port 80 on our main application like we were before, and as you can see here, what we want to do is create a new server from our HTTPS library that we pulled in, and provide it the options object that contains information such as our certificate and private key, as well as the app, our express app, that will be handling all requests, and then we'll want to set up that server. I'm going to go ahead and remove this for now, and we'll take that https library and call createServer, and provide it our options object that we created up earlier, and provide it our express app. And finally, we want to listen on port 443 for this new created server, and do a little formatting here. So this is all great and dandy, but if anybody tries to go to just hackershall. com, they are not going to find any response, because we have nothing listening to the standard HTTP protocol port, which is port 80. So what we really want to do is two different things. One, we want to create a server that is just going to listen to port 80, and then redirect all traffic that comes in on that port over to the secure version of our application, which is listening on port 443. So what I'm going to do is I'm going to actually come up here and create a new express app, and we'll just call it insecureApp, and its only job will be to redirect traffic back to our secure application. So I'm going to come back down here, I'm going to actually utilize what we had before, so I'm going to paste in our original express server that was listening on port 80, and I'm going to change app to our insecure express app that we just created. So this express app will be listening on port 80, and it would respond to any requests if we had anything set up for it to respond to. The only thing that we want to set up is to listen for all requests and redirect them to our secure server that we set up just below this. So what I want to do is come over to our configurations directory and create a new file, and we'll call that redirectRequests. js. Now I'm just going to paste in a body of code here that is simply creating a function that takes in an express app and assigns it to a middleware that will listen for all routes that come in that's denoted by the wildcard asterisk that we have listed there, and we will set up our redirect on the response to that request, and we're going to redirect with an HTTP status of 307. We're also going to provide the full URL, which includes the host and the path that the original request was coming in on, and this will set up a middleware in our express server to handle all requests that come in on this insecure app that's listening on port 80, and provide a response to those requests with a redirect of an HTTP status of 307 to the secure version of the URL they were trying to reach. Now to put this in use, I'm going to come back over to our server. js file, and we'll pull in that particular configuration. So I'll say import redirectRequests. Then we're just going to invoke it here, and we're going to provide it the insecure express app that we created, and this will establish middleware on that specific express server to listen and respond to any requests to it to redirect those requests to our secure version. So now we'll go ahead and fire up our application and see what happens when we attempt to hit our application on port 80. So I'm back over here in Chrome, and I have the Developer tools up here so we can capture those requests that we're about to make, and I'm going to issue a request just to the server that's listening on port 80, and I'm going to see how that redirect occurs here. So I'm going to come up here and just refresh this, and we can see that, indeed, we're seeing that it has been redirected to the HTTPS version of hackershall. com. And we see that more definitely coming down here and looking at our initial request, and we can see that, indeed, a get request was made to the http version of hackershall, a 307 Temporary Redirect was sent back, and indeed, coming to the next request we can see that a simple get request was made, the same get method that was initially requested was then issued to the secure version on HTTPS for hackershall. com. So we can see that, indeed, the redirect is occurring, but I don't know if you caught that, but instead of doing a 301 redirect, we're issuing a 307. Later on in this course, when we get to talking about strict Transport Security, I'll reveal exactly why we're using 307 redirect. A few last parting remarks regarding SSL certificates. It's paramount that you understand that a self-signed certificate should never be used in a production environment. That being said, there are a number of places and ways that you can obtain a self-signed certificate to use with your application development cycle, but when it comes to acquiring a legitimate and trusted SSL certificate, I would highly recommend reading over OWASP's TLS Protection Cheat Sheet, which has a great bit of information, not only regarding TLS configuration, but on the technical details regarding the certificate you should use. Also, it's paramount that you should use a reputable and trusted certificate authority for acquiring your production SSL certificate. That being said, LetsEncrypt is the new guy on the block that is making it head-over-heels easier to acquire a valid and free certificate for use in production. They have already established themselves, and growing to be one of the largest certificate authorities backed by a laundry list of prestigious companies that want to see them succeed. Also, as I mentioned before, it is to your benefit to use a server in front of your applications, such as Nginx or Apache or another suitable server to handle your TLS connections and your load balancing, and in some cases, such as Nginx, we'll do your redirects for you.

Login Forms from the Top
We saw in the last section how to establish an HTTPS server and issue redirects from standard web traffic on port 80 to our secure server handling TLS connections. But despite the big push for website to serve their entire contents over HTTPS, and companies such as Google placing a higher weight for sites using HTTPS on their search results, not everyone is going to serve their entire site over HTTPS. Therefore, it's worth taking a moment and talking about a critical TLS configuration misstep that still occurs today. It's key to understand that anytime we serve content over HTTP is a window of opportunity for a Man in the Middle attack. Unfortunately, there are still companies and developers misconfiguring their application login forms. They operate under the strict understanding that as long as they submit user credentials, the identified sensitive data, over HTTPS, they're operating securely. What they fail to realize is that it's the moment before they submit the credentials, when they actually load the login form over HTTP, instead of HTTPS, that they have opened themselves up to a Man in the Middle attack. This would equivalent to leaving your front door unlocked all day, only to lock it at night. Locking the doors after an unwanted person has come in doesn't do you much good. A Man in the Middle who has intercepted your login form response that was sent over HTTP, could easily augment the response, including a keylogger, for example, onto the page. I demonstrated this specific risk in an article on lockmedown. com titled Hacking an Insecure Login Form, where a login form was loaded insecurely over HTTP, and using a proxy that could intercept traffic could easily inject a keylogging script on the page before it was handed over to the client. Then all the keystrokes entered by the victim was buffered and submitted to an offsite server, capturing user credentials. So when we're talking about a website that is not serving their entire site over HTTPS, the key takeaways are this: Sometimes simply sending sensitive data over HTTPS is not enough. If there are forms involved, such as login and registration forms, proper security measures start with providing those resources, those forms, over HTTPS. If you recall, one of the provided benefits of TLS was integrity, and in our case TLS can provide the integrity that the page was not manipulated in transit. At the beginning, I mentioned that any time we serve data over HTTP, there's a window of opportunity for a Man in the Middle attack. so you might be thinking, well, what about the initial insecure HTTP request to our application, the one before the client has been redirected to the secure HTTPS version of our application. Good point, let's look at how we can address that next.

Introducing to HTTP Strict Transport Security
I have mentioned a couple of times in this module that any insecure requests in this application, that is any request over HTTP, is an opportunity for a Man in the Middle attack. So that also applies to initial requests over HTTP to our application before the browser is redirected securely, would also be susceptible to a Man in the Middle attack. As it stands, no matter how many times a browser has been redirected to an HTTPS connection of our application, if the browser is instructed to connect to our application over HTTP, the same song and dance continues to occur. An insecure HTTP request is made, our application redirects the browser to an HTTPS connection, rinse and repeat. But what if the browser was smart enough to know that this site should never be requested over HTTP? Well that is exactly the purpose of the HTTP Strict Transport Security header. It is an HTTP header that websites can issue, notifying the browser that it should only communicate with the site over HTTPS. In our previous example, instead of the standard routine of accepting an insecure request and redirecting to the secure server every time a request over HTTP is made, an initial request over HTTP is made, a redirect occurs to our application over HTTPS. Once a secure communication has been established, an HTTP Strict Transport Security header can be provided to the browser, and any supporting browser will be cognitive of the site's required HTTPS connection. As of today, all major browsers support the HSTS header. Therefore, if a user attempts to reach back out to our application over HTTP instead of HTTPS, the browser will stop the request before it is issued, and instead reissue the request over HTTPS. So you can see you automatically eliminate all those Man in the Middle opportunities because you have eliminated unneeded requests over HTTP. Other than the request prior to the browser receiving the HSTS header from your application, the only other time that an insecure request will be allowed through will be when the header itself expires, which is dictated by the maxAge field, or if the browser was reinstalled or the cache related to it was cleared. Reading up on the HSTS header will provide you some interesting results, but the information you get isn't always the best or correct. A few points I think worth mentioning that can make all the difference is that it's paramount that an HTTP Strict Transport header is only provided after a secure connection using HTTPS to your application has been established. The reason for this is that if it is set in the original HTTP response, any Man in the Middle can easily abstract that information and obscure it from the browser, again, leaving the user vulnerable on the next attempt to connect insecurely over HTTP to your application. Now some browsers are now taking the progressive action of just ignoring any HSTS header that is sent over HTTP. If at all possible, include the HSTS header on all secure responses. Only issuing it for specific requests such as a login form, can, again, leave the requester vulnerable until they stumble upon a resource that does issue that header. In addition, using a 307 redirect instead of a 301, helps preserve the request method without changing it. So if originally it was a post, it's not going to be changed to a get on the redirect. A few other additive points about the HTTP Strict Transport Security header. There are a couple of attributes that can be included, starting with the IncludeSubdomains attribute. You can designate the HSTS header to cover subdomains of the main domain as well, followed by the Preload attribute, which correlates with a list that Google Chromium maintains. I mentioned a number of times how the initial request over HTTP, until the browser has received and cached the HSTS header for that site, is vulnerable to a Man in the Middle attack. To reduce the window even more, Google Chromium maintains a list of approved and preloaded sites that the browser should only ever connect via HTTPS. Even if the browser hasn't actually accessed the site before, the preloaded list baked into the browser, such as Google Chrome's browser, will be consulted by the browser before it makes an insecure HTTP request to the intended target. So with that overview of the HTTP Strict Transport Security header, let's see how we can introduce it and implement it into our application.

Implementing the HSTS Header
Now adding an HTTP Strict Transport Security header to our responses is fairly straightforward, especially for a framework like express that makes adding middleware a breeze. To keep what we are concentrating on nice and concise, I'm going to drop in another file that will contain a middleware I will pass to our express server to use, and its sole purpose will be to set response headers. In this case, we're only concerned with setting the HTTP Strict Transport Security header. So I will come back over to our configurations directory, and I'm going to create a new file, and we'll name it responseHeaderConfig. js. Now I'm going to paste in some code that will do just that, and we can look at it a little closer. Now whether you're using a framework like Express or just vanilla Node, the end results are the same. We've defined a maxAge for how long we want this HSTS header to be observed by the browser. In this case, I have set it to one year in seconds. Then the heart of all this is setting the header on the response when we call res. set or res, short for response. set, providing it the header, in this case, the Strict Transport header, and giving it the value of the header, which is the maxAge followed by the includeSubdomains and preload attributes. In order to put it in use, we need to come back over to the server. js file and import our function. So I'm going to come up here and just import that responseHeaderConfig from our configurations directory. And then I will come down here and invoke that function that we got back, which is in this case the response header, and we'll pass in our app that is listening on our secure connections, and that's all there is to it. So we're back over here in Chrome with the Developer tools open, and what I'm going to do is issue two requests to our site, both over HTTP. We should see in the first request that, indeed, it issues the 307 redirect we saw earlier, and redirects us over to the secure connection of our site. It's the second request where we should see the HTTP Strict Transport Security header come into play. So I'm going to go ahead and drop in our site, and make that first initial request over HTTP to it, and we'll see that, indeed, it has redirected us to the secure HTTPS version, and if we come up here to the initial request, we'll see that, indeed, it did make the initial request to hackershall. com, and receive the 307 Temporary Redirect in response. And we can see that the second request here was the secure connection to hackershall. com. But here's where it gets interesting. I'm going to come up here and make another HTTP request back to the application, and we can see again it has redirected us. But if we come up here to the initial request, we'll see that it actually did not put the request through. Instead, it automatically took the initiative to issue the request, the original request, and the only request, to the site over HTTPS instead. Now to show you another little tip and trick regarding Chrome, we'll come to another page that I have loaded up on a separate tab. It is the Chrome net-internals page, specifically for the HSTS and what is has cached for sites related to that. We can come down here because we see a field labeled query domain, and stick in our site and do a query on it, and, indeed, it has found that site listed in its cached list of sites, since it has received the HSTS header from our application. We could easily just dump it in here and delete that key, and it will allow us to make an initial HTTP request again. So you can come back out here to see if the site is sending out, and the browser is caching your domain. When we're talking about security, leaning on libraries that have been highly vetted by the community at large can help reduce the chance of reintroducing known vulnerabilities due to our programming misconfiguration or ignorance when it comes to implementing security measures in our application. We saw the use of the express middleware package helmet earlier in the course when we were talking about cross-site scripting. Helmet is a highly recognized express middleware, so if you're not using express, there might be something comparable, but helmet provides a number of great smaller security-related middleware, such as handling the HTTP Script Transport Security header for us. For now, we're going to go back to our responseHeaderConfig file and show you how easy it is to add the HSTS header using helmet. So I'm going to come back to our responseHeaderConfig. js file, and the first thing we're going to want to do is just go ahead and install the helmet Node package. And the 2. 3. 0 is the latest stable version for helmet. With that installed, I'm going to go ahead and close this terminal window, and back in our file I'm going to go ahead and import that helmet library. So now with that imported, I'm going to go ahead and just replace the function that we're passing to express middleware method, which is the use method here, and replace it with the use of helmets HSTS module. And what we're doing here is simply only initializing the HSTS module of helmet, and giving it an options object specifying the maxAge that we saw earlier. Now with helmet it defines it in milliseconds rather than seconds, but I still define one year, and also turned on to include subdomains, as well as the preload attribute. And that is all that it requires to use helmet to implement your HTTP Strict Transport Security header on all your responses. Before we move on, one last word regarding the preload attribute that we saw added to the HSTS header. The site, hstspreload. appspot. com, is a site where you can apply for your site to be included in the list of preloaded sites that certain browsers will pull from. There's instructions down here of what the requirements are that you must meet when you apply, followed by a review process for getting approval. Upon approval, your site will be included on that preloaded list that supporting browsers such as IE11 Edge, Chrome, and Firefox all pull from.

Introducing to Content Security Policy
Content Security Policy is another HTTP header like we saw with the HTTP Strict Transport Security header. However, the CSP header has a complete different objective. In case you missed the module on cross-site scripting, the primary use of the CSP header is to mitigate and report cross-site scripting attacks. However, we can leverage the benefit of the CSP header when it comes to serving our site over HTTPS. Early in the course we talked about the problem of having mixed content on a site, where the page might be loaded over HTTPS, but some resources embedded in the page are being requested insecurely over HTTP. I also mentioned that some browsers are actively blocking mixed content outright. Relying on browsers performing that security mitigation would not be in our best interest, so we can use the Content Security Policy header to notify the browser about how content should be loaded, or, in our case, what it should do regarding mixed content. The header itself is composed of directives and the vales that are assigned to those directives. As you might have seen from the module on cross-site scripting, the CSP header supports a number of different directives, allowing you to be very granular about various resources such as scripts, style sheets, images, and the list goes on, but the default, -src, is our catchall directive that we'll apply to a resource if it isn't specifically called out in its own directive. So as in this example, specifying the default -src directive with a value of HTTPS, states that all resources must be loaded over HTTPS or they should be blocked by the browser. There is another feature of the CSP header that we can use to our advantage. The report-uri directive allows us to specify a URL, but the browser will submit any policy violations in JSON format to that URL, or URLs. Though reports can capture and warn for any number of configurable violations, when it comes to warning against mixed content, we can use it to send reports about mixed content violations that occur. So let's look at how we can implement the Content Security Policy header into our application.

Implementing the CSP Header
Since the CSP header is just that, a response header, we're going to automatically include it on all responses. We can leverage our responseHeaderConfig. js file for doing just that. I'm going to paste in the code to add the CSP header to the response, and then we can dissect it. So here inside we will add an additional header on the response, and I'll paste in our additional set method for the response. Now there is a lot going on here, and there is definitely a cleaner more pragmatic way to implement this vanilla application of the Content Security Policy, but this approach makes it a bit easier to explain. Our site is using some resources outside of the application, such as fonts from the Google API. The main difference from our implementation of it earlier in the module on cross-site scripting, is the inclusion of the HTTPS, which states that the specific defined resource, as defined by the directives, such as style sheets, images, scripts, and so on, all should be loaded over HTTPS. One challenge when working with clients, such as browsers, is that not all of them work and behave the same way. When we're talking about response headers, browsers don't always implement the same feature the same way. Content Security Policy is one of those features, so getting the correct browser headers set can be a challenge. This is where using helmet, the express middleware, comes into play. Helmet does the heavy lifting of user agent sniffing in order to set the headers according to the agent. So let's see how we can implement helmet instead. So the first thing I'm going to do is remove where we are directly setting the Content Security Policy on the response here in our express middleware. Then, once again, I am going to pull in the helmet module. Now I'm going to go ahead and paste in the code that is going to instantiate the Content Security Policy module of helmet into the express middleware. And as you saw before, it looks very similar, except it's a lot cleaner, a lot more concise, and specifying the same directives that we were specifying before. So let's see how this works, and look at it in the browser once we are providing that header. So I'm going to go ahead and fire up our application. So we're back here in Chrome with the Developer tools open, and I'm going to go ahead and refresh our site here, and load it up, and we can come up here to the initial request, and I'm just going to extend this window so we can see a little bit better. And we can see that in the response headers, that indeed, the Content Security Policy did get set with the directives and the values that we had specified in helmet. But if you also notice over here on the left, there is an error of the cspviolation. Now in our directives, we had specified here the report-uri of /cspviolation. Now that uri does not exist, but I wanted to show you here what it would do in the case that a violation was triggered, we can come down here and see that the request payload that the browser is going to attempt to send is a notification that we are trying to load an inline script, and yet we have not specified the unsafe-inline value for the script directive. So it is triggering a violation, and the browser is attempting to send this cspviolation to the URL that we specified, in this case, cspviolation. So we can see here that we could use this to our advantage to set up a URL that accepts JSON, and be able to have those violations reported to our specified uri when certain violations occur. So as you can see, we could really leverage the Content Security Policy to both enforce that resources are only loaded over HTTPS, as well as monitoring that there is no mixed content within our site, by not only utilizing the directives to enforce those policies, but also to capture through the report-uri directive as well.

Summary
In this module, we had a chance to look more closely at utilizing the Transport Layer Security in our application to mitigate a number of security risks, by covering a number of topics, such as understanding the difference between the acronym soup of TLS, SSL, and HTTPS. The benefits of using Transport Layer Security, and how we can implement a server to serve content over HTTPS and redirect insecure traffic. Also, the importance of serving login forms and other sensitive data handling forms over HTTPS. Also, how the HTTP Strict Transport Security header can minimize the window of opportunity for Man in the Middle attacks, and how to implement them in our application directly, or through the use of supporting middleware such as helmet. Also, utilizing the Content Security Policy header to block content that isn't being loaded over HTTPS. Benjamin Franklin once said, "failing to prepare, you are preparing to fail. " As I mentioned earlier on in this course, application security isn't easy, and if we fail to make security a core component at the onset of our application development lifecycle, it could make or, as it has for many companies, break your chances of success. Lockmedown. com is a place dedicated to helping the everyday developer with the information they need to write secure applications through technical articles on application security and cloud computing. And finally, have you ever wondered what a narrative storytelling meets technology podcast would sound like. Well, look no further. The Lock Me Down podcast is unlike any other technology podcast you have ever heard. Mysterious, intriguing, and captivating stories? Check. Informative and instructional web security information for developers? Definitely. Crazy company security snafus? Absolutely. A monthly podcast that you won't want to miss, so stop on by, I would love to hear from you.
