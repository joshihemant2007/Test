Discover how the Node framework can help you write server-side code and build lightweight, scalable network applications.



Intro to Node.js
Intro to Node.js
You're online applications starting to fail It's crawling on the network just as fast a snail We need evented programming starting from the top Better write some code so the whole world doesn't stop With a non-blocking model we will be just fine Built on Google Chromes we ain't run time All you need to do is write some JavaScript code And use the Real Time Web with Node Hello, I'm Gregg Pollack, and you're watching Real Time Web with Node. js. In this level, we're going to give you a quick introduction to Node, talk about what it is, what it isn't, blocking, non-blocking, what evented programming is, and then finally what what that event loop is, that you've heard about with Node. So, let's jump into it. Node. js allows you to build scalable network applications using JavaScript on server-side. Underneath the covers of node, you're going to find the V8 JavaScript Runtime, this is the same Runtime that is used in your Chrome Browser on your client-side. What Node does, is provides a wrapper around this engine, providing additional functionality for building network applications. It's really fast. Why is it fast? Well if you looked under the covers of Node and this Runtime, you'd find it's all written in C, which obviously is very fast. So, what can you build with Node? Well here's a couple examples. You could build a Websocket server, so a good example of this is maybe a chat server, where you have your browser, lots of browsers connecting to the server and there's chat going on, you're sending messages back and forth between the client and the server, and this socket stays open. You could also do a file upload client, when you think about uploading big large files, you want to be able to do it in a way that's not blocking, so you can do more than one file at a time, and maybe even start processing the file, as you get the first few pieces of it. Also, you could create an Ad server, when you think about ads that get served on web pages all over the net, they need to be really fast. These are maybe images that are appearing on other people's websites, and they need to be able to be rapid and quick across the network. Also, any real-time data apps, so not just from on the internet, not just from your browser to your server, but any sort of network servers, maybe even local network servers, would be a good fit for Node. js Node. js is not a web framework, it's not going to replace Rails, it's not going to replace Django. It's very low level network communication we're talking about here. There are libraries that people have written that sit on top of Node to be a web framework, but Node at it's most basic level is not that. Node is also not for beginners, because we are talking about network communication. Node is also not a multi-thread application, when we write our applications with Node, we write them as if we're dealing with a single threaded server. Before we get into some actual Node code, we need to make sure everybody knows the difference between blocking code and non-blocking code. So here's some pseudo code to print some file contents. First, we want to read the file from the filesystem, set it equal to the contents variable, print the contents variable, and then do something else. So if we think about how this code executes, first, we read from the file system, we can't actually print out the contents until we've read out all the contents from the files, so it's kind of blocking here, and then obviously we can do something else. What would a non-blocking version of this code look like? Well, we might read the file from the filesystem, whenever we're complete with that, print out the contents from the file, and then finally, do something else. That technique there, saying, when you're complete do this, we call a callback. We're going to callback that function once the file is done reading. Executing the pseudo code, might go like this, where we read the file from the filesystem, we might do something else, though it's simply going to continue on, and then at any point in time in the future, when it's done reading the file, it's going to print the contents. Now, here's some actual Node code. First of all, the blocking version of reading out the file might look like this, where we're getting all the contents of the file, we're then logging that out and then doing something else, so obviously when this gets executed, it just runs one at a time. The non-blocking version of this in Node, is going to call readfile, and then look at this, we're actually sending in a function as the second parameter to readfile, that's our callback, and when we get the contents, log the contents, and then we can say doing something else. So when we execute this, as we mentioned, it's going to start reading the file, it's then going to continue execution, and when it's done reading the file, it's going to print out the content at some point in the future. Hopefully, this JavaScript syntax looks familiar, and there's another way we can write this, which would be just fine. We could declare the function, and set that equal to a variable, and then when we call refile we can send that function into readfile. Either syntax would work just fine, they do the same thing. Let's take a closer look at this code and let's see what happens when we're reading two files at the same time. First of all, if we had to do this in a blocking way, when we look at the timeline, if this was blocking, it would read one file and then the next file. However, since our code is non-blocking, if we read two files at the same time, they're going to read in parallel, and happen much quicker. Now, it's time for our Node. js hello world, or in our case let's do a hello dog. So, our first one in this file, we need to require the HTTP module, so we're including another library. This is how we include libraries typically in Node. We're going to call the createServer function. That function takes as it's single parameter, a callback with request and response, we're then going to write a 200 status code in the header for the response, we're going to write out the response body, and then finally, we're going to end the response connection. We want our sever to listen in on port 8080. Then, to ensure our server's running, we're simply going to logout, listening on port 8080. We run this server on our command line, we're going to see that it prints out listening on port 8080, and then if we use the curl command line tool to hit the server, it's going to return to us, hello, this is dog. We could also just call up our browser and go to that port, and we would hit the same result. Now, let's talk a little bit about how Node executes this code. The first time we go through this code and execute it, Node is going to register events. In this case, we're registering the request event, for whenever a request comes in. Once it gets done executing the script, Node goes into something called an event loop. It's checking for events, continuously. Did a request come in, did a request come in, did a request come in? As soon as a request comes in, it's going to trigger that event, and it's going to run the callback that we wrote and print our hello, this is dog. Now, you might be wondering, why are we writing JavaScript? Well, the creator of Node, Ryan Dahl, wrote this really good quote, which kind of explains why. I'll let you read it. So JavaScript, makes it really easy for us to program in an evented way, to do evented programming, using that event loop, and write code that is potentially non-blocking. When we run a Node application, like we said, it registers a bunch of events, like request, connection, or close, and those events sometimes even trigger even more events, and then we have this event loop, which is constantly looking for events, and once your application gets into that event loop, it can start triggering and emitting events into what we might call our event queue. So if a request event comes in at the same time, as a close event, well events are going to be processed one at a time on our event loop. Let's make our hello world code a little bit more complex, and simulate a long running process. So here we're creating our server, we write the status code back to the response, we write dog is running, now we're going to do a timeout, we're going to pause for about five seconds to simulate a long running process, once that timeout is done, we're going to write out dog is done to the response, and end the response. We're going to pause for 500 milliseconds, which is basically five seconds, and listen on port 8080. You might notice here, there are two different events in our code, we have the request event, which we should be familiar with from earlier, and we also have a timeout event. So every time a request comes in, it's going to create a new event, a timeout event, which will then be called back in five seconds. We're going to send in two requests to our hello world server with the timeout and see what happens. So, our first request comes in, triggers that request event, the request callback executes, a set timeout code registers and it's going to wait five seconds, meanwhile, another request comes in, triggers that request event again, the callback executes, the set timeout registers, and now this has to wait five seconds. And, when our first timeout is done, it's going to trigger that set timeout event, which will trigger the set timeout callback, and it returns that response. Then, our second request is going to trigger the event, and do the callback and so on and so forth. So, as you can see, two requests can happen at the same time, and nothing is blocking. What would this look like though, if that set timeout was blocking? Well, let's try it. So a request comes in, the request callback executes, and the set timeout blocks the world. It stops the world. Nothing else can execute on this process, while we are on a timeout, it is officially blocked. So, if a request tries to come in, well, it just has to wait for the sever to get unblocked. Once it is unblocked, it will trigger the set timeout event, and so on and so forth, and the second request gets to block the server again. Obviously, blocking is bad, and you might be wondering why would anybody write a programming language or a framework that blocks and stops the world. Well, you find this in a lot of programming languages, often when you do a call out to web servers, it'll block, when you're doing a read or write the database, it'll block, or when you're calling out to a C extension, it will block. And this is one of the reasons why people love Node. js, cause from the very start with Node, it's purpose was to be completely non-blocking, and all of the libraries that you'll find for Node are all non-blocking.

Events
Events
Your online application's starting to fail. It's crawling on the network just as fast as a snail. We need inventive programming starting from the top. Better write some code so the world doesn't stop. With the non-blocking model we will be just fine. Built on Google Chrome's V8 runtime. And all you need to do is write some JavaScript code And use the real-time web with Node. You're watching Real Time Web with Node. js and this is level two where we're going to be going over events in more detail. When we talk about events, you might think about the document object model in your browser, because the DOM triggers events and you can listen for those events, events like click, submit, or hover. If you want to run some code when those events get triggered, you might run some jQuery, for instance, listening for a click event, and when click event is triggered, you want to run some sort of function. This code effectively attaches that function to the DOM listening for that click event. Just like in the DOM, many objects in Node also emit events, and odds are if they emit events, they inherit from the EventEmitter constructor. The net. Server class inherits from EventEmitter, and it emits a request event, as we saw in level one. If we're reading a file and we call fs. readStream, it returns a stream which inherits from EventEmitter which will event the data event as we're reading data out of the file. Let's take a closer look at the EventEmitter constructor by creating our own custom event emitter. So we're going to require that class. For our custom event emitter, we're going to create a logger. So we want our logger to sometimes emit error events, warn events, and info events, and we want to be able to write listeners so we can listen for when those events occur. If we wanted to listen for the error event, we could write some code like this. So here we're saying on the error event, run this callback. To trigger or emit the event, we call logger. emit, we specify the name of the event we want to trigger, and any additional parameters here will get passed to the listeners. And here's just another example where we log another error message. And we can call this emitter as many times as we want to emit the error event. So back in level one, you'll remember we had a function with a request and a response, and we wanted that callback to be called every time our server emitted a request event. Here's the code that we wrote, but you might be wondering, what is going on here? How is that event getting attached? Well, we're going to go ahead and look at that a little deeper. We're going to dive into the documentation now and see what's going on under the hood. So if we look up the createServer function, we can see that it returns a new web server object. We pass as a parameter a requestListener which listens on the request event. If we look up the server documentation, we're going to see that it's an event emitter that emits several events, one of which is the request event, and you can see here the request event passes two parameters for the callback, which is what we're using as our only parameter to the createServer function. If we wanted to, we could write this code in a different way. Instead of sending the callback into createServer, we could instead just create the server with no parameters and then tell the server that on the request event, call this function. This syntax is typically how you add event listeners in Node. You can listen to multiple events on an object or you can have multiple functions that listen to the same event. It doesn't matter. For instance, if we wanted to listen to the close event on our server and call a function, we could simply write server. on close and then send in a function.

Streams
Streams
Your online application's starting to fail It's crawling on the network Just as fast as a snail We need a vented programing starting from the top Better write some code So the world doesn't stop With the non-blocking model We will be just fine Builds on Google Chrome We hate runtime And all you need to do is write some JavaScript code And use the real-time web with Node - You're watching Real-Time Web with Node. I'm Carlos Souza and in this level we're going to be talking about streams. When we're writing applications that depend a lot on network access and accessing files in the disk, one thing that we have to keep an eye out for is how the data is being transferred back and forth. Lucky for us this is where Node. js really shines. For ultimate efficiency and especially when we're dealing with large-sized data that's being sent across the wire we need to be able to access that data piece by piece or chunk by chunk. When that happens we can start manipulating that data as soon as it arrives in the server and keep it from being held into memory all at once. Streams are like channels where data can simply flow through. They can be of different types but we're going to be looking at the two most common, readable and writeable streams. In the streams API that we cover here is for Node version 0. 10, also known as streams2 API. Some of the code that we've seen in the course has already involved working with streams. The request object for example is a readable stream and the response object is a writeable stream. We read data from the request and we write data to the response. When we run this code, and issue a request from the browser, our sever responds with a 200 status code and writes dog is running to the stream. The browser automatically receives that response. Then we fire a set timeout for five seconds but the stream is still kept open. The channel between the server and the client is still good to receive data, so five seconds later we write again to the stream, this time dog is done. And finally, we close it. We've seen how to write to the response but how might we read from the request? As we've mentioned before, the request object is a readable stream and it also inherits from EventEmitter. This is a great combination because the request object can then communicate with other objects through firing events. The events fired are readable which is fired when data is ready to be consumed and end which is fired when the client is done sending all the data. Now let's write some code where we print to the console the data that we receive from the request. So, inside of our request handler we start by responding with a 200 status code, then we'll listen to the readable event on the request object. Inside of that, we declare a chunk variable. Inside of the while loop we're going to read out a chunk from the request and if it's not null we'll print it to the console. We have to call the toString function because the chunks we get they're buffers so we might be dealing with binary data here. Finally, we'll listen to the end event and when that event is fired, we just finish the response. With this code we're printing to the console the data that we get from the client. How might we change this so that we echo back to the client the data that we get on the request? All we have to do is change one line. In this case, instead of console. log, we call response. write here. Notice that we don't have to call the toString function. Response. write does that behind the scenes for us. When all we need to do is write to a writable stream as soon as you read from a readable stream which is exactly what we're doing here Node actually offers a helper method that we can use to pipe these two operations together. This method is called pipe. Pipe handles all of the event listening and chunk reading behind the scenes, so we can replace all of this code with this one line. Now, when we run curl from the terminal and send in the string hello we can see that string being sent back. In case you're used to the Unix syntax then you might remember pipe from the command line which streams the output of one operation to the input of the next one. Whenever you can, prefer using pipe over listening to the readable event and manually reading the chunks. This can help protect your application from future breaking changes to the stream's API which is still not stable. Remember that Node itself hasn't reached 1. 0 yet so it's always good to check whether a specific API that we want to use is stable or not and we can do that looking at the docs. Each core module has a stability score next to it. We can see that the file system module is considered stable with a score of three. This means that no major changes are expected any time soon. On the other hand, the streams modules is still unstable with a score of two. This means that changes to the API are still possible. So, next time a new version of Node comes out it's important to check for any changes on streams or any other unstable API that your Node application might be using. Let's go over another example of using streams. This time we're going to read the contents from a file in the file system and stream it to another file. So, first we require the file system module, then we create a readStream from the original file, readme. md and store that to the file variable. Then we create a writeStream to the destination file, readme_copy. md and store that on the new file variable. All we have to do is call file. pipe passing in the new file. Streaming is so powerful yet so simple to use with a pipe function that there's third-party libraries that heavily depend on it. One example is the Gulp build system. Gulp exposes the pipe function as its public API so you can do all sorts of manipulation on assets with very few lines of code. I suggest you check out Gulp's website to look at some examples of using streams in the wild. We can pipe any read stream into any write stream, so let's combine the two examples so we can read from the request and pipe it to a file, so we'll keep a write stream as is but instead of reading from a file, we're going to read from the request calling request. pipe and piping the content to the new file. Lastly, we'll listen to the end event and close the response responding with an uploaded string. Now when we run this from our client we call curl with the --upload-file option passing in a file as an argument and then we can see the response back. So, let's take a moment to visualize what's going on here because it's pretty amazing that Node supports this. So, we're streaming pieces of the file from the client to the server and the server is streaming those pieces to disk as they're being read from the request. At no point in time is the server holding the entire file in memory at once. It's all just flowing continuously and due to Node's nature, it's all non-blocking, so if you try to upload two files at the same time to the server we can see that our Node server can handle them simultaneously. One of the reasons that Ryan Dahl created Node. js was to deal with file uploads. If you've done enough web development then you're probably familiar with the whole drama that goes around implementing file uploads correctly. What a lot of web apps will try to do is to load the entire file into memory before writing it to disk which can cause all sorts of issues on the server side and affect all the other users of that same web app. And it's also tricky to be able to provide the file progress to the clients as the file is being uploaded. In Node. js we can actually do this quite simple, so let's look at how we can implement our own file upload with progress. This is what our uploader will look like. We need to be able to issue a request passing in a file either from the command line using curl or from the browser and then receive the progress as the file is being uploaded. To implement this, all we need is the HTTP module in the file system module which you've already been using from our previous examples. So, we'll start with their upload code which we already created. Then we need to know what the entire size of the file is and we do that by reading the content-length header from the request. We're going to store it on the fileBytes variable. We'll create the uploadBytes variable to keep track of how many bytes were uploaded and we'll initialize it to zero. Then listening to the readable event we'll loop through and read each of the chunks from the request. Inside of the while loop we'll increment the uploadedBytes variable with a length of each chunk. Then we calculate progress by dividing uploadedBytes by fileBytes and multiply it by 100. Then we send the progress back to the client using the response. write function. We use parseInt to round the progress to an integer. Down at the bottom pipe is still taking care of the actual upload for us and the only reason why we're using the readable event is so that we can keep track of the current progress. Now when we run our code, and upload our file we can see the progress. Nice.

Modules
Modules
You're online application's starting to fail, And it's crawling on the network just as fast as a snail. We need invented programming starting from the top. Better write some codes so the world doesn't stop. With the non-blocking model we will be just fine. Built on Google Chrome V8 runtime, And all you need to do is write some JavaScript code, And use the Real Time Web with node. You're watching Real Time Web with node. This is level four. We are going to be talking about modules. So in previous levels we brought in modules from other libraries so we could use their code. Remember we used the http library, and the fs or file system library. But how does require return these libraries? How does it find these files? And how might we create our own modules so we could share code between different applications. Let's create a really simple module. We'll call it custom_hello. js. It has it's own file. Inside there we'll define a function, which simply logs out to the console hello. In order to expose this method, make it public, we need to write module. exports = hello. Then inside of our application file we can write var hello = require custom_hello. Notice we have to do that dot slash. I'll explain why later. Then we just write hello to call a method, and it will work. Now let's write another module, and we'll define it in a different way. We'll write a goodbye module. Notice we'll just do exports. goodbye. Explicitly setting goodbye as a public method. Then inside our app. js, we can require the module and simply call it gb. goodbye. Notice in our first module, we can only set one object equal to module dot exports. That's going to be the only public method in this module. Whereas with goodbye, we could set multiple methods as public. Lastly if we wanted to, we could simply call the goodbye method in one line by requiring it and then calling the goodbye method. Let's create another module this time with three functions. Foo, bar and baz. Here you can see them visually represented. Now we want two of these methods to be accessible from outside the module. Foo, so we do exports. foo = foo. And bar. So we do exports. bar = bar. So inside our application to call these functions we require the module, and then we can simply call myMod. foo and myMod. bar. Baz on the other hand is a private function, which is only available from within the module. Let's write some code to do an http request, and then we'll refactor it into a module. So here you can see we require the http module. The message we'll send into the request is, "Here's looking at you, kid. " We'll have a couple of options that we'll need to set for the request. The host, the port, the path and the method. To initialize a request we'll call http. request. We'll send in our options. Then we'll pass in a call back function, which will be executed when the response returns. Inside of this function we'll listen for the data event, and we'll specify that when data gets received we'll simply log it out to the console. Now to write data into the request we're going to call request. write(message). We only want to write one message, so we need to tell the request that it's finished by writing request. end. Let's encapsulate this functionality so we can reuse it by first wrapping it in a function. So in this function we're going to send in the message, which is going to create the request. Then we can just invoke it by writing makeRequest "Here's looking at you, kid. " Let's shrink this code, and now we're going to to encapsulate this functionality inside of a module. We'll call it make_request. js. Remember, to expose this function we need to write module. exports = makeRequest. Then inside of our application we can require the module and simply makeRequest. So now let's jump into how exactly require looks for modules. Remember, some of the modules we're using don't have that dot slash. So what's going on there? When we require a module using dot slash, it's going to look in the same directory as our application for a file with that name. Make_request. js. If we did dot doth slash. Well, it would look up a directory. If we specify an absolute path, well, they would look in that directory as well. Now inside our app, if we just do make_request and we don't specify any sort of directory that it might be in. Well, it's going to search inside of a node modules directory inside of our current app. If it doesn't find it there, well, it's going to go looking for a node modules directory in our home directory. Then it will look inside /home/node_modules. And lastly it will look at the root path. Notice here it's going up one directory at a time looking for that module. Now you might be wondering, do you really put individual files inside these node module directories? That might get sloppy after awhile, and you would be right. Most of the time when you look inside a node modules folder you're going to see directories. Each directory is a package which represents a module. How do we find out about packages for application, and where do they come from? Well, they come from npm. If you're familiar with CPAN for Perl or RubyGems for Ruby, well, npm is where we find packages and modules for node. It comes with node. Basically it's this little command line tool just like RubyGems. It has a big module repository. That's where you'll be able to search for useful shared open source libraries. There's also really good dependency management built in. So if you have a package and it depends on other packages. Well, it's going to go and fetch those when you install that package. It's also easy to publish your own modules. So you can publish your own open source, and allow people to reuse your code. Npmjs. org is the website if you want to check it out. In our application we need the request package. In order to install it we can simply run npm install request like you see there. This is going to install the request package underneath our applications node modules directory. So it's going to create a directory called request and put all the files inside that package inside that directory. Then when we require this module, it's going to go look inside our node modules directory, find the package and include it. Some modules you might want to install globally instead of just underneath your application. For example here we're installing the coffee-script module globally with a dash g option. Coffee-script comes with an executable, so we can run coffee and then specify a file that we want to translate into JavaScript. One thing to note here is that a globally installed module can't be required from inside your application like you see here. It wouldn't work. In order to do that, we still need to install coffee-script in this case locally to our application, and then we can require it. So the next time you find yourself coding and thinking, maybe somebody already wrote this code. You might want to head over to the npm registry. You can search on there for existing shared libraries. You can also go to GitHub and search there. Or even on the npm command line if you think you might know the name, you can do npm search and then type in the name you think it is or what it does and you might get lucky and find a shared library. It's a best practice that when you're creating a node project that you create a package. json file. Inside here you can specify a lot of options. Here we're going to specify the name of the app, the version of the app. But the most important part here is we're specifying the dependencies. The modules that our application needs to run. Here you can see our application requires the connect module. And we're also specifying the version number that our application needs to run. Once we specify the dependencies, we may want to check that we have all of them installed. We can do that by running npm install. This is going to look inside our package. json file. And if there's any dependencies we don't have in our node modules directory, it's going to go fetch them and in this case install the connect module. If you start working on somebody else's node project it's not going to have a node modules directory coming with it with all the dependencies. So you're going to need to remember to run npm install so that it will go fetch the dependencies and create that node modules directory. Another thing worth noting is if you looked inside that connect folder that was just created, you would see another package. json file. And that might have more dependencies that the connect module depends on. So when you run npm install it's actually going to go and not only fetch your application's dependencies, but it's going to go fetch those modules dependencies as well. For example, connect might go and fetch the qs library, mime library and formidable library, and install that in its own node modules directory. Before we get into the challenges, we need to make sure everybody understands semantic versioning. This is what npm uses to version all of their modules. So in our library we were requiring connect 1. 8. 7. That one represents a major version of that module. The eight is a minor version. And the seven is a patch version. What's the difference? Well, a patch version doesn't change the API. It doesn't change the names of the functions you may call. A minor version probably won't. It's a little safer to assume it's not. And then a major version you can assume will. If you're developing a new app, you might want to make sure you're using the most recent technologies. So in your package. json you could write something like this. Connect and then ~1. What that's going to do is go and fetch the most recent version in between 1. 0. 0 but less than 2. 0. 0. Now this of course is going to be a little dangerous, because there might be minor versions that break things. But if you're starting an app you might be able to live on the edge. A little less dangerous you can specify ~1. 8. This would make sure the version is greater or equal to 1. 8. 0 but less than 1. 9. 0. The safest way to keep up to date with the most recent patch level would be to specify ~1. 8. 7 specifying the patch number. In this case it will look for versions greater than 1. 8. 7 but less than 1. 9. 0. For more information on semantic versioning, check out semver. org.

Express
Express
Your online application's starting to fail It's crawling on the network Just as fast as a snail We need to invent a program And starting from the top, Better write some codes So the world doesn't stop With the non blocking model, We will be just fine, Build some Google chromes, we ain't run time And all you need to do is Rent some JavaScript code And use the real time web with Node You're watching real time web with Node and this is Level five where we're going to be going over express. As you saw with Node, it's a very low level which means you're probably going to want to build a web framework if you're building a big web application or, better yet, use somebody else's web framework which sits on top of Node to build the big web app. Express is a Sinatra inspired web development framework for Node. Sinatra, in case you're not familiar, is a simple development web framework for Ruby. And it takes some inspiration from that, gives you stuff like Easy route URLs for callbacks, middleware and environment based configuration, redirection helpers and file uploads. So I guess you, a lot of codes, you're going to need out of the box to start building websites. In this level, we're going to go over some of the basics. To start building our Express App, the first thing we got to do is require the library. If you don't yet have installed, you can run npm install express and we're going to do dash dash save. What that's going to do is not only install the module in your Node modules folder, but also add it to our dependencies file. Our package dot Json. Next, we'll create an instance of Express by invoking the express function, then we can start defining end points. Here, we're going to define an end point at the root route so someone does a get request, it's going to call this callback resending in. Here, we'll call the response dot send file which will read in a file from our file system and send it back with a response. Lastly, we'll tell it to listen on port 8080. Now, if we run this code, we call up our browser, local host port 8080, we'll see that the index dot HTML got loaded. Now let's take a look at a more complex example. We want to create an end point where I can send in a Twitter username and it will call out to Twitter, get the latest ten tweets, and then display those back for our user. So to do that, first we're going to need the request module and the URL module, then we'll create a new get end point, which takes in the tweets and the username, notice the colon there, that means we have a dynamic username. Then we have our callback, with the request and response. Inside there, we'll grab the username out of the request parameters, request parameters dot username. So if that's Gregg or Eric, it's going to store that in the username variable. Then we have a bunch of different options we're going to specify from the protocol to the host to the path name to the Query. Then lastly, we'll call a request with our URL. The response will be returned back from that function call and we'll pipe the response back in to the response that goes back to our user's browser. Before I show you this code in action, there's one caviar and that is if you tried this code as it is, it wouldn't quite work. That's because of the Twitter API. It's changed since we wrote this code so that you have to authenticate even when you want to pull a user's Twitter stream and get the data back in Json format. So keep that in mind. You'll have to add a little more code if you really want to do this. Okay, let's check this out in action. First thing we need to do is start up our Node server. So there we go. Now, if we want to go ahead and hit that URL, we're going to use curl to go to local host 8080, and then give our Tweets slash eallam because that's the name of the Twitter user, we want to get the Json feedback and there it is. It's not that pretty. Luckily, I know another npm module called pretty Json, we can install that globally, and that will give us a little executable so we can pipe the output into that executable, pretty Json, and now we have pretty Json with all the information from that user's Twitter stream. Instead of simply piping the Json through, let's figure out how we might take that Json data and put it into our web browser using some templates. First thing we need to do is install a templating library. For this example, we'll use ejs which stands for Embedded Java Script. We'll install it with npm install ejs. By default, it will look for templates under the views directory. Here we are back in our application. Now instead of using Pipe, we're going to call request and give it a callback so that we can have access to the air, response, and body. The first thing we want to do is parse the Json which we got back in the response body. We'll set that equal to the Tweets variable. Next, we need to define what data is going to go into our template, so we can render out the Tweets. We do this by setting the locals property on our express response. Here, we'll pass in the retweets and the username. And lastly, we'll tell our response which template to render out. In this case, tweets dot ejs which stands for embedded Java Script. If we open up this template, we'll see that we have some HTML and in there we have bracket percent equals and then we've got name and then we end it with a percent bracket. That's telling our Node app to render that variable inside our HTML. Then we'll look at the list of the tweets and notice here, we're using bracket percentage and since tweets is nra, we'll do tweets dot four each and send in a function to invoke on each of the tweets. Inside of there, we can simply use a list item and then call tweet dot text. Because we know each tweet is an object which has a text key which contains the contents of the tweet. Then we simply need to end our four each function. If you're coming from Ruby nrl's, this probably looks really familiar. If you're not coming from nrl's, it might not. So again, we use bracket percent equals if we want the value that gets returned from the expression we put inside of there to get printed out into the page. So, in our case, name, want to print that out to the page. But, if we just want to run some code, in this case just iterate through nra, we just use bracket percent. So the result of going through that four each won't get printed out to the page, but every time we loop through that, it's going to print out another list item. Now, if we jump into our council, we'll run our Node app. Now if we jump over to our browser, we'll go to local host slash code school this time, and we've got all the tweets from code school.

Socket.io
Socket.io
Your online application's starting to fail It's crawling on the network Just as fast as a snail We need a vented programing starting from the top Better write some code So the world doesn't stop With the non-blocking model We will be just fine Builds on Google Chrome We hate runtime And all you need to do is write some JavaScript code And use the real-time web with Node. You're watching Real-Time Web with Node and this is level six where we're going to be taking a look at Socket. IO. Obviously this is called real time. Node is really good with real-time apps, so let's start building a real-time app. We're going to be building a chat application in the browser using websockets. Traditionally a browser's request and response cycle looks something like this where browser sends a request to the server, waits around for it to get back and then whenever it gets back it then renders onto the page. These days modern browsers have websockets. Websockets allow us to create a connection with each of our clients to the server. Over this connection we can send and receive data from the server back and forth in real time. However, we can't relay on every browser working with websockets, so we need to use a library or a module that has intelligent fallbacks in case the websocket doesn't work. In this case, we're going to be using the Socket. IO library. Let's install Socket. IO. We'll just do npm install, socket. io --save so it'll install it and also add it to our package. json. And inside of our application, we'll require the Express module, we'll initialize an Express application, then we'll create an HTTP server and have it dispatch requests to express, also we'll require the Socket. IO module and also allow it to use the HTTP server to listen for requests. So now Socket. IO and Express and sharing the same HTTP server. We'll then need to listen for connection events inside Socket. IO and when a client connects we're simply going to log out client connected to the console. For server. index. html file using the sendFile function we've seen earlier and lastly we'll have our server listen on port 8080. Now we're in the HTML that we're going to be sending through Express, we need to include the Socket. IO library. This will get loaded in our clients' browsers and connect to our Socket. IO server. Let's add one more thing to our connection event. Here we're going to call client. emit messages hello world so this is emitting the messages event on our client which in this case is our browser and we're going to send the object hello: 'world'. Then inside of our browser we're going to listen for that messages event. When it gets called, we'll call alert and then we'll have it alert the data that it received looking up the hello property which has a value of world. So, let's run our code. First, we'll start up our Node server. And if we jump into our browser, go to the right port, it'll connect using Socket. IO, send a message back into our browser and we'll get an alert pop up. We even get the log message that a client successfully connected. And every time we refresh it's going to reconnect. So, our browser's listening for messages but we're going to want to send messages from our browser when somebody types something into the chat rook back to our server. So, we also want our server to listen for the messages event and when it does, we'll log it out to our console for now. We then need to write some JavaScript code that will run inside the browser so that when somebody submits new code into the chat room in this case we're just going to do some jQuery, we'll hook on to the chat forum submit button so when somebody hits submit it will grab the message out of the chat input text field, grab the value from there, set that equal to the message variable. Then we'll emit that messages event on the server by calling socket. emit messages and simply send in the message that they typed into that form field. Now we'll start up our node server again and if we go into our browser, reconnect. Now, we'll jump back into our browser, type in hello, this is dog and we can see that hello, this is dog printed out back on the console and we can go back and forth and it works pretty well. So, we know how to send messages from the server to the client and the client to the server but this is a chat room, so we're going to be having multiple clients connecting to our server and we're going to need to broadcast somebody's text that they send to the chat room to everybody. Luckily, Socket. IO has a broadcast property and when you call emit on that broadcast property with messages, it's going to send them to all the other connected sockets. In this case, all the other clients in the chat room. So, now back on our server, when our server receives the message event, this time around it's going to call client. broadcast. emit messages, data, that's going to broadcast the message to all the other clients aside from this one that sent the message. Back in the client side we're going to revise the messages listener. In this case when we get a messages event we simply want to insert the message onto the screen and I'm not going to show you that insert message function but you can image it just uses some jQuery to insert that text onto the screen. So, let's run our server again. Go to localhost:8080. We're going to actually call up another browser and go to the same port, so we have two clients connected. So, now when we type in a message, we say hello, this is dog we can see that it broadcasted it to the other client. Then we can say hello, no, this is spider. And we can see that it broadcast that message to our other client and also logged it out to the console. But you might notice we have no idea who's saying what on this chat server. We probably need some usernames. So, how might we implement that? Well, maybe what we'll do on the server side is we'll create a join event. When somebody calls join, we'll assume they're going to send in a name variable and then we'll set a value on the client, client. nickname equals name. Sending values this way means that the value is available both on the server and the client. Then back in our client when we connect to the server we're going to print out a little status so we know that we're connected, then we'll prompt the user, call that simple JavaScript function prompt, what is your nickname? Then we'll take that value and emit the join event sending in the nickname back to the server. Now back in our server we need to change our messages listener so that before we broadcast the message we get the nickname of the client and then once we've retrieved the nickname we'll have a callback here which will then broadcast our message with our username. Lastly, if you're in a chat room you just don't get to see what you type in so why don't we just go ahead and emit the chat message on the current client, the one that invoked the message event so that when we type in some code and hit return we'll see what we typed back in the browser. Let's go ahead and try out this new code and when browser will go it should prompt us for our username, this one's Dog. Let's start up another browser and this person's nickname is Spider and we can see Dog joined the chat, Spider joined the chat. Now if we type in a message it shows us who's typing what.

Persisting Data
Persisting Data
Your online applications starting to fail It's crawling on the network just as fast as a snail We need evented programming Starting from the top Better write some code So the world doesn't stop With the non-blocking model We will be just fine Build some Google Chrome's The eight run time And all you need to do Was write some JavaScript code And use the Real Time Web with Node You're watching Real Time Web with Node, and you've made it to the final level. Level seven, where we're going to be talking about persisting data. So back in our chat app, if we say, hello, anyone out there? (laughing) And then somebody else joins. Connects to the server. It's of course, Spider, who else would it be. They're not going to see any of our previous messages. But that's typically not how chat applications, how you want them to work. So, let's figure out how we might persist these messages as they come in so that new people who join see the previous couple of messages. You'll notice here's our old code. We're on Join. We're sending the Nickname. We're broadcasting who joined the chat. And then on messages, when a new message comes in on the server side, we emit it to everybody else and we also emit it back to us. So let's jump in here. What we might do to store the messages, is create a messages array on the server side, where we're going to put all the messages. Then we'll create a store messages function. This function takes the name of the person who sent the message and what they sent and then we'll simply push onto the messages array an object with the name and the data which is the message. Then if our messages is greater than ten in length, we'll go ahead and shift one off, shift the first one off so there will only ever be ten previous messages, then down below in the messages listener after we get done emitting the messages, let's store that message that we just received. We're storing all the messages as they get received, but we need to go back into the join listener so that when a new client joins we iterate through each of the messages like you see here and emit to that client that just joined all the messages. So display them onto their screen. So if we jump back into our browser and we type a couple messages and we connect a new client, we can see that all the messages are there waiting for us. Now let's exit our server and restart it and go back into our browser. As you can see now that we've restarted our server, our messages array got blanked out and our messages aren't there anymore. So we need to think about how we can persist those messages even if our server restarts. One way to solve this problem is to use a database of some sort, luckily node works great with all sorts of databases from Mongo to Couch, Postgre, Memcached, Riak, Redis, they all play well with node and they all have non-blocking drivers. Lots of times in other languages that use these databases you'll find they have drivers that are blocking that means when you go to submit a SQL request, well your process kind of just hangs there, can't process anything else while it's waiting for the database to return, kind of crazy. Well node of course everything we write is non-blocking so that means you could have two queries and they both submit queries to databases and your process can do other stuff while it's waiting for these two queries to come back and then call the callbacks and then do more stuff pretty neat. So (mumbles) and luckily Redis has all sorts of data structures that we can store inside of its database. From strings to hashes to lists to sets to sorted sets. We're going to be using strings, lists, and sets. Now Redis has a great homepage, it makes it really easy to start playing with the different components and different data structures. So if we go into the documentation here the different commands and we look under strings, we can see that we can use get, we can even start playing with it right here in the browser. So we can say something like set newkey to set a value. We'll set for value dog and then if we get newkey we're getting back dog, so newkey is our key and then dog was our value. Now let's jump into lists. We're going to be using the Lpush list command. We can take out the syntax and then we can start pushing things onto a new list, so let's give that a try. We'll push onto our new list dog we'll push onto our new list cat and then we'll use the Lrange command to get back the values out of it from zero to negative one, giving us all the values on the list. To connect our node applications Redis we're going to be using the node Redis library this is where you can find it on Github, to install it we call just npm install redis dash dash save, so that we can install it and add it to our package. json. Inside of our code we simply require redis then we can create a redis client by calling redis. createClient then we can start issuing commands to the database. We can call set message1 hello this is dog, set message2 hello no this is spider, so we're setting the keys in the values. To get the messages out of the database we simply call get and we send in a callback this goes with that non-blocking thing we're going to get this out of the database but while it's fetching it we can go off and do other stuff and then when the value comes back from the database it will invoke this callback function and log it out to the console. If we want to store a list in the redis database we could create a message and lpush left push onto the messages list this current message and specify a callback here. This callback is optional but it sends back in the reply variable here the list link in case you need it. If we add another string of messages you can see here that it returns the length of two. Instead of logging out the length of the array to the screen we're going to use the Ltrim function, the Ltrim function in this case we're going to send in zero and one it's going to keep the first two strings in the array and remove the rest. If we want to retrieve the values from the list we can use Lrange remember we saw that before sending in zero to negative one which will return all the elements in the list. If we log them out to the console here's what we would get. If we jump back int our old code you can see here's our store message function and we need to rewrite this to use Redis. First we need to create our Redis client and then inside of our store function we need to take the name and the data that we send in, put them into an object, and then call json stringify which will turn that object into a string we can easily store in Redis. Then we'll call Lpush send that in as a message and then call Ltrim so it'll keep the newest ten items in the array. Here's our old join listener where we're iterating through all the messages when somebody joins and putting it onto the screen. We'll modify this code to use Redis, first fetching all of the list items with Lrange then we'll reverse the messages so they're emitted in the correct order, then we'll iterate through each message that gets returned in that list. First parsing the string that gets returned into a json object and then finally emitting that to the client. Here we are back in our browser, we say hello everyone it's me. Now if we connect another client, and they type in their name we'll see it properly loads a list from Redis and broadcast it into our browser. If we exit our server and restart it, we open up a new client give it a new nickname and we can see it's properly loaded all the old messages from Redis even though we restarted our server. There's one more thing we need to do to create this chatter application and that's to show a list of who is currently in the room who is connected. We're going to do that using a set, sets are lists of unique data, we can't have duplicates. To store a set in Redis we're going to call Sadd and then specify the set name in this case names and then the value we want to send into the set in this case dog and then spider and then Gregg. To remove an item we simply call Srem for remove and send in the set name and the value we want to remove. (mumbles) all the numbers of a set we call smembers sending in the name of the set in this case names and then we'll specify what to do when the set gets returned. In this case log it out to the console. Now we need to jump back into our join event listener on our server. When somebody joins the first thing we need to do is we're going to emit the add chatter event we're going to broadcast it to all of our clients so we can add that chatter, then we need to add this chatter to our Redis set. We're going to call the set chatters. Now back in our client we need to define the add chatter listener and this will invoke a callback that receives the name of this new chatter and here we'll simply build a new jquery element with the new chatter's name and then append that to the chatter's element. So we add this new chatter when they join and we let everyone know about it but what if there's already chatters in the chat room, what if there's already users in our set? We need to check for that, so we'll use our Redis client to list out all of the people in our set all the names, and then on that callback we'll iterate through each of the names and then on our client which is connected, we'll emit add chatter and send in each name. The last thing we need to do is remove a chatter when their websocket disconnects. So we'll say on the disconnect event get their current nickname, broadcast the remove chatter event to all of our other clients and then remove them from our Redis set then on the client side we need to listen for that remove chatter event and when that gets called we'll simply use some jquery to remove it from the list. So now if we jump back into our browser we can send in the message you'll notice dog is already connected, we'll start up a new client and look we can see that both spider and dog are connected users. Let's see if we can connect another client, so here we'll connect Gregg and we can see that all three people are in the room. And everybody can see who is chatting.


