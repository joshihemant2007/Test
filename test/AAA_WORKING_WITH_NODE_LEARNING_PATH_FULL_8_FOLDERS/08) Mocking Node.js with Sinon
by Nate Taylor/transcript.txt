Creating unit tests that are independent of external systems can be difficult and intimidating. In this course, Mocking Node.js with Sinon, you’ll learn to use the Sinon library for mocking external dependencies while testing your code. First, you’ll explore why mocking matters. Next, you’ll discover the differences between mocks, stubs, spies, and fakes. Finally, you’ll learn how to use a mock in your unit tests. When you’re finished with this course, you’ll have the skills and knowledge of using mocks needed to write unit tests isolated from external dependencies.

Course Overview
[Autogenerated] Hi, everyone. My name is Nate Taylor. And welcome to my course mocking Know Js with signing I am a solution architect at Amateur in Omaha, Nebraska. Creating unit tests is a skill just like any other part of software development. And creating unit tests that are independent of external systems can be tricky and intimidating to solve that in this course, we're gonna cover spying on functions to see what they're doing, stubbing out functions to control how they behave and mocking functions to verify the behavior is correct. By the end of this course, you'll know how and just as importantly, win to create spies. Stubbs fakes and mocks for your unit tests in Know Js Before beginning the course, you should be familiar with no Js and have a basic understanding of what a unit ______. I hope you'll join me on this journey to learn sign and Js with the mocking know Js with signing course at portal site

Spying on Functions
Spying on Functions
[Autogenerated] using fakes or test doubles. When writing tests can often become a stumbling block, it can make testing go from a simple, if not time consuming, activity, the one that requires more abstraction and focus. Writing tests against functions that don't have external dependencies is usually pretty straightforward. After all, testing a function like sub total on the screen depends on Lee on the parameters passed in. However, when it comes to testing functions like create, the PATH forward can be a little unclear. It might seem simpler to avoid test doubles and just call the function as it is, and then check the result that you wanted is in the database to make sure it worked. But what might initially seem simpler can often be more difficult and require more work than utilizing fakes. For example, there are two tests on the screen. The first test creates a new file named test dot text. It checks out. The result is undefined because a successful file creation will return undefined. The second test deletes a file named test dot delete, not text. As with the first test, it checks that the result value is undefined because a successful deletion will also return undefined in the terminal. All execute these tests by running the command in PMT. A quick aside here in PMT is the same is running in P m test or in P M run test. It's just a short cut. When these tests run, you can see in the terminal that both of the tests past. Additionally, you can look at the File Explorer and see that the file test dot text has been added and the file test dot delete dot text has been removed. But what would happen if we re run these tests? When you re run the tests? Both tests fail, and when you look at the terminal, you can see the two separate errors. The 1st 1 tells you that the file already exists. Test dot text, which tells you that you can't create the file because a file by the same name already exists. The second heir is actually the opposite case. It says that there's no such file or directory for test dot delete dot text. In this case, the application is unable to delete a file that does not exist. This situation is pretty common when it comes to testing and it's at this point that you as a developer are faced with a choice. On the one hand, you could write your tests to ensure that the file system is set up before each test run. That is, you could make sure that test dot delete dot texts exists, and that test dot text does not exist. Your other option would be to use a test double toe help make these tests Maur repeatable. At first blush, the first choice might make sense. After all, it's only two files, and you could accomplish that with a function like before. Each and creating two files is probably easier than learning a new library such a sign in. But that easy solution is actually a trap in disguise. Sure, right now it's only two files, but what about when you want to verify that a file is able to be updated or what? If the files are improperly cleaned up between test runs, then you'd have a mix of some files you need and others that you don't. It's usually around this time that developers start to wonder if testing is even really worth it, particularly when they seem to be writing more code for their test harness than they do for their application. There's good news, though. Using a faking framework helps simplify the case. Sure, there will be a learning curve as you add a new tool to your toolbox. But that tool, in this case, Sinan, will help you become better at testing. In fact, if you've ever used consul dot Log when you've been debugging, then you're already on your way to using a spy. Up next, I'll show you how spies can be thought of as the test equivalent of consul dot log.

What Is a Spy?
[Autogenerated] one of the first pieces of Java script that I ever learned was window dot alert and then later console dot lock. It was a way for me to check that my code reached a certain point. How can a spy be compared to counsel dot log To start, we need to talk about what a spy really is. A test Spi is a lot like a real life spy or possibly just your nosy neighbor. Perhaps you've had a nosy neighbor growing up. I know I did. That nosy neighbor knows all about your family. They know what time you leave the house and how long you're gone in what time you get back. They know about the last time that you mowed your yard and they can tell you how many times the UPS driver dropped off packages this week. They know a lot of things that go on around your home. If someone wanted to know if you were home, they could ask your neighbor and learn not only that, you are home, but you've been home for a couple hours and you're probably gonna be leaving soon to go to the grocery store. A test Spi is a lot like that neighbor. But instead of knowing about you, your family in your house, they know about your functions. Sinan defines a spy as a function that records arguments, return values the value of this and exceptions throne, if any, for all of the function calls. Once you define a spy, it can answer some basic questions for you, such as what arguments were passed to that function. What value did that function return? Did that function throw any exceptions? Or how many times did that function get called? The 1st 2 questions might seem a bit odd. That is, Why would I need a spy to tell me what parameters were sent to a function or what values were returned. After all that, we already know that information. For example, if we have a function named sub total that sums up all the items in a list, we might call that function like you see on the screen. We would already know that we passed in an array with two objects, and we would also know that the value of the sub variable would be 5 79 So how does the spy really help us The answer is that if you were testing the sub total function, you would not spy on sub total. Instead, you'd spy on some function that is called within sub total. Let me emphasize this because it's very important when you start using test doubles like spies never spy on the function that's under test. Let me say it again because this is often the first mistake that people make when they start using fakes. Don't spy on the function that's under test. Okay, so you're never gonna fi on the function that's under test. What functions should you spy on? Imagine. You have a function called Create User, and that function will create a new user object and then save that object to the database. It might look something like the code you see on the screen. For all intents and purposes, this is pseudo code. But what it's doing is creating a new user and then saving it to the user's table. In this code, you would not spy on create user because that's the function under test. Instead, you'd want to spy on D b dot safe. This would let you know if d b save ever got called more than that, it could answer those four questions from above. What arguments are passed into that function? Users and a user object? What value did that function return? The user with its idea signed? Did that function throw any exceptions? No. How many times did the D B save function get called? Just the one time earlier, I said that this function Spies was parallel to consul dot log. How is that true? Well, I don't know if you're like me, but before I started writing tests, if the create user function was causing me problems, I might add some council log statements to it. It might look something like the code on the screen where I have to separate console log statements. Then I would run my code and I'd look at my console to see what was output. When new user was logged out, I'd know the value of user that was going to be passed into my safe function. And when the Userssaved value was logged out, I would know a couple things, one that my save function was called, and two it didn't throw any exceptions. Armed with this information, I'd be more equipped to debug why my user wasn't showing up in the database. Of course, if my userssaved didn't ever show up in the console, then I know either that the function never got called or that it through an exception. And in some ways, that's the peace of mind that spies were providing you. They're letting you be that nosy neighbor and see what a function inside of your function is doing. If you ask your spy, it'll tell you if something was called or not and how many times it was called. Now that you understand what a spy is, it's time to get into the code and start using them up. Next, I'll do a very quick walkthrough of our sample project to make sure we're all on the same page before diving into creating spies.

Getting Set Up
[Autogenerated] in order to understand test doubles such as spies will be using a very basic node Web application. Getting that application set up will be pretty straightforward. Let's start by taking a look at the application. When it first loads, you can see the screen is split into a blue column and a white column. The Blue column has an input field and button at the top. If you type in that field and click the button, it'll add a new file to the blue section. When that file is highlighted, what you type on the right side will be the file contents. If you save that file, you can see that you can switch back and forth between the files and the contents. Update. This is a tool that global Mantex uses on their Internet. For editing, you kind of think of it is a very rudimentary knowledge base, and while it is rudimentary, it'll have several functions that will help demonstrate how test doubles work. For example, we'll end up using our test doubles as we create files and read files from the file system to get the code head over to the get hub repo. You see on the screen mocking node with Sinan Clone this repo down to your machine. If you'd like to follow along while you're on this page, check out the branches. In addition to the master branch, there's five other branches. There's replacing functions with Stubbs simplifying fakes, spying on functions start and using mocks to isolate. There's one branch for each module. In this course, each of these branches will have all the code that is completed through that module. For example, the spying on functions will have the code we write in this module. The replacing functions with Stubbs will have all the code from both East Spy and Stub module. The START branch is where we'll start in this module. I'd strongly recommend you follow along with the code in this course. And don't worry if you get stock, because you can always check out the right branch and see the completed code. For example, if you get stuck on this module on spies, just check out spying on functions and you'll have the completed code for spies, so you can use this as a safety net that gives you freedom to try out an experiment. Now that you've got the code pulled down. Open that folder in your I d. E. I'll be using V s code, but any I d that you're familiar with will work. Then make sure you're using the start branch. The next step, as with all note projects, is to run in P M install to make sure that you have all of the necessary dependencies. Well, that's installing. Take a look at the package dot Jason file. There's three libraries to note in particular. The first is Mocha. This is our testing library. You don't have to use Mocha for signing to work, but it's my personal preference, and so that's what we'll be using in this course. The second library is Chae. This is a library that pairs with Mocha to give it some expanded assertions and testing. Again. It's not required, but my preference and then the third library sign it. This is the library that the course is all about. This library will provide us with various test doubles for all of our tests. While you're here, I notice that there's only two commands in the scripts section. Those are Start, which will run the Web application that you just saw, and the second is test, which will run the mocha tests. We'll be spending the bulk of our time with the test script, but you can still run. Start to see the full blown application if you want. Next, let's take a look at some of the files in the application. If you run the Web application, the index dot Js file will be used to manage all the various routes, such as adding a new file. The files in the Views folder are the E. J s views for the application. For example, there's a header file for the global Mantex header that we saw. The public folder has CSS and images for the application, and the data folder is where the files are stored. Remember earlier we tried deleting the test dot delete dot text file in our test. This is where that's violas stored. You won't be touching any of those files I just mentioned for this course. In fact, unless you want to look around and see what's in them, we won't even be opening them because the course isn't about building a Web application. Instead, it's about mocking out node functionality using signing so that only leaves a couple of files that you will be either manipulating or looking at. Most notably, there's a file dot management dot Js file. This file exposes some functions for file manipulation. You can see the top that it requires the F S module from node to do file system manipulation. You'll be looking at this file for reference, but for the purpose of the course, you won't need to modify this file. Then there's the file file that management dot spied on spec dot Js. This is an example of a file that you will be modifying. This is the test file for Foot, the file management module. One thing to note here, I do not recommend breaking up your tests into a dot spy or dot stub file. I'm only doing that in this course for two reasons. First, I want to provide an easy way for you to look up. Use cases later. If you forgot how you created a spy, you can quickly jump to the dot spy dot spec file and see. And second, while learning test doubles, there's some overlaps between the various kinds, and creating them in separate files helps provide a little bit of a simpler way to organize those duplicate examples. But remember, in a real application, your test files will be a mix of Spy Stubbs fakes and mocks, and that's okay, Okay, enough talk. Let's get into creating some spies and see these things at work up. Next, I'll walk you through the spy function and the two things that you need to do in order to use it.

Creating a Spy
[Autogenerated] with Sinan Spies or the basic building block that is there. The simplest thing you can do with Sinan and creating spies is pretty straightforward Star by loading your I d. If you open the file file that management dot spied out specked at J s, you can see that it has one test and it's not that great or even useful, so we'll want to replace it for our first test. We want to verify that the create file function works correctly. So start with a new describe lock inside of file management. Inside of that block, add a new it block for our first test. We want to make sure that our function create file actually calls right file sink. This is the function from the F S module of node that will actually save our file out to the file system. So let's start by adding the line for the function under test and that's file management dot create file. Let's pass in the file name test dot text. If we were to run this file right now, the only way we'd know that it called right file sink would be to look at that data directory and that's not very automated. So let's create a spy before the create file line at a new line and create a spy called Rights by Let's take a look at the line. We just added Spy is a function that we required. At the top of our file system from Sinan F. S is the module that we want to spy on. As with spy, we required this file At the top of our test right file sink is the function in the module that we want to spy on and write. Spy is our spy. We'll use this variable in this test to verify our behavior. Next, let's add our expectation. We'll do this after we've called Create file before running the test. Let's look at our expectations statement a minute. There's a function on our right Spy Variable named called With This Function will return True. If the spy is called with the parameters you specify, it will return false if it's either not called or called with other parameters. In our case, we're passing in test dot text, but we know the module places that file in the data folder, and we also know that when it writes the file. It writes it with no text. So that's where are empty string comes in. But if you open up the file management dot Js file and look at the create file function, you'll see there's actually 1/3 parameter. It's an object with a value for the flag key of W X. This is the right mode for right file sink. It tells the function to throw an exception if the file already exists. But what it does matters less right now than that. It's there going back to the test. Notice that while right file sink has three parameters in our file, our test is only checking for two. This is a feature of signing. It will only check the perimeters, you specify. If you only specified the name, it would ignore the second and third parameters. It lets you focus your tests on the details that you care about. Now that we've got this, let's run our test and see what happens when you run it, you get an air. It tells us that it expected the value of false to be true, Which means signing doesn't think right file sink got called, However, If you expand that data directory, you see that the file is there. So it seems quite likely that it did, in fact get called. So how did the file get created? But the test failed. Will join me in the next clip to see why this test failed and what we can do to make it pass.

Using a Spy
[Autogenerated] We just saw a spy get created. But our test still fail, even though from what we can tell, the function actually worked and our tests probably should have passed. Let's return to that test file. Do you have any idea of why our test failed even though the file was created? If not, that's okay. Let's write a second test and see if that sheds any light on the problem. Start by copying the first test and let's modify the name so that we're not confused. Let's upend dash injected at the end. Next, let's call a slightly different function, one named create file Injected and let's pass in F S as a second parameter before we run this test. Let's make sure that we're on Lee gonna run this test, So rename it to it. Not only, And let's also make sure the test dot text file is deleted so that we can see if it really gets created or not. Now let's run our test with in PMT, just like last time the file is created. But unlike last time this test passes Does comparing these two tests give you any clues about why one passes and the other fails. If not, that's okay. It's not exactly obvious. In the second test, we take the F S module that has been spied on and we pass it into our function. If we look at the create file injected function in our file management file, well, see that it uses the past in F s to call right file sink as opposed to the right file sink that's required at the top of the file management module. Let's return to our spec file in the first test. The F s that file management is using does not have a spy on the right file sink function. Only the second test us. I can tell you from firsthand experience that it's very common to think you've got everything set up correctly only to realize later that your function under test isn't actually using your spy. Assuming we don't wanna have to go on, modify all of our functions to take in an extra f s parameter. How could we make our first test work notice Line five of our module. This is where we required our file management module and then notice line 10. This is where we decided to spy on F s dot right file sink. The problem is that by the time we get to line 10 the file management module has already brought in F s. And so lying 10 while spying on F s doesn't actually do anything inside a file management did solve this. We need to change how we bring in file management. We're going to use proxy choir here, which is not specific to sign it. However, it's a library that proxies a require statement to use a different object. In our case, we're going to want to intercept the require for F s and send it our faked out F s. And we do that with a proxy choir function inside of our test. This tells proxy Choir to bring in file management and to set the F s module that file management might want to use with our mocked out F s module. Let's once again delete that text file in this time replaced the Onley on our second test with a skip to tell the test runner that we don't want to run that test now run the tests again, and this time our first test passes, which means that right file sink was called with our two parameters. It was called with data slash test out text, and it was called with an empty string. Now that we've successfully written a test that verifies our right file sink function is called, Let's add another test to make sure it's not called when it shouldn't be. Let's copy our first test and let's change the name to should not create a new file If no file name is specified. Next, let's delete test dot text as a parameter from the create file function. If we look at our create file function in the file management module will notice that if the file name is not supplied, it will throw an exception. So let's update our test case to handle that. And finally, let's update our expectation. We don't want our right spy to have been called it all. So let's state that let's delete our test out text file again. So we kind of see the tests at work. And this time, let's run the tests and make sure that when we do not specify a file name, we don't try to create a file. And when you run that test. You'll see you have one passing test, one pending test, which is the one that has the dot Skip on it and one failing test. And you're failing. Test has this error message attempted to wrap right file sink, which is already wrapped. That's, ah, somewhat cryptic error message. But in the next clip, I'll show you exactly how to fix it so that even this test passes.

Restoring Spies
[Autogenerated] So far, we've been unable to run multiple tests against right file sink, but with just a tiny bit of setup, we can fix that. Head back to the spec file noticed that both line 10 and 18 create a new spy on the function right file sink. And that's on the F S module. And this is where the problem starts. Notice, though, that both tests to create a new variable for the spy. So it's not a scoping issue, that is, It's not that right. Spy is in a global scope and it's re used elsewhere. Instead, it's an air raised by Sinan. Essentially, you have created a spy on lying 10 and then you tried to create the exact same spy again down online. 18. Based on how Sinan works, this won't ever work because F s dot right file sink is already spied on. And you don't want to spy on a spy Thankfully, sign and provides a way to reset this spy after a spy is used. You can call the restore function on the spy to restore the spied on function back to its native function. In this case, it means f s dot right file sink would no longer be spied upon. Its just the normal right file sink. But where should you call this restore function? Let's do it. After our expectation in both of our tests, let's run in P M t again to run our tests. You can see at the top that that didn't really do anything. We're still getting the already wrapped error message. You have any guesses on why that's the case? If you look even further up, the first test is failing because we didn't delete the file when that test failed. The restore function never got called, which means for Test two. We're still getting the same air. Thankfully, Sinan provides a concept of a sandbox that will greatly help us out. Starting several versions ago, Inversion five the library made sign in a sandbox by default. So if you see code out in the wild that uses create sandbox, just know that that's the old way of doing it. Let's start by removing those restore statements we just added. Then let's update the require statement for Sinan instead of requiring spy, require the sign and library next update each of the three tests instead of rights by equals spy use rights by equals sign in dot Spy Then we just need one more step we need to add. And after each function to our describe, if you're not familiar with moka, the after each function runs after each and every it function, so it will run and it function, and then it'll run after each to restore sign in, and then you run the next test and then a run sign and restore again, and we'll keep doing this until all of the tests have been run. So delete the test dot text file and then hop down to the terminal and run your tests one more time. I'm gonna clear out the terminal so we have a fresh start and now we have two passing tests. Of course, we still have our one pending test, but that's expected. We're now verifying that we're calling right file sink or if we do not pass a file name, we're verifying that we are not calling right file sink. Let's run our tests once more, but this time, don't delete the test file that was created in the first test on this test run. We now have one passing and one failing test. Our second test now passes even though our first test fails. That is the after each function runs after every test, regardless of if that test passed or failed, or even if it through an exception. And in our case, that means that it restored the right file sink back to its original state before running our second test. But let's look at that first test failure. It's throwing an exception. It tells us the file test out text already exists. This seems to indicate that perhaps a spy might not be the best way to test this function. So what would be a good use case for spies?

Why Use Spies?
[Autogenerated] We've covered spies quite a bit in this module, but we haven't really discussed when they're good and when they're not, let's start by reminding ourselves what a spy is. We started by talking about how a spy is a lot like that nosy neighbor. Just as a nosy neighbor knows about everything that goes on around your house, a spy knows what goes on with your function. Specifically, it can answer some basic questions for you, such as what arguments air passed into that function. What value did that function return? Did that function throw any exceptions? How many times did that function get called as you've already seen? A spy accomplishes this with various assertions you've seen called with and not called. But these aren't the only things you contest. You can also check how many times a spy was called with the called Count property, whether or not the spy through an exception with the through function or what object the spy returned with the returned function. You can also get pretty specific about how the function was called. You've already seen called with, but you could also make sure that a list of perimeters matches exactly that is, if you specify two parameters and the function was called with three, the test would fail, and you can accomplish this with the called with exactly function or if your spy is called multiple times and you want to make sure that every time it's called, it has a certain parameter you can use. The function always called with this is in contrast to called with, which will return true as long as the spy was called. At least one time with those parameters, always called with will only return. True if every indication had the parameters that you specified, I've shown a lot of functions that return truer falls, for example, called with when those past It's great, but when they fail, you're not exactly sure why they failed. Did it fail because the function wasn't called at all? Or was it called with a different parameter? If you want to be able to write Maur expressive assertions, you can use a combination of get call and our eggs. For example, if you wanted to verify that a spy was called with test dot text, you could use the code like you see on the screen, Spy dot Get call zero to get the first call and then argh! Zero to get the first argument, and you expect that to equal test out text. If this test failed, it would tell you something like expected my test dot text to equal text dot text. Regardless of which of these functions or properties you used, the spy is only telling you about what's going on with your function. It's not changing anything about your function, much like your nosy neighbor can tell you what happened around your house during the day. But if they saw it on fire or someone trying to break in, they're not gonna do anything to prevent that. That is, they can give you a very detailed report, but they can't do much to truly help you out. We already saw that with one of our tests. While we were spying on right file sink, we were able to check that it was called and even verify that was called with the right parameters, but we couldn't stop it from creating a file, and that led to some problems, as we saw in the last clip. If you don't delete that test dot text file. After each test run, you'll get an exception in your test will fail. In this case, we're breaking a general rule of unit tests. That is, the test should not pass or fail based on an external system. In our test is failing because of file already exists. The failing test is not solved by changing code, but rather by changing the system. All of this indicates that spies are very useful if you just need to monitor a function going back to the example of consul dot logs. Spicer. Great. If you want to know that you got to a certain line of code or if a certain function was called, but they're not good if you want to prevent that function from actually happening, that is. If you wanted to check that right file sink function was called but also prevented from writing out to the file system, then spies are not a good match. Now you know some good use cases for using spies and, just as importantly, some bad use cases. The question is, if spies are bad for these use cases, what can we use? Instead? I'll show you that answer in the next module

Replacing Functions with Stubs
Replacing Functions with Stubs
[Autogenerated] you've already learned about the most basic test double that. Sinan has the spy, and you learn that while it's good for some things, there's definitely cases where it can be frustrating to use. This module will tell you about the next test. Double that signing offers the stub. If you remember the spy module when we introduced you to a spy, we compared them to a nosy neighbor. They could answer all sorts of questions about your functions, but beyond that, they couldn't do much. A stub is a step up from a spy. A stub can be thought of as a stunt double. A stunt double looks like the original character. He's going to be the same size and shape, but his job is to make sure that the main character doesn't get hurt during the movie. So any time there's going to be an _________, _____ or some other kind of dangerous situation, the main character steps out and the stunt double comes in. This is very similar to a stop, but with testing, we're hopefully not experiencing any kind of explosions. Instead, are dangerous situations are connecting to a database, manipulating files calling out to an a P I or any other kind of external system that we might use. These are dangerous because we don't want to experience any side effects from running our tests. Once a stub is put in place, some of the things that you can have it do include. Return a specific value throwing exception, resolve or reject a promise, or call a separate fake function. Each of these give you the test creator the ability to control the way that your test runs without spending a lot of time setting up external systems. For example, earlier in the course, we saw two test conditions that could easily fail if the system was not configured correctly. If the file we were deleting didn't exist, they would throw an exception. Similarly, if the file we're creating did exist, it would throw an exception rather than taking time to configure the file system. In between each test, Stubbs allow you to configure the environment solely in your test. So do you think you're starting tohave an understanding on Stubbs? Great. Coming up. I'll show you just how easy it is to stub out the right file sink function that we saw in the last module

Creating a Stub
[Autogenerated] spies are the basic building block for signing incidents. Stubbs Build on Top of Spies You already know a large portion of what you need to know. To start using Stubbs, you can start by checking out the Spying on Functions Branch to start with the code that last module ended with. Or if you're continuing on with the code from the last module, make sure you create a file named File that management dot stub dot spec dot Js. Notice that there's four require statements at the top. Then we have our describe block for file management before continuing on. Let's make sure this test suite is the only one that runs so open up. File that management dot spy dot speck and add a skip to its top level describe, then go back into the stub dot speck. And as we learned in the last module, we need to set up our sandbox so we can easily restore our stubbed out functions back to their original functionality. So we'll do this by requiring signing. Then we'll add. And after each inside of our describe lock, now we're ready to write our first test. So let's delete this useless if true, equals true test. Let's start by verifying that create file writes a new file. And so now we need to create a stub for right file sink, as I mentioned just a minute ago, this is very similar to creating a spy because Stubbs and spies are very similar. In fact, if you notice the only difference here is instead of calling signing dot spy, we called sinan dot stub. Then, just as we did with our spy we need to require are filed up management file, and we'll do this by using proxy choir and make sure we pass in our F S module. Next, let's call our function under test, namely the file management dot Create file and let's pass in the file name test dot text. At this point, we're ready for an assertion, but what are we going to assert? How do we check that a file has been created for? Right now, let's cheat a little. And let's assume that if we called right file sink, our file was created. Now I know we saw in the last module that that's not necessarily true, but for right now let's do this will cover the other cases in just a minute. This will now test that right stub was called one time, and it's also a good reminder that you can use spy functions with stubs because of how they're related. Let's hop down into the terminal and run our test with In PMT, the test runs and passes, which means that our right stub was called. But if you go over to the File Explorer and expand data, you'll see that there's not a file there that's our stub. Acting as a stunt double. It intercepted that call and acted like everything was fine while keeping the call from hitting the database. But as I just mentioned, this test proves that the function was called but doesn't have a full picture. What about the case where the file already exists? Shouldn't have thrown exception it should. And coming up. I'll show you one step. You need to take to test out that your code correctly handles the case when right file sink throws an exception

Stubbing out Exceptions
[Autogenerated] earlier, we talked about some of the things that Stubbs conducive for you when testing and one of those things was throwing an exception. How can we configure our stub to simulate that event? Let's go back to our stub test file. In our first test, we created a very basic check that was to ensure that right file sink was called. Unfortunately, we know that's not the only case for that function, as we saw a numerous times earlier. In the course, if you create a file with the same name, IRA system throws an exception. So how can we test that? Well, let's start by copying our first test. But let's rename it, too, should throw an exception if the file already exists. Since we're expecting our create file function to re throw any errors, let's start by changing our assertion. Noticed that we've wrapped our create file inside of another function. This is to make sure that the Chai Assertion Library handles the function correctly. If we were to call our function directly, Chae would be unable to detect if it through an error. But if we run this test right now, it'll fail because our stub is not throwing an error. In fact, it's behaving perfectly fine in order for the stub to throw an error, we need to tell it to. So let's add that behavior between the right stub and file management line tell right stub to throw a new air. Now, when we run our test, it passes. That is when right file sink throws an error. We know that create file allows that error to bubble up and take a look at that data directory again. It's still does not have our tests, not text file, that is, we were able to force or simulate an exception, even if the external system is not set up in a way that would cause an exception. This is part of the power of Stubbs. You can start to force your system into air states that would either take time, effort or both to get configured correctly in the real world. But thanks to Stubbs, you know that the create file function now works correctly. One thing to note, though, we could change the string we passed into create file and our test would still thrown exception. Why? Well, because we're telling our stub to always throw an exception. There's gotta be some way, though, that we can tell it to Onley. Thrown exception in some cases, right? Well, there is. And I'll show you two different ways that you can configure your stubs to do just that in the next clip.

Stub Specific Calls
[Autogenerated] So far, all of the stubs we've created have triggered for every call. But sometimes you need a function to behave one way, with one set of arguments and a different way with a separate set before we see how to create specific Stubbs. Let's run the application so you can see the behavior we want to test. I've already run in P M. Start notice that the Web server is running on Port 30 30. This is to make sure it doesn't collide with other node servers. You might be running on your machine, which would default. Support 3000. If you browse to that address, you'll see the sample application from earlier in the text box Inter a file named sample dot text and then click the plus button. The file was created, and you can see it in the list. Now Inter sample that text a second time and click the plus button. This time, the new file is named sample one dot text. This is the behavior that we want to test. Let's go back to the I D and open up the file file that management dot Js In this file, there's a function named create file safe inside of this function, the right file sink function is called multiple times. The first time is online 31 it's inside of a try catch block. The second time is online 44. This function attempts to create the file that you've specified. If that fails, it will try to create a file with the same name, but with a number appended to it, I want to make a note here. I wouldn't consider this good code for a couple of reasons. One were using exceptions for Flo Control. If this was production code, I'd expect there to be a check to see if the file exists before trying to create it the first time into we never checked the exception to make sure that it's saying the file already exists. Any type of exception will trigger are safe name, but for demonstration purposes, this code's fine. Also note that there's a function in between the two right file sinks and that's read dir Sink, which gets a list of files, and we'll need to stub that out as well now that we have an idea of what the function is that we're trying to test. Let's head back into the file management stub, speck and create a new test. Let's name this. Create file safe should create a file named Test Out one. When test already exists, as we've done in the past, let's create our stub for right file sink. Next. We also need to create a stub for Reed Dir Sink. Now we need to bring in file management with IRA Proxy Choir statement. Now that we have all of that, we need to configure our right stub to throw an exception and our reader stub to return a list of files. The problem is, right now we're telling our right stub to always throw an exception, but that's not what we want. Remember, we only want right stub to throw an exception on our first call, our second Cole. We actually wanted to succeed, so we need to configure our stub. We have a couple of options. First, we could specify the call number that we want to throw an exception here. We see that we're telling it on call zero to throw an error. The line immediately after that specifies what it should do the rest of the time that is on all the calls, except for what we've specified. Return undefined. This is one way, however, it's not my personal preferred way. I'd prefer to be explicit about what makes the function throw an exception, and you can do that using the with our ex function. So replace on call zero with the function with our eggs and then pass it the string dash slash data slash test dot text In this test, we're telling it whenever it sees right file Sink called with a parameter of data slash test dot text, it should throw an exception, Otherwise it should return undefined. So now that we have that coded up, let's run our tests with in PMT. When we do, we see that all of our tests pass. We were able to configure our stubbed, either throw an exception or return a value based on the arguments that were specified. And even more than that, one nice reason to do it this way was that if there was an error in our code and we didn't update the file name every time we tried to call it with test dot text, it would throw an exception whether it was the first time or the last time. So far, everything we've been doing has been with synchronous functions. But as you and I know, not all JavaScript functions air synchronous. Is there a way to use Stubbs with asynchronous functions? Well, there's good news. There is a way. In the next clip, I'll show you the one function you need to use to make Stubbs work with asynchronous functions.

Stubbing Asynchronous Functions
[Autogenerated] asynchronous functions can often be difficult to test because they don't always immediately return a result. However, using Sinan Stubbs can simplify this. Let's start by adding a new test to our stubs spec file and let's call this one. Get all files should return a list of files. This time, we won't be testing file creation, but one of the functions that Reid's files, namely, get all files. This function is used in the APP to get all files that display on the left hand side. Let's open up file management and take a look at that function. In this function, we see that it uses reader to a synchronously. Get a list of files. Since Reader is a sink, it accepts a standard node callback of error and data. Now that we know we need to stub out reader, let's head back to our test file and add that that part should probably be pretty standard by now. And so should the next line, where we use proxy choir to bring in file management. Now we need some way to check the data on this function, So let's start by calling the get all files function and inside of our call back, we're gonna add our expectation. If you're not familiar with mocha, make sure you use the dot to dot e que el to compare this array and not to equal if you use to equal it will fail because this array will not be the exact array returned from the function. Here we write our expect statement inside the call back to get all files because that's ultimately where data is gonna get returned. The question, though, is how do we tell reader to return data specifically, how do we tell it to return a list that has a single file test dot text sign and accomplishes this by using a function named yields? Let's pause here for a moment and look at this new line. It might not be obvious what the perimeters are for yield. Or more specifically, it might not be obvious why the first parameter is no. Remember with node functions, the standard callback format is error is the first parameter, and the data or value is the second parameter. As a result, we need to yield to values the first parameter no maps to the air perimeter and the second parameter the array maps to the data perimeter. If you run this test with in PMT, you will once again see that all your tests passed and just to see that the expectation inside of a callback does work, let's tweak it a little bit, change the expectation to be test one dot text and then re run your tests. This time it predictably fails. It was telling you that it expects test to equal test one. While yield is helpful, a lot of libraries have moved on to promises. So how can we use Sign in to test a promise? Let's create a new test for our reader. And let's call this one. Get all files promise should return a list of files and let's make sure that we stop out the Reed Dura function. Next, we need to create one more stub. This creates a new util object with one function named Promise. If I and that function is a stub that returns the stub we just created, I want you to note that we only have to do this because our file management module is using nodes Util Promise if I to convert reader from a callback style function to a promise based one. If you were using a library that already has promises, you would not need to do this step. But to make sure our stub is being used correctly, we need to make sure promise. If I returns that read a stub. Next, let's pass in both F s and you till to our proxy choir statement. Now let's add our assertion. Sins were using mocha weaken Return a promise from our test and mocha will automatically wait up to two seconds for it to resolve. Because of this, we can put our expectation inside of a then block and know that our test won't end before the then blocked gets called. The only thing missing right now is telling the stub that we needed to resolve a promise based on what we've done in the past. Do you have any guesses on how we can do that? If you said sign and probably has a resolves function, you'd be right. So let's add that now. And just like that, if we run our tests, they all pass. And again, if you wanted to verify that it's actually testing, you can change the exception and see that it fails. I'm gonna leave it with test out text so that it passes. I'm sure that you can guess. You can also reject a promise using a function named rejects. But what else can you do with a stub? The next clip will show you a couple more interesting functions that you can perform.

Other Stub Functionality
[Autogenerated] you've already seen the common stub functions such as throws, yields or results. But there's also a couple more interesting functions that can be used with Stubbs. As you saw earlier. By using a combination of on call and with our eggs, you can get pretty creative with what your stub returns and win. But sometimes those functions aren't enough. Other times configuring a stub using those methods can be exhausting, particularly if it's a function that's going to get called a lot. Thankfully, Sinan has another function named Calls Fake and that could be used for this situation. Calls Fake accepts a function as its one and only parameter. Whenever your stub is called, it will call the fake function that you passed in. You could use this tohave. It just return a single value, although that's probably overkill, since you could also just use the returns function to return a single value instead, Calls fake is great if you want to do some kind of logic whenever the stuff is called. If you use the spread operator on the function, you'll actually have access to the arguments passed into your stub. For example, the right stuff on the screen. The Ark's property would have the file name, the contents and the flag object. Receiving this data allows you even more control over what you do with your stub. Another interesting but lesser used feature on the stubs is the ability to provide your own behavior. This allows you to add a function to Stubbs. For example, Instead of returns or throws, you could add something like logs call. You could then use this new behavior as a method on your stub. There's two important notes about ad behavior. First, if you're adding a new behavior, it must be added before you define the stub that you want to use it on. Otherwise we'll get an error. And second behaviors, like other stub functions, are able to be chained. So if you wanted, you could have something like this. My stub logs call and then returns high. At this point, you've seen how and win to you spies as well as how and when to use Stubbs. Sometimes, though, keeping that distinction in mind is annoying, or possibly not even valuable. Coming up in the next module, I'll show you a test double that you can use in Sign in if you don't want to worry about the distinctions between spies and Stubbs

Simplifying with Fakes
Simplifying with Fakes
[Autogenerated] when you're first starting out, it's easy to mix up whether you should use a spy or a stub. And once you've been testing for a while, you start to wonder if there's a reason they're different. Sinan has 1/3 type of test double that minimizes this confusion. Let's start with a quick reminder about what a spy is. Remember that a spy is like that nosy neighbor. They keep track of all the things that go on with your function. Spies answer questions like How many times was this function called or what arguments are passed into this function, or even to this function? Thrown exception? And remember, we said that a stub was like a stunt double. It was there to keep us from the explosions, falls and other dangers that a function might have. Instead of checking to see if a function did throw an exception with a stub, you're able to force a function to throw an exception on Lee. Just like in the movies, it's not your actual function. Throwing an exception, it's the stunt double or stub. On the one hand, we have a spy that we can use to snoop on our functions. And on the other hand, we have our stunt double that can jump in when things get a little dangerous. And with Sinan fakes can blend these two together of fake is really like combining spies and Stubbs. In fact, some of the newer frameworks and frameworks and other languages have decided to ignore the spy and stub distinction altogether. And on Lee have fakes this new test of what will allow you to ask questions about your function while simultaneously controlling the behavior. If you look at signs definition of a fake, it states that a fake is a function that has the ability to set a default behavior. Additionally, it's a function that records arguments, return value, the value of this and exceptions throne, if any, for all of its calls. And finally, it's immutable. Once it's created, the behavior will not change. The 1st 2 parts should sound a lot like the definition for stubs and spies, respectively. That is, a fake can have behaviors associated with it, and it can also record information about a function as faras the fakes, a mutability. We'll see that later on in this module. After hearing all of this you might be asking yourself of a fake is so similar to a spy and a stub. Can I create it and use it just the same as I would aspire stub? The answer is almost, and I'll show you the two main differences in the next clip.

Replacing a Spy with a Fake
[Autogenerated] Creating a fake is just slightly different than creating a spy or stub. But don't worry while it is different. What you've already learned will help you with fakes as well as we did in the last module. We want to make sure our fakes back is the only one that runs. So open up file management stub dot spec an ad dot skip to its top level Describe. Now open up the fake spec file. We're going to start by removing this worthless test, and we want to replace it by recreating the first test we did in the course. If you remember back to the module on spies, the first test we did was spy on the right file sink function to make sure that when we called create file, we called right file sync with the correct arguments. So let's create a test for that condition again. Will delete. This test will add one that says it should create a new file. Now we need to create a fake. In the past, we would have created it using syntax like this, But if you were to hump down in the terminal right now and run in PMT to run the tests, you'd receive an error. The error is expected F argument to be a function, and that's pretty cryptic. The reason it gives you this error is that the function fake here that's off of Sinan only takes one parameter, and it expects that perimeter to be a function in our case, we passed in a module, not a function for that first parameter. If we want to create a fake like this, we actually need to tweak the perimeter just a bit this time, instead of passing in right file sink as a string, we simply pass in the function F s dot right file sink at this point, are fake, right? Fake is essentially a spy. We've taken an existing function and wrapped it, and now we can observe and record its interactions. But what we decided was to let the behavior be the actual function. So let's continue writing our test. The next thing we need to do is ad R. F s module via proxy choir, just like we have in all of our other tests. Then we need to make our function call. We need to call, create, file and pass in test dot text. And finally, we need to add an assertion just like we did with our other tests. Now that we have that created, let's hop back down into the terminal and run the tests again. When you run the test, it fails. It tells you that it expected false to be true. Which means that it doesn't think right file sink was called with our perimeters. But if you look at the data folder, you can see the test file exists. This is actually very similar to that first test in which we ran into the same problem. Only this time we made sure to have our proxy choir statement. So what's going on? If I'm being honest, I haven't actually been telling the entire truth. Fakes aren't just a blend of Stubbs and spies. They're similar but not identical. And this is one of those differences. Unlike spies and Stubbs, fakes do not automatically replace the function that you're faking out. That is, even though we're passing F s into proxy choir. At that point in time, F s dot right file sink has not yet been replaced with are fake in order to tell signing that we want to use our fake. We need to call the replace function in between creating the fake and using proxy choir called sinan dot replace. That function takes three parameters. The 1st 2 are the module and the function that you're replacing. And the third is the function that is replacing the native function. Now that we have that, let's run our tests once more. But before we do that, let's make sure to remove that test dot text file. When we run our test, it passes, and if we were to run it one more time without deleting our file, it airs out because the file already exists. So at this point, we've basically recreated a spy using a fake. But it's not behaving like a stub, that is, it's not preventing the file from being written out. Even though we replaced the function coming up, I'll show you the one thing you need to do to make a fake act like a stub

Replacing a Stub with a Fake
[Autogenerated] in order to truly simplify spies and Stubbs with fakes, we need to be able to add behavior to a fake. That is, we need to be able to tell it to throw or return values as we did in the last clip. Let's take a test case that we've already seen before. But this time let's take one from the module on Stubbs Start by creating a new test. And let's name this one should throw an exception when the file already exists. Now we need to create our fake. Last time we passed in our function into the fake function on Sinan. But when we did that, we found out that that did not make the function act differently. So we can't create our fake that way if we want to control what the fake does. Instead, we need to tweak our fake just ever so slightly notice that this time we're not calling the fake function on Sinan instead were accessing the fake property. Let me state that again because the first time I tried using fakes, I lost a little bit of time trying to figure out why it wasn't working to create a fake with behavior. You used the fake property and not the fake function. Also noticed that on that same line, we set up the behavior. We told it that we wanted to throw an error. As with the last clip we need to replace the function with are fake and then, just like every other time, we need to use proxy choir to make sure our module is getting the correct f s. Finally, we need to call our function and make our assertion, just like in the last module. Since we're testing that it throws an error, we want to call the create file function inside of an anonymous function that's inside of the expect statement. Let's run that test. But before we do, if you haven't already, make sure you delete that test out text file so that the first test doesn't fail. When we run our tests, they all pass and it passes. Even though test out text already existed in our data folder because the first test ran just like with our other stub, this fake now prevents the normal behavior from happening. In addition to throwing an error, fakes have other behaviors that could be applied for example. Let's write a test for our function. Get all files, which, if you remember, is an Ace Inc function that takes a call back. So let's name that function. Get all files, should return a list of files. And let's start by defining our fake remembering to use the property, not the function. Then, let's tell, are fake to yield our results. And do you remember what the next step is? That's right. We've got to replace our function. And, of course, don't forget about proxy Choir. And finally, we need to call our function and make sure that we're checking the data in the call back, just like we did with Stubbs. Hop on down to the terminal. You know, I'm gonna clear mine out and run the tests again, and this time, when you run the test, you get an error for this last test. But it doesn't seem to be related to your actual test. That is. It's not saying that the function returned the wrong data. Looking at this air, do you have any idea why you might be getting this air? Do you ever back to the definition of fakes that we looked at the start of the module. The third point there was that once a fake is created, its immutable. In our test, we created a fake on the first line, and then we tried to change it on the second line by telling it what to return. This ultimately led to the air. Thankfully, the fix is really simple. When you define the fake, make sure you also define the behavior. So change that first line to include the yields line. I'm going to delete the test out text file, clear out my console and run the test one more time. And when I do, it passes. So why did I make a point of calling out this behavior? Because again, when I first started trying to use fakes, I tried to make them just like I made my Stubbs, and this error was confusing to me. I tried a few different things before realizing that I just needed to state the behavior when it was created. So I want to save you from that frustration. There's some other differences between fakes and what you're used to with spies and Stubbs. And in the next clip, I'll highlight some of those major differences which can assist you in determining which type of test double you should use

How Are Fakes Different?
[Autogenerated] So far you've seen how fakes overlap with spies and Stubbs. But there are some differences. One of the first differences we already saw. And that is fakes don't automatically replace the function you're calling with a stub calling sinan dot stub with F s and right file sink. That was all you needed to do for the right file sink method on the F S module to be stubbed out. But with fakes, you need to take that step yourself. So you need to use the code on the right using the replace function. And while this is a difference and an extra step, it's really not that big of a deal. There are other differences that might have a bigger impact. For example, if you remember the last module, we set up a test where we made right file sink thrown exception when we called it with test out text, but not when it was called with test one dot text. We did that by using the code on the screen. We also could have used get call zero instead of with our eggs. The point here, though, is that we were able to configure it to behave differently based on the call number or call arguments. However, fakes don't have that option. If you try to use with our eggs with a fake, like the code you see on the screen, you'd receive an error where it says, Sign n dot faked out with our eggs is not a function, and you'd get a similar error if you tried this with get call. This means that if you're using a fake toe, add a behavior to a function. It needs to always exhibit the same behavior. You cannot at this time at least, have it returned. Different values based on arguments or the number of times it's called. There's a few other functions that are not present on fakes. A CZ well, the calls fake function. There's no way to tell a fake to call a fake function that you supply like you can do with Stubbs. You also cannot tell a fake to call the real function with a call through function like you could with a stub, and you can't add behavior. So with fakes, you can't add a custom function like we did with logs. Call on the stub in the last module without these functions, then when should you use fakes? They are still a great option for a lot of tests. For example, almost all of our tests did not need to alter the return value based on what was passed into the function. And that's not just true for this course. In my testing, the overwhelming majority of my use cases don't depend on the input arguments. Additionally, fakes are fairly lightweight. There's not a lot of baggage with them. Yeah, they might have fewer behaviors that you can add, but that could be viewed as a positive. It's easier to focus on the behaviors they do have, then trying to figure out which of the several behaviors you might want to use on a stub. Sometimes you want to verify the behavior of your system more than just the state of the system and coming up in the next module. I'll show you how the final test double, and Sinan accomplishes this exact scenario

Using Mocks to Isolate Code
Using Mocks to Isolate Code
[Autogenerated] most of the time, you don't want to tie your tests to the specific implementation details of your function. Instead, you want to make sure that the inputs produce the correct outputs. But there are other times in which one thing you want to do is make sure a specific implementation is to find one example of when you'd want to test not only the functionality, but the implementation is when you need to make sure something only happens once. For example, think of a financial system. You want to make sure that when you perform a purchase that the right person is charged. But you also want to make sure that they're only charged once. This would be a great time to use a mock. In some ways, mocks are similar to fakes and that they're a combination of spies and Stubbs. However, the main difference is that mocks arm or upfront about what they're trying to verify. You can think of MOX kind of like a good friend that you can trust, and they'll always be direct with you. They don't him and haul around with you. If they want to go somewhere for lunch, they'll tell you If they want to stay home and started going out, they'll let you know before you get ready. The point is, they're up front. And so our MOX since mocks air similar to spies, and Stubbs will skip the definition. But we will take a look at a recommendation from Sinan. And that is that if you want to control how your unit in her test is being used, and you like stating expectations up front as opposed to asserting after the fact you Tzemach there's one key phrase in there that speaks mortem ox than anything else. And that is that you like stating your expectations up front. By this point, the code on the screen should look pretty familiar. We've created a stub. Then we told it what to Dio. And then we call the function that used the stub. And finally we checked with stub did what it was supposed to d'oh with mocks. However, it's almost inverted. Sticking with some pseudo code, you might see a mock like this where you set up the expectation first and then call the function. In this case, you're stating your expectations up front, you're being clear about what it is that you want to make sure your code does. Are you ready to get past the pseudo code that you just saw in these examples and see how these really work? The next clip will walk you through the two changes you'll need to make in your tests to use mocks instead of a spy stub or fake.

Creating a Mock
[Autogenerated] Creating a mock is not any more difficult than creating a spy or a stub, and it requires less steps than creating a fake, as we've done in each module. The first thing we want to do here is make sure that our new file will be the only file running. So go into the fake dot spec file and add a dot skip to the top level. Describe now return to the mach dot spec file. As always, we want to write a new test to replace that worthless, True equals true test. Let's start with that first test we wrote way back at the beginning of the course. In that test, we wanted to verify that are right file sink function was getting called Let's name This test should call right file sink when creating a file. Now let's create our mock. Here we see our first difference between this test double and other test doubles. When we create a mock, we mock the entire module and not just a single function in this case were mocking the F S module. Next, let's set up the expectations that we want to check. Since our right Mok is a mocked version of the F S module. Our expectations statement will call out right file sink in the expects function, and here were specifying that we expect that function toe on Lee be called one time. The next two lines are our normal proxy choir statement, as well as the line that calls the function. Now that we have those two lines, how do we actually check that our expectation is met? Once we're done with the rest of the test, we need to call the verify function on our mock. This will have sign and go back through and verify that all of the expectations on the mock that we already established are true. So jump into the terminal and run the tests. When you do, it passes more than that. Notice that there's not a test dot text file in the data folder. Your mock intercepted the function just like a stub would, as we saw in the last module, fakes can't be limited down based on the arguments that are passed into the function. But what about mocks? Can they? The good news is that they can, and in the next clip, I'll show you exactly how to do that. With exceptions,

Mocking Specific Calls
[Autogenerated] as we've seen elsewhere in the course. Sometimes it's helpful to be able to specify multiple behaviors for a test. Double mocks syntax. Make that pretty straightforward. Do you remember the function? Create file safe? It tries to create a file, and if that fails, it then tries to upend a number to the name and create that as the new file. Let's use mocks to create a test for that, so we'll start by creating a new test. And let's name this one. Create file safe should create a new file with a number upended. Then we need to create a mock for our F S module. Now we need to set the expectations on our mock. Let's start by setting the expectation for right file sink. The first expectation that we're gonna set is that when the argument data slash test out text is past, we wanna throw an exception. The second expectation is that when the argument data slash test one dot text is passed in, we want to make sure that gets called once, and we'll clean up those expectations little bit. Next, let's add a mock for our reader sink function. With this expectation. We're saying that we're expecting our reader sink function to only be called one time. And when it's called, we expected to return an array that has a file test dot text. Now we need to add our standard proxy choir line as well as the line calling, create file safe and remember to pass in test on text to that create file safe function. The only thing we have left to do is to make sure that our Mok is satisfied. And you remember the function that we used to do that. That's right. We need to call verify on our mock. So now let's hop back down into our terminal and run our tests once more and when we do once again all of our test pass all of our mocks have been verified that the functions have been called. That is, we verified that when we called it with test dot text it through an exception. When we called it with test one dot text that it was only called one time and that when our reader sink function was called, it was only called one time, and so far all of our mocks have done just that they verified that functions have been called. But what if we want to verify that a function was not called? How could we do that up? Next, I'll show you the one function you need to test those conditions.

Verifying a Function Wasn't Called
[Autogenerated] sometimes ensuring that a function was not called. Is Justus important as verifying that another function was called? If you remember almost all the functions in the file, that management module checked to make sure that a file name is supplied before doing anything. So let's write a test that verifies that when we try to create a new file without a name we don't ever actually call right file sink. Let's call this test create file should never call right file sink when the file is empty. And as we've done every time in this module, let's create a new Mach for F s. For the moment, let's delay setting up our expectation. Instead, let's set up our proxy choir statement and then because our function is going to throw an error if we don't specify a file name, we need to wrap our function inside of a try catch and make sure you don't specify a file name this time, even though we've been doing that so often and as always, we need to verify our mock at the end. Now we want to make sure that right file sink does not get called. In fact, we never wanted to be called. So that's actually the name of the function that will use to verify that as we hop down and run our tests, we once again see that all of our tests are passing, going beyond our sample file a p I that we've been testing. There's other times you'd want a test that a function didn't get called. For example, imagine an e commerce application that might want to verify that a customer's car does not get charged. If the user needs to log in first or on any site where the user can change their password, you'd want to make sure that the new password does not get set. If the old password is not correct, either of these two cases would make a good use of ensuring that a function was not called. And since mocks helped test, the implementation amok is a perfect test double to use. To verify this, mock expectations combine both spy and stub AP eyes, which means even some of the functions that you haven't seen, like resolves or returns. We're still available for MOX, but there's also some other functions that you can use with mocks as well. And in the next clip, I'll walk you through those

Other Mocking Functions
[Autogenerated] a lot can get accomplished with just once with our eggs and never. But there's still other functions that can help you get even further with your testing. As we've already seen, we can use ones to ensure that a function is called exactly one time. There's other functions for verifying the number of times a function was called as well as you might expect. There's twice to verify that it's called two times and thrice to verify that it's called three times. But there's also a function named exactly. This function takes a number and verifies that the function is called that number of times. That is, if you called twice or exactly and passed in two. Those two functions are equal. Each of the previous functions air helpful when you need to verify that a function is called an exact number of times. However, there are also functions that can help verify if a function is called a less precise number of times. The at least function takes a number and verifies that the function is called at least that many times. Unlike the previous functions, if it's called more times and specified, the expectation will still be valid and still succeed. The at most function is essentially the opposite of at least it to takes a number and verifies that the function is not called any more times than is specified. Like at least if the function is called fewer times it won't throw an exception. As we've seen, mocks have various functions that allow you to be as specific auras Vega's You need to be, and this is true when you're setting up the conditions on your mock you've already seen with arts and Dysfunction operates much like the same function on spies. If a function takes multiple parameters, but you don't specify all of them, the mock will still work. For example, the mock on the screen that has with ARDS data slash test dot text. This will work even though right file sink has three parameters. There's another function as well, and that is with exact our eggs. Unlike with our eggs, this requires the argument list to match the functions. Arguments exactly. That is, if we were to have a mock like the one you see on the screen where we call with exact our eggs and we pass in data slash test on text. This mark would not work because right file sinks. Additional arguments would cause it to fail. One final thing to note about these expectations is that they're changeable. You've already seen this, but it might not have clicked. For example, we can combine with ARDS and once or never like the code you see on the screen. But it doesn't end there using the at least, and at most functions you could combine them. This would be a valid expectation chain that will make sure the function is called between one and five times. You can even work in an argument list like the last mock. This would verify that our Mok is called with the perimeter of data slash test out text between one and five times. This power allows you to build as complex mocks as you need to verify the implementation of your function because of the time you spent learning spies and Stubbs, you probably picked up on mocks a little bit faster than some of the other test doubles. But before you hop off, let's take a minute or two to do a quick run through of what the various to test doubles are that signing offers

Comparing Test Doubles
[Autogenerated] There's a lot of commonality between all of the test doubles, but also some uniqueness. Let's quickly review each of the test doubles. The first double we talked about was a spy. This was that nosy neighbor of Sinan. It knows all about your function, and it knows what's going on with it and win. It can tell you if a function through an exception or what arguments were passed into the function. But a spy is pretty horrible at controlling behavior. For that we have our stunt doubles or our stubs. Stubbs can still answer questions, but they also protect you from the dangers of your function. For example, if you want to force a function to throw an exception or return a specific value than a stub is there for you. Additionally, it'll prevent the original function from producing any _____ side effects it steps in and acts just like the real function. Exactly how a stunt double acts like the main character in Sign In. There's 1/3 test double that is a blend of the spy in the stub, and that's the fake fakes. Provide a single A P I that allow you to either spy on a function or alter its behavior. They do simplify the difference between spies and Stubbs. And while they do free you from the question of which one should you create, they're not a universal replacement. Remember, there are some functions that are available to Stubbs that are not available to fakes. And then in this module we learned about mocks. Unlike fakes, mocks do contain all of the spy and stub AP eyes. They also provide their own functions on top. Those extra functions all focus on counting the number of times a mock was called with functions like once, never in at least mocks air. Most useful when you want to verify the behavior of the function, when you want to make sure that a particular function is or is not called mocks or a great choice. Additionally, when you want to set up multiple expectations, mocks can often be a better choice because you can set up multiple expectations as opposed to creating multiple assertions in a single test. Finally, I want to say thank you for taking the time to watch this course. I really enjoyed working through Sinan and the various test doubles. I know It's not always obvious how to use test doubles when you start testing your applications, but hopefully over the last hour or so, we've been able to demystify the major signing concepts. I'd love it if you would leave a rating for my course, and I'd also love to hear from you. You can reach out to me on Twitter at the address on the screen.
