Performance is one of the most essential aspects of any application. Everyone wants their server to perform optimally and at the best efficiency. In this course we will understand the basics of query optimization and look at practical tips and tricks for performance tuning.

Introduction
Introduction
MySQL Query Optimization and Performance Tuning. Hi, this is Pinal Dave for Pluralsight. Welcome to MySQL Query Optimization and Performance Tuning course. We'll be working together on this journey to tune MySQL Queries. Let us assume that we are going on a long road trip. There are a few basic things we always remember like the ties of the car should have proper air pressure, we should fill up the tank with fuel, and the engine should be well oiled. You start your journey and it starts smooth. Now all of the sudden, your car starts to slow down without any reason. You get out of the car and check tire pressure, fuel level or oil level in the engine, but sometimes there is more to it than what we see on our very first look. We need to go beyond the basic best practices and understand the inner working of the engine to find the real fault in the car. Once we know the engine and its inner working, we can find out the real problem and fix it. This course is also organized based on the same philosophy. First, we'll be looking at the best practices for performance optimization. We will learn about what are the things _____ and developers should keep in mind before even starting performance tuning. Once we learn the best practices to implement for basic performance of any query, we will learn about the various stages and their functions. Next, we will focus on the tuning of queries, which developer often writes in the real-world scenarios. We will explore various practices for measuring performance and _____. Well, I'm very confident that you will enjoy the course. We will be discussing about Optimizing Data Access, Understanding MySQL Query Optimization, and Performance Optimization by Practical Query Tuning. Let's start our journey.

Optimizing Data Access
Introduction
Hi, this is Pinal Dave, and welcome to the module of Optimizing Data Access. I often see in _____ that most of the queries are retrieving more data than they needed. It may come as a surprise to many, but when developers are writing queries hardly they get the exact requirements of the data to the trial. As the requirements are often changing, developers have to rewrite many queries to adjust the new needs. Amid all this developer often ends up writing queries, which not only satisfy their current needs, but also include a few data, which they anticipate to be used in the near future. If their guess is correct, they do not have write new queries and avoid changing code, however, there are chances that the developer has incorrectly predicted the future, and the query now retrieves more data than it requires. It is very crucial for developers to understand the proper data needs and implement best practices for data retrieval before Query Tuning phase. In this module, we will discuss a few of the best practices related to data access.

Prerequisite
Before we continue with the course, let's see the prerequisite for this course. If you are absolutely new to MySQL, it is recommended that you watch MySQL Fundamentals and MySQL Fundamentals Part 2 course before starting this course. This course has covered various concepts from how to retrieve data from database to stored procedures, functions, triggers and a few of the basic optimization traits. Indexes are considered a silver bullet to performance. If you want to learn more about indexes, watch MySQL Indexing for Performance course before beginning this course. Once you complete MySQL Indexing for Performance, this course begins from the point where MySQL Indexing for Performance stops. I strongly encourage everybody who wants to learn about Performance Tuning to watch MySQL Indexing for Performance.

Overheard
My day job makes me travel to various organizations everyday and meet developers and DBA from all over the world. When I ask them their number one problem with their business, the usual answer is bad performance of an application. When asked further, the reason for the bad performance is poorly written queries, which often brings quite a lot more data than required by the application. When I ask the developers why don't they fix them, I usually get the following answer. More data does not hurt, but if we get less we might have to re-write queries to get them in the future. It is just an extra column in the result set, it does not hurt. WE are going to implement paging in application, let us get the entire result set now. We are just retrieving one extra row, so don't worry about it. Well, in reality, all of these statements are not good for your application. I can confidently tell that your application is facing performance problems if your developer says any of the statements I just mentioned. It's very important for developers to understand data needs totally and clearly. Here are a few of the best practices every developer should keep them in mind.

Understanding Data Needs
Now let's see a few of the best practices every developer should follow. Retrieve rows which are required in the application. Make sure you use proper WHERE clause with your SELECT statement. For just a few rows, it's not necessary that you retrieve entire table every single time in your application. Retrieving more data than you need will just slow down your application, as well as it will waste bandwidth of your network. Retrieve columns which are required in the application. Avoid using SELECT * and list Column Names in your SELECT clause. _____ you need every single column from your table, there should be no need to use SELECT * in your SELECT statement. It's quite possible today you need all the columns from your application, but later on tomorrow when you add additional columns to your table, you may not need that particular column in your queries. At that point of time, your SELECT * is now retrieving more data than is required by your application. I strongly insist that even though you need all the columns of your table in your application, still list all the column names in your SELECT clause. If you retrieve same set of data multiple times, it's always a good idea that you use CACHE property of your application no matter what programming language you use, ASP, ASP. NET, PHP, cold fusion or any other language. Every single language has some mechanism to cache your data for a specific time of interval. Order the data only if you are not ordering them in your application. If you order your data in your database, and once again, reorder the same data in your application, it will just waste your resources. From years of experience, I have noticed that it's always more efficient to order your data in your database in SELECT READY. Now let's further understand some of the best practices with the help of demonstration.

Demo: Setup
In this course, we'll be using MySQL version 5. 6. 14, however, most of the queries which you will see in this course will just work fine in many of the earlier versions. I'll be also using MySQL Workbench as default IDE for executing all my SQL queries. You can alternatively use command prompt or any other IDE as you choose. The version of MySQL Workbench installed on my machine is 6. 0. 7.

Demo: Best Practices for Data Access
We'll be using sakila database for all of our examples. Sakila database is a sample database available for free on mysql. com site. Let's assume that our application requirement is to list all the actors with first names starting from A. For this, we can write simple query like, select * FROM actor. If we execute this query, it will retrieve all the actors from actor table, however it will not satisfy our requirement of actos with name starting with A. For that, we additionally write WHERE clause. Now this particular WHERE clause will limit the number of the rows which we will retrieve in our results set. You can clearly see, now it has only those actors where name is starting with A. Our requirement was to list only actor's name, there was no need of last-update times 10. We can easily get rid of that if we just specify list of the column name in SELECT clause instead of writing star when we select the statement, and click on Execute. It will now return us only three columns, actor_id, first_name, and Last_name. It will remove any additional role which we do not require in our result set. If our requirement is to order all the actors in ascending order of the last name, we can further do that with the help of ORDER BY clause. When we select the statement and click on Execute, it will take our result set and order by last name. However, if for any reason you are going to take this result set and further order in your application, you should not use ORDER BY in your query. You should order your result set only once, either in application or in database. From my many years of experience, I can confidently tell you if your choice to order your data, always order in your database. When you use ORDER BY in your SELECT statement, it is much more efficient than just taking this result set and ordering in your application. Now, in the next example we will see why using * is a really bad idea in SELECT clause.

Demo: Why SELECT Star (*) is Bad Idea
Let's assume that our business application requirement is to list all the customers and the staff who have sold them in rental store. Let's start building this query. First, we'll retrieve name of all the customers. There are total 9 columns over here. Now we also want name of the staff from rental store. For that first we have to join, this query with rental table. Then we JOIN that with rental table and click on Execute. It will return us way more columns than what we had initially seen. We can also see a lot of data related to rental table. When we further JOIN that with store table, we additionally see columns from table store. To get our necessary data, we now have to join that with table staff, select the statement, and click on Execute. At this point of time, our result set contains our necessary data. It has name of the customer, as well it has data for staff as well, however, there are plenty of additional columns and rows in this result set. If we just use this query for our application, our application will be for sure very, very slow. Remember, our rule is to get only rows and columns which are required by our application. If there is any single additional column exists in a result set, we should somehow remove them. This particular behavior where we have lots of columns in the result set is because we have used SELECT * from list of tables. When we use * in query, it will list all the columns used in your FROM clause. That means it will list columns from customers, rentals, store, and staff. In reality, we only need columns from customer and staff. We can easily do that by specifying column names from staff table. If we want all the columns from customer table, we can just specify customer. * and it will list all the columns from customer table and two additional columns. Let's select this query and click on execute. Now our result set will contain only columns from customer table and two columns from staff table. Well, technically, we still need only two columns from our customer table, we do not need email id or any other information from customer table as well. Let's further trim down our query with name of the customer and name of the staff. Now select the statement and click on Execute. Here we go, our result set now contains name of the customer and name of the staff who has helped this customer in rental store. When you carefully observe out this result set, you can see that many of the rows are repeated. This is also true for other customers when we scroll down. Our requirement was to list name of the customer with the staff. In this query we have many of the duplicate records. We need to remove these duplicate records and list only unique rows for each customer and staff. We can easily do that with the help of DISTINCT keyword. DISTINCT keyword will group by this result set with the columns used in SELECT clause. Let's SELECT the statement and click on Execute. Here is the result which we need. Here we have customer name associated with the staff who has helped this customer. There are no duplicate rows when we combine customer name and name of the staff. When we scroll further down, we can still see the same pattern. This final query is the query which we were looking for. It does not have any additional row or any additional column than what we require in our application. Remember, there are two major rules for optimizing data access. First, no additional columns, and second, no additional rows.

Summary in Sixty Seconds
Summary in Sixty Seconds. Do not retrieve the data which is not useful to the application. Avoid using * in SELECT statement. It is always a good idea to write new queries as well modify the existing ones instead of writing query which retrieves more than required now.

Understanding MySQL Query Optimization
Introduction
Hi, this is Pinal Dave and in this module we will understand MySQL Query Optimization. In Formula one race, every racer wants to win, but there are two key important variables which are deciding factors in the decision of the winner, the skill of the racer and the engine of the car. Query optimization is just such a race. For any query to run faster, there are two important factors, the skill of the developer and MySQL Query Optimizer Engine. In this module, we will understand how MySQL Query Optimizer Engine works so we can use this additional knowledge to further improve our skills and write extreme fast performing queries. We will discuss about query execution path, maximizing query optimizer performance, understanding query states, query optimizer responsibilities and limitations, and before we conclude the module we will understand how EXPLAIN command works.

Execution Path of a Query
Execution Path of a Query. Here is the big picture of how a query is executed in MySQL Server. Query Optimizer is the heart and soul of this entire process. Query tuning in MySQL is very logical process. Once you understand the execution part of a query and also understand how Query Optimizer works, you pretty much have to put all this understanding together to write optimal query for your MySQL Server. Now let's understand this entire process step by step.

Client Protocols
First of all, the client sends the SQL statement to the MySQL Server with the help of Client server protocols. MySQL _____ protocol is half _____. We do not have to understand it in very much detail, however, it's important for us to understand MySQL Server and client can talk one at a time. What that means is that when Client has sent all the information to the MySQL Server, at that time, only Client will be able to talk to MySQL Server. Before MySQL responds anything to Client, it must receive all the information from the Client. Later on, once it has received all the information, it can respond back with necessary information back to the Client. At that point of the time, Client cannot get or send any other information. Though it looked like a limitation of MySQL Server, Client Server protocol, it is not the case. The half-duplex nature of Client Server Protocol makes MySQL communication simple, fast, and efficient. Here is an important learning from this discussion. When we send a query from Client to MySQL Server, MySQL Server will create the entire result set and will send it back to Client. However, if Client wants only selected row from the entire result set, Client cannot do anything after it has sent the original query. If Clients want only selected row from the entire result set, Client should have already included a WHERE clause in the original query. Client cannot _____the result first and later on write sub-query or any other condition on that query. This is the reason, as we discussed in earlier module, lots of users fetch all the data into the application and later on filter that out with the help of application conditions. This is really not the optimal way to write query. A developer must fetch only the queries which are required by the application. This way, when Client sends the request to the MySQL Server, MySQL Server will respond back with only the rows which client wants to consume. Next, we will understand about Cache.

Query Cache
Query Cache. When MySQL generates any result set, it stores them into Query Cache along with the query Text. Now let us assume that Client has submitted a query to MySQL, which is identical to another query executed a while ago. First, MySQL engine checks for Query Text in Query Cache. If Query Cache contains exactly the same query sent by Client, Query Cache will return the result back to the client from Cache without executing the query. This, indeed, improves performance of MySQL at many _____. Remember, the query submitted from the Client has to be exactly the same with regards to space between words, and case of the query syntax. When MySQL Engine does not find exact Query Text in the Query Cache, it goes to Parser and Preprocessor. Let us understand them next.

Parser
Once MySQL does not find a match in a Query Cache, the next step in Execution Path is Parser. The primary responsibility of Parser is to take a single query and divide it into multiple tokens or operators and build a Parse tree from them. Now this Parse tree is validated against MySQL's language grammar. What I mean by grammar is that order of various keywords and operators in SQL statement. For example, ORDER BY should be always the last clause in SELECT statement, and FROM clause should follow the SELECT clause. Once query is validated with grammar in Praser, the next step is Preprocessor.

Preprocessor
Before Query reaches to Preprocessor, the grammar of SQL query is already validated. Now, Preprocessor has to check various privileges, as well as check additional semintic _____to the query. For example, Preprocessor checks the table used in the query exists in the database, as well as various other things like column name and other aliases. Parser and Preprocessor, both of them plays very important role in execution path of query, however, the time they take in this entire process is very negligible.

Query Optimizer
Once query passes from Parser and Preprocessor stage, it's validated for the syntax. The next step is to go to Query Optimizer. The primary responsibility of Query Optimizer is to _____ from Parse tree created by Parser or Preprocessor to query plan. A query can be executed many different ways, but at the end it produces same result. The task Query Optimizer does is to evaluate various execution plans and find the best option to execute the query. In MySQL, the Optimizer follows cost based algorithm. That means it tries to predict and forecast the cost of various execution plan and operator. Once it has predicted the cost of all the elements of execution plan, it chooses the execution plan with least cost. That means it selects least expensive execution plan for the query with the help of syntax like source datas you can figure out what it costs. We will see how to find query costs later on in this module during demonstration. It is very important to remember that while calculating query costs, MySQL Optimizer does not include effect of Query Cache. It always assumes that every read is happening due to disc IO operation. Let's understand next, Query Optimizer responsibilities and limitations.

Query Optimizer Responsibilities
Here are a few of the primary responsibilities of Query optimizer. It converts sub-optimal join types to efficient join. it reorders table used in join to reduce IO wired disk operation. It reduces complex constant expressions to simple expression to be used in query. It takes various algebraic rules and simplifies them by applying various optimizing algorithms. Within a query, it is possible to short circuit any logic. MySQL Query Optimizer does the same as well. For example, if query has rare condition where 1 equal 2, which is always going to be false, MySQL Query Optimizer will not evaluate any of the conditions because the very first condition is false, hence the entire query is never going to return any result to you. One of the prime responsibility of Query Optimizer is to use Optimal index for the query. ORDER BY is one of the most expensive operations of MySQL query. Query Optimizer carefully evaluates the ORDER BY and order the result set in such a way it uses least amount of resources from server, mean, max, average, and there are many other aggregate functions we commonly use in our query. MySQL Query Optimizer evaluates all of these aggregate functions and comes up with one execution plan which optimizes use of all the aggregate functions. Next we will see some of the limitation of Query Optimizer.

Query Optimizer Limitations
Query Optimizer limitations. Just like responsibilities of Query Optimizer there are a few of limitation with Query Optimizer as well. No parallel query execution. This is a very crucial one. Let's assume that your computer or system has more than one CPU. The other CPU are just sitting idle or not utilized right now. As soon as you run query in MySQL Server, it will use one of the CPU and execute the query. Even though other three CPUs are just sitting there idle, MySQL Server will not use any of those CPU. Additionally, MySQL Query Optimizer has no consideration for parallel running query. If there is another query running on another CPU, MySQL Optimizer will not know anything about that. Hence, not only it will not use the intelligency of that parallel running query, it will also not factor in any of the cost associated with it. Also, Query Optimizer heavily depends on statistics to come up with most optimal query plan, however, these particular statistics are now dependent on the storage engine. What it means is that if you are _____ or _____ as a storage engine, your statistics will now depend on the behavior and property of your storage engine. Once in a while Query Optimizer may make a different decision than what you think is right. For example, you may want your query to execute fast, however, MySQL Query Optimizer will build execution plan which uses least resources. It's quite possible you want your query to use least resources, but it will come up with a plan which will utilize lots of resources, but gives you fastest result. Currently there is no way to figure it out what plan MySQL Query Optimizer is going to take, and because of that we cannot control this particular behavior of Query Optimizer. MySQL Query Optimizer often does not consider the cost of stored routines. What it means is that if you have used stored procedure or function in your query, MySQL Query Optimizer is not able to come up with good estimation for those routines. Well, despite all this limitation, MySQL Query Optimizer in most cases makes right decisions. The end goal of Query Optimizer is to come up with most optimal plan for your query. We will understand Query Optimizer responsibilities and limitations with the help of a demonstration in the next module.

Query Execution Engine and Storage
Once query is optimized and query plan is built, it's given to the Query Execution Engine. In most of the database, Query Execution Engine executes the plan, which is in byte code. However, in case of the MySQL execution plan is in format of data structure. MySQL follows the instruction given in a Query Execution Plan to get desired result set. MySQL Query Execution Engine follows the _____ implemented by Storage Engine interface known as Handler API. Every execution plan will have its own instance of a handler API. This Handler API will interface with Storage Engine like mysm, noBD or any other storage engine, and get necessary data back to Query Execution Engine. Remember, every storage engine has a different structure and different properties. Some of the MySQL limitation, which we have discussed earlier _____ differences between storage engine. If your statistics are not updated at the storage engine level, it quite possible your Query Execution Engine will execute plan sub-optimally. One more thing to note over here is that if there is any property which is common across any of the storage engine, those are stored at server level and not stored in storage engine. For example, date/time or any server level information, the final part of this entire execution part of the query is to return results to the client.

Returning Result to Client
Once query Execution Engine has executed Query Plan and has result set, it will return it to the Client. Even though result set does not have any row in it, Query Execution Engine still returns empty result set to the client. It is very important that Client, which has generated additional query gets some response at the end of the execution of the query. One more thing, if query is cacheable, MySQL will place that result set into Query Cache. Next time, when the same query is executed again, MySQL does not have to follow the same process again, instead it can just give the result back from Query Cache. Now we know the entire execution part of a query. Next, we will understand a few additional information that can help us to maximize our query performance.

Additional Notes on Query Optimizer
Here are a few information related to Query Optimizer. Query Optimizer is a cost based optimizer. It selects the path using the least resources. MySQL execution plan is a tree of instructions. We can see that with the help of command EXPLAIN EXTENDED. MySQL Query Optimizer has two different kind of optimization. First, there's static optimization where it just inspects the parse tree and executes the query. Second one is dynamic optimization. In this case, it does contextual inspection of various factors of query. That means rare condition statistics of the storage API, available indexes, and a lot of the information. With the help of static and dynamic optimization, query Optimizer comes up with most efficient plan for any query. Now let's see steps to improve query performance.

Maximizing Query Optimizer Performance
Maximizing Query Optimizer Performance. This is a three step process. Step number 1, Optimizing Data Access. We learned about various tricks to optimize data access in previous module. Understanding query optimization. In this module we explored and learned how query optimization works. The third and most crucial step after optimizing data access and understanding query optimization is Query Re-write. We will understand about query re-write in next module, however, before we end this module, there are two important things for us to learn. First, is query states and second is EXPLAIN command.

Understanding Query States
Understanding Query States. In performance tuning, it's very important to understand what our query is doing at any given point of time. We can get the help of command SHOW FULL PROCESSLIST to understand where exactly our query is at in query's lifecycle. There are various states associated with it. We will go over a few of the frequently occurring query states. Sleep. When a thread or a collection is waiting for a new query from Client, it is marked as Sleep Query. When any connection is either executing query or returning the data to the Client, at that point of the time it is marked as query state. Locked. When one thread is waiting because another thread has logged the same resources, this particular state is visible. Analyzing and statistics. When a collection is checking storage engine for various information related to statistics and building optimized query plan, this particular state is visible. Copying to template table. This particular state is visible when we use group by and MySQL or paste the result to temporary table to aggregate the result. Sorting results. This is particularly visible when MySQL is sorting the data to display in the result set. When we use ORDER BY clause, this particular state is visible. Sending data. This data is visible when queries are sending data between stages of the query. Well, this is just partial list of the query state. I encourage you to try out SHOW FULL PROCESSLIST on your busy server and see what are the different states available. Here is the URL of MySQL official documentation of general thread states. On this particular URL, you can see details of pretty much every single state available for MySQL Query. Understanding this state will help you to identify where exactly your query is in its lifecycle and help you further tune it easily. Consider this as a homework and read every state and their explanation.

Demo: Show Full Processlist
Now let's see how SHOW FULL PROCESSLIST works. In MySQL Workbench, let's execute this statement. We can see there are four different rows over here. That means on my MySQL instance there are four different connections. First is Id of the connection or thread, second is User, third is Host, and fourth is Status of the query. For three queries it says Sleep. That means they are waiting for Query to execute and on the fourth thread it says Query. That means it has just executed Query. Time stands for idle time, and State is initial addition. The last column displays the query. Now pay special attention to the State over here. As we execute Query, this particular column of state will keep on changing. In another window we will execute this long query. Once we execute this query, we will go back to another window and watch what each of the threads are doing, click on Execute, go back to another instance, and click on execute SHOW FULL PROCESSLIST. Whenever a collection displays different State, it says Sending data. On the info column it is also showing the same query which we have just executed right now. That means this particular query is now sending data from storage to MySQL Server or from MySQL Server to Client. Now, let's execute the same query again. This time, this thread is now into Sleep state as it has already executed the query. Now let's go back to this query and click on Execute. Now we'll keep on clicking Execute. You can clearly see what each of the threads are doing in MySQL. Before tuning any query, I always check what are the different states. It states for longer time when I execute SHOW FULL PROCESSLIST.

Understanding Explain Command
Before we conclude this session, let's understand about EXPLAIN command. When we use EXPLAIN command with any SELECT query, it gives us following information, id, select_type, table, type, possible_keys, key, key_len, ref, rows. In simpler word, EXPLAIN command gives us idea of what exactly any SQL query is doing when it is executed. It is very difficult to understand the EXPLAIN command with the help of a slide. Let's understand EXPLAIN command with the help of demonstration.

Demo: Explain Command
Here we are back in MySQL Workbench. Here we will understand how EXPLAIN command works. First we will execute this simple select query where we are retrieving data from actor table. Here is the result set and output window displays that this query was executed at this particular time. This was the text of the query and this many rows were returned. On the last column, we can see it took almost 0 seconds to execute and almost 0 seconds to fetch. Definitely it's not 0 seconds, but it is very close to that. Now let's use EXPLAIN command right before the SELECT statement and click on Execute. Over here you will see very different information in result set. Id is one, second column is select_type. That means this was simple select statement over here. The table was actor, and type was everything. There was no possible_keys, key_len or reference over here because this was very simple select statement. It returned us 200 rows. Now we will take a little bit complex example. Over here we will have a CROSS JOIN with actor table and address table, SELECT the statement, and click on Execute. It will return us a few rows over here. Now let's execute the same SELECT statement with EXPLAIN command. SELECT the statement and click on Execute. Over here, now you will see two rows because there are two different tables at _____, the select_type is still SIMPLE as it is not using Union or any sub-queries. Tables used over here are actor and address. Type of the join is ALL because there is nothing special over here. This query has te return all the data and rows returned from actor table is 200 and from address table is 603. On the last column of Extra, we can see there is additional information about join buffer used in this query. Now let's go to a different example where we are using INNER JOIN. This time, we will directly execute the statement with EXPLAIN command, select the statement, and click on Execute. You will notice there are many other information over here. First column is what we have seen before, however, in the second column where file_actor table is used, we have different information in column. The type over here is reference. That means film_actor table has a column which is being referenced from another table. The possible_keys which are used over here are PRIMARY keys, however, when we see the next column of key, we can see that the index or the key which was actually used was PRIMARY key indeed the length of the key was 2, and the reference column, which was compared with the index was sakila. actor. actor_id. The second column written has 13 rows. Well, we have covered the EXPLAIN command in detail in our earlier course of MySQL for indexing. EXPLAIN command gives us a lot of different information about how any particular query is executed. It also tells us information about what index is being used and what index may be used.

Demo: Explain Extended Command
Let's understand a couple of additional commands which will help us to understand our query in more detail. EXPLAIN EXTENDED. We will affix this command to a SELECT query. Now we will execute it and you can see over here It is additional information of filtered column. As we have not used any filtered or rare condition over here, our query is showing us 100 percent. So the real interesting part comes right after EXPLAIN EXTENDED. Once you execute a query with EXPLAIN EXTENDED, execute SHOW WARNINGS command right after that. When you execute the same, it will give us very different information now. In the message column it will give us a select statement. This select statement is our reconstructed query. MySQL reconstructed our select query into Execution Plan. This query may be very different from what we have returned in our SELECT query, however, it will give us absolutely same result. If our tables are reorganized or if our JOINS can be optimized, MySQL Execution Plan would help reconstructed our query with those optimized joins and Pre's with the help of EXPLAIN EXTENDED and SHOW WARNING you can see what actually MySQL is going to execute when we supply any SELECT query. If we study this a lot, it will give us very good idea that what actually MySQL wants internally to execute our query. If we start writing the query, the way MySQL works it will reduce the burden on MySQL Optimizer and your query will start executing faster. During my _____ _____ I spent a lot of time understanding reconstructed query. I believe that has significantly helped me in my career of performance tuning expert.

Summary in Sixty Seconds
Summary in Sixty Seconds. MySQL Optimizer uses Cost Based Algorithm to find the most optimal plan for any query. You can use command EXPLAIN to see details about Query Plans. MySQL Storage Engine plays a key role in the performance of query as the optimizer depends on it for various crucial information.

Performance Optimization by Practical Query Tuning
Introduction
Hi, this is Pinal Dave, and in this module we will understand Performance Optimization by Practical Query Tuning. In an earlier module, we have learned what are the best practices we should implement before starting performance tuning and we understood how the Query Optimizer works. In this module, we will be covering concepts which directly impact the performance of the query. In this module, we will see various practical examples of how query optimization works in MySQL. In MySQL, there is no out-of-the-box tool to measure performance of the query. Hence, we will be using various techniques to validate performance gain of a query. In this demo-oriented module, we will see that every query is different and there are different methods to tune each of them. We will cover in this module the following most frequently encountered issues by developer. With the help of demonstration, we will understand how to tune Joins, Subqueries, Union, Aggregated Functions, Grouping, and Indexing. We will also understand what are the best practices a developer should remember when writing any MySQL query. Remember that we have covered indexes in our earlier course of MySQL Indexing for Performance. Hence, we will only cover a few of the essential concepts related to indexes in this course. I recommend to watch MySQL Indexing for Performance for additional in-depth learning related to indexes. Now let us directly jump into demonstration and learn how to tune MySQL queries.

Demo: Index Used for SELECT clause
Now let's see very first example of MySQL query performance tuning. We'll be using MySQL Workbench as a default ID for all of _____ MySQL query. We'll also use Sakila as sample database for all of our examples. Sakila database is record of film rental activity of people. Though we have covered indexing in-depth in our other course, we will start this very first example with fundamentals of index. In this demonstration, we will understand how index can impact positively on query performance. Our problem statement is to retrieve film_id and length of a film where length is less than 50 and 100 minutes. We'll be writing two separate queries, one for retrieving films with less than 50 minutes length, and second query where we will retrieve films with length less than 100 minutes. First we will use Sakila database, click on Execute, and context of this query is now changed to Sakila database. First, let's retrieve all the rows and tables from sakila. film table, select the query, and click on Execute. It will retrieve all the rows and columns from film table. In our query, you can see I have used two part name, sakila. film, however, we have already specified context of this query to Sakila database. Hence, we do not need sakila. as a prefix in this query. We can execute this query without sakila. as a prefix to film table. Let's select this query and click on Execute. It will still return us same result. As a user, you are free to use either of the methods. Throughout this demonstration, we'll be using both of the methods in place of each other. Now in our result set we are getting pretty much every single record from film table. Now let's add WHERE clause to this query. We'll include the condition, length is less than 50, because we want to retrieve all of the films which has length less than 50. Select this query and click on Execute. Earlier we were getting 1000 rows in our result set, however, now we are only getting 28 rows. When we scroll right in this result set, we can see that length of all the film which we have retrieved are less than 50. Let's further understand this query with the help of EXPLAIN command. EXPLAIN SELECT * FROM sakila. film WHERE length is less than 50, it's the same query with the prefix EXPLAIN. Select this query and click on Execute. In our result set, we can see it is doing SIMPLE select from film table. Even though our result is returning us 28 rows, MySQL still examines all the 1000 rows from this query. So, in other words, even though we are retrieving 28 rows, MySQL Engine still had to scan all the 1000 rows from this table. This is not an optimized query. For 28 rows, an optimized query will not scan entire table, it will scan either 28 or a few more rows. Let's try to optimize this query with the help of index. When we carefully observe this query, we have length column used in WHERE clause. Let's attempt to create index on length clause. ALTER TABLE sakila. film, ADD KEY name of the index on length column. Select the statement and click on Execute. It has successfully created index on length column of film table. Now let's execute the same query we have executed earlier with EXPLAIN keyword. Select the statement, click on Execute. In our result set, now we can see that this query is now scanning only 27 rows. Select is still SIMPLE, however, it is doing range type of scan. The key on index it can possibly use is IX_length, which we have just created. In reality, it is also using the same index which it has qualified as possible keys. You can see that in key column, the length of the index is 3 and it is scanning only 27 rows. You can see in Extra column it is also indicating Using index condition. What that means is that with the help of this index, this particular query is now much faster than the earlier execution. MySQL has to scan much lower data internally to retrieve 27 rows with compared to earlier query which was scanning 1000 rows. Now let's change the WHERE condition from 50 to 100. Remember that we also have to retrieve all the films with length less than 100. Select this query and click on Execute. When we observe the result set, we can see that MySQL is indicating possible keys as IX_length, however, the same key is now no more used in real execution. Hence, MySQL still has to scan all the 1000 rows to retrieve every single film which has length less than 100. Let's execute this query without EXPLAIN keyword. In reality, it is only retrieving 378 rows, however, when we execute that with the help of EXPLAIN, it has to scan all the 1000 rows to retrieve these 378 rows. That means MySQL has to scan 3 times more rows when we change our WHERE condition from 50 to 100. Let's stop and think for a moment. Even though we have created index on length column, why it is not being used by our query? The answer is very simple. If you use * and if your data set is relatively larger, MySQL will not use index which you have created on your WHERE condition. MySQL finds it's much easier to scan entire table than using this index. For the same reason, over here, MySQL scans entire table to return us all the films with the length less than 100 with all the columns. Let's go back up and see our problem statement, Retrieve film_id and length. That means we retrieve only two columns, film_id and length, however, we are retrieving pretty much everything single column from this table. Let's change the * to the two columns which we are to retrieve, which is film_id and length. Now, once again, select the statement and click on Execute, let's examine our result set. It is still a SIMPLE scan, however, the type of the scan is range, the possible_key used is IX_length, and in reality it is also using the same keys, which is IX_lenght. MySQL has to scan 377 rows only to return us this result set. In Extra column, we can see it is also using index on WHERE clause. As soon as we replace * with column, which we needed in our business logic, MySQL has automatically used index to retrieve the result set. Here is the lesson to remember. Only retrieve the columns which you need in your query. If you use *, it's quite possible that MySQL will not use any of your indexes, and will, by default, scan entire table. If your query is retrieving any of the column which you are not using in your application, I strongly recommend that you remove that from your query. Now, let's do cleanup and drop the index which we have just created. Select the statement and click on Execute. We have dropped the index which we have just created for this demonstration.

Demo: One Complex Query vs Multiple Simple Queries
In this second demonstration, we will try to answer a very crucial question which developers often encounter. Should we have one Complex Query or multiple Simple Queries? There is no right or wrong answer for this question. We have to understand in which scenario a complex query is advantageous and where to use multiple simple queries. In this demonstration, we will also learn a new technique to measure query cost. Once again, we will use Sakila database and here is a complex query. This query retrieves all the columns from film, film_actor, and film_category table. Let's select this query and click on Execute, and the query returned us 8 rows. Now let's measure the cost of this query with the command SHOW STATUS LIKE 'Last_Query_Cost'. When we execute this statement, it displays query cost of the last executed query. I often run both of these statements together to make sure that SHOW STATUS LIKE 'Last_Query_Cost' displays the cost of the query which I just executed. In this case, the cost of this query is 10. 799. Let's record this somewhere on a notepad. In the next step, now we will try to decompose this query. To decompose this query, we need to understand what data this query returns. There are three different tables used in this query. All the Joins between these three tables are on film_id. The WHERE condition also is on column film_id, hence, this entire query will only return as a result for film_id = 10. We can decompose this one big query into three different queries. For each of these three queries, we can keep the WHERE condition as it is. Here is the first query where we are retrieving all the columns from film table where film_id is 10. Let's execute this query with SHOW STATUS statement. Click on Execute, and it will display us the cost of this query, which is 2. 399. Similarly, I have query from film_actor table. Again, the WHERE condition is film_id = 10. Let's select the statement and click on Execute. It also returned us 2. 399 as a cost. Let's make a note of this cost also on a notepad. The third query is on film_category table. Once again, the WHERE condition is film_id = 10. Let's execute this entire query with SHOW STATUS statement. When we click on Execute, it also returns result as 2. 399. In other words, the data with this one complex query as returned is equal to addition of all the data returned by three queries on film table, film_actor table, and film_category table. Amount of the data which is retrieved is same. Now let's see cost of these queries. The cost of the complex query is 10. 799, whereas cost of the multiple queries is 2. 399 + 2. 399 + 2. 399. Hence, the total cost of the multiple queries is 7. 197, whereas cost of one complex query is 10. 799. On a very first look, based on this scenario, we can say that multiple simple queries are better than one complex query. Remember, in this case, we are just adding up the cost of the queries. In reality, there is additional cost associated with every single query execution. For example, building execution plan, building a parse tree, as well as additional network traffic between Client and MySQL Engine, it's quite possible when you add all of them up, multiple queries may not be that advantage to the complex queries. However if you note this huge difference between query cost of complex query and multiple queries, there are chances that executing multiple queries may be advantageous in your scenario. With the help of the method which I just demonstrated to you in this example, you can figure out if you want to keep one complex query or decompose it into multiple queries. In the next example, we will see how a single complex query is performing better than multiple simple queries.

Demo: One Complex Query vs Multiple Simple Queries - Part 2
In the last example, we noticed that one single complex query is more expensive in terms of query cost than multiple simple queries. In this example, we will see how a complex query is more cost effective than multiple simple queries. Here is a query where we are retrieving data from four different tables, film, inventory, store, and address. All of these tables belong to database Sakila. Let's see the condition which we have used in the JOINs. Table film and inventory are joined with column film_id, table inventory and store are joined with column store_id, table store and table address are joined with column address_id, whereas WHERE condition is on column film_id of film table. Table film and inventory contains film_id column, however, table store and address does not contain column film_id. This query is very different from the query we have executed in last demonstration. In this case, if we want to decompose this one query to multiple queries, we cannot just use same WHERE condition, we have to do a little bit of legwork over here when we have to decompose this one query. For example, to decompose this query for film and inventory, we can keep WHERE condition as film_id = 10 as the original complex query, however, when we decompose table store and address at that time, we will have to be creative with our WHERE condition. In this case, I will use store_id in 1 and 2. The reason for using value 1 and 2 over here is that when we executed the earlier query of inventory, it only contains two store values. Let's see that in action and understand it. First of all, let's execute this complex query with SHOW STATUS statement and note the query cost in our notepad. Query cost is 6. 199. Now let's execute this very first query with SHOW STATUS statement. The query cost is 2. 399. Let's make a note of that. Now let's execute the second query with WHERE condition film_id = 10. Click on Execute, and the cost of this query is 2. 399. Let's make a note of that as well. Now we will execute the next query where we will retrieve data from store table. Let's go and see what are the different store_id returned by this query from Inventory table. Click on the tab over here and with the help of visual inspection we can say that it retrieves two different values of 1 and 2. We will use this value 1 and 2 in the WHERE condition of the next query. Now let's execute this entire query along with SHOW STATUS statement. When we execute this query, at that time we can see two tabs. Once again, the cost of the query is 2. 399, just like every other query. Now we have to retrieve data from address table. Let's go to the result of our recently executed query as it will contain column address_id. There are two distinct values in address_id column, they are 1 and 2. Once again, we will put these two values into WHERE condition of our address table. Now select the statement and click on Execute. The cost of the query is 2. 399. Just like the earlier example, we will once again add all the values of multiple simple queries over here. The cost of one complex query is 6. 199, whereas cost of multiple simple queries is 7. 197. In this case, it's very clear that one complex query is much more economical than multiple complex queries. As I said earlier, there is no right or wrong answer when it is about executing one complex query versus multiple simple queries. I strongly urge that you try out various combinations of simple query and see if the cost of multiple queries is higher or a cost of one complex query is higher. Go for the solution where you find queries are using resources much more efficiently.

Demo: One Complex Query vs Multiple Simple Queries with Index
In this example, we will learn that we can divide a big query into multiple small queries and improve the performance of the queries with the help of indexes. We'll be using Sakila database and here is our problem statement, Retrieve all columns of the table film where length is less than 80 minutes. Remember, we have to retrieve all the columns. That means we have to use* instead of individual columns. Here is the statement SELECT * FROM sakila. film WHERE length is less than 80. That means this query will retrieve all the films where length of the movie is less than 80 minutes. Select the statement and click on Execute. In result set, we can see we have retrieved 243 rows from table sakila. film. Now let's understand more details about the execution of this query with the help of EXPLAIN command. Select the statement and click on Execute. We can see that it is a SIMPLE select from film table where it is retrieving ALL the data. To retrieve 243 rows, MySQL Server has to scan all the 1000 rows from this table. This is because we have not created any index on column length of film table. Let's quickly create index on column length of film table. Select the statement and click on Execute. Statement has executed successfully. Hence, the index is created on column length on sakila. film table. Now let's execute same SELECT statement with EXPLAIN once again. Our assumption is that this query should use the index which we have just created. Click on Execute and now let's examine our result set. Once again, it is SIMPLE select statement and possible_keys column indicates IX_length index. That means IX_length index qualify for potential index to improve performance of our SELECT statement. However, very next column of key indicates that index which was qualified to be used for this query is not used to retrieve data. The matter of the fact, MySQL Engine still scans all the 1000 rows to retrieve data for this query. From earlier experiment, we know it should only scan around 243 rows to retrieve data for the query. This is because MySQL Engine finds it is much more economical to scan entire table to retrieve all the films with less than 80 minutes length. This particular query does not use our index. If this query would have used index, it might have not scanned all the 1000 rows to retrieve 243 rows. We can definitely press * with few columns and maybe our query start using indexes. However, our business need is to retrieve all the columns from table film. Hence, we must use * in this solution. In this kind of scenario, you can divide this one big query into multiple queries with different WHERE condition. Let's see how we can do that. Here it is, this one big WHERE condition is now divided into two different WHERE conditions. The first WHERE condition is where we are retrieving all the film with length less than 61 and in second query we are retrieving all the film with length 61 and from 61 to 79. That means when we add the result set of these two queries we will get our final result set. Let's select this one query and click on Execute. In the result set, we can see this particular query uses our newly created index IX_length and it retrieves 103 rows. Now let's execute this second query. Upon execution, we can see that it also executes with the help of our newly created index IX_length and it also retrieves 139 rows. Now when you add the result set of these two queries, it is very close to the result set of our earlier query. You can see that this one big query was not using any indexes. Hence, MySQL Engine had to scan 1000 rows. However, as soon as we divided this one big query into multiple small queries, it started to use indexes, and now MySQL Engine does not have to scan entire 1000 rows to retrieve us over 200 rows. With the help of indexes, it can directly pinpoint the rows it needs to retrieve and return them to application. You may wonder, how did I come up with this magic number of 61 where below this number and above this number this query started to use indexes. The answer is that there is no real science. I just came up with this number with the help of trial and error. I typed a few different numbers and figured it out when I am retrieving data lower than 61 and higher than 61 it is using my newly created index. In your real world scenario, this number can be anything, however, the purpose of this demonstration was to explain to you that if your query is not using the index which you have created, you can re-write this query little bit _____ and union them together at the end to get desired result and the performance of multiple small queries will be much higher than one complex query. In this example, I have used >= and <= over here. Instead of this you can also use BETWEEN. These two are essentially same thing. You can even execute this query and can get almost identical result. Since >= and <= are identical to BETWEEN, you can use either of them in place of each other. Now let's drop our newly created index and clean up our database.

Demo: Table Order in Join Clause - INNER JOIN
In this demonstration, we will try to answer one of the most frequently asked questions related to table order in join condition. The question is, does table order in join condition matter for performance. This is a very tricky question. We'll divide this big question into two parts. First is INNER JOIN, and second is OUTER JOIN. In this demonstration we'll try to answer, does table order INNER JOIN conditions matter? Well, _____ statement uses same tables, film, film_actor, and film_category, however, the order of this table is different. For example, here film is first table, but in the third example film_category is the first base table. In case of the second SELECT statement, we have film_actor as a third table, however, film_actor is second table in other two SELECT statement. Where would the order of the table here random. The condition between all these three tables is same, film_id is a common column that exists in all the three tables. We are using the same film_id in our WHERE clause as well. The size of table film is different from size of table film_actor and the size of table film_category is different from other two tables. They all contain different columns and different number of rows. Here is question to you. If I'm doing INNER JOIN, should I have table with the least number of the rows first or the table with the least number of the columns last? I'm very sure I'll get different answer right now. You may also write down your answer on a notepad. Now let's execute all the three statements. On output window, we can see that all the three SELECT statements returning us 8 rows. If we carefully observe the result set, we can also see that result set is also saying the order of the columns may be different over here because order of the column is always best on the order of the table which you have used in your SELECT statement. That means on a first SELECT statement, all the column from the film table is first followed by column from film_actor table, and last all the columns from the table film_category. Even though order of the column is different, the result is same. What I mean by result is that each column contains almost same result which other SELECT statement contains. Remember, in relational database, order of the column in result set should not really matter for your application. A good application does not depend on which order a result set retrieves columns. You should be binding a column name from your result set with your application variable and it should not be dependent on the order the column is retrieved. Now if you do not consider the order of the column, our result set is absolutely identical to each other. Let's revisit our question again. Does table order in JOIN condition matter with regards to performance. Now let's execute all the three queries with the prefix of EXPLAIN EXTENDED. EXPLAIN EXTENDED will display how these queries are executed. I'll select all these three queries together and click on Execute. We have six different result sets. Let's start with our very first result set. Our first query it contains three tables, the order of the execution of this table is f, fc, and fa. The cost of this query is 10. 799. Let's go to our second query, order of the table once again is exactly same as our very first query, which is f, fc, and fa. The cost is 10. 799 once again. For the query number 3, the order of the execution is also same for all the tables, which is f, fc, and fa. F stands for table film, fc stands for film_category, and fa stands for film_actor. The cost of the query is, once again, 10. 799. That means execution plan for all the three queries is same. Also, the cost for all the three queries is identical to each other. What we can conclude from this is it does not matter what order we use table in our JOINs. MySQL Engine is smart enough to reorder them internally and come up with best execution plan. For example, in a query number 3, I'll use film_category as a base table followed by film_actor and film table. When we see the execution plan, it still uses film as a base table, film_category as a second table, and film_actor as a third table. MySQL Engine internally reordered the execution or placement of the table and join them and come up with execution plan which is most efficient for this query. Because execution plan for all the three queries is the same, MySQL Engine come up with the same course for all the three execution plans. Remember what I mentioned earlier, this is only true if it is in a JOIN. Let me summarize the learning in one statement. In case of INNER JOIN, it does not matter what order we use tables in our join condition. The result set is the same, as well as the cost of the query is also same, however, this is not true if you are using OUTER JOIN. In the next example we'll explore that table order methods in JOIN condition when we are using OUTER JOIN.

Demo: Table Order in Join Clause - OUTER JOIN
In this example, we will see, Does table order in outer join conditions matter with regards to performance. The answer is yes. In case of the inner join, the table order did not matter in join condition, but in case of outer join, it does matter. We'll be using Sakila database, and now we'll execute these three queries together. When we check the result of these three queries, it is identical. All three queries return 8 rows. The way the database is set up, the result of these queries is identical to each other, however, in case of the OUTER JOIN, it's quite possible when we change order of the tables, the result may be very different from each other. You always want to use the tables in the order it satisfies your business requirement. However, if changing the order of table is not changing result set, it still affects performance. We can see that with the help of EXPLAIN command. We can execute three queries which we have just executed with the help of EXPLAIN command and we will see the cost of the queries with SHOW STATUS statement. Let's execute these three queries together. When we execute them, we get _____. Let's go to the first query. Here we can see the execution of the table is in the order of f, fa, and fc, which means the Execution order of the table is very similar in the order the table used in original query. Let's check the query cost. The query cost is 19. 199. Now let's go to the second query. When we check the result set of second query, once again we can notice that table order is exactly the same as the original query. That means f, fc, fa, and f, fc, and fa. Once again, the tables are joined in the same order as they are joined in original table. Now let's check the query cost, it's 10. 799. This value is much lower than the query cost of earlier query. Now let's go and check third query. Let's check the result set for this third query. Over here we can see the order of the query in Execution plan is f, fc, and fa, however, in the original query the order is very different, it is fc, fa, and f. MySQL Server optimized this particular join and it has rendered the result set which are very similar to the query which we have executed before. Hence, the cost is also very similar to the second query, which is 10. 799. So in this case, MySQL Query Optimizer was able to tune this execution plan give us optimal performance, however, in case of the very first query, MySQL Server was not able to tune this execution plan, and hence, it has to return us high query cost. When we are using OUTER JOIN, our first priority should be optimal result set. If we are getting similar results, we should experiment with different order of the table and see which one gives us optimal result. Given the integrity of the business requirement, you can change the order of the table in JOIN condition if you are using OUTER JOINs. Remember, if joins are in order may get different results sometimes and different performance if you are using OUTER JOINs.

Demo: Most Optimal Choice - Subquery vs Exists vs Joins
In this demonstration, we'll try to answer one of the most crucial questions developers often ask. What is the most optimal way to write queries, subquery, Exists or Joins? A single query can be returned multiple different ways. How do we know which one is the most optimal way to write query? Honestly, there is no right or wrong answer over here. You can write one query many different ways and each of the ways can be optimal in certain circumstances. Nobody can tell you that one will always work better than other one. What I'm going to do today in this example is to teach you how you can write a single query different ways and compare their performance. Once you compare their performance, you can come up with the answer yourself. In a different scenario, you'll find different way of written query optimal. Select the one which works the best and discard others. So let's start with our example. We will use Sakila database for this example. Sakila database is database of film renters. In this query, we will list every film where inventory_id is less than 555. Let's select this query and click on Execute. Our results it returns us, 114 rows. Now, let's see our Execution plan details with the help of EXPLAIN keyword. Click on Execute and here is our execution plan detail. We have three rows over here. In our example we are using subquery. Right after the IN keyword we have subquery over here. This query can be executed on its own as well. We are _____ the result set of this query to the outer query and every film_id received from this subquery becomes the WHERE condition of outer query. When we execute this we are getting 114 rows as the result set. In our execution plan, we can see that it is also using subquery logic. The total rows which are scanned to get us 114 rows result is 1000 from table f, which is fillm and 553 rows from MATERIALIZED table, which is best on subquery of inventory table. In other words, each row of this result set is compared with outer row, and if they match, the row is returned to the client. The same logic can be returned with the help of EXIST command as well. Here it is. SELECT * FROM film WHERE EXISTS another subquery. This subquery is SELECT film_id from inventory WHERE inventory_id is less than 555. This is the same WHERE condition as we have seen earlier, however, in addition to this condition, we also have another condition, which is i. film_id = f. film_id. That means our WHERE condition of outer query is now validated inside subquery. This is called correlated subquery. Let's execute this query and we can see that it also returns us 114 rows. If you carefully observe the result set, it is identical result set to our earlier query. Now let's understand the execution plan with the help of EXPLAIN. Select the statement and click on Execute. Here it is. When we see the execution plan, we only see 2 rows. _____ still scans 1000 rows to get us result set, however, the _____ subquery now only scans 2 rows. This is because we have used EXISTS keywords. the way the EXISTS works is that it will look for first affirmative answer from result set. Once it receives first an affirmative answer, it will stop examining other rows for similar answer. In this case, with the help of EXISTS, now the inventory table scans only 2 rows. When we look at this query, it's very clear that EXISTS is much better than IN. The number of the rows we just scan when we have used EXISTS keyword is much lower than when we have used keyword. We can also generate the same result set with the help of JOIN. Here is the query which returns us exact identical result set to our earlier results. It also returns us 114 rows. Now let's see the execution plan of this query where we have used JOIN keyword with the help of EXPLAIN. Click on Execute and now we can see a very different execution plan. Table i from inventory gets 552 rows scanned and table f from film only gets 1 row scanned. Well, when you look at the number of the rows scanned, it looks like JOIN is the most optimal way to go. In simpler word, it seems like IN was the worst EXISTS was good, but JOIN is the best solution. This is definitely true if you are just measuring the performance of the query with the help of number of rows scanned. However, in these kind of scenarios, we should do deeper test of the performance. Let me show you one more trick how you can do the performance comparison of different type of queries. for doing a performance test, we will be executing this query in the loop. First we will create a very similar table of the result set these queries produce. I will call it filmcopy. Now we have created a table where we can hold temporary results. We will create a stored procedure where we will use subquery as a main body. We'll insert the value from this particular query into the test table. We return the logic of the loop inside this stored procedure. Similar way we'll create another stored procedure where we will use logic with EXISTS. The same result set will once again populate it into this test table. Following the same path, we will create a _____ procedure. We will insert the result of JOIN into this test table. Now let's create all these 3 stored procedures first. Stored procedures are created successfully. The next thing which we will do is to run this stored procedure into loops. Let's execute our very first stored procedure and we will loop over the logic of SubQ 1000 _____ times. Select the statement and click on Execute. You can see in the output window that this stored procedure has taken 3. 573 seconds to execute. Now we wil truncate the test table and we will once again loop over the ExistQ 1000 times. You can notice that this particular query took 8. 112 seconds to complete. This means the logic with the Subq was optimal and the logic with EXISTS was not optimal. Well, once again, truncate the table, and now we will execute our current stored procedure where we have used JOIN. We'll loop over the Join, once again, 1000 times. Select the stored procedure and click on Execute. In the result set, you can see that it took 12. 901 seconds to execute the stored procedure. From the result set, what we have earlier assumed that subquery was the slowest and Join was the best. However, after performance test, we are getting absolutely reverse result. What we are getting is that our logic with IN clause was optimal and our logic with JOIN clause was suboptimal. Well, if you go with the logic of number of the rows, you may end up with very incorrect conclusion. It's always a good idea to do a performance test by executing queries multiple time on your _____. In this particular case, our logic of subquery was optimal. If I had to tune this particular query, I'll just leave the subquery as it is and discard other two options. Remember, this particular answer which we have arrived is based on the result set and the workload I had in this system. In your system, data distribution, as well as the relationship of the table might be very different. you may get any other method as an optimal method as well. That is why it's very, very important for you to understand that after writing queries it's always good idea to do performance test. Now let's drop the stored procedure and TEST table and clean up our database.

Demo: Most Optimal Choice - Subquery vs Exists vs Joins - Part 2
Now let us see one more example of correlated subquery and once again we'll try to answer the same question What is the most optimal way to write queries, Subqueries, Exists or with the help of Joins? Here we have Subquery we are retreaving the inventory of the older films where the length of the film is less than 55 minutes. when we select the query, we retrieve 294 rows. When we see the execution plan with the help of EXPLAIN, we see in result set that there are 1000 rows scanned from the table _____ and 2 rows scanned from the table inventory. The total rows scanned over here is 1000 from table film and 2 from table inventory. Remember, this is the case of subquery. It's quite possible that 2 rows are multiplied multiple times with this 1000 rows. Who knows what the final outcome of this query. And then we will do performance test and figure it out, which is the most optimal way to write this query. Now we move to a query with EXISTS keyword. When we select the data from this query, it once again returns us 294 rows. Upon looking at the execution plan, we can see it has to scan 4581 rows from the table inventory and 1 row from table film. However, when we add this up, this is definitely much bigger number than what we have seen subquery. Let's not think here too much and move further to JOIN example. Here we are joining two tables, inventory with film. When we look at the execution plan, we can see that it once again retrieves 1000 row from table film and 2 rows from table inventory. Well, all this looks very good, but we really do not know which one of this query is most optimal. Just like last time, we'll once again create a temporary table where we will be storing data from result set. Now we'll create three stored procedures. Each stored procedure will contain each of the query types. Over here we have subquery, next we have a query with EXISTS, and right after that we have query where we have used JOIN. Let's create these three stored procedures. Select the code for the stored procedure and click on execute. Query executed successfully. Hence, store procedures are created without any error. Now we'll execute these three stored procedures where we are going to look at our logic 1000 times inside the stored procedure. First we'll call stored procedure with subquery. It took 3. 011 seconds to execute this stored procedure. Let's truncate the table. Now, once again, we'll execute the query where we will use Exist key word. It took around 12 seconds. This is definitely not a good way to write this particular query. Now we'll truncate the table again and we will execute the stored procedure where we have used Joins and syntex. Select the statement and click on Execute. The query executed in 2. 808 seconds. Upon looking at performance data of this three stored procedure where we have executed them in almost same environment 1000 times, we can see that query with Exist is most expensive, but query with Join is most efficient query. Remember, the lesson which we learn in earlier clip, the same lesson applies once again. For different data set, different method works efficiently. It's quite possible one method will work for your one set of data. The same method may not be the ideal solution for different set of data and different Query. Do the performance test and figure it out which one is the most optimal solution for your query and your data set. Now let's do cleanup and drop all the stored procedures and table, which we have created for test purpose.

Demo: Tuning Aggregate Function
In this example, we will understand how we can tune aggregate functions, MIN and MAX. In the real world, developer often face performance degradation of query when they have to use aggregate functions like MIN or MAX. To find out MIN or MAX value from any column, MySQL Engine has to scan entire table first. Well, there are definitely few who work around to this particular limitation. We will see that in this demonstration. Just like any other example, we will be using Sakila database. Here is a simple query where we are retrieving all the films with the length of 100 minutes. Select the statement and click on execute. The result set contains 12 rows. The minimum film_id is 65 and the maximum film_id here is 994. I was able to figure this out by just visual inspection, but in real-world scenario, you will have to run some queries to figure that out. Here is very common method to figure it out minimum film_id from this query. We can use function MIN or film_id column. Let's select this statement and click on Execute. It will return us minimum film_id, which is 65, from this query. Here is another method. When we are using ORDER BY clause along with LIMIT keyword. ORDER BY clause will order this entire table from lowest film_id to largest film_id and we will limit this result set to return us only 1 record. Let's select the statement and click on Execute. This query also returns us minimum value of film_id which is 65. Well, let's use EXPLAIN keyword to understand execution plan of these queries. Select the statement and click on execute. Here it is. You can see this is a SIMPLE select on film table where MySQL Engine has to scan 1000 rows to figure it out what is the minimum value of film_id column. Now let's go back and check what is the execution plan where we have used ORDER BY and LIMIT clause. Select the statement with EXPLAIN keyword and click on Execute. You will notice MySQL has to scan a single row to figure out minimum value for film_id column. This is because we have a primary key index on film_id and MySQL was able to pinpoint that particular row with the help of ORDER BY, WHERE, and LIMIT. Method 2 is definitely much more efficient than using function MIN. There are definitely cases where you have to use function Minimum or any other aggregate function, but if you can be creative and replace the function with this kind of logic, you should definitely attempt that as that will give you optimal performance. Well, that example contained minimum function. Now we will see how we can find maximum value of a column with similar logic. Here it is, we have a SELECT statement with maximum function. When you click on Execute, it returns this value 994. Now here we have another SELECT statement where we have used similar _____ trick one more time. We have WHERE clause, ORDER BY, film_id DESC, and LIMIT of returning 1 row. Select the statement, click on Execute. We can definitely see the answer is same, 994. Now let's go to execution plan. First we will see the execution plan of MAX function with the help of EXPLAIN keyword. Select the statement and click on Execute. MySQL engine has to scan entire 1000 rows. to return such result with the help of MAX function. However, when we see the execution plan of second query, where we have used WHERE, ORDER BY, and LIMIT _____, we can see that MySQL Engine has to only scan one row. Well, this was very simple trick about how you can optimize your query if you have used any aggregation function like MIN or MAX. Remember, we are getting this optimal performance because we have index already created on film_id column. It's quite possible you may end up getting similar or worse performance if you do not have index on the column where we are using aggregation. The only way to figure it out is to do a performance testing on the queries which you are using.

Demo: Optimizing Group By Clause
On my blog sqlauthority. com, one of the most popular questions I see in comments is, how to optimize group by clause. It seems like in any query, as soon as user put group by clause, query suddenly starts getting slow. Lots of people seems to think GROUP BY is a culprit for slow performance. Well, definitely GROUP BY has its own impact, but I would not say that it's the sole reason for slowing down performance of your query. There are work around to optimize GROUP BY as well. Let's see that in this example. Here are two queries. First query where we have used GROUP BY title and length and in second query instead of using title and length we have just used single column of film_id. Well, on a very first look, they both look very different query, but if you understand the structure of table film, you will definitely agree that both of these queries is going to return us identical results. Before we understand the structure of the table film, let's execute both of these queries one by one. Select the query, click on Execute, it returns us 378 rows. You can quickly observer the result set as well. now let's execute this second query. When we execute the query, it once again returns 378 rows. I have previously compared the result and they are identical. The reason for both of these queries to give us same result is very simple. Column film_id is primary key of the table film. And when we use GROUP BY function with title and length column, that pretty much makes this combination unique. If combination of both of these columns is unique, we can easily replace them with another unique column, which corresponds to these columns. What that means is that instead of these two columns, we can use another single column, which has one-to-one relationship with these two columns. That means primary key of that table is a good candidate to replace combination of both of these columns. We have definitely replaced both of these columns with primary keys and we have definitely got identical results, but the real question is that is it improving the performance of this query. Well, let's see the exception plan of both of these queries one by one. Here is our first query where we have used title and length in GROUP BY. Let's see the execution plan of the same. When we see the execution plan, we can see that to retrieve 378 rows, MySQL Engine has to scan entire table as none of the index is used to execute this query. Now let us see second query where we replace title and length with film_id. Let's execute this query with EXPLAIN keyword and click on execute. Now when we see the execution plan, we can see that there are many different index qualified to execute with this query. MySQL Engine figures out that it's optimal to use PRIMARY key index with this query. However, when we go further, we still it is scanning 1000 rows. That means even though it is using Index, MySQL Engine still has scan entire table to read the result from film table. Well, if that is the case, index has not helped improving the performance of this query. Before we reach to that conclusion, let's do a quick performance test. Here, once again, we'll create a small table called TestTable. In this table we will insert the data when we execute our queries in LOOP. Here is our first query into the stored procedure called FirstOption. Let's create this stored procedure. Now create second stored procedure, and the stored procedure is created successfully. Now we will call first stored procedure and we'll pass parameter 1000. That means the logic which we have used in FirstOption will be looked for 1000 times. Select the stored procedure and click on Execute. This query took 12. 246 seconds to execute. Now let's again clean the table, the TestTable by truncating it, and once again, execute secondOption with a parameter 1000. That means this logic will be executed 1000 times. Select the stored procedure and click on Execute. Well, you can see that SecondOption took only 3. 057 seconds. SecondOption where we have used primary key in GROUP By, instead of multiple columns from the same table is 4 times faster than other query. Remember, in this case, I had a one-to-one relationship between film_id, which is a primary key. I linked the column together, which are title and length. If you ever face similar situation, you can replace multiple column with primary key and get much faster performance of the query. If you do not have one-to-one relationship, you may not get accurate results or your result will be entirely different than the original intended result. If you are a data purist, you will disagree that both of these queries are totally different queries. As I said, these two queries are not the same, it just happens to be returning same result in this environment where there is a one-to-one relationship between columns. If you are not sure if you can replace two columns with another column, there is another way of tuning GROUP BY as well. You can create index on title and length column or the column which you have used in your GROUP BY statement. This kind of index created on your GROUP BY clause may help performance of your query.

Demo: Optimizing Paging with LIMIT Clause
In this example, we will understand how we can use LIMIT keyword to optimize the case where we have the loop paging in your application. Here is our problem statement. Retrieve row number 396 to 400 from table customer where table is ordered by customer_id. What that means is that we need to retrieve 5 rows from table customer when it is ordered by customer_id. Lots of developers just select * from customer table and brings this entire result set into your application. Right after that they will apply concept related to paging on this big result set. This is not good because you only need 5 rows, but here you are bringing in 599 rows from your database to your application. When you retrieve all the data from your application, your application cannot use any index or any other optimization best practices you applied. The good idea would be to only retrieve the rows which you need. Additionally, you also do not need to retrieve row number which are over 400 as we need data from 396 to 400. We can use LIMIT keyword to limit the data to retrieve only 400 rows. when we use LIMIT keyword, it will not retrieve all the data, rather it will limit the result set to the number which we have passed right after that. One of our business requirement is the table should be ordered by customer_id. We can quickly add ORDER BY clause to this query and execute this statement. Now our result set contains 400 rows, but it also satisfies the need of table should be ORDER BY customer_ids. Still, if you look at it you are retrieving 400 rows where you only need 5 rows. You can be creative with LIMIT clause over here. You can change the LIMIT clause instead of 400 to 395. Right after that you can specify offset. This means start from row number 395 and retrieve 5 next rows. When you execute this statement, MySQL Engine will now retrieve only 5 rows. It will start from next row of your LIMIT clause and will give you number of the rows which you have specified right after that. You can see in the result set it has retrieved us 5 rows from 396 to 400. If you have to implement paging logic in your application, I strongly suggest that you use power of database to do paging instead of bringing entire result set in your application and applying paging functions and classes over it

Demo: Impact on Performance of UNION and UNION ALL
One of the very common confusions developer has with Union and Union All. The confusion is they do not know when to use what or what is the impact on performance of using either of them. Well, Union and Union All are not the same. When you use Union function, it will give you distinct result from your entire result set. However, when you use Union All, at that time, MySQL Engine will not do distinct on your result set. That means if you have a duplicate value, Union All will not remove them, but will keep as it is. However, if you have any duplicate value in your result set, Union will remove them. Well, this is the difference between them in terms of what they return in the result set. So if you want to remove duplicate result from your result set, you will have to use Union, and if you do not want to remove duplicate result from your result set, you will have to use Union All. You cannot replace each other in that scenario. However, there are cases where I've seen developer using Union instead of Union All and it has negative impact on performance, but result stays as it is. For example, in Sakila database we have similar situation. We have three tables, staff, customer, and actor. All three tables have different data in them. If you Union them or if you Union All them, they are going to give us identical result. Let's check that with the help of EXAMPLE. First we'll execute the query where we are using Union All. Select the statement and click on Execute. It will return us 801 row from 3 tables of staff, customer, and actor. Now we'll execute similar query with Union instead of Union All. When we execute this query, it will also return us 801 row and result set is absolutely identical to earlier result set. Now in this scenario, there are no duplicate values into this table, hence our result is same when we are using Union or Union All. If you ever face situation where there are no duplicate, I strongly request you to use Union All instead of Union. Let's do a quick performance test of this with the help of stored procedure where we loop over this query multiple times. Let's create a simple table, customer test with three columns in it. We'll be using this table within our stored procedure for performance test. Table is created successfully. Now we'll create 2 stored procedures, one where we will use union All and another one where we have used Union. Select the code and click on Execute. Stored procedures are created now successfully. Now we will call each of the stored procedure in _____ The parameter which you are passing over here is 1000. That means the logic that we have used in this stored procedure will be looked over 1000 times. Let's select the statement and click on execute. You can see in output window that this stored procedure took 4. 680 seconds. Let's look at the test table and now we will repeat the test again with second stored procedure over here. Select the statement and click on Execute. Well, second stored procedure took 5. 320 seconds to return us same result set. That means the query where we have used Union is slower than the query where we have used union All. So if there is a scenario where you can use either Union or Union All, I strongly suggest that you use Union All, but your business requirement is to remove duplicate rows you must use Union in that case as Union eliminates duplicate rows. Now let's cleanup by dropping stored procedure and test table.

Demo: Index and Not Equal to Operator
In this example, we will see how we can re-write a simple query and improve the performance of it with the help of index. For example, you want to retrieve every single data related to customer from customers table where store_id is not equal to 2. You can simply execute this query to get your necessary data. This query returns you 326 rows. Let's check execution plan of this query with the help of EXPLAIN. When you execute this query, you can see that MySQL has to scan 599 rows to return you 326 rows. Even though there are possible index addition MySQL does not use that index when it executes this query. Well, let's think about it, how we can tune this query. It would be good idea that MySQL uses the index which is it suggesting that this query can use. The reality is that because we have used store_id does not equal to 2, MySQL will not use any index with this query. This happens because we have used not equal sign here. Let's see if we can convert this not equal to equal to. For that, we need to see what are the different store_id used in customer table. Let's execute this query to find out what are different values of store_id in customer table. There are only two values, 1 and 2. That means we can get exactly the same result as this query if we change not equal to 2 to equal to 1. Let's execute this query, which is very identical to the query which we have executed earlier. Select the statement and click on Execute. It once again returns us 326 rows, but when we check the execution plan with the help of EXPLAIN keyword, we can see it uses the index which it has suggested earlier. With simple tricks like this, you can optimize your Query performance in multiple falls. MySQL also scans only 326 rows to return you 326 rows.

Summary in Sixty Seconds
Summary in Sixty Seconds. There are various tips we have covered in this module, however, here are the few tips you must not forget. You can use EXPLAIN keywords to check the execution plan of the query. Avoid using <> operator in query as it ignores index created on table. Use Union All in place of Union if you do not care about duplicate data. Always test your query with real data on your development server before deploying it on production.

Best Practices
Best Practices
Hi, this is Pinal Dave, and welcome to the module of Best Practices. In this course, all along we have been learning best practices to keep your queries optimized. However, a few best practices are so important that the developer should never, ever forget them. In this module, I have picked a few of the most important best practices to keep your queries running at optimal speed. Use EXPLAIN keyword to use the execution plan for your query. Two key elements to watch for in Execution Plans are index usage and rows scanned for query. Use LIMIT 1 clause when retrieving Unique Rows. You can also use LIMIT to improve performance of aggregation functions like MIN or MAX. If your query uses <> to operator, try to convert that to = operator. = operator increases chances of your index to be used for your query. Avoid using SELECT * unless you are retrieving all the columns of your table. SELECT * forces full table scan by ignoring indexes to execute the query. Additionally, if you retrieve columns which you don't use in your application, it also wastes your network bandwidth. Split your big DELETE, UPDATE or INSERT query into multiple small queries. It improves the performance, as well as gives you better control on data movement. Use appropriate data types for columns if you are going to only store integer, do not create your column with data type _____. Remember smaller columns are faster for performance. MySQL query cache is case and space sensitive. That means if you are going to get the same result set multiple times, try to use same query with same case and spacing between the words. This improves your query performance by many times because MySQL engine will be able to return your result set with regard to index. Remember, if you create index on the column which you have used in a WHERE clause it improves the performance. This is just generic advice. Additionally, it's also a good idea to create index on the columns which you have used in the JOIN. Once again, this is just generic guideline, it does not mean that you will go and create index on every column used in your JOIN. Use your best judgment and test your queries before you create too many indexes. Use UNION ALL keyword instead of UNION keyword if duplicate data is permissible in your result set. UNION ALL gives better performance than UNION because it does not have to do distinct operation on your query. If you are going to just use INNER JOIN, the table order used in your JOIN clause does not matter. Also, if column used in ORDER BY clause are indexed, they help with the performance of the query when you are doing one of the most expensive operations of MySQL, which is _____. If your application implements pagination, it's a good idea that you use LIMIT clause to implement paging in your database itself. Not only this improves performance, but it also reduces unnecessary network traffic between your database and your client application. And here are my final words. There can be multiple ways to write a query to produce the same result set. It is possible that one method works for one query, whereas another method works for another query. Always test your query with near real data and schema on your development server before deploying to your production server. I hope you enjoyed this course and do reach out to me in case of query or confusion. I will be happy to answer any of your questions related to MySQL. Thanks for watching this course.
