DevOps engineers are often asked to build, test, and deploy applications in a way that's reliable and repeatable without making code changes to the application itself. One of the tools that's available to do that is Jenkins pipelines. In this course, Building a Modern CI/CD Pipeline with Jenkins, you will dive into foundational knowledge to write a Jenkins pipeline. First, you will learn the basic syntax and expressions. Next, you will discover how to version your pipeline code in GitHub. Finally, you will explore how to import functions and pipeline code from a shared library. When you are finished with this course, you will have the skills and knowledge needed by DevOps engineers to create, version, and deploy pipeline code.

Course Overview
Course Overview
Hi, everyone. My name is Christopher Blackden, And welcome to my course, Building a Modern CI/CD Pipeline with Jenkins. I'm a full‑time DevOps engineer, and my primary continuous integration and deployment tool is Jenkins because it's got an ecosystem of plugins that can run on any platform. Jenkins pipelines are powerful because they can be used to create intricate deployment processes that can be maintained and versioned alongside application code. This course is meant for DevOps or software engineers who want to script pipelines to build, test, and deploy their containerized applications to a Kubernetes cluster. We'll be covering how to build Docker containers, run unit tests and container scanning tools, and finally to deploy to a Kubernetes cluster using Jenkins pipelines. Some of the major topics that we'll cover include the syntax and features of Jenkins pipeline code, using open‑source container scanning tools, creating reusable shared libraries to use with Jenkins pipelines, and using flow control steps and conditions to control deployment. By the end of this course, you'll know how to write Jenkins continuous integration and deployment pipelines, and deploy your applications from a version control system like Git. Before beginning this course, you should be familiar with the basic Jenkins concepts and very comfortable using the command line. I hope you'll join me on this journey to learn about continuous deployment pipelines with the Building a Modern CI/CD Pipelines with Jenkins course, at Pluralsight.

Getting Started with Jenkins Scripted Pipelines
Getting Started with Jenkins Scripted Pipelines
Welcome to Building a Modern CI/CD pipeline with Jenkins. There is a lot of good stuff in this course for building continuous integration and continues deployment pipelines for a modern application. Specifically, we're going to be looking at a container‑based application that deploys to a Kubernetes cluster. So first things first, we're going to be building our pipeline with scripted pipelines, so we're going to cover a little bit of scripted pipelines 101. To do that, we need to go over how to configure Jenkins integration with GitHub, and then because there's so many different ways you can write your pipelines, I want to make sure that you know where to find the scripted pipeline documentation. Finally, we're going to go ahead and run a sample Hello World pipeline just to see it all in action. So some of the things we're not going to do here are set up Jenkins from start to finish. I'm assuming that you already have at least a basic installation of Jenkins CI/CD's server somewhere. So if you don't, there's a couple of courses here that can get you started, like Getting Started with Jenkins 2, and this is a good resource to actually install and configure the your initial Jenkins setup. We'll go over a few of the settings that we need to for this course, but for the most part, I'm assuming you've done this already. Next, I'd recommend Groovy: Getting Started. This may seem like a bit of an odd one, but actually Jenkins scripted pipelines are written in Groovy‑based DSL. Now, for those of you who are not familiar, Groovy is kind of like JavaLite. It's based on Java classes and uses a lot of the same syntax, but it's a dynamic language, which means you don't have to compile it before you execute it. You don't need to know a ton of Groovy for this course. Just the basic syntax will get you by. We'll go over more detailed stuff later on. For now, if you're interested, check out this course. And finally, Continuous Integration and Continuous Delivery: The Big Picture. This kind of gives you a sense of what the best practices are to start building pipelines. We're going to be diving into some specific Jenkins Pipelines here, but this will give you an overview of what you can shoot for and what kinds of things you can achieve with this framework. So our course pipeline is actually going to be pretty simple. We're going to take a GitHub repository with an already constructed app, and we're going to create a pipeline that, without making any changes to the code itself, will build the containers for the application and then run those containers through a variety of testing suites, in this case, Anchore and Trivy, which are two container scanning applications. And finally, once those scans are done, we're going to deliver it to a Kubernetes cluster. This should be a super interesting course, and I'm really looking forward to it, so let's get started.

Building a Modern Ci_cd Pipeline with Jenkins
[Autogenerated] If you want to follow along with the course, you'll need to repost. The first is the demo application Repo, which is just a fork of the azure voting app reddest demo that the Azure docks have provided. And the second is a demo shared Pipeline Repo. This isn't gonna be as important early on in the course, but you'll find yourself referencing it later on. I encourage you to check him out, review some of the code inside and follow along if you can. It really does help when trying to get the material down. You could also do one better and fork your own repo for each of these and play around with it yourself. Try some new things now let's continue with the rest of the course.

Setting up Jenkins for Scripted Pipelines
So Jenkins can be set up any number of ways and with several different configurations. I've seen it done with several different source code plugins, deployment styles, over Windows and Linux. My wife likes to joke that Jenkins is what happened when the Ask Jeeves guy went into witness protection. And I disagree with that because instead of just serving web pages, Jenkins does pretty much everything for you as long as it's configured properly. So in this section of the course, we're going to look at how we're going to configure Jenkins for this course and for scripted Pipelines, and we're going to look at how the GitHub integration is set up. So first things first, if you've played with Jenkins at all, or if you've set up any jobs, you've probably set up Freestyle jobs, and these are a little bit different than Scripted Pipelines in a number of ways. For example, with Freestyle jobs, you've probably configured them through the UI, whereas what Scripted Pipelines, you're configuring them through code. Instead of clicking through a bunch of manual windows, you're defining your build instructions alongside your application code. Also with Freestyle jobs, none of your changes are really tracked. There's plugins that Jenkins can use to address some of that, but really, they're not very robust, and they leave a lot to be desired. With Scripted Pipelines, you track all of your changes to each build instruction through source control, as you do with your application code. Another difference with Freestyle jobs, if you need to move them to a different Jenkins server or change hardware, you're pretty much recreating them from scratch. With Jenkins Scripted Pipelines, you just import the new Pipeline wherever you want it to be. Another difference is, with Freestyle jobs you need a separate job for each step in the Pipeline. It's actually a best practice using a series of Freestyle jobs, to use a different step for each significant step in the Pipeline, like build, test, or deploy, and then put them all downstream from one another. And that way, you know if your Pipeline fails, where it fails and how do you address it. With Scripted Pipelines, all of that's built in, and you have the additional benefit of being able to parameterize these scripts and using them for different applications so long as they share similar build steps. We'll go into that later in the course as well. And finally, creating and configuring Freestyle jobs is a very manual process. I remember one of my first jobs when I got into DevOps in the first place was setting up a series of Freestyle jobs that took me couple of months to actually get through. Whereas Pipelines, they can be pretty much automatically generated, and we'll go into that a little bit more as the course goes on. But a lot of what you'll see in Scripted Pipelines is programmatically already set up, and you just need to tweak it for your needs. So one more thing before we continue on, there are some very specific definitions when referring to the Jenkins documentation, so we're going to cover some of that here. First and foremost, a Pipeline is a series of tasks required to build, test, or deploy an application. So this is start to finish your process on how do you get your application from source control into production. The next term you'll hear a lot in this course is agent, and an agent in Jenkins terminology defines which Jenkins build agent should run the Pipeline. So, for example, if you have an application that you need to build on Windows and Linux, you'll have an agent for each of those and then be able to run that Pipeline on both of those agents, depending on how you want to build it or test your application. The next term I want you to know is a stage, and that is a section of the Pipeline such as build or test. And finally, a step in each stage is the specific instructions to execute the stage. Now, if you don't get all this now, don't worry. This'll make a lot more sense once we start getting into the code, but it's important to have these definitions because the Jenkins documentation will refer to each of these as such. Speaking of the Jenkins documentation, there several different ways to set up Jenkins. I'm not going to pretend to be able to cover them all in the course. It would go on for far too long if I could cover every technology and every plugin. Instead, here are some links to the Jenkins Pipeline documentation, and this is very good for how to configure and set up Jenkins Pipelines to do things other than deploy to Kubernetes or run unit testing or any other tips and tricks you might want to implement in your Pipelines. Second is your Pipeline syntax. Now the Pipeline syntax for Jenkins is very specific. I mentioned it's a Groovy DSL, but it's not strictly Groovy. There are some tips and tricks to it. If you run vanilla Groovy but try to run that same code in a Jenkins Pipeline, it's going to break. So consult this when you need to insert a step into your Jenkins Pipeline. And finally, there's a Pipeline steps document here that has a list of Pipeline‑compatible plugins and how to generate steps for them. I mentioned earlier that these steps can be automatically generated, and this document here has quite a number of them already written out. So if you have something that you want to build into a Jenkins Pipeline, check here and see if that plugin has a prebuilt Pipeline step for you to use already. All right, in this demo, we're going to go over how to set up GitHub integration with Jenkins. I imagine this is something you all already have done, but just to be safe, I'll go over it anyways. If you have done it or you know how to do it, just skip that step. And second, I'm going to go over the Scripted Pipelines plugin and how to start using it. All right, let's cut over to our first demo of the course.

Connecting Jenkins to GitHub
So, first thing, we're going to take a look at the app we're going to be using for this course. This is an Azure voting demo app that runs on Kubernetes. It lends itself very well to a Kubernetes‑style deployment. And you'll see there's even a jenkins‑tutorial folder here. If we click on this and take a look at one of the shell scripts, it's not really a Jenkinsfile. These are just really shell scripts that install the necessary tools. We're going to ignore these for now and set up our own Jenkins Pipeline to use this. But if we go under azure‑vote, there's actually a Dockerfile here. There's some application code. If we go back to the root of the repository, we'll see that there's an‑all‑in‑one vote YAML, and this looks like a Kubernetes deployment manifest. So part of the goal for this course is that we don't want to make any changes to the application code. If you're a DevOps engineer that's going to be supporting developers or supporting a team of developers, we don't want to make any changes to their code to get it to run better. We just want to get it deployed, as is, but in a safe and secure manner. So this is the app that we'll be using. I forked it to my personal account here, and I'll show you why in just a minute. Let's switch over to my profile settings. All right, so I'm here in the Public profile page from my GitHub account, and under Developer settings, Personal access tokens, you see we've got a couple of tokens here, but we want to set one up for Jenkins as well. We're going to generate a new token, and we're going to call it Jenkins. Now we could give this a lot of different permissions. I don't want to give more permissions to Jenkins than it needs, though. So let's go over to Jenkins and see exactly what it needs for GitHub integration. Okay, I'm here at my local Jenkins instance, and the first thing I'm going to do is click on Manage Jenkins on the left‑hand side. Now, if we scroll down here to Configure System and then scroll a little bit further down here to the GitHub section, we're going to add a new GitHub server. Now, it's already got the API URL for GitHub plugged in, so we're just going to go ahead and call this our GitHub Connection. And under Credentials, let's click on the question mark on the right‑hand side here. If you ever have any questions about Jenkins settings, that question mark usually has the answer for you. So it says to register with GitHub, we need our token to have the admin:repo_hook, repo, and repo:status scopes. So let's go back to GitHub and set up our token. So back here in GitHub, I've set up the token, I've set up the scopes. Let's go ahead and generate the token. And here it is. Let's copy it off for now. You're only going to see it once, so make sure you save this off. Let's go back over to Jenkins and plug it in. So back here on Jenkins, I'm going to add a new Jenkins credential, and we're going to use the Secret text kind, plug in our secret text. And I've already got one here with GitHub Token because I was playing around with this earlier, so we're going to call this GitHub Connection. Let's click Add, and then if we go under Credentials, we have GitHub Connection here. Let's minimize that so we can see a little better, and I'll go ahead and test the connection, and it works. So now let's save that and continue on with our setup.

The Scripted Pipeline Plugin
So I'm here in my Jenkins instance, and we're going to go back into Manage Jenkins to take a look at this. Now check out here under Manage Plugins. You see I've just done my updates here, so the course is going to be, at least for now, on the latest versions of all of these. But let's go ahead and check out the installed plugins, and go ahead and filter this page to just pipeline. So there's a lot here, but if we just go down a little bit, you'll see that the Jenkins Pipeline plugin is already installed. And there's some other things that we can use here to extend our pipelines, but the basic Pipeline plugin that has everything we need for this course is already here. If you expand on that a little bit, it will take you to the plugin page and give you some of the documentation and syntax reference that I mentioned earlier in the course. But it'll also take you to GitHub page for the plugin. Since Jenkins is an open source project, all the plugins for it are open source as well. So you can go and take a look at the code any time you need. For now, let's go back to our presentation and talk a little bit more about scripted pipelines and how to use them.

Scripted Pipeline Syntax
So now that we've connected GitHub with Jenkins, let's take a look at the Scripted Pipeline itself. In this section of the course, we're going to go over how to actually create a Scripted Pipeline job, a Hello World for Scripted Pipelines, if you will, and go over some of the basic syntax that you'll need to set up a Pipeline and run it. So just to give you an idea of how to use Jenkinsfiles and how to include a Scripted Pipeline with your code, we're going to take a look here at a sample of a GitHub repository. Really, it's a mock of a GitHub repository. You've got your application code, your README, gitignore, maybe a Kubernetes configuration, some other stuff, and a Dockerfile. Well, the Jenkinsfile, which is going to contain your Scripted Pipeline, is going to live at the root of your GitHub repository in a separate file called Jenkinsfile. And this can be changed, but by default that's what it's called, and this is what Jenkins is going to look for when you import a job from GitHub with a Scripted Pipeline. To look at a little bit more of the detail of what is in a Scripted Pipeline file, this is it. This is the Hello World Pipeline we're going to run a little bit later in the demo. And you remember back in the last section, I said that syntax was very important and that certain words had a very strict definition, this has all of them here. So we have our pipeline, which is the complete script from beginning to end. And then agent. In this case, we're not specifying an agent; we're just saying it can run on any agent. You do have to include an agent block in your Pipeline, but it's important to know that you can specify that this can run in a Docker container or run on a specific node. There's several different ways to configure this, but it is a required block in the Pipeline. And next we have our stages block, and we'll go into this in the next slide a little bit more, but each Pipeline is going to have more than one stage, and each stage is going to have one or more steps. So in this case we've only got one stage and that is our Hello World stage, and we've got one step in that stage, which is to just return Hello World. This is a pretty simple example. They will get infinitely more complicated as the course goes on, but having this basic framework will allow you to understand the rest of them a lot more. We can include more than one stage in our Pipeline by just adding another stage block after the first one So we have our Build stage in this example with one, whatever the steps for the build process are. And then we have a Test stage in the Pipeline with whatever steps we need to test it. Those will run one after the other, and if one fails, let's say, for example, Build fails in this case, Test won't run and Jenkins will return an error. Again, this will make a little bit more sense as we go along in the course, but this is a good thing to keep in mind when you're talking about building a Scripted Pipeline. All right, in this demo, we're going to run a Hello World Scripted Pipeline, as well as see where we can find some of the generated steps that we can put in later stages in our demos. Let's get started.

Running Scripted Pipelines
So back here in Jenkins, this is a fresh instance, the same one we were using in the last demo. The first thing we're going to do is create a new job. And you'll see there's a couple of different types of Jenkins jobs that we can set up here. In this course, we're primarily going to be focusing on the pipeline type of job and the multibranch pipeline type of job. The only difference between these two is that the multibranch pipeline will go and scan your Git repository for other branches, and then use that pipeline on those other branches. We'll get into how to use these later on in the course. For now, we're going to just create a regular pipeline job. And since every job has to have a name, we're going to call this one Hello Pipeline. Once that's done, click OK. Okay, now we've got a few other options here. These are the, most of the same ones as you'll find in the freestyle jobs, but the real part we're interested in is down here under Pipeline. Now there's two ways that you can do this. You can either use a pipeline script, which we can generate and input here, or we can use a pipeline from SCM. If you take a look, the script path is set to Jenkinsfile, which is at the root of our GitHub repository. This is configurable, but it's best practice to leave it at the default. We're going to, for now, go back to the Pipeline script, and try the sample Hello World pipeline. So you see, this is the same one we had in the slides earlier, I'm just going to Save this, and then click Build Now. And this is not going to take very long to run at all. There we go. You'll see we have one block called Hello, that is our stage. Each other state is appended to this screen as we add more and more of them. But we can get these logs from that by hovering over this block here, and clicking on Logs, and we'll see the Hello World message that was printed from the step in that pipeline stage. The other thing we can do is go under the job here, and look at the Console Output. And you'll see we actually have a little bit more of a breakdown here, we have the pipeline stage, the stage name, which was Hello, and then the echo Hello World step in that pipeline. So let's go back to the pipeline, and make some changes, and see what happens. If we want to add another stage here, let's take a copy of this first one, and we'll call this one Goodbye. And we'll just have this one echo Hello World, then Goodbye World. So let's Save this and run our new pipeline, Alright, we have the Hello and Goodbye stages now. You see Goodbye happens right after Hello. And if we look at the Logs, it's got the Goodbye World message in that stage, but not the Hello World message that was in the stage before. And the same is reflected if we go into the Console Output, there's a shortcut here, if you click on the blue dot on the left here, it will take you straight to the Console Output instead of having to go to the job run and then to the Console Output. But you'll see we've got the same thing here, we've got the Hello and Goodbye stages, wanting, running one after the other. We also have the ability to restart from a stage. So if we click on Restart from Stage, and specify that we want to start the pipeline at the Goodbye stage, this might be if a build fails or something like that, and you have a very long build step that you want to skip. We can then go into that build, and then to Console Output, and we'll see that it only ran the Goodbye stage, it skipped the Hello stage because we restarted it from the second stage. So let's go back into our Pipeline configuration. There's one more section I want to show you here under Pipeline Syntax, and this is where it gets a little bit interesting. You can actually generate snippets of pipeline code based on what plugins are installed in your Jenkins system. So, for example, I have the PowerShell plugin installed on my Jenkins system. So if if I want to execute a PowerShell command like Write‑Output, then I'd just enter that here. And then when we click the Generate Pipeline Script, you'll see that we have a PowerShell command, but it's not the way we would typically expect to see it. Let's copy this for now, and then go back to our pipeline script. Now if I want to add another stage here that's Hello from PowerShell, and instead of using the echo command, which is a generic shell command, we're going to use that PowerShell script that was generated for us in the last step. Now let's save this, and run the pipeline again. Great, looks like that ran with no issues. You can see here we're using the PowerShell Script plugin from Jenkins, instead of the print message that we had in the last stage. If we go over to the Console Output, we don't really see much of a difference, just that it's running the PowerShell plugin on the step right before the output. And in this way, you can really customize these pipelines to do anything you need them to do. Now that we've seen the pipeline run, let's add the Jenkins file to our Git repository.

Running Scripted Pipelines from SCM
So I'm here in my Azure voting app repository, and the first thing I'm going to do actually is create a new file at the root here called Jenkinsfile. And for now we're just going to copy and paste the code from our previous job, so I'm going to go ahead and do that first. So this is the same code we had in the last demo, but I'm going to make some changes to it. Instead of doing Hello, Goodbye, and pwsh Hello, I want to actually get some specific information that I can use to make sure that I'm running this on my Git branch. So that's actually the first thing to do is I'm going to change this Hello stage to a Verify Branch stage. And instead of echoing Hello World, I'm just going to echo the environment variable for GIT_BRANCH. And we can remove all these other stages for now. Now it's important to note that you're not going to have this by default. In fact, Jenkins will insert a number of environment variables at runtime. It's how it does a lot of the configuration behind the scenes. It will set environment variables based on what settings you have in your Jenkins configuration at runtime. So in the specific case of Git or GitHub, it will actually create this GIT_BRANCH environment variable for us to use if you're running from a GIT_BRANCH. So let's save this, and then I'm going to break a couple of rules here and just commit directly to master so we can show this and move on the demo. Great, now let's go over to Jenkins. So I'm back here in my Jenkins console, and I'm going to create a new pipeline job for this. So let's go up to New Item, select Pipeline, and we'll call this Voting App Pipeline. Now that we're in the Pipeline configuration for this project, we can specify that this is a GitHub project and provide a GitHub URL. And then if we scroll down, we're going to leave the Build Triggers alone, we don't want to build every commit just yet, but under pipeline script, instead of making this a script that I copy and paste like we did in the last one, I'm going to use the pipeline script from SCM. And I'll also have to specify that this is a Git project and provide the Repository URL here as well. Now because this is a public project, we should be able to run it from here, so I'll go ahead and click Save. And then if we click on Build Now, you'll see that the first thing it does is check out source code, but then our Verify Branch step failed. Let's see what happened here. Oh, I forgot to put it in quotes, that's what happened, so let me go fix that off camera, and then I'll run this again. Okay, that's better, that ran now. And if we go to the Console Output for that job and scroll down a little bit, we see the branch name did get printed, so that was just a minor fix there. Let's go back to the job. And because we specified a GitHub URL for this earlier, I can actually go straight to the repository from this job, and you can see the file I changed right here. So that was the fix, just adding quotes to line 7. Alright, let's wrap this module up and go to the summary

Summary
All right, in this module, we learned about the Scripted Pipeline feature in Jenkins and how pipelines are different from traditional freestyle jobs. We also learned how to generate pipeline code and what is the anatomy of a Jenkinsfile, which we'll be diving more into in the next module. We also learned how to set up GitHub integration with our Jenkins server and where the documentation is so you can extend your pipelines beyond what's shown in this course. Because Jenkins is so customizable, I imagine you'll be the using these documents a lot. Thank you for joining me so far, and I'll see you in the next module.

Building and Testing Code
Building and Testing Code
Welcome back. In this module, we are going to be building and testing code in the Jenkins Pipeline. So now that our GitHub and Jenkins integration is done, we're going to start by building the container that we're going to deploy. And to do that, we're going to introduce how to run shell scripts in pipelines. After that, we're going to do some unit testing on the application, and we'll introduce the concept of the Multibranch Pipeline and post steps. In our case, we're going to see about setting up post steps to notify us of a successful build or a failed build and take different actions from there. So here's our course pipeline, and we've just finished integrating GitHub with Jenkins. We're going to stay in GitHub for a little while and take a look at what else we can do with the pipeline code. Now this is the scripted pipeline that we ran in our demo. It's a simple Hello World, but it's a little bit confusing if you're new to scripted pipelines because this echo command is not actually running a shell command or a batch command echo. It's a step in the Jenkins Pipeline syntax. So let's go into the documentation and take a look at it. So back here in the Pipeline Steps Reference that I put a link to earlier, there's a bunch of different things here, but let's just search for echo. And we have a few different plugins, but here's the one we're using under Pipeline: Basic Steps. So if we click on that, you see it's actually the echo pipeline command. It's not a shell script in itself. It's just taking a String and printing it. We have a few other options for running shell scripts. Let's go take a look at them. So back in Pipeline Steps Reference, let's search for some other ways that we can run shell scripts in our Pipeline scripts. Now I'm on a Windows 10 device running PowerShell Core, and the executable for that is pwsh. So let's see if we search for pwsh, it takes us down to this Pipeline: Nodes and Processes section. If we go in there, we see we have a few different options to run shell scripts on our systems. So we have Batch, PowerShell, and PowerShell Core, of course, but we also have shell for Linux. So depending on what host machine or agent you're running this on, you might want to use a different command. Let's go back to the slides, and we'll go into this a little bit further. So this is the Hello World step that we had in our demo script in the last module, but an equivalent to that on a Linux box or host would be this here, which is the shell step to run the script echo Hello World. On this machine, since again I'm running Windows 10 with PowerShell Core, it will look something like this where it's using the pwsh pipeline step to run a Write‑Output cmdlet using PowerShell Core. If this doesn't make sense now, that's fine. We're going to do this a little bit more the demo and go a little bit more hands on. In this demo, we're going to build our Docker container by running shell scripts in our pipeline. Let's get started.

Running Shell Scripts in a Jenkinsfile
All right, I'm back here in my Jenkinsfile, and I'm going to go ahead and pull some changes I made off screen, and then we'll go through them. So this is the new stage we're adding, It's a Docker build stage, and I split it up into two different calls. One I'm doing on a single line, and one I'm doing multi‑line. So the first on on line 12 is going to list the Docker images we have on our system. This will kind of be a sanity check just to show that it's working. And then I'm going to change into the azure‑vote directory, because that's where our Dockerfile is, and build our Docker container. For some reason, I put docker images there twice. That's okay. And after that, I'll change to the original directory I started the stage in so that if I add any more stages later on it won't affect them. So let's go ahead and switch over to Jenkins and take a look at it running. Okay, we're back here in Jenkins, and the script has finished running. Let's go ahead and go straight to our console output. If we scroll down a little bit, we still have the Verify Branch step, which is confirming that we are on the master branch. You'll also see that we have the docker images command that we ran. It's not showing anything because we don't have any images on this box yet. The next step was to build the Dockerfile, and you can see that happening in these steps here. It'll output everything until it gets to the bottom where you can see that we now have some Docker containers built on this system. Let's go to the next demo.

Introduction to Multi-branch Pipelines
Alright, back here in our course pipeline, now that we have our Docker images built, we're going to go on to the next stage and unit test them. Unit testing a Docker container is a fairly straightforward process. You simply bring up a copy of that container and then run tests of your application against it. Based on whether those tests pass or fail, you can either go onto the next test or report a bug or even go back to the drawing board. The advantage of having a multi‑branch pipeline in Jenkins is that you can run the same Jenkins file or even slight variations of it against the same code base. So you can run it against the master branch or any feature branches, and you can have either the same unit tests or add unit tests as you continue your development. Since it's all stored alongside your application code, it's easy to version, easy to change, and easy to merge. In this demo, we're going to run unit tests on our new Docker containers. We're going to spin them up per branch in a multi‑branch pipeline, and then if and when they fail, we will introduce a failure post step that will let us take some specific action after we've tested the container. Let's get started.

Configuring Multi-branch Pipelines
I'm back in the GitHub repository for this project, and I've added another branch called add‑tests. So the problem with our current Jenkins job is that it's only running against the master branch. But for this example, I want to make sure that all of my testing and, in this case, my Jenkins Pipeline is running on both branches. So let's go over to Jenkins and set up a Multibranch Pipeline. So we're back in the Jenkins home page, and the first thing I'm going to do is delete the Voting App Pipeline. We're not going to need this anymore. We're going to be replacing it with the Multibranch Pipeline. So let's go up to New Item, and we'll keep the same name. But instead of making this a regular pipeline, will make it a MultiBranch Pipeline. The first thing you want to do when setting up a Multibranch Pipeline is configure your branch source, and this is the Git or GitHub or other version control repository with all of your code in it. In my case, it's GitHub, and I have the GitHub token as a username and password without the username so it recognizes me for the credentials. And then I just have to provide the HTTPS URL to our repo. So let's go ahead and do that really quick. And we can click Validate, see it's the right one. And we're going to keep the rest of this as default. We don't want to change too much for now. Note, in Build Configuration, it's still using the Jenkinsfile and looking for it at the root of the repository. So let's go ahead and save this, and it's going to go through and check, and it found both of our branches, master and add‑tests. And the default behavior is to run through them both. Let's pause the video here, and I'll unpause when it's finished running. All right, it looks like our master branch has passed, which makes sense because it passed for us in the last section. But the add‑tests branch has failed. And I already know why it failed. I set it up to fail, but let's go ahead and take a look at the logs for it anyways. Now I added three new stages at the end of the master branch pipeline, the Start test app, the Run Tests, and the Stop test app stages. Let's dive into the code, and I'll show you what each of these do and why it failed. So I'm back in Visual Studio Code in my Jenkinsfile, and it's got the three new stages here, Start test app on line 22, Run Tests on line 38, and Stop test app on line 45. And you can tell from the Stop test app stage that I'm expecting to have a Docker Compose file here that starts and stops the application. And if you look in the repository on the left side, I do have a docker‑compose file in my repository. What I'm missing in the Start test app stage is the Docker Compose upline. So it should've tried to start the app with Docker Compose and then run this PowerShell script. This script is going to try and ping the container three times, and if it can't, it will just fail out. So we're going to go check the console output and see if that's what happened in just a moment. But before we leave here, note on line 4 I'm actually using an environment variable called STAGE_NAME that I'm not setting anywhere. Jenkins sets certain variables at runtime for each pipeline. So whenever your stage is running, you have access to an environment variable called STAGE_NAME. That's just the name of the stage in the pipeline. So we're going to see that inaction in just a minute. Let's go over to our console output and make sure that this is what we're expecting to see. All right, we're here in the console log for the add‑tests branch, and right there in the middle it says, Start test app, which is the STAGE_NAME that failed. It tries to start the container three times, and then it goes straight to the post steps. So we know that's why our container is not starting is because we forgot to add a Start command. Let's go back to Visual Studio Code and add the command in. So, as I mentioned in one of the previous videos, this repository does have a docker‑compose file, and we can use that docker‑compose file to spin up and spin down a test copy of the application. So let's add that into our Jenkinsfile and commit it to Git. We're going to do this the same way we would any other code change, which is really the power of these Jenkinsfiles. I'll go ahead and speed the video up from here so you're not just watching me type. All right, let's go back to Jenkins, All right, if we hit Build Now, it'll run this one more time, and that should pick up our new commit and then run the rest of the pipeline. Let's pause the video, and I'll resume it when it's finished. All right, looks like that's finished running. I actually had to run it again because I did something a little foolish on my end. So let's go to the console output for that second run, and you'll see I actually forgot to include my unit test file from my local repository. So that's not a thing with the Jenkins Pipeline. If we go to the next build, that test did run, and it passed, so the pipeline is now green. You can also set up on the GitHub side to have this as a branch protection check to block any merging unless your test branch passes in Jenkins. In the next video, we're going to go over how to use post conditions so you can take different actions if your pipeline succeeds or fails.

Using Post-build Pipeline Steps
So I'm back in the Pipeline Syntax documentation, and some of you might've caught this in the last video, but we can also add post steps at the end of our build based on if the build was successful or failing. So here in the table of contents on the right side, there's a post section. Go over there, and you'll see we can set certain conditions in our pipeline. So if the build is successful, or if it's changed, or if you need something to always run regardless of the stages, success or failure, there's a condition for it here. Let's go take a look at what that looks like in the pipeline script. So I'm back here in the Jenkinsfile for my project, and you'll see I have a post section inside of the Start test app stage, and I have two conditions in that stage, If it's a successful stage, if it passes without any issues, then I know the app has started successfully, Docker Compose works, and I want it to print, App started successfully. But if it's a failure, I just print, App failed to start. And we can look for these in the console output. So let's go back to our Jenkins console and take a look for them. Okay, so we have a couple of different builds to choose from here. The Start test app failed in build number one, so let's go to the console output for that first. And I also put some emojis in there. So we can just search for a smiley face, and we don't find it. But search for a frowny face, and it takes us right to the line in question, which is, App failed to start. Let's go to the next successful build and see if we can find the success message. There we go. It says, App started successfully. Now these are pretty simple examples. You can use them to send email if you have the email plugin set up or Slack messages if you have the Slack integration plugin set up. You can get pretty creative with ease, but this gives you a tool to be able to respond a little bit quicker to the status of your pipeline while you're running it. All right, let's go ahead and wrap up the module.

Summary
In this module, we talked about how to set up a Multibranch Pipeline job and pointed it each branch in our GitHub repository. This is extremely important when running unit tests and making sure that it's safe to integrate with the rest of your master branch. We also went over how to include post steps in a Jenkins Pipeline job, including failure and success post steps so that based on what your pipeline is doing in the middle of a run, you can respond to different events. In the next section, we're going to look at how to integrate third‑party security tools and run them in parallel so that you don't have to wait for one to finish before the other. Thank you for watching, and I'll see you in the next section.

Integrating Container Security and Compliance
Integrating Container Security and Compliance
Welcome back to the course. In this module, we're going to talk about integrating container security and compliance into our Jenkins Pipelines. So first things first. If we're going to talk about how to scan containers, we need to be able to get to them. And most container scanning solutions operate off of a registry. So the first thing we're going to cover is how to upload your container into a Docker registry. And the Jenkins Pipeline concepts we're going to use to do this arer script blocks and some of the more advanced Docker pipeline steps. We'll go into each of these a little more as the module goes on, but in essence, script blocks allow you to run blocks of Groovy code as a single script in your pipeline, whereas the Docker plugin allows you to work with containers in some ways you might not expect from a Jenkins Pipeline. We're also going to set up two third‑party scanning tools and integrating them into our pipeline. One is called Anchore, and the other is called Trivy. These are both open source products with enterprise licensing agreements if you choose to pay for them. But the reason that I picked these two is they're each a little bit different. Anchore, for example, has a plugin that you can interface with directly from the Jenkins Pipeline, whereas Trivy, you can install on your build agents and then run directly from there. And finally, since both of these take quite a bit of time and we do want to deliver the results to our developers a little bit faster, we're also going to learn how to set up parallel stages in a Jenkins Pipeline. So these will run at the same time without being dependent on one another. So going back to the course pipeline graph we have here, this is where we're at in the third section here. We're going to run the Anchore and Trivy container scanners in parallel of each other after configuring them to run from our Jenkins Pipeline. In this demo, we're going to just upload the container to a Docker registry. Just a small task we need to do as a prerequisite before we go into scanning them. Let's get started.

Push Container to Registry
Alright, welcome back to the course. I'm here in Docker Hub, where I've actually put the Docker container repository for this course. You can see now there's nothing in here, I did have something in here, but I deleted it just to illustrate the point. You see we've got these Docker push commands here on the right side, and if we wanted to, we could just run those with a shell step in our Jenkins pipeline, and that would upload the Docker container just fine. But we're going to see if we can use some of the advanced Docker features from the Docker pipeline plugin. Let's switch over to the Jenkins documentation. So I'm here in the Pipeline Syntax page, and we've been here a couple of times, but let's actually poke around a little bit. We kind of just been where we needed to be to get the step done. Let's actually take a look around at some of these things. If we go one level up in the navigation here, see, we actually get to a full Pipelines page here, and this has got a lot more documentation, a lot more information on how to use Jenkins files and Jenkins pipelines. A lot of it. I've kind of gone over through the course so far. I don't typically like to cover documentation from start to finish because that's not what you're here to do, your here to watch it happen. But it's useful to us now because we want to use some of the more advanced Docker features. So on the right side here, there's a section called Using Docker with Pipeline. Let's go ahead and navigate there. And this is just a few of the higher‑level Docker commands that you can use to customize your pipelines, including running your steps inside a Docker container or even running the whole pipeline inside a Docker container. If we scroll down to the bottom, there's a tag called Using a custom registry. So let's go there, that's the section we're interested in right now. You can just call methods on Docker without instantiating it, and then pass in a few parameters, like image, registry, and credentials. Let's go over to Jenkins to take a look at it. So as you might imagine, the first thing we need to do in order to set up our Docker Hub push command is authenticate to the Docker registry. So since we're not using a Docker login command like we would interactively, we need to provide credentials somehow. Now Jenkins does have a way to pass credentials, it's over here on the left side in the Credentials pane. Let's go over there for a minute. You see, I've already got a few set up here, including Docker Hub, which is the ID of the username and password combination for my Docker account. And there's a couple of things that you can tell about it right off the bat, one, if we hover over this icon here, it says that it's a username and password, and two, it's got my username in plain text here, but not the password. If we actually click on that, there's not really a way for us to see my password in plain text, there's no passwords in plain text in Jenkins. So once you put your password in, it's stored securely, and you don't have to go in and retrieve it, unless you're changing it. So remember the ID Docker Hub because that's going to become important when we actually take a look at the code for this. Let's go over to Visual Studio Code and see how that looks. Okay, so we're back in Visual Studio Code in the Jenkinsfile, and there's a lot going on here, so I'm going to break it down line by line. There's a lot of new stuff here for us to cover. I've got my stage Push Container, and that's something we've seen before. I'm opening the steps block on line 53, and then I'm going to use the echo command to say the Workspace is $WORKSPACE. That is one of the environmental variables that Jenkins injects into the project while we're running it. And the workspace in Jenkins terminology is the folder that our job is running in. So, this'll make a little bit more sense when I actually pull it up in the console later on, but for now, just know that that is the environmental variable for the workspace that we're going to run our job in. And in the next line, I've got a d,i,r, or dir command, and if you'll remember, we're not actually running a Dockerfile inside of our root directory. The Dockerfile for this application is under azure‑vote, which is a sub directory of our root directory. So we could change to it in a shell script and then run a Docker build command from there, but since we wanted to use some of the lesser‑known features, we can actually just use a dir block, and then specify the directory we want to run it in, and each command in that dir block will run from that directory. On the next line, I have a script block, and script blocks are really just a way to run Groovy code as a single script, instead of having to define it line by line. So if I wanted to write just a quick Groovy script or call some Groovy functions, as I'm going to do with this Docker command, then that's where I'd do it, and that way it'll evaluate them all at the same time, rather than try and do it line by line. And then finally, I'm calling my Docker plugin with the registry index.docker.io, that's the default URL for this plugin, but it's also the URL for Docker Hub. And then the next parameter I'm passing in is actually Docker Hub, which, if you'll remember, is the ID for the Jenkins credentials we want to use to log in. Again, it's not the username or password, it's the ID for the credentials from the Jenkins system, and that'll let Jenkins know that we want to use the credentials pair with that ID to execute this command. But then from there, we're using the docker.build command and storing that in the image variable. For those of you who are not familiar, def is the keyword to define a variable in Groovy. Once we have that docker.build step running, we can just run an image.push, and that will push the image that we've just built up to the Docker registry. Let's go back to Jenkins and take a look at it running. Okay, so I'm back in my Jenkins UI, and I ran this before I started the video back up, and that's because you don't need to really watch this, you've seen it before, it's kind of like watching paint dry at a certain point, you know it's going to happen, just let it run. Plus, with the Console Output for this job, we can see everything that's happened anyway. So if I go into the Console Output here, and then scroll down to our Push Container build step, you see it's running the workspace is C:\ Program Files (x86) Jenkins\workspace, and that's the variable that we talked about earlier. Jenkins sets that at runtime, that's the folder that our job is running in. And then on the next line where we run the dir command, we see that it's running this step in the azure‑vote subdirectory of that. Go down a little bit further, and we can see it's pulling up the credential store and running a Docker login command with the username and password that was stored in that credentials pair, and then building the container from our workspace azure‑vote directory. Let's scroll down a little bit more until it finishes, and then pushed it up to Docker Hub. Let's cut over to Docker Hub and see if we can find it. Alright, I'm here in Docker Hub, and let's go ahead and refresh the page, and you see we do have a new container there. If we go under Tags, you'll see we push something just a couple of minutes ago under the latest tag. So now that we've got our container image in Docker Hub, let's see how we can pull it down and run it through some container scanning tools.

Trivy Overview
So the first scanner we're going to talk about is Trivy. Now, Trivy is an open source product maintained by Aqua Security, and it is a container vulnerability scanner. So it doesn't have any zero‑day exploits or anything like that, but it's better than nothing, and it should get us off to a good start. It's also extremely simple to use. Here is the GitHub page for it. But you'll see in just a moment it's actually a really simple thing to run. Essentially, Trivy is a binary that you build or install or download, and then that binary will pull the vulnerability database from Aqua Security and use that to scan the container. Very simple. Plug and play can be installed and run with just a couple of lines of code. This would be the command to run it in a shell script or something like that. Since we're running this in a pipeline, it's going to look a little more like this. And this is how you'd run it in a Linux environment. As long as Trivy is installed on the host machine, it'll take care of itself from there. The other small complication that I'm going to have on this system, but you might not, is I'm running it on Windows, so I have to run it through WSL, or Windows Subsystem for Linux. Because there's no Windows binary for Trivy, I have to take that extra step. You might not necessarily have to. And this is one of the reasons if you're building, if you're setting up this pipeline in a production environment, you should definitely be doing it on a Linux system or Linux servers. Since I'm demoing this, I'll show it on Windows, but that's the difference right there. It's just a small change that I have to make on my end. All right, in this demo, we're going to set up Trivy and run it against a container in our pipeline. Let's get started.

Implementing Trivy
So I'm here on the GitHub page for Trivy, and if we scroll down a little bit here, we've got some documentation on what it is and how to use it, including installation. So my WSL instance is an Ubuntu Linux instance, and we've got the commands here to add the repository to our app to get installer and then install Trivy. I've already done that, so let's cut over to WSL and take a look at it. Okay. I'm here in the Windows terminal with my Ubuntu WSL instance, and I've already installed Trivy. You can take a look at it by doing this. So it's installed and ready to go, and what Trivy does, like I said, it's going to pull the vulnerability database first, and that's kind of an automated thing. The first time you install it, it will look for a vulnerability database and then try and update itself every time. I'm going to go ahead and clear that database so you can see it run for the first time. Okay, that's done. Let's take a look at it running in the console before we actually go to our pipeline. It's pretty easy. We just run Trivy against our container image from the repository. Okay, so that took a little while to run. We've actually got a lot of vulnerabilities in this application. I'm really glad this is for a demo and not an actual application that I'm working on. But now that we've seen it run, we kind of get an idea of what we're expecting to see in the pipeline. Let's cut over to Jenkins and watch it run there. Alright, as with the last one, I have cut out the waiting part for you and just gone straight to the good stuff. So let's go to the console output and you see there is quite a bit more in our console now. So we have to actually click on Full log to see all of it, and then we can search for our Run Trivy step. Now there are filters that you can use to put this in a separate file or to output it somewhere else, or even just to see critical vulnerabilities, instead of all of them. I didn't turn any of those on just to show you the huge number of things that's wrong with this container. So again, really glad that I'm not working on this in a production system, but it works fine. We have our report and we can work from there. Let's see about adding another container scanner that might give us a few more features.

Anchore Overview
Okay, so the next container scanner we're going to talk about is Anchore, and this is another one that's open source, but it's got enterprise features. So the engine and the database itself are open source, but then you pay for things like enterprise authentication and log in, additional security, etc., etc., and we'll go into that a little bit more. I'm only using the open source version, so we're only going to show the open source features here. And this is maintained by Anchore Incorporated, you can look them up on your own, and this is a vulnerability and policy scanner. So in that way, it does vulnerability scans, but it's also similar to something like Chef Inspect where you can define a policy that you want your container to adhere to and then make sure it does or fail the build if it doesn't. As I mentioned, there is an open source component to it. Here is the GitHub page where you can look that up and check it out yourself. Anchore is a little bit more complicated, it actually needs an on‑prem engine set up before it runs and the engine in the database run together. It's not difficult to set up, but it does need to be running before you run your build. It's not the kind of thing you can just spin up at runtime like trivia, but those two together, once they're running, they will allow you to use the Anchore CLI. They'll enable an Anchore CLI, which you can then use to scan your container. Now Jenkins, the plugin for it abstracts the CLI a little bit, but you can use the CLI commands on your own if you have something more manual you want to run. I'm not going to go into that in this course because this isn't an Anchore course, but it's worth knowing so you can check it out and evaluate it for yourself. And the steps to run Anchore, because it does have its own Jenkins plugin, so we get a few more full bodied features with it, and it's a little bit easier to use. So the steps to run anchor from a Jenkins pipeline are that we take the containers we want to run it against and put them into a text file called anchore_images. And then we pass that text file into the Anchore plugin. Now again, I'm running this on Windows using PowerShell 7, but if you're running this on Linux, it's essentially the same thing just using the echo command, instead of write output. And in a Jenkins pipeline, that just looks like this. So we don't have to define a script block, we don't have to use a shell script or any other custom blocks. We can just use it directly by calling the Anchore plugin, and that's really nice because it means that we can actually run this on either Windows or Linux without making any changes to it. In this demo, we're going to install and configure the Anchore plugin, and then use it against our demo container. Let's get started.

Implementing Anchore
Okay, I'm back here in Jenkins, and the first thing I need to do is install the Anchore plugin. So this is a Jenkins plugin. Let's go under Manage Jenkins and scroll down to Manage Plugins. And then under the Available plugins tab, we can search for Anchore. Great. So that's it there. I will pause the video here and wait for it to finish. Alright, now we can see the Anchore plugin is installed, let's go ahead and configure it by going back to Manage Jenkins. Each plugin has its own spot where it installs to and where you can configure it. The Anchore plugin specifically is under Configure System, and we'll just search for Anchore. Now some of this is already left over. I am running the Anchore engine as a localhost because I'm going to have it run in the background while I'm doing this demo, but if you had an enterprise installation in a separate Anchore policy or Anchore engine server, that's where you plug in the URL for that. And then the default username and password combination is admin/foobar. So the user name is admin, and the password is foobar. Let's go ahead and save this and then run our Jenkins pipeline. Okay, we're back in Jenkins. You can see that this looks a little bit different than any of the other pipelines we've run and that's because the Anchore plugin is adding some features for us to use. For starters, since it was a successful build, we do have a few artifacts that it's generated that we can check out. We also have the option to download all of them at once. We see that the report itself failed, the container failed, but we knew it would because it's got a pretty extensive list of vulnerabilities for it. I didn't want that to break the build this time because we're just showing this off and it would take longer than it would to produce this course to fix all of those. So for now, we just have a few artifacts that we can use right out of the box, including a report from this button here on the left side, and that gives us a bit more of a graphical view of some of these vulnerabilities, what they are and what we can do about them. Okay, so that's Anchore in a nutshell. In the next video, we're going to talk about running jobs in sequence and in parallel. We'll see you there.

Running Stages in Parallel
So if you've read The DevOps Handbook, you'll know that one of the most critical concepts in there is getting feedback to developers faster. So we want to be able to let them know what worked and what didn't as soon as possible. And one of the ways we can cut down on that time, once we have all of these working stages in place, is by putting some of them in parallel. So in this example, let's say you have three different stages. Each of them takes five minutes. If you run them one after the other, it'll take 15 minutes. But if you can run two or more of them at the same time then you're cutting that time out for every step that you run in parallel. Now this is not the best thing to do in every circumstance. For example, we learned earlier in the module that Trivy is dependent on the Docker container it's scanning to be in a Docker Registry first. So if we try to run the push stage at the same time as the Trivy stage, then that's going to fail. It's not going to work so well for our Pipeline. But in this example, and this is what we're going to show in the demo next, if we try to run our two scanning tools at the same time after pushing the container up to the Docker Registry, that's going to work fine for us. In this demo, we're going to run both of the Anchore and Trivy stages in parallel and then see how much time that cuts off of our build. Let's get started.

Demo: Parallel Stages
So we're back in Visual Studio code, and I've gone ahead and made a few changes to this pipeline already, we're just going to step through them now. To run parallel stages in Jenkins, you really just wrap it in another stage block. So on line 52 there, I have a separate stage called Container Scanning, and in that stage is a parallel block with two more stages in there, and those are the two that we just finished going over in the last few videos. Just to make it easier to read at the end when we go through the console output, I went ahead and commented out the trivy output because that was just a lot of junk text that we really don't want to read. So instead, I put a sleep timer for 30 seconds, and it's important to note that these two will run at the same time. But their output is not going to overlap. They're just going to get written to separate logs, and then which ever one finishes first is going to have that stages output at the top of the console log; and then another thing to note is that the default behavior is to wait for both of these stages to finish before kicking off the next stage. So if we had a stage after Container Scanning, it would wait until both of these stages, Run Trivy and Run Anchore, have finished before starting that next stage. All right, let's go over to Jenkins. So for every other video in this module I've made it a practice not to show the pipeline running, and I'm going to break that a little bit here because I want to actually show that one of these stages will pause and let the other one finish about halfway through the run. Let's see if we can watch that in the video. Okay I lied a little bit there. I sped up the video just to get to the end where it started to run the Container Scanning stage, then we see our Run Trivy step took exactly 30 seconds, which is what we would expect, and Run Anchore took 18 seconds. So let's go back and check out the console output for these. You see that it does kick off the parallel pipeline stages, but then it branches off into Run Anchore and Run Trivy, and displays the log output for both of those one after the other. All right, that's it for this module. Let's go to the summary.

Summary
Alright, we covered quite a bit in this module. First thing we did was we uploaded containers to the registry using the Docker plugin for Jenkins files. Then we went and went through two different container scanning tools, Anchore where we set up the plugin and then ran the scan using the plugin and got some of the reports from there, and then we went through Trivy, which is a very different type of scanner. We just ran it directly from the pipeline after installing it. And then we learned to run both of those in parallel, using the parallel stage block. In the next section, we're going to learn how to deploy this application to a Kubernetes cluster. And finally, we'll wrap up with some other things that you can do with your Jenkins pipelines that make it a little bit cleaner, a little bit easier to use. Thanks for joining me so far, and I hope to see you in the next module.

Implementing Continuous Deployment Pipelines
Implementing Continuous Deployment Pipelines
Welcome back to the course. In this module, we're going to be implementing continuous deployment pipelines. So the goal of this module is to set up a continuous deployment pipeline to deploy an application to a Kubernetes cluster and it's only fair since we've been using an Azure demo app this whole time that we're going to use the Azure Kubernetes Service, or AKS, for our deployment. We're also going to show how to deploy two different service levels like QA or PROD in the same pipeline. And to give us a little bit more control over when that happens, we're going to be adding some when conditions and input steps into our Jenkins pipeline. So we're back to our good old course pipeline diagram, and if you're following along, this is where we are now is on the final step of the pipeline is deploying to Kubernetes. So by this point, our code has been checked‑in, built, unit tested, ran through some security scanners, and finally, we're ready for deployment. Now Kubernetes is a huge topic, and I wouldn't do it justice by trying to explain it all here, but there are some other courses on Pluralsight if you're interested. First off, check out Getting Started with Kubernetes. This is kind of a basics level 101 course for anyone who is new to the idea of Kubernetes or container orchestration. Next is the Kubernetes for Developers: Core Concepts course, and this is just a little bit deeper level, a little bit of a deeper dive for developers on how best to design their applications to run on a Kubernetes cluster. And finally, since we'll be deploying to Azure, the Microsoft Azure DevOps Engineer track has a Manage Azure Kubernetes Services course that goes a lot deeper into the infrastructure we'll be deploying to in this course. Alright, let's get started.

Introduction to When Conditions
So the first pipeline‑specific concept we're going to go over is the concept of a when condition. And in a nutshell, this is a way to block certain steps in your pipeline from running if a certain condition is met. So, for example, I have two branches here. I have my master branch and a feature branch. I want to run most of the same steps on them, except I don't want to deploy the feature branch because I don't know if it's stable or not. So a when condition will allow me to run the same build step on both, the same test steps on both, but when it comes to the actual shipping and deployment stage, the feature branch won't run that step. The master branch will, but the feature branch will not. And the only way to get that feature into a container and deploy that is going to be to merge it into the master branch. So this is how it looks in code. We've got two different stages here, one that will always run. And if I'm not mistaken, this was our Hello World example, the first one we took a look at. The second stage there has a when block right inside the stage that will only trigger the rest of the stage if it's on the master branch. And these conditions don't have to be a branch. So in the Jenkins file documentation, they have the ability to run things like environment variables, get tags, or even write your own Groovy expression. And as long as it evaluates to true, it will trigger the stage. So with that in mind, let's take a look at the next section, input steps.

Introduction to Input Steps
So an input step is a little bit different than a when condition. This leaves the decision on whether to run your pipeline or the stage in your pipeline up to a user, So it's kind of like a manual gate that you have to get through if you want to run the rest of the pipeline. So, for example here, if you have a deployment and you need to know if it's okay to go into production, but your organization has mandated that you have a UX team that needs to take a look at it before it goes to the production environment, when you run your pipeline, you can set it to automatically deploy the new version to QA, and then it would go to the UX team afterwards, and if they give it the green light, then that same build will go straight into the production environment, no hassle. If, however, you have that same example and the build goes into QA, but the UX team sees something they don't like, then that build will stop right there. They, or whoever you authorize, will deny the pipeline from running the rest of the build and PROD stays unchanged, and once the fix is in, you rerun the process until you get the green check mark. Here's how it looks in code. It's just a simple step with a message, and that message can be whatever you want it to be. There's a few other parameters you can pass in as well, but message is the only required one. So in this demo, we're going to add a when condition to our pipeline, and this condition will say that we should only deploy containers to the PROD environment if we're on the master branch. You can deploy whatever else we need to QA to get it tested, but only code that our testers have verified should go into PROD; and next we're going to add an input step to get our testing team to allow some manual input on whether the build should proceed or not, and again, this should only deploy to the PROD environment if it's been approved. Let's get started.

Setting up an Azure Service Principal
Okay, so the first thing I need to do to run this pipeline is connect my Jenkins installation to Azure Kubernetes service. So to do that, I'm going to look under the Manage Jenkins section here and go down to Manage Plugins. And now I've already installed these, but let's go ahead and take a look at the installed Kubernetes plugins. As you can see, we've got a couple of them here already. We've got the Azure Container Service plugin, which, even though Azure Container Service has been deprecated in favor of Azure Kubernetes Service, the Azure Container Service Plugin is still the Microsoft recommended way to deploy to Azure Kubernetes service from Jenkins. There's also a Google Kubernetes Engine plugin, further down and a Kubernetes Continuous Deploy plugin, if we're just deploying to something that's not Azure or GKE. Each one of these is a little bit different, but the idea is pretty much the same, and we can get the usage by actually clicking on the plugin, and they've got some prerequisites here, some instructions on how to configure the plugin. I've checked all of these out and the documentation is pretty good on each of them, so you can follow the instructions here if you need to use these to deploy to a Kubernetes cluster on something that's not Azure. But if you have trouble with the instructions here or there's not enough for you, you can also check out the plugin on GitHub. And that may or may not have some additional set up instructions or tips in the read me. If not, you can open an issue or get in touch with one of the developers and figure out what you need to do from there. Let's go back to Jenkins for a moment. So I'm back in Jenkins. Let's actually figure out what we need to put in our Jenkins file to get it to run. If I go to the Voting App Pipeline project here and go down to Pipeline Syntax in the bottom left, then it's going to give me a few sample steps. At the top is actually acsDeploy, which is what we want, and we've seen this screen before, but it's important to know that there are some of the other plugins and here as well, like KubernetesEngineDeploy and KubernetesDeploy. And from here, we need to create an Azure service principal to authenticate Jenkins to our Azure subscription. So let's cut over to Azure, and we'll do that really quick. Okay, I'm here in my Azure account, and the first thing I'm going to do is go up to Azure Active Directory, and on the left side, over here, under App registrations, you see I've already set this up, but we can create a new registration for our Jenkins App. We could do that right up here, just type in whatever name that fits and assign it to the organization. We'll go ahead and set up a new one and call this Jenkins demo, and we'll go ahead and register that. So now that that's created, we have an application ID and a tenant ID and we're going to need to save those for later. Let's copy them down, and I'll save them off screen. All right, so now that I've got those, I can go over to my Azure subscription. Okay, so I've got a subscription here called Pluralsight_demos. And let's go into that for a moment. And to finish creating a service principal for Azure, we want to give the app registration we just created permissions to our Kubernetes cluster, and that will mean that when we give Jenkins the app registration that we just created, Jenkins will then also have permissions to the Kubernetes cluster. So it's important that we don't give it too much scope because we don't want Jenkins making any changes that we didn't authorize it to make. So do that, let's go over to Access control, or IAM. We're going to use the Add button up here to create a new role assignment. And the role here will determine what level of permissions this user is going to have. So if I just search for Kubernetes, you see we've got a couple of different roles here from the Azure Kubernetes Service. I want to give it the contributor role. I'm going to give it the Kubernetes Cluster Service admin role and the reader role, so it can deploy clusters and read from my resource groups. Next, let's search for the Jenkins demo app that we created. You see, I've got Jenkins app already, that was the one I was using to test it out. But Let's go ahead and pick Jenkins demo and then click Save. And there's one thing left to do. Let's go back to Azure Active Directory. So I'm back in Azure Active directory and I've got my Jenkins demo application. And there's one thing that's missing, and that's we need a secret token or certificate to authenticate with. So let's click on that and go to Certificates & secrets on the left hand side. And in this case, I'm just going to use a new client secret. So let's create a new one there, have it never expire, and call this my secret jenkins. And it's important to know, this is the only time you'll be able to copy this down, so I'll just copy that and save it off screen. And if you're following along and you want to get a little sneaky, I'm going to delete these all after I have finished the course, so I don't mind showing you what the keys are. But now we're done in Azure, lets go back over to Jenkins and plug it all in.

Connecting Jenkins to Azure Kubernetes Service
Alright, I'm back here in Jenkins, and the first thing I'm going to do is actually add the credentials that we got from Azure into Jenkins. So we have to click on Add here, and we're going to add a new Jenkins credential. And since we installed the Azure container service plugin, that also installed the Azure credentials plugin, which has a bunch of these credential types that are specific to a Microsoft Azure account. So the one I want, in particular, for Jenkins is a service principal, and that's going to ask for a few different things from our Azure account, including a subscription id, which I forgot to get in the last video, but it's pretty easy to get without too much poking around. If you're curious about anything, you can also click on this question mark on the right side and that will give you a little bit more information on what it is you're looking for. So let me just plug all that in really fast. Alright, all that's been plugged in. Let's go down and click on Verify Service Principal. Alright, we can see that that was successful. Let's go ahead and give it a name so we remember it. I'll call this Jenkins demo so it matches with the app registration we put into Azure. And now when we go to select our Azure credentials from the drop‑down, and that'll automatically populate our resource group and container service. So in this case, we have qa‑demo and prod‑.demo, or where my two Kubernetes clusters are. And then you can see that in the qa‑demo resource group, I have the qa‑demo‑cluster, and in the prod‑demo group, I have the prod‑demo‑cluster. They may seem like a small detail right now, but that'll be important later on. So the next thing we need is the path to our Kubernetes deployment manifest. This is usually a YAML file at the root of our workspace. So in that case, we just plug in this line here and that's going to go through from our workspace and look for the *.yaml so any *.yaml files. That also includes our Docker compose file, so you'll have to rename that or specify the deployment file if you want to get this to work. I've already done that, and I will highlight that when I get to the code, but I just want to point that out here just in case you're skipping around. But with that all set, let's go ahead and verify the configuration. Configuration is verified. If we hit the Generate Pipeline Script button down here, it will actually create the step that we can then plug into our Jenkins file. If you remember those old Staples commercials with the easy button and you press the easy button and something does all the work for you, that's kind of what this is. This is the easy button approach to Jenkins Pipeline script. Let's go over to the code and actually take a look at it.

Using When Conditions
All right, we're here in the Jenkins file for this project, and you see I've added some stages right after the Run Trivy stage from the last module. And this has got a few other things in here, so we're going to go through it bit by bit. The first thing I want to point out is a new block, which is the environment block. And this is a pretty easy one to remember, it's just setting an environment variable for the duration of that stage. Now, this might be useful in plenty of other ways, but the way I'm using it here is so that I can take the step that was generated in the last video, and instead of generating that same step for each cluster, I just pass in the environment variable and set that at the beginning of the stage. So my first step is deploying to environment, which in this case is going to evaluate two QA. And then when I run my acsDeploy stage, in the containerService and resourceGroupNames, because those had the environment level anyways, I'm also adding that in. And if we scroll down a little bit, I am actually running the same thing in prod, it's the exact same code line for line, character for character, and that just helps keep it a little bit drier. Like do not repeat yourself. So it's the same code for both steps. The other block that's new here, that's only in the production steps is a when condition that's looking for the master branch. So that says to the Jenkins pipeline, do not evaluate these steps, do not run them, skip right over them if you're not on the master branch. And then finally, the input step in the Approve PROD Deploy stage is going to prompt a user, do you want to deploy, proceed or abort? And it will leave it up to a user to decide whether to continue the pipeline or not. And you can specify which user you want to do this from any user that's present in your Jenkins user base. But that will pause the build for as long as it takes for someone to approve it, or if you set the time out option like I have on line 92, just for the length of the time out. Let's cut over to Jenkins and actually take a look at this run. So I'm back in the Jenkins console and I've got two branches here, the add‑deploy branch and the master branch. And the first thing I want to do is run add‑deploy, because that's where our changes are right now. I'll go ahead and pause the video and wait for it to run. And I'll show you what happened when it's finished. Okay, so the pipeline's finished running and it was a successful build. But if we scroll over here to the right, we see that the Approve PROD Deploy and Deploy to PROD never even ran. They just got skipped over. Let's take a look at the console output. If we scroll all the way down to the bottom, you see that Jenkins has skipped those stages due to a conditional, in this case, the branch name. But if we scroll up a little bit, it looks like our Kubernetes deploy worked just fine in QA. In fact, here's the IP address that it deployed to. So if we go to that IP address, we see our voting app is up and running, and we can use it as expected. So since we know that works, I'll go ahead and merge the branch off screen to the master branch, and then we can take a look at it run with the input step in the next video.

Using Input Steps
All right, I'm back in the Jenkins. UI. I've merged the code from add deploy into master off screen, and I'll go ahead and scan the repository now so it reflects those changes. Great. So I ended up deleting the branch, so that's why we only see the master branch now, and let's go in there and actually run a build. Now the pipeline has changed a lot since the last time we ran this from master, but I'll go ahead and pause the video here and we'll resume when it's finished. Okay, so the build is still running, but if we scroll to the right here, you see it's actually running the Approve PROD Deploy stage, and it's been paused for a few seconds now, but if we click on that stage, we get a prompt from Jenkins, do we want to deploy, proceed or abort? Well, in this case, I'll pick abort just to demonstrate what happens there. It will abort the rest of the pipeline, meaning that those two stages don't get run. Some of the more eagle‑eyed viewers might have caught this in the last video, but I added a post step to that stage that said, if it's been aborted, go ahead and print production deploy denied, which it says right here near the bottom; and that can be a good way to log why a build never got run. But let's go back to the master branch and run it again, and I'll approve it this time so that we see what happens when it does get deployed. Okay, I'm back here at the approve stage, and this time I'm going to proceed with the deployment, and it looks like the pipeline's finished. We can actually go right into the logs here from Jenkins, and we'll scroll back over a little bit, we see there are two messages here. The first is the print message, which says, deploying to prod, if you'll remember, that was our environment variable that we set on that stage; and the next, if we open this up here, this is the output from deploying to our AKS cluster. If we go down to the bottom, we'll see the IP address it deployed to. So let's actually open up this log so it's a little bit easier to copy, and then we'll go down to the bottom and go right to that IP address to take a look at the voting app which is now deployed in our production cluster. Let's go to the summary.

Summary
All right, in this module we used a when condition to keep steps from running when we didn't want them to and used an input step to require manual approval before continuing the pipeline. And that's it for the demo pipeline. It's done. It's finished. It runs. But there are a few things that we can do to clean it up a little bit and to make it a little bit more robust. So in the next module, we're going to cover some things we can do to improve Jenkins and Jenkins pipelines. I hope to see you there.

Troubleshooting and Improving Jenkins Pipelines
Troubleshooting and Improving Jenkins Pipelines
Welcome to the last module in the course, Troubleshooting and Improving Jenkins Pipelines. So we're just about at the end of our course here. We've covered the course pipeline and how to deploy building your application to the Kubernetes cluster you'll be deploying to, but there are a few improvements we can make to our pipelines to make them a little bit more extendable and a little bit more reusable. First, we're going to go through the scripted pipeline and declarative pipeline references, and this is useful to know about for several different reasons, but not the least of which is if you have trouble building your pipeline, if there's a step that you need and you can't find the right documentation or the right answers online, there's a few things here that you can check if you need some more reference materials; and the last thing we're going to go over is Groovy Shared Libraries. These can be really useful when you want to provide methods to your developers, but don't want them to see the internals of those methods, or even just to abstract pipelines from them completely. We'll go over that a little bit more at the end of this module.

Declarative vs. Scripted Pipelines
So first things first. When it comes to the Jenkins documentation, there's actually two different kinds of pipeline code. There's a declarative pipeline and a scripted pipeline. Declarative pipeline is what we've been using throughout the course, and scripted pipeline is very similar, which we'll go into in just a minute, but with one key difference. It's important to note that you can run the entire pipeline with either declarative or scripted with the stuff we've covered in this course so far. I think you get a little bit more control with declarative pipelines, and I'll go into that a little bit more in the demo. But as for the differences between the two, what you're looking at here is a declarative pipeline. It's what we've come to know and expect from this course, and this has a very simple job, it just prints 'This is the master branch' when it's on the master branch. Otherwise, as we covered in one of the previous modules, it'll just skip over the step altogether. This is the same stage in a scripted pipeline. So instead of having a pipeline bracket at the top and then specifying which agent to run on, you just have a node bracket and the stages go in the middle. The other key difference is it's using a groovy domain specific language, or DSL, to control pipeline logic. So as with the declarative pipelines, we had to specify when we wanted it to run. In this case, we just have a stage that runs and then specify using if else or try catch finally blocks what we want to run inside of that stage. It's running the same steps from the pipeline reference. It's not actually running groovy code. It's a domain specific language, so it's just using a groovy‑like syntax to control the flow. So all the steps you've learned up until now are still going to work in either pipeline. It's just a matter of how you want it to run. And like I said during the demo, I'll show you why I think you'll get more out of a declarative pipeline. So first things first, we're going to go into the Declarative Directive Generator, and this is a good way to put together steps from your declarative pipeline. If you're having trouble with setting up your when conditions or input steps or anything else from a declarative pipeline, this is a really handy tool to know about. Next we're going to look at the environment variables reference. This is something built into Jenkins that tells you which environment variables Jenkins is making available for you to use. And then, finally, as promised, we're going to go into declarative versus scripted pipelines. I'll give you my opinion on each, show you how they both run, and you can make your own decisions from there based on what you're comfortable with. Let's get started.

Declarative Scripted Pipeline Demo
Welcome back. We are here in the Voting App Pipeline, which is what we've been using throughout the course. I've got a couple of extra branches that might not look as familiar here, but we'll go through those as the rest of the module continues. For now, let's go over to the Pipeline Syntax section on the left side. Now we've been here a couple of times before, but we're going to check out some new sections today. On the left here there's a section called Declarative Directive Generator, and this is very similar to the Snippet Generator, except it works for any declarative steps that you might want to run. So for example, if we wanted to set up a specialized when condition, you see there's quite a bit more when conditions than we've covered in the course, and each one of these will fit a different case. I'm going to go ahead and stick with a branch. But instead of just running on the master branch, I want this to run any time that the word pipeline is in the branch or specifically any time the word pipeline is at the end of a branch. So I want to use REGEXP to parse it out. So first I'm going to put in my REGEXP, and then under Advanced, I can use the Regular Expression comparator. And when I hit Generate, I have my when condition ready to go. We'll see an example of this in just a few minutes. For now let's scroll back to the top and look up the environment variables reference. Here under Global Variables Reference, this is where Jenkins includes a lot of the environment variables and functions that you can run from the plugins that are installed in your Pipeline steps. So this includes the Docker withRegistry function that we ran earlier in the course. But if you scroll down a little bit further, it also includes things like CHANGE_AUTHOR and BRANCH_NAME. That can be useful for creating conditions or logs or even submitters for your build. Let's cut over to Visual Studio Code, and we can take a look at some of the differences between a Declarative and a Scripted Pipeline. So some of this may look familiar to you. I'm using the same repository we used earlier, the AZURE‑VOTING‑APP, but I'm not actually making any more code changes; I'm just changing the Jenkinsfile. And you can see I'm on the scripted‑pipeline branch because we're running a Scripted Pipeline. Got our node block at the top with our stage in the middle, and that stage is Echo on master. And it's looking for an environment variable called BRANCH_NAME and comparing it to the master branch. So if it detects that it's running on the master branch, it will say, This is the master branch. Otherwise, This is NOT the master branch. It's using the same echo commands from the Jenkins Declarative Pipeline. These are not Groovy commands. Groovy uses the Java println command to write code to standard output. So let's cut over to Jenkins and we'll actually take a look at it running. Okay, back here in Jenkins, and I'm on the scripted‑pipeline branch. Let's hit Build Now. All right, and you can see we had one step that ran. It should read, This is not the master branch, because we're not on the master branch. So that did exactly what it was supposed to do. Let's go into the Console Output and take a look. It doesn't actually look all that different from a Declarative Pipeline in the Console Output. They're ultimately running the same steps, just with different logic. Let's take a look at the code for a Declarative Pipeline, and I'll give you my input on why I think that's a better way to run your Jenkins Pipelines. So now we're in Visual Studio Code on the Declarative Branch Pipeline, and this should look pretty familiar to you. We've been running Declarative Pipelines this whole course, but there's two stages in here that I want to illustrate. The first is the Declarative Pipeline step, with the branch pattern that we made earlier in the video, using the REGEXP comparator to only run on the Declarative Pipeline branch. The second stage is actually running the same code we had in the Scripted Pipeline in a script block. So the reason I think that you can get more out of Declarative Pipelines is because you can run a Groovy DSL script as a separate block in a Declarative Pipeline. So if you're the kind of person that you need your if‑else or try‑catch‑finally blocks in order to have your code make sense, this is where you can put them in a Declarative Pipeline. You also get the operators and conditionals like when statements or input steps, and you can specify different agents to run on or any number of other options. You just get more control because you have access to more in a Declarative Pipeline, including Scripted Pipeline steps. So if we run this, it's going to look for the pipeline pattern, and then it will print, This is a Pipeline branch. And then the second stage will run, This is NOT the master branch, because we're still not on the master branch here. Let's cut over to Jenkins and take a look at it run. All right, I'm back here in Jenkins. Let's build the Pipeline. All right, our Pipeline is finished. We see our Declarative step, which has printed, This is a pipeline branch. Now let's take a look at our Scripted step. That has printed, This is NOT the master branch. So the same kind of logic, the same kind of control flow in a Declarative Pipeline that you would get on a Scripted Pipeline on its own. That's it for this video. Let's move on to shared libraries

Introduction to Shared Global Libraries
So as a DevOps engineer, your job is to get your developer's application code from source control into production as quickly, securely, and with as much feedback as possible, but that might be a problem if you have a developer that needs to authenticate something and accidentally leaves a secret in plain text or needs to create a new resource, but forgets to turn it off afterwards. So to handle that, Jenkins has the concept of a shared global library, and what that does is it takes the pipeline code outside of the application code repository and puts it into its own. You can then call into from the application repository. So, for example, if you need to provide some sort of authentication token, you can have a function in your shared library that will authenticate that application and then give your developers a function that they can put in their Jenkins pipelines that will do all the work on their behalf. Or you might want to abstract the pipeline from them all together and say we're not going to let you develop the app code and the pipeline. DevOps will make the pipelines and the application developer will make the application. You can do both of those with a shared library and plenty more things which we'll go into in the next demo. In this demo, we're going to go over shared Groovy scripts and Groovy functions and how you can make helper utilities for pipeline code and how you can make helper functions for Jenkins files, and then we're going to go over reusable pipelines so pipelines that your developer won't necessarily see, but if you have a similar deployment process for all your applications can be reused and pass in parameters, instead of rerunning the entire pipeline or having separate pipelines for each application. Let's get started.

Shared Global Libraries: Hello World
So I'm here in a separate repository called DEMOSHAREDPIPELINE. This is a separate GitHub repository from the Azure voting app that we were using earlier. I'll include a link and the files for both of these in the notes for the course. But in the DEMOSHAREDPIPELINE, I have a folder called vars. And it's important to note that no matter what style of global library you're using, you're going to have to have a folder called vars or source. In this case, I just went with vars. But in the vars folder I have a couple of different Groovy files and some text files that match them. It's considered a best practice to have a text file, a company or Groovy file describing what it does. So, for example, my helloWorld.txt will show it prints Hello World, but my helloWorld.groovy is just a Groovy function that prints Hello World. Let's cut over to the Azure voting app repository and see how I've used this. Alright, I'm here in the Azure voting app Jenkinsfile on a branch called hello‑library, and that's the branch I'll be using to show the Hello World function. You'll notice a couple of differences here. The first thing I'm doing on line 1 is importing the demo‑shared‑pipeline global library from GitHub, and that tells Jenkins to go get that library and make the functions in it available for use in the pipeline. And then on line 9 I'm actually calling the helloWorld function inside of a script block. So let's cut over to Jenkins and take a look at it run. Alright, I'm here in the hello‑library branch. Let's click Build Now. Alright, that's done. If you go into the Console Output, you see there's a separate step now at the beginning to load the library from GitHub. And once that's loaded, we can scroll down a little bit and see that Hello World ran just fine. Let's take a look at something a little bit more advanced in the next video

Shared Global Libraries: Functions with Parameters
I'm back in the shared global library in the helloArgs.groovy script, and you see I've got two functions here. The first is call which accept a name string and prints Hello name string. And the second function I have is goodbyeWorld, which will take the same name string and print Goodbye. So the first function, because it's named call, that one will be called by default. So if I call the file name, which in this case is helloArgs, whatever function is named call will be the default function that's called. It's not impossible to call another function from the same file, but it is another step that you have to add, which I will demo in just a moment. Let's go over to the Jenkins file and take a look at how you can call these. Okay, I'm here in the helloArgs branch of the Azure Voting App Jenkins file, and this should look really similar to the last one. We have the stage with the helloArgs function being called and were passing in Jenkins as our name string. And then we have another stage where we're calling goodbyeWorld, and you see we've just appended the name of the function onto the name of the file being called. So it's just a little bit extra that you have to do if you want to call different functions from the same file. I'm passing in Jenkins in both cases, so it'll be pretty easy to identify. Let's switch over to Jenkins and take a look at it run. Okay, I'm here in the Jenkins UI. You see all of our steps of run. Let's go into the console output. If you scroll down a little bit, you see that are Hello Jenkins and Goodbye Jenkins strings both printed. In the next video, we'll see how we can abstract the pipeline completely and take it out of the application repo altogether.

Shared Global Libraries: Shared Pipelines
Okay, I'm here in my shared global library, and I'm in the last file I have, which is echoPipeline.groovy. And you see I have one call function here and a few other things in there. I'm going to explain what's going on. What this function is, is it contains an entire Pipeline. So I could put the entire Pipeline from our course in here into the shared library instead of having it in the application repository. But I've made this one a little bit simpler, a little bit easier to demo, and I've just got one stage in here called Echo from the other side. And what it does is, it just takes a message that I'm going to pass in and prints it. So you see, I'm actually running config.message, which is what I'm printing out. Setting up a Pipeline like this, you can pass in different parameters like message or anything else you want to set up and then refer to them as a property of config. So this might be really useful if you have a standard deploy process, where you deploy several different applications the same way but still need to pass in some different parameters like the name of the application or the owner of the application. Let's go over to the Jenkinsfile and take a look at how it runs. All right, I'm here in the Jenkinsfile of our AZURE‑VOTING‑APP with the pipeline‑library branch, and this looks quite a bit different to what we've been seeing throughout the rest of the course. I have my library call at the top on line 1, but then I just have echoPipeline, which is the name of the file that contains our shared Pipeline. And I'm passing in a message parameter that just reads, I tried to ping a thousand times. If there's any Adele fans here, you can get mad at me now. But let's see what happens when we take this over to Jenkins and run it. All right, we're here in Jenkins under the pipeline‑library branch, and this has run the steps from our Pipeline despite not actually having the Pipeline in the application repo. So if you see under Console Output, we've loaded the Pipeline under the global shared library, and right there it says Echo from the other side. I tried to paying a thousand times. That's it for this module. Let's wrap up.

Summary
In this module, we covered the Jenkins Internal tools, including the differences between a scripted and a declarative pipeline. You can run scripted pipeline steps and logic in a declarative pipeline, but that doesn't work the other way around. All of them still use the same pipeline steps, which are in the documentation, we've gone over that the rest of the course. We also took a look at the directive generator and variables reference. Finally, we covered the Groovy shared libraries and how to use reusable pipelines and shared methods. Thank you all for watching. This has been a lot of fun to make, and I hope to see you in the next course.
