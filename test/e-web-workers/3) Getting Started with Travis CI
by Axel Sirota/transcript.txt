It is essential to make your systems prone to catching ever-present bugs. In this course, Getting Started with Travis CI, you will gain the ability to add CI/CD to your project with Travis CI. First, you will learn about CI in general, and builds. Next, you will discover the Builds Matrix, the main feature of Travis CI to parallelize. Finally, you will explore how to deploy effortlessly within Travis. When youâ€™re finished with this course, you will have the skills and knowledge of CI/CD needed to deliver features faster and more secure than you ever imagined

Course Overview
Course Overview
Hi everyone. My name is Axel Sirota. Welcome to my course, Getting Started with Travis CI. I am a machine learning engineer at ASAPP, ML fanatic, obsessed with CICD, and I am very excited to present this to you. Bugs exist. This is a fact. However, in today's world not maintaining the high bar in quality is just not acceptable, while also having to deliver features faster than ever. Here is where Travis CI saves the day. This super simple CI server can help you build and deliver quality software in a reliable way. Our journey begins at the basics of CI/CD, and we will revisit the main options to choose a CI server. Next, we will learn how to configure our first build in Travis CI, only to go a deep dive into the build matrix, the main feature of Travis CI to parallelize and organize work. Finally, you will explore how to deploy effortlessly within Travis CI. By the end of this course, you will have the skills and knowledge of CI/CD needed to deliver features faster and more secure than you ever imagined. I hope you'll join me on this journey to learn how to write CI/CD to your projects with the Getting Started with Travis CI course at Pluralsight.

Continuous Integration: Which Tool to Use?
Why All the Fuss with Continuous Integration?
Hi. Welcome to Getting Started with Travis CI at Pluralsight. I am Axel, and I am super excited to be your captain in this journey. To give a brief summary, I am a machine learning engineer at ASAPP, ML fanatic, and I am obsessed with CI/CD. So let's start this trip. Making software is hard. We know that. But do you what is harder? Making developers talk. Now going serious. You imagine you are making this big project, and you work alone. Life is nice since basically every time you work, you have the ground truth of what the project looks like. But what happens if we add Jessica? Jessica and you will work in parallel. That means that both will take a new functionality to add to the system and work it on their own. As you won't like making changes in the same place, first both of you will copy the latest stable version of the software you are making and copy it to your local machines. A couple of weeks go by, and both finish the feature. Then as you finish first, you will commit those changes. Oh no, but you forgot to run the tests. No problem since it wasn't a requirement to commit those changes, right? Now when Jessica finishes, she will have two problems. When she tries to commit her changes, maybe the interfaces she was using changed because of you. Even if that did not happen, now tests don't pass on her machine due to your changes. So now she has to spend some days or even weeks to redo her work to comply with your changes. Yuck. Now as this is a super long project in the meantime, you took a new bug fix to solve, and it was fast. So you finished before Jessica finishes, adapting her work to your previous change. When you commit it, it will be okay since basically the last stable version of the software was yours. But now Jessica has the issue that after adapting her changes, she has to readapt to these new changes. What can we do then? One option could be you stop working until Jessica catches up, and then you start again. But that is a waste of time, right? Also, imagine now the team expanded to 20. It would be even more damaging to the team for online team to stop working until everybody, including Jessica, catches up. This is called the software integration problem, and it's universal to every software development practice. It means that the working team can and will have colliding versions of the same software as they develop in parallel. Basically in a chart what we have is this event of high risk called integration event where the whole developing stops to integrate the versions to a common stable one. Continuous integration tries to solve this issue. What continuous integration say basically is two things. Make these features super small, such that the integration happens daily. That will reduce the risk. And force tests to pass to commit changes. And that doesn't end there. Also, commit everyone to make sure tests pass after the commit was made also. What this will do is reducing the risk of every integration to make them a none event. If we look at the picture, it will be like the following where each integration is almost effortless. And for example in this case, all the dotted circles happen in one single day. So it will be minimal integrations. And what does it solve? Basically, continuous integration, or CI as shorthand, solves three common issues. It exposes real bugs against integration bugs. Basically, it eliminates the common phrase, this test failed due to integration. But when I commit it, it will pass. It increases velocity of development. Since I set them as scales, the integration cost doesn't increase, making the team stop for some time. And it adds accountability by making tests before and after the commit pass, having clear ownership of a broken test and ensuring the stability of the common version. So now we have the obvious question. How can we make that change? If we analyze this practice, and I hope by now you are convinced it's a great practice to adopt what we need to have a proper CI, are a couple of things. First, we need a system that actually enables to have multiple versions of the software code base and enables to bring the changes that happen somewhere else into my machine. This is what is called a version control system, and some common examples are GitHub, GitLab, and Bitbucket. Next, we need a fast suite of tests, something that can take the compiled code and in a minute or so say if my changes actually broke something. These usually are done in some version of the XUnit framework for testing, and examples are, depending on language, JUnit, unit tests for Python, or XUnit.net. The suite being fast is crucial since it can hold for the accountability of the changes we make. If it were slow on the integration, for example, people wouldn't wait to see if their changes broke the tests after a commit. So now you have a broken latest version that nobody can start to work into. This would kill the velocity. And finally, one needs a machine that can automatically, when requested, check out to any given version of the code, compile it, get the latest executable, run the tests, and finally notify in some manner to the owner if this run was successful based on the tests. This machine needs to be integrated with the version control system, needs to be able to run the tests, and needs to ensure that after the commit was done and successful, that final version can, in theory, be deployed to production. This is what is called a CI server. Over the next video, we will analyze what option for CI service we have. And later on we will explore throughfully Travis CI, which is our CI server of choose. Let's go.

CI Landscape: There Is No Silver Bullet
Now that we know what the CI server is, we have to choose which for our own project, and this, as always in life, depends on each particular need. Usually, in the CI world, there are three big contenders, Jenkins, Circle CI, and Travis CI. These kind of dominate the CI landscape and kind of cover between the three most of your needs as a developer needing to ship your code quick. What are the differences? Let's start with Jenkins. Jenkins is a Java-based software that is free and open source. You have to download it, start it in any given machine, and it's ready to go. It is based in a concept of plugins that people make in the open source world that you can easily install. Also, beware because anything may be out there because it's the open source world. And with simple integration with any version control system of your choose, you can quickly got to configure your tests. And this is where life can get messy since this is based in the Jenkinsfile. The Jenkinsfile is a configuration as code file written in Groovy class, some Jenkins own language syntax that determines how tests will run in Jenkins. This means that integration with non-Java software, although possible, can be messy via bash scripts. The pros of the Jenkins files, however, are that you can basically do whatever you want in the world. With almost 25 years in the market, Jenkins supports it all. Any complex pipeline you can think is doable in Jenkins. So after the heavy lifting of writing the pipeline down, it's all relax time and letting your super complex pipeline work until something fails, and this is where the cryptic Jenkins errors appear. And without a unique reliable plugin system, your DevOps or administrator can take some time to understand what is going on. So, as a quick summary, what are the pros and cons? On the pros side, it is free, it is extremely configurable, it is scalable, and it has thousands of plugins to almost any integration. On the cons side, it requires a dedicated administrator. Plugins can have some compatibility issues. It has lack of support except the open source, and it can be cumbersome and has a buggy syntax and hard to adopt. And why would I comment about Jenkins here? Because Jenkins is the homerun winner of large enterprise software. When your company starts talking about thousand, when the software is touching the millions of lines of code, and when the DevOps team starts to be a real team and not a person in your team, this is where Jenkins starts to make sense because of the configurability of the pipeline to do what you want and the scalability on your own premise cloud system where you can ensure the high availability. Next is Circle CI. Circle CI is a cloud- based CI server that was developed by companies like Facebook and Spotify. Its motto is ship things fast, and it's true to that with almost out-of- the-box testing pipelines. With as little as a YAML configuration file specifying how to run tests and compile, it is ready to support all the different versioning schemes, one needs an out-of- the-box integration with all the major version control systems. In its free version, it supports up to a thousand bits per minute in unlimited repos where each build provisions an instance of its own to ensure isolation of each build. With its Slack integration and nice dashboarding, Circle CI quickly, and with almost no configuration, takes care of the accountability by having clear visibility of the state of any project. So, it's all pros? What about the downsides? Basically, the lack of custom reporting can make a hit when a company starts to grow and needs clear and self-owned KPI's of quality. Also, it doesnâ€™t have as___many integration with third parties of work in case of needs. And finally, making Docker artifacts is not as straightforward as one would think because how they set up their cloud even with the paid version. So the delivery part of the software in CI/CD, we will cover more on this later in the course. It's kind of messy. Basically, it is _____ for the clear start of a _____ project that will grow within the company. In a snapshot, basically Circle CI is the great option for the startup and medium company that doesn't want to take involvement in hard configurations or hard administration of Jenkins. It has some private records, but nothing too hard to configure tests since it is starting as a company. So it can safely scale with Circle CI. When they grow enough, they can migrate to the paid plan that supports on-premise and self-hosted. With easier configuration of Jenkins, but not as configurable in the pipeline side, it can safely cover almost 95% of common CI problems in big software companies. And the other 5% is because of bad practices. And the final contender in this great fight for CI dominance is Travis CI. Travis CI is all about open source projects, supporting projects as big as the Python Software Foundation. Travis has full support for any open source project of your liking. It is similar to Circle CI since it is cloud-based with a YAML configuration file that really easily spins off that build. With full support to unlimited open repos and unlimited builds and users, Travis is all about the open source community. And how does it differ from Circle CI? Well, Travis is very much like Circle CI. But instead of having add-ons like ____, Slack integration, or another VCS integration, it went straight to GitHub for preferred VCS and went to support the build [00:14: 31.455 ] matrix and clear deployments. The build matrix is a system where in the same YAML file, one can simultaneously test your code in multiple versions, also in multiple operating systems. Incredible, right? We will touch base with the build matrix later in another module. And finally, Travis went ahead of Circle in the deployment race, adding out-of-the-box deployment systems to almost any open sourced system of your liking, like PyPI, Heroku, and NPM. This is incredible for any open source project to have a unique system to do it all. So as a closing remark, Jenkins is the system for large companies with complex pipelines that don't care to spend time and resources in administration efforts. Circle CI is for small and medium companies that want to start and ship fast, but with reporting included. They usually don't have enough people to have someone dedicated to administration of a system, and they really want to improve their software base fast. Travis CI is the go-to option for an open source project that can have thousands of concurrent builds at a time from thousands of users and needs to automatically consider delivery of that software for distribution. With all this information saved up, let's understand a little bit what we will do in this course.

Back to the Future: What Are You Going to Do Here?
Let's dive a little in what we will be building in this course. What we will have is a question-answer web application that basically, via NLP, answers questions. Now the application per se is not important. You can have your own. What we will do is create the whole CI/CD workflow for this application in Travis CI. This means, we will have our Python Flask application in GitHub, and in Travis CI, we will run the automatic tests and code style tests on every GitHub commit, configure the build to test various Python versions, build it up by caching the environment. Test also multiple operating systems. Package our application and delivery via PyPI. Create a Docker container for the application out of every merge to master and publish the changes automatically to Heroku for deployment, which basically will cover all the flow of developing an open source application in GitHub powered by Travis CI. Awesome, right? Let's go and start this thing.

Demo: Configure Travis CI with GitHub
And we got to the initial starting point, setting up the repository. Over this demo, we will create our repository for our application and set up Travis CI integration with our GitHub repository. Let's go. Hello, and welcome to the first demo of this course. Here is where the magic happens. We will start with our NLP application some awesome data scientist made, and we will add CI/CD to it. Before I talk on how to connect Travis to this repository, let me talk you through the course materials we have at hand. There you will find the slides for all the theory and a ZIP file per demo. Finally, you will find the readme file in the course materials explaining how we will proceed. I thought the best way to approach a course like this is sharing you the Git repository you can fork. You can check out to any given demo by doing gitcheckoutmodule, the module where you are /demo the demo you are. For example, in this case it would be gitcheckoutmodule2/demo1. With that, you can follow along in your own fork repo. If you do not want to mess with Git, you're in the subway, or simply you do not wish to follow along, suit yourself. You are more than welcome to come. You have the ZIP, file which is generated by making the Git tag to check. Having that cleared, I already have a Git repository which is called ci-cd-with-travis. That basically has the backbone of the application at this point in time. I have the application running locally. It is a flask application. So we can test it. And in the browser, let's go to localhost on the port 5000, which I have in the following tab. We can see that we got a 404, not a connection refused. This means something is listening to this port. If we go to the Ask Me endpoint, we will see our application. Let's try that. Basically, this is a simple application that expects a question in text format, and it will answer the closest answer given its training set. Let's try asking what is the capital of Ghana, and we will see it will answer Accra. You did not know that here you would learn geography, right? Anyway, the second step will be to go to travis- ci.com to sign up if you haven't already. A simple note to take, there exists travis- ci.com and travis- ci.org. However, as of today, the latter has been decommissioned and migrated to the former. So if you're creating something from scratch, start in the .com version. We sign up with our GitHub credentials, that in my case it's already logged in, and it will autodetect, so it's the same. And in your case, you will ask to sign up to synced accounts, and that's it. When you're logged in, it will show you you have zero repositories. So let's fix that. You will click on your account logo to go to your profile, repositories, and there you will have the Manage repositories on GitHub. If we click on that, it will redirect to github.com to go to the install GitHub apps synchronization with Travis. If we go down below, it will ask on which repositories you want to give access. You can select all repositories or only some. If we go to only some repositories, it will show you which ones you already have and which ones to select. For example, let me show you how to add something. I will go and add the IEEE-CICD repo that was for another conference. If I click on it, then automatically it will select that repository to sync with Travis CI. So if I approve and install, you will have this nice emoji of Travis working the synchronization with GitHub, and we go back to Travis to show that the repository is already synced up. I didn't sync the CI/CD with Travis because it was already synced. And that's it. We already linked the two accounts. Travis will actively search for the configuration file in order to start building. Let's review briefly what we learned in this module and hop on to the next one.

Summary
And we go to the end of this module. Congratulations! By taking this module, you officially said to yourself I want to develop faster. Over this module, we learned what problems that CI solves and why it's needed. What is the current landscape of CI servers and how to choose which is the optimal for you and what we are going to do in this course. And don't worry if by this module you learn that the traditional CI service to choose would be Circle CI or Jenkins. Still the knowledge you will get over this course will be foundational and can be easily transposed to other CI servers. Hop on to understand how to make your first build.

Creating Your First Build in Travis CI
How Does a CI Server Work?
In the previous module, we understood the current CI landscape and what are the different options for CI servers. In this module, we will make a deep dive into the subject by first understanding how a CI server works and finally going into the specifics of Travis CI. At the end of this module, we will create our very first build for our Python application. So, how does a CI server work? To cover this, let's think of the typical example when working in a given feature. Let's imagine we are working in the next big app on the market, and we need to add an Okta login. For that, our first thing would be to make a copy of the main branch into our machines. Later on, we would work for some days until, finally, bam. We see this on our app. We did it. Now we have to add that to the main branch such that it goes out in the next release. For that, we would first publish our version in a temporary branch. At that point, our CI server would need to get notified of the changes by our version control system, build the app with our changes. This would be to check out the code I pushed, compile it to create an executable, test it, and notify me via some system that my build succeeded or not. At that point, it would show in some dashboard that my local changes are approved and I can commit my changes to the main system. Assuming I have all of the remote changes, I can do this. At that point, the CI server should understand that there is a change in the main branch and therefore needs to trigger a new build, but check out in from the main branch with my change. If everything is okay and the tests pass, everything is fine. But in case it is not, it should notify someone that the tests are broken in the main branch and it should be fixed ASAP. Optionally, the CI server should also execute all the code necessary to package the application and publish it, although it's not mandatory for a CI. So, the basic functionalities of a CI server are integration with a version control system, ability to create independent builds of the code in different versions in parallel, and notification for results of a build. In Travis CI specifically, this work is done via the master instance living in the cloud. It can be the common one in the free case or a selfâ€‘hosted one in the paid one. That, when it gets notified of a new build, it spins up in new instance in AWS. Inside that instance, it creates a Docker container with the instruction that we specified in the YAML file. After that container is created, it runs the necessary commands of the specific build. And finally when ending, it sends back to master the information to show in the dashboard and, in the case of Travis, it can configure to have a final select integration to tell if the build failed. And that is how CI servers work. Let's use this knowledge to understand how the GitFlow works with Travis CI.

GitFlow with CI: When Travis Saves the Day!
Most companies use Git as version control system. So if you're working in an open source project, chances are you're using GitHub and Travis CI. In this short video, let's see how GitFlow works with Travis CI. GitFlow refers to the following graph of a Git strategy, which is basically what the software development world is using today. Let's revisit it shortly. In GitFlow, we have several types of branches, feature branches, develop, release branches, hotfixes, and master. Develop is the integration branch. It's the branch where all the features will be integrated and from where the release branches and hotfixes will start. So a feature branch is where basically we are making a new feature. It starts from develop, and it ends in develop. When we decide we want to make a new release, we branch from develop a new release branch. And at that point in time, we can start the release, and only bug fixes will go into the release branch. When we decide that the release branch is ready to go regarding bug fixes, we merge the release branch into develop and into master. Master will be a copy of the code that is actually in production. At that point, usually we tag master, and that tag triggers a deployment to production. So at that point in time, the release branch and master will have the same code, and develop will get all the bug fixes that the release branch got. Finally, a hotfix is basically a commit or a branch that we use to go from master into develop and master again to solve something in production, and it works as a release branch. In this context, we must trigger our CI in every pull request of our release branch into develop, a commit change in develop so we can have accountability of the tests post-merge, a commit change in master, making sure whatever we will deploy is actually okay, and a commit change in a release or hotfix branch since there may be multiple bug fixing commits in those branches, and we need to test those. Also, for develop, we must have a notification system alerting the team the build is broken, and it should publish our coverage and add a quality metrics to some system since develop is the development state of our project. Finally and also for master, we should deploy on tags to production. A quick comment before entering in how to create our first build in the world of CI/CD with Travis because very much has been told of this. CI/CD stands for continuous integration and continuous delivery or deployment, and the idea is that for achieving continuous deployment, one has to deploy everything that is in develop. Basically with Travis this is simple since basically we eradicate master and the release branches. And after every merge to develop, we add the deployment steps. However, another valid strategy could be that after every big feature we could deploy to production. In that case, a workflow could be that if we merge a big feature, something that was needed for some time or a bug fix, we tag develop. And then the deployment workflow is triggered on tags only. This was in a short video how GitFlow will work with Travis CI to achieve CI and CD. Let's dive deeper into how we can specify the test and compile commands in any project, which is done via the travis.yml configuration file.

Talk Is Cheap, Bring the Code: The travis.yml!
All the configuration of a job in Travis CI is done via the .travis .yml file. Let's understand how to write one and what is the lifecycle of a build. Let's imagine that we want to start having a simple CI in our Python application. What do we do? Travis CI needs a .travis .yml file that will specify how the build should work. This will have the information of the programming language, the type of operating system, comments to compile to create environment to run the tests, and if there are any checks to make. As with all these concepts, it's easier if we start from an example. A pretty simple example for a .travis .yml file, from now on a Travis YAML file, will be the following where in this YAML we specify, we are having Python as language for our application. Specifically, we want to test for both Python 2.7 and 3.5 versions. This is part of what is known as the build matrix, and we will cover that in next modules, that before executing the test, we need to create an environment. For Python, it will be a virtual environment, and the commands are those in the screen. And that finally the tests are run. We execute inside the virtual environment the py.test command. Cute, right? What then will happen is that when a build is triggered, we will get right now on how that can happen. Two jobs will spin up. Why two? One testing with Python 2.7 and one testing with Python 3.5. This is awesome for open source when we want to test something for multiple versions. Now, for a build to be triggered, we have to do two things. The first is connecting the repository with Travis CI. That will tell Travis to start watching the repo at every commit. We did this in the previous demo. Secondly, to have the .travis .yml file in the repo only after both things happen in the build, which will be triggered for the conditions specified. It can be in PRs on all branches and subbranches, on tags, whatever you would like. Let's suppose that we already did the first step, and Jessica created in her branch a .travis .yml file and open a PR. What will happen? In master, there still would be a Travis CI file, so no build happens there. However in the branch, let's call it .travis, there is, and we open the PR. Therefore, our first build will be triggered, and the status in GitHub PR will appear. When merged, a new build will be triggered since now the commit changed in master, and there is a Travis YAML file. That means that now we will have a build in master, and the job for the PR will be deleted since that branch doesn't exist anymore. When a new branch starts from master, it will already have the file, so a new job will be created for that branch, and so on. However, if we did not configure Travis with the repo in the first place, and we do it after merging the .travis .yml file, then when configuring the first job to build will be the master job since the file will be already there. What other things can we add to the Travis YAML file? Every build in Travis has to follow in steps before and after install, before and after script, before and after success, before and after deploy, which are optional. And the following extra assets are modifiers. One can specify on which branches to run, which environment variables to sit, which notification systems to use, if we want to run a Docker image or not, and many, many more things that get added all the time. I suggest go into the docs all the time. Here is this more complex example where we will specify that the operating system will be Ubuntu Xenial, that we will only run in master, that we will validate in parallel for Python 2.7, 3.5, 3.6, and 3.7, that before the installation of the virtual environment, we need to install some APT packages, that we probably install the Python virtual environment with the .test quotes to run the tests, after success to publish the code coverage via codecov, and finally, to deploy the app to Heroku which is some of the out-of-the-box deployments that Travis has and we will revisit later in the course. To wrap up, the Travis YAML file is the unique file that specifies everything related to how to configure a build. It has different stages that we can manipulate and modify to control the flow like, for example, on which branch to run on. It will trigger builds only if the repository is added to our Travis CI user dashboard configuration, and it will notify to GitHub the status of the build. The best way of learning more on the Travis YAML file is by doing it. So let's go to the demo where we will create the first build for our Python NLP application.

Demo: Configuring CI for Your Python Application!
And we've got to the demo of this module. I know this module was a bit technical, but we need it to understand the basic components of Travis, to understand all that will be going on in the demo. Over this demo, we will configure our repository in Travis CI, we will add the Travis YAML file with our first build, and we will explore how it impacts the Travis UI dashboard. Hop on! Hi. Welcome to the first demo of module 3. I am now in my console, and I will show you how to go to the point of time in Git of this demo, and let's add a Travis YAML file, open a PR, and see what happens on travisci.com side in the UI dashboard. So for that, when you clone this repo, which is ci-cd-with-travis, you will see we are in master. Let's execute git checkout module3-demo1. This is a tag. So now we went back in time in the repo to the commit that defined that we are in the demo1. I have one already open my IDE of choice, which is PyCharm. But you can use any IDE you may want. So in PyCharm, here is the Travis YAML file we will use. We will specify that the language is Python, that the Python version is 3.6, the install command to run inside the virtual environment is pip install -r requirements.txt. And then the script to run is python -m pytest -v for verbose. It is important to understand that for Python, Travis already creates a virtual environment and activates it. You don't need to do that. So in order for it to make a change against the master branch such that we can see what changes we have, let's make a change and create a branch. So I will add a simple comment that I will not push, and I will create a new branch from this new commit, create a commit, push it and see what happens in Travis CI. Let's look together. The commit message I will use will be Testing changes in the travis.yaml file. And let's push. Now we have a new branch in place that goes from the commit that was that we defined the YAML file. Let's see what happens in Travis CI. So we open, in my case Firefox, and I will go to travis- ci.com. There, Travis already detected I created a branch called test-branch. So it will run. Let's look what happens there. We can see that it detected it had only one job, it was in Python 3.6 and with an AMD64 architecture. The job log it's outputted here where basically we are defining some variables in the job config, and then it will activate the virtual environment, run the pip install -r requirements, and then will run the tests. And the test passed. Awesome! If we check, now this branch is green. This is basically our first build in Travis CI for this Python application. If we opened a PR, then we would have a job in the GitHub state where basically it will say the state for this branch. Let's do that. So let's open a new tab and go to the repo. I am not in the repo, and I will create a pull request. Now I will open a pull request against master, and let's open it. What will happen is that if we check, now Travis CI already have a check and updated GitHub that this branch is okay. With this, we can see that with a simple Travis YAML file with five lines, we already have a working job that will run on every commit to every branch. Let's go to the summary and hop on to the

Summary
next module to make this YAML file a little more complex. That was a function demo, right? It's incredible how much we can achieve and how automatic things are with a proper CI in place. And we only needed a couple of lines in the YAML file to do so. I know that it may appear little since we only wrote a couple of lines, but the concepts behind were huge. So let's recap. Over this module, we understood how a CI server works and how Travis CI enables GitFlow to have a proper software development practice. We learned about the job lifecycle and how to specify and manipulate it with a Travis YAML file. And finally, we put all in practice, creating our first build. It was a lot, and a lot more fun is coming. Now that we know the basics of a build, let's tweak it to the extreme to adjust it to our needs. We will learn about spinning up parallelizing work, how to organize repeatable tasks into stages, which will make our life a lot easier. We will learn about caching and scripting.

Configuring Your Build with the Build Matrix and Build Stages
Build Matrix: The Champion
Sometimes the simple compile test and build flow does fit our needs, especially in the enterprise world. Travis CI adjusts easily to these cases offering the build matrix, cache layers, the possibility of building with scripts and build stages. Ride with me, and let's tackle them. We started developing our Python application for open source and bam. We got our first star in GitHub. We are super excited. But all of a sudden, an issue appears. Please, can we use this app in Windows? Oh my God, we are starting to promote our app, and now we have to support multiple operating systems. How are we going to do that? Later on that day, a new issue arrives. I want to have two jobs in parallel for integration and unit tests. This sounds super cool, but right now we don't support it. Can we? All these tiny configurations to the build flow will allow us to make super powerful contributions. Let's try to solve these issues and help our application succeed. The build matrix is one, if not the, main feature of Travis CI. It allows to effortlessly create multiple parallel jobs in a given build to simplify continuous integration. And what can we parallelize? Well, multiple language versions, for example Python 2.7, 3.5, 3.6, and 3.7, multiple environment variables, for example for tests to be unit or integration, and multiple operating systems, for example Ubuntu, Windows, and macOS El Capitan, and many more things. Let's see an example. For example, in this Ruby case, we would have a matrix expansion of all the possible combinations of ENV variables, gemfiles, and RVMs, which would lead to eight jobs in parallel. For example, one of those jobs could be run a Ruby version of 2.5 with Rails version of 3.0 .x and not isolated. An important remark to keep into account is that as we expand the matrix, it can grow factorially. However, Travis allows up to 200 parallel jobs at any time. So we must include the items that we do care. And what if I care in the above example about all the cases except test in isolated mode for Rails 3.2 for some reason we don't know. Well, what we can do is to follow an example where, in this case, we will have in theory all eight jobs, but we would exclude the two jobs that have the options of gemfiles rails- 3.2 and ISOLATED true. There are two options because those two variables will have those values both for rvm 2.5 and 2.2. Similarly, we can include specific jobs aside of the matrix expansion where, in this case, we have three jobs matrix that only has included items, not expanded ones. For each Python version, we are setting the environment variable TEST_SUITE to a specific latest for each version. Imagine we have the above matrix expansion and the pypy job fails right now because of bad dependencies. But the other two jobs are ongoing for some time. You go for a Coke and when you come back, the build is still going on. What the hell? By default, Travis CI does not fail until all jobs finish, which may be cumbersome. In the case we don't want that, we can specify to fail fast. We will do this in the demo. Another thing to take into account, imagine we have the following matrix expansion. How many jobs will run? One would imagine it would be 2 x 2 x 4 - 2. That means 14 jobs, right? However, the answer is 16. Why? Because for env exclusions, the string has to be exactly the same. In our case, as we have an extra space, it doesn't match so we actually are not excluding anything. This can be a point of eternal headaches if not taken into account always. Finally, imagine we have our CI in place, and our application is growing. But the architecture team wants to test a whole new messaging system. How do we do that and not break the build without having a super gigantic branch that basically changes everything? Well, Travis already thought of that and created the allow failure style for experimental branches and characteristics. For example, in the following case, we are experimenting how our application will work in pypy. So we allow it to fail. This is extremely powerful if we mix it with the build matrix because, for example, we can allow to fail some environment variable setting that uses the new messaging system. It's important to mention two peculiarities that Travis CI has with allowing failures. The first one is that the match for every filter must be in the equal form. We cannot allow failures on reg access matching some tags. And if we allow failures on the combination of two variables, they both need to be an exact match. The second one is that every variable we are allowing the failure needs to be defined in the top level of the build matrix. So, for example, in our example above, we can allow failures in Python versions, but not on the environment variables versions since those are not defined on the top level. Let's see an example. In the following case, no job will be allowed to fail. Why? Because the env variable is not defined in the top level, only PHP variable. Therefore, we cannot allow to fail the env variable match. With all these examples, you're starting to figure out that we can do a lot with build matrix. It is a unique feature of Travis CI, and it is very _____ for open source where we need to test multiple language versions and operating systems all at the same time. But, however, it has flexibility to allow experimentation, exclusions, inclusions, and many more things. Before moving on, let's do a quick demo on how to tweak our Python application to support those operating systems and language validations.

Demo: Testing Multiple Versions with Build Matrix
And swiftly we go to the first demo of this module. We will verify multiple operating systems in our CI, test against multiple Python versions, and experiment with a Python development version, all in the same YAML file. Let's do it. Hi. Welcome to the first demo of module 4. Now, as before, what I did was I am in the same repo, but on the tag module 4 demo 1. And for verifying what happens when we open a PR, what we will do is I will create a develop branch that I already have, and we will have a new branch that we will make changes to the Travis YAML file with all the necessary changes to verify multiple operating systems, multiple Python versions, and allowing failures on an experimental Python version. So let's check how the Travis YAML file will look like for that complex flow and then how a PR will look like when, on this new branch, we try to merge into develop. Let's go. I have now opened my IDE of preference, which is PyCharm, and let's see how the Travis YAML file has to look like in order to test multiple Python versions, multiple operating systems, and verify experimental branches. In Travis, by default, all the virtual machines are Linux. In fact, they are Xenial Linux. That means that they are Ubuntu and Xenial distribution, which is Ubuntu 16.0 .4. So if the jobs that include we only specify Python, for example 3.8, then what will happen is that it will be a Xenial Linux machine. In that way, we can start including jobs like we are doing in the first four, setting the Python version to 3.8, 3.8 with another distribution like Bionic, which is 18.0 .4, 3.7, or 3.8 .dev, which is the development branch in the 3.8 Python version. With these we are testing multiple Python versions in Linux. It is a little bit harder to test multiple Python versions in Windows and macOS due to the fact that Python is still been arranging Travis for those operating systems. But still I wanted to show you how to do it at least with some Python versions such that you have the template. So in macOS, what we have to define is the OS to be OS X, which is macOS. And then you have to define the image of XCode you want. And with that, the Python will be included. So in the docs of travis- ci.com, it will show you that as the date of recording now the latest XCode image is the 11.2, and it will have Python 3.7 .4. So we don't have available 3.8 in macOS. Also, if you try to put language Python, it will fail. That is because the way that Travis CI works with macOS, it is not using the system Python, but installing via Homebrew. Finally for Windows, first we need to install choco, which is the APT installer for Windows. And there we will install the version that we want. So the Windows machines that actually have Travis CI, which is Windows 10 as of the date of recording, it will have Python 3.8 .0. So awesome. In this way, we included all the different test cases that we wanted. Finally, we are allowing the failures for the Python version 3.8 -dev. So it's basically says okay, for this super new Python version, I will allow the failures and see what happens. The installing is always the same. Once we are in the virtual environment, we have to do the pip3 install of the pip library per se and then all the requirements. And finally, this took me a little bit of time of research, but this is the way of executing Python for it to work on the free operating systems because Python alone would work in Linux, but it wouldn't work in macOS because it points to another Python, the 2.7. And in Windows, it is an existing. So basically you need to do this, which is basically run this command or the other command. Depending on the operating system, one will work and the other will not work. And with this Travis YAML file, what we are doing is we are verifying the versions of Python 3.7, 3.8, and 3.8 -dev. We are verifying in Windows, in macOS, and we allow in the failure in 3.8 -dev. For all of them, we are creating a virtual environment and running the tests. So let's make some tiny comment as before, create a branch, create a PR, and see what happens on travis- ci.com. Here I have already created another branch called test-branch and opened a PR of test- branch into development. We can see that then Travis CI created two jobs, one for the branch per se and another one for the pull request. Let's click on those and see how the job looks like. So if we go to Details, that will show the GitHub apps pull check of Travis. There it will have a link for the build actually in the Travis, but it also has a table showing everything that we are doing. If we check, we are testing actually six jobs, Python 3.8 .0 in Xenial Linux, another one in Bionic Linux, Python 3.7 .4 in Xenial Linux, Python 3.7 .4 in macOS, and Python 3.8 .0 in Windows. And then it is allowed to fail the job in Python 3.8 -dev on Xenial Linux. Let's go how this looks like in travis- ci.com. This is what is called the build view in Travis CI. Basically, it will show I triggered a build, and these are all my jobs where it will show in separate the jobs that are allowed to fail. At this point in time, the first three jobs in Linux have already finished, and the one in macOS and Windows are scheduled and starting. If we go and do a little switch in the time space and bam. All the six jobs ended. In this case, our NLP Python application works, both in macOS, Windows, and Linux in two different distributions and in Python 3.8 and 3.7 and also in 3.8 -dev, even though it was allowed to fail. So as we have a success, we can go to the PR and check how the build checks actually look like right now. And this is the PR view for these builds. We can check that now for that branch, the Travis CI build actually says it was successful and the time spent. Awesome. Of course, the build for the pull request, in this case, it will be exactly the same. So if our tests are not flaky, it will pass again. But sometimes for branches and pull requests, the build will be different. It depends if we have some stage that is dependent on a certain condition like been in a pull request. When both will pass, the Merge button will be green, and we will be able to merge. Let's wait on that, and let's finish this demo. And now the pull request build also finished. We can check that in no more than 4 or 5 minutes, we did a lot of verifications on our library or application. This is incredible for open source. Now if we click the Merge button, it will merge, and a new job will be triggered, the one in develop of course. And if that passes, as we expect it because our changes are not that aggressive, then we will have a complete CI. Let's see for a little bit how a pull request and the build history will look like actually on travis- ci.com. And we got to the Branches tab in the repo in travis- ci.com. And we can check that for the different branches, it shows all the past builds and how they went. We can also go and click one of those, and it will redirect us to the job. For example, this one was the first build that we have, the one in the previous module. With this, let's end this demo. Thanks.

Speeding up More with Caching
Caching is one of those subjects that everyone thinks is important, but always it demands some time to understand and dominate. Caching in Travis CI is made simple, but powerful. Let's imagine we are continuing to develop our Python application, but we have gotten to a point where the creation of a virtual environment is taking over half of each job's time. Incredible, right? That is the cry for caching. Caches let Travis CI store directories between builds, which is useful for storing dependencies that take longer to compile or download, even more if they do not change a lot. Basically, Travis stores the directories specified with a key that results of the check sum of the combination of language, OS, and branch. And which directories does it cache? Travis already knows for which common language the default directory where we install things such that we don't have to worry about locations. For example, if for Python we specify cache equals pip, then automatically Travis will cache the home.cache pip directory, which is the default one, the one that actually pip will go and download all the packages. The same is true for other languages, like Ruby, Node, and Java. And if I want to cache some custom directory of my own, of course you can. You have to specify its path, and it's done. Knowing that, Travis needs to write permissions on this directory. For example, in the following example, we are also caching the .autoconf directory. So we cache everything, right? Well, not so much. As the cache is not local to the instances, but is in a storage provider, a virtual machine has to still download these files. This means that if we have super big files, it will still take a long time. You'll gain nothing. For example, Android SDKs, Debian packages, JDK packages, compile binaries, or Docker images are examples of things that are not such a good idea to cache. And how does the cache lookup work for branches? First, Travis first checks the branch cache for that language and OS. If it doesn't find anything, it will look on the default branch and the language and OS, and that's it. So, for example, suppose that we are running Python in Windows, and we are in the branch check-cache. Then first, Travis will look for the combination check-cache Python windows, later on develop Python windows. And if it doesn't find anything, it means there is no cache. And what about for PRs? First, it will look at the pull request cache, later on the target branch for that language and OS, and then finally on the default branch and language and OS. And if it doesn't find anything, it will mean there is no cache. So to wrap up, caching works on a non-local network level, which restricts the file to cache to my size. But it can have a tremendous impact on the environment creation. Travis already has precooked for a lot of languages how the caching should work to the point of making it a one-liner. And it has a fallback system for different branching strategies to try to always find a cache. Let's see how all these work in a demo.

Demo: Configuring the Build with Cache Layers
And quickly, we get to the second demo. In this demo, we will cache the virtual environment creation for pip packages using caching, and we will validate how to adapt the cloning depth in Git for quick checkout. With these two assets, we start to see how customizable the flow can be and how fast it can get. And now we move to develop into the module 4/demo 2 tag as we can check. This tag we will check how to add caching and how to tweak the cloning depth in Git for a faster checkout. Of course, in our case, it will not make such a huge impact because our application is really small. When you start having a really big application, you will start to see the impact. Let's go to the IDE and see what changes we did to the Travis YAML file for adding caching and tweaking the cloning depth. I am now in PyCharm, which is my IDE that I prefer, and you can check that all the thing that we added was four lines. And that, I promise you, will make a minute faster to build. The first line that we added was that the cache, it's pip. That will make that all the pip libraries that we'll download, they will be cached, and we will verify this. They will not be downloaded from the external PyPI. Finally, we added the first three lines regarding Git, which basically say for Git, when you are doing the checkout, use a cloning depth of 3. That means get the latest for commits because we don't need more than that. Do it quietly, so don't output in a verbose manner. And finally, don't track submodules. In our case, of course, we don't have submodules. It's a small project. But if you have, sometimes that can help you a lot. And also if you don't, if you add this, it will go faster because the submodule check are a little bit more commands that are annoying. So as before, let's make a quick comment to the Travis YAML file. Let's open up a PR and see how a build will look like. I have loaded to our test branch the new change in the Travis YAML file. So I am in the Branches tab, and you can see in the build history that it is being built. Let's go and click there to see how the build changed. If we go to this build, it will show all the different jobs that we had before, that nothing has changed. So let's go to the first job and see how caching changed things. I am in the job for Xenial Linux Python 3.8. And what we can check is that actually now the git clone was done with a depth of 3 in that given branch in a quiet manner and without following the submodules. And now it was faster. Before it was 3 seconds. Now it's under 1 second. So it is a change. Now will we see some change in pip? Let's look. I will click on the command for pip, and we can see that it is still downloading. Now what happened? Well, the issue is that actually at the first run we are populating the cache for this branch OS and Python version. It is empty because we didn't have any run before. So until we populate that cache, it will be empty. Therefore, it will be the same on the first run. Let's check when the job ends, how it will actually populate a cache. And now in the next build, we will find it. Let's look for that. And we can see here in the stored build cache that actually changes were detected. So in the home/ travis.cache /pip directory, we are starting to store all the different packages. Look how many. A lot because actually the line was broken there. And it created all these cache, and it uploaded it. So now that the cache is uploaded, if we run the build again, it will find the cache. Let's test that, and with that, the demo ends. I will restart the job, and I already went for that job. So let's see if now that changes. And now I am in the restarted job, and let's see. We see a new line, Setting up build cache. It found it. And then, as it found the cache, if we look down below when pip is collecting flake8, actually it is using the cached version. So it worked. Now we cached effectively all the pip packages. I hope you find this fun, useful, and a good way to speed up your build with only four lines. Let's see you at the next demo.

Adding More Parallelization: Build Stages
And no video on customizing a build would be complete without talking about stages. What are those? Build stages is the way to group jobs and run jobs in each stage in parallel, but run one stage after another sequentially. What??? Let's see how they are super useful. We have seen previously that with the build matrix we can expand jobs in parallel to an extreme point, and that is awesome. However sometimes you need some jobs before the others. Imagine you want to test your Python app in the three main operating systems and later deploy to two systems only if the free jobs in the free operating systems work. Right now with a simple matrix expansion, that wouldn't be possible out of the box. What do we do? Travis CI solution to this problem is called stages. Basically, in its basic form, it says please add a name to the jobs, and all the jobs with a given name will run in parallel. Later please tell me the order of the names you want the jobs to run. That's it. An example of stages is the following. In this case, we are defining two stages, test and deploy, in that order. This build will first spin up two test jobs in parallel, test 1 and test 2. And later, only if both succeed, it will spin a third job for deployment. However, one can name the stages and jobs with whatever name one wants, like the following where we define two stages called test and one deploy. The jobs in the tests are unit tests and integration tests. The job in the deploy stage is called Deploy to GCP. That sounds awesome, but what if I already used matrix expansion? And how do I only deploy in master? Let's analyze the following example. Here we are defining two stages, the default test stage and a stage named deploy that only runs in master branch. Then we define a matrix expansion for Python 2.7 and 3.5. As the expansion is implicit, we are not using the matrix.include or the jobs.include. Then the stage will be the default test. After both jobs finish, a new stage deploy will run only if the branch is master. This deploy job runs in Python 3.5 with a full env variable, and it will run the deploy script. It is important to note that if we haven't set Python to 3.5 in the deploy job, then it would run with the 2.7 because in the top level, that is the first option for a Python environment variable. You can already imagine with all these that we can get really funky. The important takeaway is that merging the build matrix and build stages, we can get almost any workflow we want in Travis CI. And it adjusts neatly to almost any need. Imagine how many extra lines would be to do that in Jenkins. Let's define some stages to our Python app and bring some order to the build expansion in the next demo.

Demo: Adding Stages to Your Build
If we recall in the first demo of this module, we defined a matrix expansion that allow us to verify in a cross-product fashion multiple operating systems and language versions. Later in the second demo, we added caching to speed up the development process and use the cloning depth to faster get checkout. In this demo, we will use build stages to order the build matrix expansion, and we will use conditional stages for a deploy job. Although for now, we will just echo a string. But we will have the structure for later. Hi. Welcome to the final demo of this module. We will add build stages to bring some order to our build, and also we will check conditional stages and how they work. Let's hop on. For that, if we check, what we will do is add a stage for first the tests in Linux and then another stage for the tests in another platforms. We changed the script for the Python 3.8 - dev in order to check if it actually fails what happens with the build. Does it fail? Finally, what we did is that as we didn't specify that those stages are in the same order or in another order, the default will be the first stage comes first. So what will happen is first four jobs will spin up. The fourth of the stage tests in Linux. Then, the two jobs for macOS and Windows will spin up. That is the tests in another platform. And finally, we added a final stage, which we call deploy. Basically, it will run an echo for now. But the important part is that we define a condition. We will only run the job deploy if and only if the branch is developed and actually we push to develop. That means that when we open a PR, when we have the pull request build that will have target branch develop, it will not trigger this job because the type of that job will be target branch develop, but type pull request. Let's see how all this works in a PR. What we will do is we have developed, as always, as the integration branch, we created a new branch called test branch where we'll push and open a PR and see what happens in circle CI before and after the merge. We have created our PR of test branch into develop, and two builds started, the branch build for test branch and the pull request build as the target branch develop. Both should be the same and without the deploy job. Let's check both and if actually the stages work and if the job Python 3.8 -dev actually is allowed to fail. So let's click on the details for the pull request job first. After that, we will go to the build, and we got to the build view. This is the pull request build, and we can check that we only have six jobs in two stages, the stage tests in Linux and the stage tests in another platforms. Later on when this build finishes, we will check that actually the job is allowed to fail, the one in Python 3.8 -dev. So let's wait a little bit until the build ends. This takes about 5 minutes, so I will accelerate time space, and let's sync up together after that. And bam, the build has ended. And we can check that in this pull request, the job for Python 3.8 -dev failed as we knew because the script was exit1, but the build succeeded. This is because that job was allowed to fail, and we can see actually that tiny caption that says your build matrix was set to allow the failure of that job. If we go to the branch, here I am in the branch build, and actually also the deploy job wasn't turned on, which is great. And actually also the Python 3.8 -dev job failed, and the build succeeded. So the only thing we have left is let's merge this and see if the deploy job will appear if we merge onto develop. I am in the pull request, and I will merge. So I will confirm the merge, and that created a commit in develop. Let's go to Circle CI in the Branches tab on develop and see how that job looks like. I am back again to the Branches tab in Travis CI of our repo, and a new build has started in develop. Let's click on that. If we click in this build, we can see that it was due to the merging of the pull request that we created. And if we get to see the jobs, we can see that the deploy job is there. So actually our conditions worked. Of course, we know that as our script in the deploy job is only echoing something, it will be okay. But the important thing is that actually we could control when are we deploying. In this case, our deploy job only was turned on when we merged into develop. This is crucial for getting a good CI/CD. With this, let's end this demo and this module. I will see you I hope in the next module to add the CD to CI/CD.

Summary
Oof, that was a lot. In this module, we went really deep dive into how Travis CI works and to configure the flow of the build to almost any site we want. We were super successful in this and learned a lot. Give you a tap on the shoulder because now you are ready to create virtually any CI system you need at work. In summary, we learned about the unique build matrix that allows in a really simple way to create all the jobs we may need. We learned about how to speed up the jobs with caching and different caching strategies. Finally, we learned about build stages to group jobs and allow for conditional stages. With all this, we are ready to take the final step in our journey, how to add the CD to CI/CD. I hope I see you there.

Adding CD to CI/CD: Deploying with Travis CI
What Is the CD of CI/CD?
Welcome to the final module of this course. The final case after we have a great CI in place is to deploy that amazing, new application. Let's analyze what the CD means in CI/CD and how Travis makes deployments as easy as 1, 2, 3. First, let's review really quick what does CD stand for in CI/CD? Well, funny enough, there are multiple interpretations. But there are two that got more strength, continuous delivery and continuous deployment. Continuous delivery is, citing Martin Fowler, is a series of practices designed to ensure that code can be rapidly and safely deployed to production by delivering every change to a production-like environment and ensuring business applications and services function as expected through rigorous automated testing. What does this all mean? Imagine we have develop, and a new shiny feature was just merged from a feature branch. As it got merged and we have a CI in place, we know that all tests passed. But how does this ensure that we can actually deploy right now that commit to production. If we consider the testing pyramid, then after merging to develop, we usually just run unit and component tests. Maybe even integration, maybe. There are types of testing not covered yet, which basically ensure that our APIs won't be broken by the change, which may break compatibility for example, and our components interact correctly. This is what continuous delivery tries to solve. It is the practice of this new change deploying it to a production-like environment continuously in order to do these validations. This environment is what we usually call pre-production or stage. With continuous delivery after the build ends, we will have every deployable commit in a pre-prod already validated environment. From there, we only have to push a button and, bam, we are in prod. Going to continuous delivery is tremendous for the speed of the team since with a good testing suite, we can quickly have feedback on our work and iterate. And what in the hell then is continuous deployment? Continuous deployment is basically to make that final manual deploy to production automatic after more validations pass. You may think it's the same, but not always. For example, suppose that we are making an application that is being used by a big corporation. We're in a B2B business. Usually, if you deploy continuously, users will think the system is broken since it is not predictable, and then they will stop using the system at all. That is hardly beneficial. Other times, you have to coordinate with the clients the deploy of new changes or your application integrates with a whole ecosystem that deploys separately. So you need to coordinate with them too. So, basically, although continuous deployment is a nice feature, usually it depends on the business case whether that is convenient. What by no means is in doubt is that the delivery or the deployment, everything has to be a single button and automatic. So how does CD look for libraries? Well, usually it needs to go all the way up to the package manager or that specific language. For example, in Python if we make a library, the delivery would be to publish to PyPI. In Node, to NPM. In Ruby, to a Gem file. In Docker, to Docker Hub. And many, many, many more. With this discussion in place, let's see how CD looks in Travis.

Deployments in Travis CI: As Easy as 1,2,3
Travis is a system that makes it super simple to deploy systems. Let's learn this cool feature. Deployments in Travis are configured at the deploy stage in the Travis YAML file. One option is to run your own script. But if you do not want to deal with that, Travis has precooked deployments to many providers out of the box. Let's see at least of some of the providers that Travis supports. Lambdas for AWS, S3 for AWS artifacts, Google App Engine for applications in the Google Cloud Platform, Heroku for open source applications self-hosted, language package indexes like NPM, Gemfiles and PyPI, and many, many more. So basically, almost any way of deploying your application or library is covered. Travis knows how to do it. An example deployment for a Python application to PyPI would be the following where to create that token basically you use Travis CLI, like we will use in the demo. And with that, any deployment has a provider, and the parameters are referring to that provider in the docs. With only this information, Travis for Python already knows it has to run the setup.pi install, get the wheel, upload a via Twine with these encrypted user to PyPI, and then return to you the version and the link to go to that version so that you can actually run pip install my library equals equals the new version. All that is done for you. You don't need any script. In the following example, basically we have a test stage with two jobs expanding the matrix, and then the deploy job. By default, Travis disables deployments on PRs, so this job will deploy on every commit to any named branch. What if we want to filter that? We already know how to do it, right? Another common situation would be to deploy on tags. For that, the only thing we need to do is just add on the deploy stage on tags true, and then it will deploy to all tags. We can even have multiple deployments with conditions on deploying on tags on certain branches. So for example, tags created on develop publish to PyPI, but tags on master deploy to production. Finally, as a side note, Travis also supports out-of-the-box custom internal PyPI integration where, of course, we can encrypt our password as before, and we only have to define which is the server. This is an example of how deployments will look like. But as there are lots of providers, the best thing to do is to check the docs for the one that you are interested in. I assure you, it is as easy as the one we have seen. For the sake of presenting a deployment provider also that actually deploys an app, let's see Heroku with an example. Basically with Heroku, we have to specify the api_key. We can specify the app name and any condition we want on env variables, and that's it. It will deploy the app out of the box. Of course, one can have multiple deployments and multiple providers. This follows the idea that maybe on delivery you want to publish your Docker image to ECR, publish your Python library to PyPI, and later deploy on a tag to master to Heroku. So in the following example, the same YAML file we added that on commits to develop will publish to PyPI, and then all tags to master we deployed application. Overall, you can see that it is super simple to deploy things in Travis. Let's do some demos delivering our application to PyPI and later on deploying it to Heroku.

Demo: Adding Continuous Delivery to PyPI
And now it's demo time. Over this demo, we will create the wheel artifact for our application and deploy it to PyPI using Travis CI. This will apply a lot of the examples we already have seen. Hi. Welcome to this demo. The first demo of the module of continuous deployment. On this demo, we will add the publishing to PyPI of our NLP Python application. And for that, first we need to login to PyPI, right? So the first thing we will do is go to pypi.org if you haven't already. And I am already logged in, but if you haven't, you have to create your user and register it. Whenever you do that, you will get to this home page which is basically the user homepage. There we have to create an API key for Travis to use. To do that, what we do is we go to Account settings and in Account settings, along with many, many, many stuff, we will see that actually we will have the API tokens. So in order to create one, you will click Add API token and that's it. It will create an API token. Be sure to copy that because you will never, ever, ever see that again in PyPI. These API tokens are super secure because basically are our way of programmatically assuming your identity. So they need to be secure. Whenever we have that, we need to encrypt it in order to put it in GitHub. This is really important because if we put our user and password in the public GitHub, anyone can actually use that. And that is absolutely impossible to do. So what we have to do is install the Travis CLI and encrypt it. For that, we go to the console and we run this command, sudo gem install travis -v 1.8 .10, which is the latest version as of the time of recording, --no-rdoc --no-ri. If you don't have gem installed, that means you don't have Ruby installed. If you want to know how to install Ruby, you just have to go ruby.org and download the installer. That's it. When we run this, automatically you will have Travis CLI installed. In my case, I have already installed it. So I will avoid this command. Then what you have to run is the following command, travis encrypt pypi - your API token that here is actually masked, --add at the deploy.password level --com because we are using travis- ci.com. With that, automatically this CLI will populate your Travis YAML file if you run this on your repo will the encrypted token. And that's it. Let's go to PyCharm to see how the Travis YAML has changed. And that's it. With this, we already are in the deploy job, and we can check that the only thing that changed is that now we are doing stuff in this job. We are specifying to run only in pushes to develop that the Python version is 3.8, that we want to skip the installation of the virtual env because we don't need it, and we also want to skip the script because we don't want tests to run again. We will run on develop on the deploy part that we are specifying the provider, which is PyPI. The user will be given via a token an encrypted token of the API key connected to PyPI, and actually this secure password token was inputted by the Travis encryptor on the CLI. So actually this was populated for us. Finally, we are saying that we want to publish both the sdist and the wheels. If you are not familiar to Python, you do not need to care. These are two artifacts that are created, and we want let's keep the existing. So if in case that we are already deploying a version, we want to actually do that. With this, let's push these changes and see how it looks like on the Travis side. I am already in the branch view in the build of the latest development, which is the one that we triggered, and we can check that actually the deployed job we specified to publish to PyPI, it's already there. So I will bend space- time a little bit again, and let's check how this will look like in the end. And bam, it succeeded. If we check, actually the deploy job succeeded. If we go to that job and go to the job view, then we can see that actually after doing the get clone and setting up everything, it set up the build cache, it installed the deployment provider, and it deployed the actual application in the way that we specified authenticating with the use of encrypted token API token in PyPI, and actually it exited correctly. So if everything was correct, we should be able in PyPI to see this version. Let's go and check it. We will go to pypi.org. And I am already logged in. I will see my projects. And in my projects, I already see cicdwithtravis. That is incredible. So actually we effectively in only 10 lines deployed our application to PyPI. This will be the end for a lot of open source. But let's do a step more, and in the next demo, let's deploy to Heroku too.

Demo: Adding Continuous Deployment to Heroku
And another demo. In this demo, we will go all the way to continuous deployment. We will create a Docker container for our Python application, deliver it to Docker Hub, and deploy it to Heroku using the script provider. And with that, we get to finally continuously deploy our application. We will use the Heroku script provider such that you can see that also you can deploy with scripts. You don't need the providers of Travis. Hi. Welcome to the second demo of this module. This will be the last demo we will start adding things to the Travis YAML file. Let's do a recap. We already have three stages, the test in Linux stage, test in other platforms stage, and deploy stage. For the test in Linux, we are testing several Python versions in Xenial and Bionic distributions. For the testing in other platforms, we are testing in Windows and macOS. Finally, in the deploy for now in the pushes to develop, but now we will do it in master because that's the corrected flow, and we reached the end of the course so we can do it in master now. We actually package our application and send it to PyPI. The only thing we have left is to create the Dockerfile, create the Docker container, publish it to Docker Hub in order to have a continuous delivery of containers, and finally also using Heroku, publish these to Heroku. So let's do that. How are we going to do it? Well, the first thing first is that actually we need to add that in this virtual machine we need sudo, and we are going to use Docker. For these providers, we will use the script provider in order how to show you how to use the scripts in Travis CI, which is really simple. The only thing we have to say is that this script will be the scripts that we created. Let's look at little bit at these scripts. First, let's check the Docker Hub script. We will go to .travis folder and the deploy_dockerhub script. Basically what we are doing is we will use the environment variables that Travis will set up once we configure on the build, which I will show you how to do. It will log in to Docker Hub with Docker. It will build the Dockerfile that we already have for our application. It will tag it, and then it will push it to Docker Hub. With this, we already have the [00:17: 30.597 ] delivery to Docker Hub. Finally, the deploy to Heroku, what it will do is it will install the Heroku version for Ubuntu. It will install the Heroku plugin for actually pushing from a Docker container already built to the registry. It will log in to the Heroku registry. That is an ECR, elastic container registry. And finally, it will push our application to Heroku to run via Docker. There are a lot of ways of running to Heroku. Another way will be with GitHub apps. Preferably, if you ask me, I prefer to deploy via Docker. It adds an extra step. But what I ensure is that if it works locally, it works in Heroku because it's a Docker container. The only thing that Heroku with run is docker run whatever. For just a final thing, let's check a little bit at the Dockerfile. In the Dockerfile, we are specifying that we are using Python 3.8. We are copying the requirements. We are copying all the application, actually, exposing the port 5000, and then basically setting that the command is the python qa.app, which is basically what we ran locally, but now in the Docker container. With all this, we are ready to actually push this to master. But there is one simple step that we are missing, setting all those environment variables for what is the repository in Docker Hub that it will publish the Docker image, which is my user, my password for Heroku and Docker. Let's do that. I am in the repository view of Travis CI. Let's click on More options. In more options, you will have the option settings. Inside settings, we can do things like limit the concurrent number of jobs if that's a thing that is important to you because you use it for part of the system, for example. If we want to build and push to branches, if we want to build on PRs, which usually we want, if we want to cancel a queue of the jobs, if we have a new commit coming in that will create new jobs, and finally we will set environment variables. The way to set these environment variables is super easy. We just go and input the name, the value, in which branches does it have visibility, and if we want to display it or not. For example, what I did here is input my DOCKER_EMAIL, DOCKER_PASS, DOCKER_REPO, DOCKER_USER, and the HEROKU_API_KEY and HEROKU_APP_NAME. And that's it. They will be visible for the jobs. How do we get those? Well, I will assume that all the Docker ones you already know because this is regarding Docker. But maybe in Heroku you are not so familiar. So what we have to do is go to Heroku. And when we go to heroku.com, we will go to any case login, but you can do sign up and sign up. I will log in and wait for it to ask me for my password, and I am to the user dashboard view. Here I can go to my user and go to account settings. In account settings, check that I can actually generate an API key. So with this it's basically what I copy to travis- ci.com. Is this enough? No, we need an app name. But with this you can authenticate to Heroku. So later on, you'll go back to the main view. And if you want, you can create an app. Here you will see New, create an app, and it will ask which is the app name and which region and if you want to create the pipeline or not. A pipeline is a hook from GitHub to Heroku, which we don't need because all the pipeline is being done by Travis. When we create the app, it will be done. We copy that name and send it to Travis CI. With all this, let's make a push and see how the job looks like in Travis CI. I am in the branch view in Travis CI for our repo again, and master has received a change. Therefore, it will have a new build. Remember that in GitFlow every new commit to master must lead to a new deployment, and that's basically what we did. Let's check the build view. If we go to the build view, we can check that we still have our tests in Linux, other tests in other platforms. But now we have three deploy jobs, the deploy to PyPI, the deploy to Docker Hub, and then the deploy to Heroku. We did it. Now let's wait a little bit until all the jobs end and see if our changes actually get propagated to the end and our app was deployed. Just for the record of this video, I changed the version of the library to 1.0 .1. So let's check if in all three places that's the version that is being used. And we're back, and actually the three deployment jobs were successful. So if everything is okay, we should see a new tag deployed in Docker Hub, a new version in PyPI, and actually the app deployed in Heroku. Let's go and check, right? I am now in PyPI, and we can check that cicdwithtravis was released 3 minutes ago. If we actually manage it, we can check that actually the version 1.0 .1 was released. Awesome. Then if I go to Docker Hub, we can check that actually a new tag was deployed on this Docker repo a few minutes ago. So actually also it was successful with deploy to Docker Hub. And finally in Heroku, I go to the dashboard of my actual application cicdwithtravis. And if I open it up, we can see the 404, which means that it wasn't the connection refused. It is listening there. I have in another tab the Ask Me endpoint, and we can see our application. Even we can try it out to see that it works the same. If I ask what is the capital of Ghana, it will answer Accra. But now it is in the cloud. So successfully on a commit to master, we deployed to the three places. Now join me in the last demo where we will see that actually how GitFlow will work with Travis CI when we do an actual change. For example, we will change the title in this HTML to see that actually it gets deployed on that commit.

Demo: Seeing the GitFlow in Action
What? Another demo. Finally, we go to the final demo of the course, I promise you. We saw all the different parts by separate. So now you deserve to watch the action. In this demo, we will see how every new feature in our application gets the continuous tests and, after merging, delivers to PyPI to finally deploy all the way to Heroku via delivering to Docker Hub. This shows the power of CI/CD in GitFlow with Travis CI, the power of iterating with gazelle intensity, fast. Hi. Welcome to the final demo. Let's see how GitFlow will work. So for that, let's go and open a PR against master proposing a change in the title of our application, and let's see how on the PR we will have a build. And when that succeeds and we merge, it will actually go and deploy this new version. So you trust me that actually deploys the new version on the commit to master. Also, we will create a tag, and that tag will also make Docker Hub create a new container. Just for the reference, I changed the setup.py version for this package such that _____ see a new version in PyPI. So I will create the PR, I will trigger everything, and I will show you how it went. So here I have the build for the pull request against master that actually doesn't show the deploy jobs, but we can check in the config that they exist actually. We can check that actually everything exists. So the conditions on the deploy jobs were successful, and a new commit in the master was made because I merged. So, basically, a new build was triggered. Let's see that build, and let's see how that goes and the change propagates. So for that, I will go to Branches for master, and we have a new branch. Also, as I created the tag version 1.1, it also created a new build for that tag because I didn't specify that it didn't build on the tags. And we can see that for this build, the deployed jobs actually are there. So let's wait until this succeeds like the before, and let's see if the changes get propagated, and let's do a wrap up of how development works in Travis CI. And it succeeded. Let's see if the changes went along to all different systems. So if we go to the CI/CD, if we check the releases, now we have a new release, the 1.1 release that was released a few minutes ago. So actually, this was successful. We have the new release in PyPI. Let's go to Docker Hub. In Docker Hub, if we refresh again, we can see that we get two tags now, the version 1.1 2 minutes ago and also the latest version, which is the one from Travis CI. So also it succeeded, and we have the new Docker image. Now to check. Drumroll please. Let's go to Heroku. Let's see if the title changed. I will go again, I will refresh, and we have the new title. Yes, it was deployed. So we did a change. We merged it into master, and that change propagated to the deployed system. That's CI/CD. Let's do a quick recap of all that we did, how actually GitFlow will work. So now you are in a system with CI/CD. You branch out, in this case, from develop. You are in develop, you are happy, you create your future branch, you create your features. As it's a main branch, it will have the branch build. You merge to develop. That will create a PR and a PR build that can or cannot be different from the branch build. At that point in time, we will create from develop a release branch. That release branch will have a new build, which is the release build. And at the point in time when we decide that that release branch works, we merge into master. We tag master. And at that point, those changes will get propagated and deployed, like now. And also, the old and new commits that the release branch had for bug fixes will get re-integrated into develop. And that's how the GitFlow will work. And Travis allows you to control the flow because we have seen that we can restrict the different branches that we have or branch patterns. So, for example, for release branches, we would do that on release branches, we would have different jobs. And, for example, we won't test for Windows and macOS, and that is okay. And for master, for example, we could not test at all or only test in Linux. Why? Because it's okay, because I already tested in all the other places, and I will focus on deploy. And Travis allows on that. I was really happy to grow this example with you along the course. Let's do a quick wrap-up of everything we have learned in the course.

Summary
And we got to the end of the course. In this module, we attacked the last component in our journey of getting changes deployed fast, continuous delivery and continuous deployment. In this short module, we learned about what exactly is continuous delivery and deployment. We learned how to implement CD in Travis CI with all the out-of-the-box providers, and we implemented our own CD solution for our Python NLP application. I really like a lot an analogy that once a manager said to me. CI/CD is like compound interest. The sooner you get it, the more it pays off each day because it is like that. If you arrive to a project that is not in CI/CD, you have to get it with gazelle intensity. Once I had the luck of working in a project from the very beginning of the company, the first three commits were readme, CI in place, cd in place. We couldn't be happier at the pace that we could deploy. It was a pleasure to make this course for you, and I really, really hope it was interesting for you too and an eye-opener my friend to watch it. I hope you learned so much, and you can always ping me whenever you want. I am on Facebook, LinkedIn, Twitter. You can use the Discussion tab at Pluralsight course, whatever you need to get on board the CI/CD train. I try to answer as fast as I can in order to spread the CI/CD view of the world. Thank you, thank you, thank you. Thank you so much for seeing this course, and please go to CI/CD. Bye!
