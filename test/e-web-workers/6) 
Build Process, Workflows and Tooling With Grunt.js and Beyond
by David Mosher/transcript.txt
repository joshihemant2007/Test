Transform a static app with basic script includes and no tooling into a first class citizen with a build process, preprocessing, asset pipeline and more using techniques with Grunt.js and beyond (Yeoman, Lineman and more). This course covers adding an intermediary build process so that you can use CSS preprocessors, live reload, concat and minifying resources, coffeescript while splitting asset pipeline settings for local development vs production. Youâ€™ll also learn about getting up and running with new projects using Yeoman or Lineman to get up and running quickly building single page apps and unit testing your project.

Introduction
Introduction
[Autogenerated] No, it's ah, it's really good to be here today when I got the invitation from Mark to come and do this workshop, uh, actually got referred by Paul Irish, which was pretty cool. And, uh, I was very excited because for the last two years, I've been working, um, predominantly doing from and development, but rich client app development. So a lot of beginnings with backbone. Uh, and then, uh, recently, probably past six months working really heavily with angular and then, uh, making the shift to Shopify and working with their own sort of version of that called Batman Js. You may have heard of it. And Ah, so yeah, like tooling and work clothes and all this kind of stuff is definitely near and dear to my heart. And, uh, I think part of the reason is because, um, there's such a lack of motivation on a lot of projects for front and developers because they feel like they're stuck in the server side and they're stuck with the tools of the server side. And so I think at this point in time and some of the things we're gonna look at the workshop today. There are you know, just this _________ of tools that are available now and really, the job of front and engineering is, you know, integrating that stuff and making it all work and automating as much as possible in making the development experience for people Just a delightful experience so that when you come into work, it's not, um I have to spend all my time, you know, tinkering with the back end and being stuck with the opinions of the back end, eh? So that's kind of what's gonna frame what we're gonna look at today, and we're gonna start just with some slides, that kind of given overview and paint a picture. Why? I think this shift to front and tooling and we're flows is so important at this point in time. Uh, and then we'll dig into some tools a little bit of an overview of some of the tools. And then what kind of get into the nitty gritty and basically go from start to finish on a pure grunt work flow, and then look at some of the abstractions like yeoman briefly and then a tool that I work on called linemen, which is very similar to human. So about six, uh, three years ago, I started and quit my full time job and became an independent consultant, living in Saskatoon, Saskatchewan, and met a couple of people from Columbus, Ohio. The 1st 1 his name's Justin strolls, and he started a company called Test Double, which up until recently I was. I was consulting with those guys, and testable was a really interesting environment for me because, like I said, you know, it was consulting. It was different than where I had been, and I ended up going into AA lot of companies that were heavily invested in legacy service ID tech. So, you know, I was talking to the enterprise to have a guy's at the beginning. That's kind of where I got my roots with this stuff. So, going into teaching, how did you clean JavaScript? How to avoid polluting the global name space, figuring out all of the sort of things we need to do with tooling originally starting with, you know, how can we make this stuff work for Java developers who don't really understand javascript and then moving forward as sort of node hit critical mass in the last 33 years ish and client side. NBC really became sort of ah, viable option. So that was testable. And I have nothing but good things to say about Justin and all the guys that test double. There were kind of basically my mentors in terms of thinking about tooling and thinking about testing. Part of the actual reason that we developed or Justin developed lineman, which is the two will be looking at a little bit later. Today was because I was so frustrated with having to test drive my JavaScript on Enterprise Java project. Uh, we were using Jasmine Headless Web kit and a couple of other pieces. There's a Jasmine Maven plug in which Justin wrote that integrates with the Maven Life cycle, and it was super frustrating because it was slow. The feedback cycle was really long, And so he built linemen about a year ago and sort of kick started me on this. You know, this idea of, um, we can really make a difference with front end tooling. So about six weeks ago, I left test double parted ways with them and got an opportunity to go to Shopify. And Shopify is one of the largest e commerce providers. They're based in Ottawa, Canada. And the reason that the opportunity excited me so much is because they have one of the largest client side NBC, APS in production for their admin interface. And this is what it looks like here. So you can actually go to shop by and log in and sign up with There's, like, a three step sign up and you'll get right into this admin interface where you can add products and basically all of the sort of merchant tools that you would want to use if you were setting up an online business. Um, and just some stats about the project and why it? It appealed to me. There's, like 500 coffee script files. The whole the whole admin interface is written in coffee script 76 S. E. S s miles, 450 html templates on. And then you know 80,000 customers using this, you know, and that's grows exponentially because those 80,000 customers represent merchants who then have customers that are also using this platform. So when the opportunity came up, you know, it just excited me because up until that point in my career, I had worked on, I would say medium size client rich client applications. But nothing, nothing massive and being able to go into Shopify and look at what they were using with the rails asset pipeline and sort of a traditional rail stack and bring a lot of this idea of a modern workflow was was really exciting to me. So what are we gonna cover today? You know, the quotes are up there because I think it definitely didn't deserve some defining what a modern workflow means. So we're gonna talk a little bit about that. We'll dig into grunt and friends and I put end friends because there's, like, a whole subclass of tools that sort of work in concert with grunt that we're gonna take a look at. And then along the way, I put number three a step tools. But it's not really in that order. Where can I get a bounce back and forth between those things, But just some tips and tricks that you can use within Chrome Dev tools to make your work flow a little bit better

Web Apps
[Autogenerated] So if we think about the definition of a traditional Web app, if you're a team fortress too thin, you know this is a heavy. He's like big. He's, you know, he does everything right. And if we look at all of the responsibilities of a Web app, you know we need to have template ng. We need to think about how to manage our clients. I'd assets CSS, html and Java script er, NBC, right all of the service side frameworks. Whether you're using Enterprise Java, that does spring, NBC or you're on rails. They all have opinions about how to manage NBC when you're talking about a stateless Web application and http on, and then there's those other things that are sort of just in the domain of the server side authentication, security and storage. The interesting thing to me is that for the longest time you know, the server side tools have managed their service. I'd assets that makes sense, right? If I'm working an enterprise Java and I'm using spring, then I'm gonna want something that can manage Java files because that's what I'm writing in. The reason I classified it as heavy is because not only did they manage, you know, the life cycle and the workflow for all those server side languages. But they happen to sort of have all the front end stuff kind of tucked in alongside. So they're very opinionated about how to manage that stuff. And I think that to me, that's heavy because really, you know, should the server side care about how we manage our friend and assets on dhe? The general response I get from Web developers is no, it's frustrating. You know, I want to do all these things. I want to add these pieces to my workflow. But I can't because I'm stuck in the opinions of the server side. And so if we think of the way that weather maps are being built now, this idea of a modern Web app it's a little bit smarter. And so the architecture that I've been building in the last couple of years, you know, starting with backbone and moving too angular. And now Batman eyes. This idea of splitting some of those responsibilities. So you know, the guy on the on the left? He's the engineer. He he represents our front end. The guy in the back. He's the heavy. He represents the server side. And so we've split the responsibilities. You know, the server side can still take care of the things that are important to be done on the service side. Authentication, security, storage, You know, heavy data processing. All of that kind of stuff makes sense to be done on the server side. But what about the things that we're using on the front end, like the Web technologies were using CSS html JavaScript browsers have, you know, an innate understanding of how to deal with that stuff. So why don't we move all of that logic to a workflow that deals with you know, those things there? And this is kind of the rich client NBC approach. Whether you're using back Boehner angular or Ember or Batman, you're probably gonna have some clients I templates that you want. And we're gonna look at a couple of different strategies for managing those today. Um, whether, uh, you're doing M v C or M B star. I've put that because that's the popular term. It doesn't matter. All that logic lives on the front end, and the communication mechanism becomes XML http. Request which I've denoted here is X h r. And so we've got this rich client app sitting on the front end and it's gonna communicate via X, h r and R back in now becomes a service oriented back in. And we've got small bits of Jason data that are coming back and forth on this. Separation of concerns is really been made possible because we now have a rich modern platform and all these browsers, if you look at where you know, chrome and fire, Fox and I'II before chrome, I mean browser development and platform had really stagnated fire. Fox was sort of the innovator, but even then they weren't pushing the performance boundary as much when chrome really started to kick into high gear. You know, when we saw V eight release is when you started to see the viability of this as an option to build applications. So it's really, you know, only been in the last few years that this has happened and it's only gonna get more performance. I know the chrome guys in particular investing so much time and effort into optimizing their platform, you know, so that this becomes viable on mobile. So that when you run a rich client app on a mobile device, it doesn't chew through your battery. So this is what I mean, you know, between heavy and a modern with that approach, and I talked about platform, and if we think about all of the things that are in html five, all the all the things that we're using right now, you know, like local storage and session storage and request animation frame all these things that the browser vendors air pushing into the browser as a platform. Um, it makes so much more sense to use that as a deployment target. Instead of saying, Well, I'm gonna have all my logic live on the server side and do everything there. We've got this set of rich tools that can help us there. A rich platform. Sorry. And so that kind of outlines, You know, the things that we're looking at we talked about Ah, modern web app approaches in clients. At NBC, we talked about the modern platform, the browser, and so this really gets to the heart of what we're gonna talk about today, which is modern tooling and work clothes

Tooling
[Autogenerated] So if we think about traditional tooling where the friend and is really treated as a second class citizen inside of the server side. You know, I mentioned this briefly before, so you know, there's all these concerns that tooling needs to think about. How do I compile my assets? Whether their server side or client side, cat nation and modification those air kind of client side concerns. But server side has, you know, traditionally housed all the opinions for that. How did I manage my templates? Where they were working with J. A s P A s p whatever on then, all the client side templates. How do I do Code analysis and test in the Java world? Code analysis. Static analysis is really important so that you could catch regressions. You can have some baseline metric of code quality and things like that on dhe. Then how do I split up my application into modules? Logical separated units so that I can understand how best to architect my application. And then you replicate that So you know, if you're in dot net, it's got all those opinions. But then it's also got all the front and opinions and then you go to Ruby and it's the same thing. And it's a different server side opinions, but all different front and opinions. And so what you end up with is this scenario where if I'm a friend and developer working on the dot Net project and I go to a Ruby project, I have to relearn how that server side platform manages all my friend and assets. And there's an incredible amount of cognitive overhead and contact switching that happens. And maybe this isn't as prevalent for people that are full time employees with an existing embedded technology stack. But as a consultant, my frustration was that I'm jumping from project to Project and trying to help people really get up to speed on their front and workflow. But the tools air so vastly different on the on the server sides. And so really, what we need is sort of some sort of normalization layer on the front end. And that's why I think it just makes sense to split these concerns so that we can promote front and development and client side development to a first class citizen. And so if we do this, you know the heavy he's holding his big gun. The service side. Guys, we're gonna be happier. This has been my experience because, uh, you know, we're not taking things away from them were actually unburdening them from the responsibility of having to manage our friend and assets s. So they're gonna be happier. And then we're gonna be happier because we have, you know, the ability to manage all of these things as well with the workflow that we're gonna craft. And so now all these concerns, you know, Haman and integrate these things. Whether I can captain eight men if I how many manage templates compilation static analysis module is all of these things I can have opinions about on the service side and leave those things there and then have a really good opinions about those things on the front end as well? And then the challenge really becomes integrating those pieces, right? Because if we're gonna split, we need to have a really robust strategy for figuring out how to integrate them. And so we'll take a look a little bit about that today. That's what I mean when I say, uh, you know, we want to promote Web front end development and tooling as a first class citizen. Does that make sense to everyone? Any questions? Pretty straightforward. Let's talk about a couple of just basic training things before we get into the the actual code. So a lot of the tools that we're gonna be using and the ecosystem are built on top of node a CZ. Anyone in the room played around with node at all just a little bit. Um, and I was talking with some of the people here earlier about how note makes a lot of sense from a tooling standpoint, but I'm not sure it's quite there for production. APS. I know that there was a security vulnerability that just got released on. There was some controversy over that. Do you have a question there? James James? No, he's waving his hand at me. Um, so, uh, node makes a lot of sense to me from a tooling standpoint, because there's no inherent risk of security and things like that. So if you're having a hard time selling your organization on, should we invest effort and time into looking at know Js Um, it's a It's a way easier sell to me to say we're just gonna use it for our tooling stack. And there's nothing going into production, right? There's no there's no risk that this stuff is gonna get pushed somewhere. You know, our web servers are gonna go down. You're not using it for that. So the only slide I have on node is just mentioning how require works a node. And the reason this is important is because we're gonna be looking at some code that runs on node. But it's javascript, and this is a bit of ah, mental context shift for a lot of people because traditionally, there's that that differentiation between server side and clients that when I'm working in client side, I look at JavaScript and I think, Oh, this this runs in the browser. And so we now need to think while I'm looking at JavaScript and where does it run? So there's a little bit of extra mental juggling you have to do and then thinking about how node manages its dependencies. Um, this idea of using the require keyword and it's called node require. Basically, if you're familiar with client side management strategies like required Js, they also used to require keyword which is, in my opinion, somewhat unfortunate because it overloads the semantics of require, especially when they mean different things on the client server. Because on the client side, if I'm using required Js, sometimes that implies an asynchronous load. And on the server side in node land, there is no asynchronous load because it's just accessing things on the file system. And so they happen in order. So that's the only distinction I'd like to make a boat knowed as we go forward with the workshop. Let's talk a little bit about NPM and PM sends for node packaged modules. It's not note package manager, some people like to say, and N p. M. When you install knowed, you get NPM for free, And it's a command line tool that allows you to install and publish modules to the N. P. M repositories s So you can initialize the new module with this command and PM in it and then, like it says in this screen shot here, and PM will walk you through generating a package Jason file, which will look at it in a sec and the package. Jason is basically just the meta data definition for all of the dependencies and all of those things that go along with the package. If you want to pull up this in your browser's, this is a brilliant sort of walk through of all of the metadata fields in the package Jason file. So it's just packaged out, jayson dot know jitsu dot com. And I think the joint guys with this up joint is the parent company that bought the copyright. Um, to know Js from Ryan doll Who's the creator? Ah, and they've done a really good job of being good citizens in the open source community and done a lot of really good things for no to push to push it to where it's come from, where it came from. So this is what a typical package Jason looks like. Um, this is gonna look very similar to what we kind of end up with at the end of the day and the two pieces that I want to highlight our dependencies and deaf dependencies. These air metadata feels that if you're on the no jets lose sight there, you can kind of hover over it and get the description dependencies, our modules, things that, uh in Keum is gonna pull down from its repositories when I run in P m install that I need for my for my you know, tool. In this case, we're not publishing on artifact within P. M. We're gonna using package Jason just to manage dependencies for building our workflow with grunt and Deb dependencies. The only the reason for the delineation there is these are things that if I were to publish a module upto MPM I don't need those to go up there only for, you know, the development life cycle. So I mentioned NPM install. That's basically the command that you can run if you have dependencies and Deb dependencies in your package, Jason. So, for example, if somebody in your team checked out a project from whatever source control system you're using, they would get that package Jason, which would have dependencies and Deb dependencies. And when he ran in P. M. On there local machine, it would pull down all those dependencies. And there's a couple extra flags that we're gonna use today. I've got a step stop mark down file that's in the depository that as we walk through the commit history of the project. We're going thio abusing some of these commands. The only ones I wanted to highlight here are dash dash save. So when I n p m install whatever package. So, for example, if I m p m installed run and then I had dash dash save that will install grunt to my local node modules holder. And then it will also write to the package Jason so that I can push that up to my revision control system in the next person who pulls down, get get poles or updates the package and then runs him install again, we'll get that grant package pull down. Saved Dev does the same thing, but it just right Sentries to Deb dependencies.

Grunt
[Autogenerated] So let's talk a little bit about grunt. We're just gonna go through some slides to give a really brief overview. It's not gonna be exhausted because we're gonna cover a lot of the material that's in the slides more in depth as we dig into the code base so similar to N. P M. Which has a command line binary that you can run and PM grunt has a couple of different commands that you can run. The main one is grunt, but it's split into two packages, so the 1st 1 that you're gonna want to install is grunt Dash C ally. So if you have your machines open, you can issue this command and you'll get the grunts Eli installed, and we'll need this as we work through things today. I'll just leave it up there for a sec for people. Did anyone pre install grants? Eli, I don't think I had. It s part of the setup instructions. I purposely didn't put a few things into the instructions because I wanted us to go through them today. Um, the thing I've found with attending workshops like this is, uh, I'm very cognizant of the fact that it's easy to get lost in slides on DSO. I don't have a ton of slides. The majority of the day is really going to be spent in the code. And then that way you get hands on experience. You get the muscle memory of having to type the commands, which really helps to reinforce things so that when you leave, you don't just have, you know, big raft of slides to go through. You have, you know, muscle memory built in. Now I know how the workflow works. So the way Grant works is it splits into two pieces to logical pieces. There's the command line, which is sort of the runner on, and that's installed globally. When you add that Dasha chief leg with NPM install, it's gonna install it to the global name space, the global note modules, name space, and, uh, the other piece is a grunt file, and the grunt file is basically the set of configuration that we're gonna be digging into today and building that basically sort of defines all of the pieces of the workflow that drunk is going to execute when you call grunt from the command line, getting back to the idea of node modules you'll see at the top there online. One. We've got module dot exports and that is basically no, it's way of saying when somebody requires this grunt filed out J s. This is the thing that they're going to get back, which is a function that takes grunt as an argument. And so when you called grunt from the command line, it's going to look for a grant filed out J s. And then it will inject itself as the first argument the front run time. We'll dig into that a little bit more after Grunt is really good about supporting coffee script as well. And there was a really good article. I think it was by Tim Brandy in about how coffee script is actually the ideal format for configuration files. Because if we jump back thio this when you can see the you know it's just Jason. But the extra verbosity in having to write the commas and having trade the curlies is really cleaned up when we go to the coffee file. So we're gonna start when we build our app with, um, the jazz file, and then at some point, will flip over to the coffee fall so that you can see that transformation. But either is supported. So if you open a project secret file that, yes, we're grateful about coffee. Uh, you wouldn't have both, though, because I think that would just confuse things. So if we think of, um, work the idea of a workflow, what does it mean? It really means thinking of all of the discrete pieces of work that we need to do to get some sort of artifact produced at the end. And we were talking about a rich client application. Typically, the artifact is men. If I'd compressed JavaScript file one or more bundles, men ified compressed CSS file men ified compressed her optimized images, um, and then on HTML file and that stuff is probably gonna go sit on a public Web server somewhere, And that's what's gonna run. And so grunt breaks up its configuration into this idea of tasks. So in this example, we've got the clean task. We have a newer task, and we have a coffee task, and the order that those happened in is something that we control. So right now we're looking at the definition of these tasks and some targets, which will dig into a little bit later. But I just wanted to show, uh, what some task configuration looks like. You can also write your own tasks in Grant. This is an example of a little server task that we're gonna actually write today that will spin up a development server for us. And so when you look at register task on line three, that is grants way of saying this is just a one shot task. There's nothing repetitive about it. It's only gonna, you know, basically run through the sequence of events and then finish. There's also something called multi tasks so they can. Cat task, which we're gonna use today, is an example of a multi task and a multi task is one that has a single parent configuration node with multiple targets, and it will run for each one of those targets, and they're pretty useful to set up for a kind of drying up your configuration. If you want to run one task multiple times, here's some multi task targets, so the watch task is a multi task, and it has two targets I wanna watch coffee on. I wanna watch this thing that I'm calling app which files to watch and then which tasks to run. We're gonna dig into the watch task a little bit later and grunt also allows you to do a sink tasks because note is inherently asynchronous. You're gonna want Thio think about what your task is doing. In this case, this is the image modification task, and the reason it needs to be a sink is because it's gonna process him in image files with an external shell. Commend. And we need to wait until the process code returns from that in order for grants, control flow to continue s so that it knows when it's done, and it can continue on to the next task. The idea with the workflow is that we want to string together these tasks in sort of sequence. But some of them may be a sink, and some of them may be synchronised, but we still want that sequence toe to occur in the right order. And so grant allows us to do this with a sink, and you basically just call the done function whenever whenever your task is finished. And that's what allows growth grant to say, Okay, I'm gonna return to my control flow and continue on with the next tasks. And then finally, we get to the idea of work flows again. This is using register task, but registered task can be used to alias. And you can create, you know, a task in this case called Default. That is the sum of a list of tasks that are running that sequence. And so we're gonna run through this today. When you write your own custom tasks, you can load them from just the local file system. So in this case, way down there, there's a tasks folder with that server Js file inside, and we're gonna take a look at that. You can also load external tasks, something called grunt plug ins. And those come from M. P. M s O. When I when we do in km installed and install some grand plug ins a little bit later, you'll see that we're going to do that a bunch of times. And that just means that Grant is gonna look in this node Modules folder, which is the place where NPM stores things that installs by default. Um, so if I were to say require, you know, grant contract clean By default, MPM would go to node modules and try to resolve that dependency there. So low tasks loads custom tasks load MPM tasks Loads from in P. M. There's a couple of things that can get us up to speed with two types of initialize er's grant in it is another command line that you can just also command line tool that you can install. So if you do, NPM install front, innit, Dash G. This will give you the ability to initialize sort of project templates for Grant, and there's two of them that are sort of most commonly used. One is a grunt file when you just needed stub owed a new grand file for a project on and the other one is a grunt plug in, which will take a look. A little look at a little bit later, and you can check out grant Js dot com slash project. Dash scaffolding should just kind of see how that stuff is used. Basically, you just clone one of the templates. So the front innit? Grunt file or grant immigrant plug in. You stick them inside your home directory inside of a hidden folder called Grunt in It, Uh, and then when you run, grunt in it and say Great file, it automatically knows to pick up that template and inflate them. We'll show that a little bit later. I just wanted to show it to you now so that you have it in your head. That's a lot of stuff, like just a brief overview. Like I said, we covered tasks, multi tasks. We talked about the fact that you can use Js or coffee in grant files. It doesn't matter, grants Eli being the thing that you used to kick off a sequence of tasks grant in it for when you want to stubbled a new grand file, we're gonna plug in the idea of work flows using register tasked alias things that they'll run in sequence and then loading custom tasks from that tasks. Folder

Project Setup
[Autogenerated] anyone play team Fortress to it's double time. So did everyone check out the project directory? Cool. Did how many people pulled down the aliases that I sent in the pre installation instructions? You don't need them. The only one that's really useful is hissed because it gives you a nice sort of formatted list of all of the commits. And what we're gonna be doing is, uh, going back in time to beginning of this project and starting to work our way towards the head of master using something called get Girl. Um, and I put a link to get crawl. You don't have to use get crawl. You can always just run your get client of choice. I use get X, the row and Jay's get export. And you can also visualize that here. So if you like a gooey client, um, this might be something better and get X, you could just right click and say, check out, commit. I could do that here and now You can see I'm a head detached state of the Shaw that matches that commit. So does everybody have get sims dollars? Revokable down? You're starting. I'm assuming right from the beginning yet of your father. Are you saying get excellent, Get crawl through the same thing more? Uh, yeah, effectively. I mean, get X allows you to visualize the commit history with this gooey and then you can, like, right click and say Checco commit. So if that's easier for you, I'm gonna be doing the same thing with get crawl. And I've actually got a couple of aliases. This is my alias. Forget girl. I had some commented. Oh, ____. That. I was trying to get work with command line arguments, but I stuck it bash scripting so but this just runs get crawl, master. And so the way get crawl works It just says, whatever branch I'm on, Whatever show I'm on, I'm on income and go to the next one. So my little next alias when you see me typing that is just doing get Carl master. And then I also have one for previous Which does this get check out head care. Uh, what is that? Carrot, I think, um, one which basically goes back in history One. So those were just little aliases that I'm gonna use if you feel most comfortable using get X and a degree client. Yeah, you can just click on these commits right click. Say Checco commit. That's effectively. Gonna do the same thing. We could go back and forth in time. You have the wrong Yeah. So this get X is Rohan Jay's fork of get X, which you can grab at Rohan Jadot. Get have dot io slash Get next. Okay. He's done some nice improvements to the gooey that are different than the standard Get X. Your story? Yeah, from an ftm workflow. All right, so yep. So for people who haven't cloned it, just give me a sec to do that. Everyone on the Internet doing okay so far Looking good. Cool. Did you get the right get X installed? Yeah. Okay. We could just wait a second more. I got a decent clean up here, anyway, Um, one of the byproducts of sort of jumping back and forth in time through get is that files that existed at the head? If I go back in time, get councilman untracked files, and so I'm gonna actually just remove those. You won't have to do this if you're doing a fresh check out, but it's just something to be aware of. So if you do get status and you see like a bunch of contract files, it's because if we're going back in time, it doesn't delete those files from the disk, just something to be aware of. Um, And as we're going through, we're gonna be installing packages with N P. M. And then later with power. And the fact that those folders remain may cause problems. It shouldn't. But if it does, we can just remove those folders from the command line and then rerun and PM install and rerun Bauer install on. That'll get us to a clean state. And we've got a couple other tasks that we can use to kind of clean up the state of the file system in between. We're actually build that in grunt as we go through the project. So I'm just gonna get rid of node modules. Power modules. You guys don't have to do this, and I'm gonna get rid of dissed. I started to get X, but when I run it from the command line, it's not actually opening. There's an option. Yeah, drop down. If you go to get X sensate, enable terminal usage in the menu. Then you can open every from the life and how Oh, there's the option and give exit. So, yeah, right up here from the get go. And that will set up the right path and everything. Depending on your terminal, you may have to restart. Ah, I used terminal dot ap. Some people use I term. Um, there's a couple other ones, but it should just work because I think unable to release it makes it so that when I get axe here it opens. We'll see. Just CD and type X. Yeah. So what I use get export is, um, this is sort of a meta tooling point of view, but I use it for if I'm doing a bunch of work in get, uh I don't always want to commit because I don't know what I want to do. But sometimes I get, like, a whole bunch of files in this unstaged changes list on the left there, uh and then I go in to get X, and I sort of stage things logically so that I can tell a story with the commits as I'm going through. And really, that's kind of what I've tried to do with the history here. So, as you see, um, the history kind of really tells a story. We have the starting point and then all of the sequential steps that we're gonna go through a cz we build up this workflow with run, so if if you get stuck and you're wondering what step we're on Um so if you've checked out the starting point down here in get X or you can always do get hissed, uh, let me go back to Master Hissed is my alias. That basically gives you the sequential timeline just nicely formatted. The default one is get log, which kind of gives you a lot more information that then you want. Sometimes that's useful. But for a really sort of quick snapshot, you could go get ______ if you if you're using my aliases. And if you're not using my aliases, it's a really long, really long version of log. Make that bigger. So rather than typo that every time I want that for my eye just alias it to history, then it gives you the pretty format. With all of the date formatting sorted, all that kind of stuff and If there's multiple branch histories and everything, it'll actually format it kind of like get X is doing here with the branches appearing off to the side and everything, so that you get that nice visual of like when branches got merged back into the branch that you're on. So if we want to look at the earliest commit, we can just say get hissed and tail and then that bottom one there is the one that we're gonna check out. So the way that I would do that from the command line and it's just too pace that short shots they get check out and I'm in detached head State. That's kind of how you move around and get you can check out whatever show you want. Um, we're not gonna be working with branching. That's just a sort of get fundamentals are a bit beyond the scope. But if people have questions about this stuff, I'm more than happy to answer them. So if everyone is two thumbs up on that and is able to check that, I'm still helping someone get, uh, okay, we're not gonna jump too much further. The other thing. I'll make a note of is when I've done these workshops in the past. Sometimes people get so absorbed and wanting to keep up with what's going on on. I'm trying. I'll try and do my best to really pace it so that we keep everyone at the same level. But if you feel like you're just falling behind in everything, just remember we've got the video recording, so you can just sort of sit back and take it and really absorb instead of tryto keep up with everything. The muscle memory is important, but I think being able to see clearly what's happening instead of missing things if you're focusing on trying to get stuff done, But yeah, you know, as much as possible would be great to have everyone working with this. So now get crawl too to wear. Yeah. Um, So did you check out the instructions on get girl? Yep. Conceded my path. It's Did you make it? Executed was executed. Oops. So all I had to do with mine. Waas? Yeah, Just stick it, stick it in there Like the instructions. This bin directory in my home directory is on my path, so anything that I add in there is automatically available. It's inexcusable. Yeah, it's usually a path issue. Thanks for talking. No problem. I could be the rubber duck. Anyone heard of rubber doctor bugging? It's when you put a rubber duck on your desk and you have a problem that you can't figure out and you talk to the rubber duck and the active verbalizing. Your problem usually helps you figure out what the problem was, so it's rubber doctor bugging. It's also called teddy bearing. You can use any an inanimate object, basically, but it's just the active verbalizing it. That usually helps your brain kind of get out of its funk, so

Starting Point
[Autogenerated] So this is the starting point. We've got, um, basically static assets in this folder. We've got an index html Java script folder on images folder a CSS folder. That vendor One can go away, I think. No, the vendor one stays. So let's open up the index html. And take a look at the app that we're gonna be working with this. Anyone heard of this game? The banner saga. It's an indie studio. Uh, that put out this Kickstarter game, I think was like a year and 1/2 ago. And, uh, it's a cool strategy game. So if you're into chess and strategy games plus Vikings and just the cool factor, then check out the banner saga. So when I was thinking about what to use for this, uh, I remembered back I think I built this eight or nine months ago. Maybe, um and I used it a cz motivation to both, um learned how to write coffee script with backbone and then also had a red angular. So I wrote it in backbone first. And then I wrote it in angular. And so we're gonna do the reverse order. Today we're gonna view the AP pre constructed an angular on the point isn't to understand those frameworks. We might touch a little bit on some of the nuance of that stuff, but Mark in front of masters have some really great stuff courses on angular and backbone. I think that we're just recently done. So I'm gonna try and avoid touching on that because the purpose of this is to really look at, um, constructing this right thinking about if I'm working with an app like this that's existing in my server side framework, and I've got static assets. How do we sort of start slicing them all up and making them work? So the APP does really simple things. When you play the game, you can pick six units so you can click on these units and sort of a jump to the next available slot in the load out. And if I click X by hovering over and I click another unit and he'll go into the next available slot, so there's a little bit of logic under the hood. This is the angular version, and then there's two way data binding. So if I click on a unit, I get into the editing interface. And so I can, you know, go here and increase the stats for this unit. And you can see that as I'm doing that, um, her portrait up in the top there is also being updated. So that blue number and the bottom number or the black number which shows that told a number of staff points that I've allocated and this total number I have available How many gamers do we have here? I know you're a gamer. Yeah. So, um, the whole idea with this app was, you know, I want to think about replicating the load out construction tool that was in the game so that I could share these links with my friends and say, without them having to go into the game and say, This is my load. I just kicked ___ in this in this version and did a really good job. There's a couple of features not implemented in this angle. A version that are implemented in the backbone one there, just the ability to rank up. So if you click the rank up in this version, it won't work and reset to minimums. Doesn't work either. And so when we're all done. If you're interested in digging into angular on and, you know we dig into the background source, one of the sort of homework things you might want to do is jump back to this point in time and see, How would I? How would I implement those features inside of angular? Um, should be pretty straightforward, given the source. You get done editing and get back here. So that's it. And the thing that makes this se va ble there's no server side. This is entirely rich. Client up is I can hit command are and my load out stays the reason being, I'm actually encoding the entire load out Jason as base 64 in the URL and just storing it in the hash. Now that's pretty long. Um, any world of Warcraft players anyone know there was? Ah, there's a talent calculator for World of Warcraft that they were able to serialize all of the talents that you made for your character and like, you know, just a few random characters like this. And so my goal when designing this initially was to get it so that they would be really short, but I didn't get to that point and I tried to do some optimization. It was just like I screw it. I don't care. I'm gonna I'm gonna put that whole thing in the world. So that's the app that we're gonna be working with. Um, let's take a look at the source tree and see what it looks like. So if you open up the index HTML, you'll notice there's nothing crazy in here. This is probably a pretty typical dependency management strategy for front of naps. For a lot of people, right? They just stick script elements in the head, and they list in order the things that need to load properly. So in this case, Jake Worry is my first dependency than angular, and I know that when I load angular and it's Detective Jay Cory, it's going to use that for its internal systems, then underscore, which I use for functional stuff within the app that base 64 library that I used to encode the string on do a couple other manipulations. Extend is a library that add some sugar around, being able to define modules without using a module system, just using a name space on the global And then here's all the actual app dependencies, so you can see kind of the the AP domain, right? There's unit data. There's some translators. There's a couple directives for angular. There's a few controllers that control the state, the app and everything like that. Um, the important thing is not necessarily what the files are, but that this is the dependency management strategy that's being used in some cases, probably the majority of Web app. So I would say the majority of legacy of applications. The rest of the file is basically just angular, specific stuff. So we've got our NGF directive and then templates that sort of swap in and out. You'll notice that these pieces of mark up are stuck straight into the index html. And so one thing we'll take a look at a little bit later is does that make sense for a certain scale of app on how we can go about pre compiling those using run. So the other assets that we have in here we've got us a sheet just plain old CSS um, and this was actually generated from a pre processor. But I stuck it in here because I think when we're talking about management strategies for style, she eats a lot of people. Just use plain CSS pre processors are still something that isa bit opaque to. A lot of people don't understand the benefit and then because not a lot of legacy service side environments have really good support or at least didn't have really good support, I think it's becoming a lot better now. Um, people just wouldn't use them because they didn't know how to integrate it into their workflow. So we're gonna take a look at how to how to do that and then all the image assets and then those Js files and then the bender dependencies. That's all we're gonna look at in that committee. We go next or get crawl, master or open up, get X and check out the next position. And if you want to see, I've staged all of the commit messages so that when you do get log after we get to the next one, it'll be the top one on the list, and you can kind of see what we're gonna talk about in that section. And the reason I did this eyes for my own sanity because it's kind of like speaker notes for me and s so that when you go back and look at this stuff later, you can kind of replay this history and go through it and be like, Oh, yeah, this is what we did at this stuff. Um, a couple of commits from now. I also introduced a step stop mark down file, which is gonna have individual alternative steps that we need to do, like when we need to npm install where we need to power install, and I'll point that out when we get to it.

Working With Grunt
NPM Init and Grunt
[Autogenerated] So we've got a new file that appeared when we went to this one. Is anyone having trouble? I just wanna make sure everyone's able to get to the next commit. Okay, That's what this is, Master. No, this is not master Crawl. You can say get Get crawl, Master. Which means go to the next, commit on the way to head in Master, you just have to give it a branch that it knows which which tree to crawl basically. And if I go pre ve That's my little binding for it. So so, yeah, in Kim in it. So at this stage, we want to think about, uh, starting to sta. Vote that package, Jason, because we're gonna use package Jason and NPM for managing all the dependencies. So if we open that file up, you can see there's a few sort of basic pieces in here. Uh, what? The main is Grant filed out Js There's scripts, metadata element on how that works is if you have, uh, from the command line, you can type in P. M. And then the name of that key, so I could take 10 PM test and it would do that on, then an author and a license. Let's create that just so you can kind of get a sense for that. So if you go in P. M, if you just remove that package, Jason, and then do you N p m in it, it's gonna walk you through this little wizard on. If you just hit, enter through it, it'll go through the default. So what name do we want for this? Pactual called the workshop on what version following semantic version ing. I'm to jump over and show you that anyone not familiar with semantic version ing it's a good thing, toe know. Basically, it just means that there's a logical sequence that you increment your version numbers for packages so that people looking at them can understand whether it's safe to upgrade or not. So on the far end patch versions, I know that, for example, if our pat your fire version of our package was 0.0, not one and the author released 0.0 dot two, it would be safe for me to upgrade. If they release 0.1 dot two. That would indicate to me that there's a breaking a backwards compatibility breaking change, and I probably shouldn't update. That's all you need to know. Boats, semantic version ing. You should try and follow it when you're releasing your own packages. If you're gonna develop them a description. So this is the friend Masters Workshop. What entry point in this case, I am gonna put Grant file that GS because I know that that's gonna come in the next step. We don't need a test command. That's the git. Repositories are automatically detected It key words you can use if you're gonna publish your package to N. P. M. We're not gonna do that. So I'm just gonna hit enter. I'll put my name for the author, even put your name and the default licenses BSD I usually put m i t. Um just because that's the license I prefer. So on dhe, then what it does is it says all right, I've got this preview of what I'm gonna write. Do you want me to write it and we can see us? And now I have ah modified package, Jason. And if we open that, you can see that it got all the media. So when you're stepping out a new project. Probably gonna wanna npm, innit? To get started to say, Here's my bucket of metadata that's gonna describe this thing. And it's also the place that grunt I's gonna NPM is gonna install packages into any questions on that one entry point. Ah, so the entry point, um, the main if you require from the root directory, it's the file that will be exported via that require the node require It's not really needed. It's, I mean for this case because we're not gonna be requiring it on Grant by default. Just looks for a grandchild at JSC. Can't filed out coffee. So it's set up the convention to do that. Mane is purely for, um, letting other node modules know which file to export. And this becomes sort of more relevant when you get if you look at packages on get hub, for example, and you see like a lib directory, and maybe they have, like, a cli dot Js or something like that. It just allows you to like sub path to say this is the thing that I want you to start. This is the entry point, Um and so I think if we go next. Yeah, there we go. Now we can see a grunt file and there's nothing in it, and that's okay. Um so let's do there's gonna pull up my notes here, so we need to do a couple things. Now that we have packaged Jason, we need to install grunt. So let's do NPM install grunt, dash, dash save so that we could get it written to our package. Jason. And if you run that, it's gonna go off to the Internet and grab a bunch of things. And then if we look at our package Jason, you'll see that in the dependencies at the bottom. There, all this scroll this down so everyone can see it's stuck, the latest version of Grant in there. You can also define which version of a dependency you want to in start installed within PM So you can say in Kim installed grunt. I think it's at if we wanted, like 0.3 dot zero version. So that's just something to keep in mind if you have, like, a specific version you know, is the one that you want to use in your project. You could do that, and we already installed the C L I. Did everyone do that if you didn't MPM installed SG grants, Eli. Now this brings up an interesting point. You see, I got a permission error. I set up node on this environment in a bad way. I did it with sue. Do. And you shouldn't do that when you install note, because then it requires sue due to install of the user line packages. And really, none of those packages should have elevated privileges to be installed. So don't do what I did. But if you get that error, uh, then you'll need to do si do and take your password in. There's something to be aware of. There's a really good just, uh, that Isaac's. He's the guy who wrote in P m ise. It s on Twitter. He has unlike how to fix that if you've done that. And there's, like, a bunch of different ways to fix it with the permissions so I can give that as a resource at the end. All right, so we got our dependency. Let's go. Next. This modifies the gun file. Andi, think I already covered this in the slights will probably go next pretty fast. but yeah. Module dot exports The thing that's gonna be exported when no, it's required. Fix this up. A function that's gonna grant is going to inject itself as the first argument.

Gruntfile.js
[Autogenerated] Let's go next. And now we've got our steps dot MD file, which just came in. So if you're using your text editor and you have this file open as we keep going through, you'll get the next set of commands that we're gonna work through. And if at some point you have local modifications, you're gonna get a message like this, your local changes to the following files would be overwritten by check out. And so in this case, the reason is because I'm out If we modified package Jason. So to get by that, I'm just going to say, Get stash. And that just gets Dash basically is a temporary workspace that gets rid of that stuff. And if you want to see what's in the stash, he's a list. So I have a couple things in this dash. Um, So what I use the stash for is just sort of like a work in progress stuff that I'm not ready to commit. But if I want to switch between branches or whatever, I can just stash it, go switch, and then you can say, get stash pop. So if I wanted to get that back, you pop it out. That's just some get tooling stuff. So let's stash that again, and then let's go Next. And now we get into some more of the meat of building up our workflow, and you can see we got a couple more commands that showed up. We've already done Grunt and Grant See, Allied SG. So the next thing we're gonna want to do is make their tasks because we're gonna create. At some point, we're gonna create a, ah, local task, a custom test that we're gonna work with, and then we're gonna install Grant, contribute cat and save it. I'll put it in our package. Jason, here we go. We've also got some entries that showed up in the grand file because this is the first step of our workflow. So there's a couple things to point out here, um, one actually let me go back. One commit shoot. I thought I had stage something differently, but, um, when we're thinking about a workflow, especially when we're gonna be sort of doing compilation and unification and just sort of processing resources, there's this idea that we need some sort of temporary workspace to do that. So if you're used coming from other environments. There's like the idea of a dot temp folder or just some place that we're going to execute and put things on the file system. Because Grant is inherently about modifying files. That's basically what all the tasks do the access files, they manipulate them and twist them and change them and then combine them on and then sort of inject them into this workflow pipeline. So the 1st 1 that I'd like to point out is this idea of a generated folder. And so when I'm thinking of ah, place to stick things, that's just the best name that I can come up with. You can come up with whatever you want. There's no convention around this. It's basically just pick a name that's meaningful to you that indicates where you're gonna store sort of temporary ____. The other important thing to note is that if you check out the get ignore file which came in here, um, we've actually got a couple of entries because we don't want our workflow thio generate a bunch of artifacts and then check those into revision control, right? Those air, just parts of our workflow that are gonna lead to the end result artifact. I'm Technically, we probably aren't even gonna check in those artifacts that a result of our build process that we're gonna build because really, all we want in our source control system is the source definition for how to build the app and then our grunt file, which is sort of the tech, the tasks for how to build a wrap, the sources, what what the app is. And then we probably want to have some sort of continuous integration environment where we push all that stuff up on it, builds it, checks out from get, does the install, does the build process and then deploys onto our server. That's why we ignore this stuff on. We're preemptively ignoring the disc folder I'm generated is what I use to indicate sort of temporary working space stuff and then dissed is the compiled artifact that we're gonna push up to our production server. Neither of those we want to commit. Let's go back to the ground because there's quite a bit that happened here. And let's check out index dot html so you'll notice that I replaced all of those static vendor and AP bundles in index dot html with generated slash, Js slash app dot minn dot Js And so that is sort of, you know, I was thinking, What is this, some temporary dev time target that I want to deploy two. And it's, um, unified javascript file. Right? And the reason that we're moving that into sort of this configuration for the King cat task is so that, uh, if we add files, we can go here and add them. Um, it's really not changing it too much, right? Because the list of files is still the same. But now we've integrated as part of our bill task. When you're defining task configurations and grunt usually start with this root level node called the config. In some grant files, you'll just see Grant, innit? Config called. But what it's initializing is this, you know, sort of parent object that has the configuration and then the first that sort of first route nodes that come into that are the task configurations. And typically the name of that key matches the name of the task. And if we actually open up cap dot Js inside of node modules run contributing cat tasks catches if you're using sublime text, even command t and do this Well, whatever. I think text mate has committed command. He is well, there can't be. So if you look at that, you can see that it is a multi task. And if you remember, from the slides of multi task is something that can have multiple targets to generate over. Uh, and there's only one piece of convention you need to know about multi tasks. The name of the task, which is this first argument, has to match the key. And so multi tasks are sort of convention driven in that approach. Custom tasks, whatever. You know, whatever you build don't have to match the key. But I think it's generally probably a best practice just so that people don't get confused. And then the other important convention is that the file name right? Can cat dot Js matches as well, So there's some conventions around howto how to store those things, and then So this is the task. This is the target. And in our case, I think we only have one target in here. Yep, the AP target. And then there's multiple ways that you can tell grunt how to manage files. In this case, we're using something called the compact Definition. Typically, when you're thinking about grunt tasks, you're going to be working with files and you usually have an input and output. So a source and a destination in this case, I like to put the destination at the top son. It's clear to me, you know, where's this stuff going? Some people like to put the source of the top. This is just sort of stylistic, um, and then the source, which can be, ah, bunch of different things. In this case, it's an array of files. And so what grunt does is when it runs the can cat task. It goes and looks at all of the targets because this is a multi task. So in this case, it's gonna run APP. App is just something I picked. There's no convention around target names, but you should usually pick something that's meaningful. And in this case, I thought it was appropriate because it kind of represents all of the compiled dependencies for this project, um, rate. Oh, yeah. So there's a couple of different ways you can grab vials. One is listing them as an array of files. One is using filed lobbing, which will take a look at a little later. You can have single files on, and then you can also use a couple of different ways to access files. Um, that will take a look at. So let's try and run this by running grunt. So if you run that from your terminal, you'll see some output running. Can cat nap the logging in Grant the default. Logging is really good S o. The typical pattern is the task name and then the target catnap. And then what happened? Another really good thing to know about Grant is if you want to see exactly everything that happened, the verbose flag makes it really useful. So then this is useful when your debugging. So if you write a task and for example, it's not picking up a file that you're working with, you put the verbal swag on, and then you can kind of get into the guts of what went wrong. So if we go through this, we can see all the things that it's doing. So it read the grant file. That was okay. It initialized that config, which we can see her down in the bottom here. Um, it registered some tasks. So that's loading tasks from this tasks folder, which there are no tests yet, But we're gonna create some, um and then it loaded a bunch of in P m tasks in this case, just one grand contribute cat. And then we created the default task so that we don't have to type something after we run. Grunt. Then you can see all of the files that the King Cat Teske went and did and grants really good in the logging. It verifies that those files exist. So any time you're working with files, you can access them like that, make sure they all are there. I mean, if a file doesn't exist, it'll it'll continue. But it will probably give you a warning, and then you can see what happened. So if we look inside of generated Jess, there's are apt up men, and if we open that in this case, it's not modified. But I just called Adapt up men because, as you'll see later, I didn't wanna have to keep switching back between app dot Js and abduct. Mend it. Yes. When we wanted to test production versus development bundles. So this is basically just the contaminated source of all of our stuff, right? The vendor dependencies come first and our dependencies come second. So if you think about this is a dependency management strategy, it works. It's worked in the browser for however long browsers have been around. If you think about a rich client application at its base level is basically just the sum of its contaminated JavaScript files, Right? So, uh, I think a lot of people look at things like required Js or common Js or even the ECMO script six modules and think, What the heck? How am I gonna integrate this into my pipeline? And so the thing I'd say is, you know, practice pragmatism. If your project is small, you don't need require Js, right? If you have three javascript files that you're loading or you're building something, um, concatenation works pretty well as a dependency management strategy. When you start to scale up and you get a little bit bigger in scope, this project is, you know, probably right at the boundary of where I would split to say maybe there's more robust dependency management strategy that I would want to use, but in general, um, I don't think, uh, cat nation should be shied away from, uh and I don't think there should be, um, this pressure to say Well, we need to use required Js or we need to use common Js in our project. So if you're getting pressure from people, you know, tell them to practice pragmatism and really think about what they're doing. So this is the base template for what we're gonna do going forward. We're going to, you know, have some new task configuration. We're gonna install it in P m task. Or maybe we'll create a custom task. We're going to find some targets and a list of files that are input what the output is, where it's gonna go. We're going to tell grunt to initialize that configuration. And then we're gonna keep adding to this NPM tasks list until we get to a point in the process where it becomes really cumbersome and then we're gonna change it and go thio reduce that to eliminate the duplication. One more note on default. So default again is sort of grant convention for what to do if there's nothing else. If I wanted to change this, for example, too, um, you know, work flow. Now, if I run ground, it's gonna say or couldn't find a default task. So if you're doing that and you see, it means you haven't said a default test. But I can go grant for Cliff and at work so you can kind of see how that last piece where you define a list of tasks we only have one in our in our list, but that is basically essentially defining the workflow that we're gonna work with. See if I got all of the things on there, I think so. Let's go next.

Globs and CoffeeScript
[Autogenerated] Koncak clogs another useful get command. If you want to visualize, you can use get X to see the diff But you can just say get show and he'll actually show the diff between what happened the previous commit was and this committee So it's a good way to visualize kind of what we're doing. So one of the things that makes sense when you move to contamination as sort of figuring out the load order for this app is, um let's see if we can eliminate some of this duplication. And what I've done here is basically used glob ing. And so glob ing is using something under the hood called note glob. I mean, this is pretty core to command line and file system, so I've reduced all of those dependencies to one list inside of config. One list inside of data inside of directives, controllers and service is and then anything else. And so the reason this is kind of cool is because now, before, if I wanted to add a file to my project, I'd have to go and, you know, add it first to the index html in the head, stick it in the right spot for the Lord order. Uh, and now if I want to add ah, file to my project, I can just stick it in the folder and the gloves will pick it up automatically. So there's a little bit of automation that happens there, and it just reduces the amount of cognitive load right? This list of steps that you have to think of when you add a file this strategy works really well for frameworks that are opinionated about life cycle and modules, which angular is. The reason for that is, um, this is the briefest thing that I'm gonna touch a boat on. Angular. The only thing that angular needs as sort of its first dependency is the definition of the module. So in this case, this TBs dot battle planner N G. As long as that comes first, the order of any of the files that I load after don't matter. And the reason for that is angular actually waits until it's scanned the dom completely. It's done a compile phase, and then it has a bootstrap phase. When it says, Is everything ready as everything loaded? Am I ready to go? Then it kicks it off And the cool thing about that is, um if you're using angular, you don't need to use something like required Js. You can just be smart about how you can Cat Captain eight. Maybe you can make multiple bundles if you're worried about cashing and granularity and things like that, but you don't have to think about it. Um and this makes a lot of sense when we take a look at what the APP looks like in backbone. A little bit later, let's go next. Oh, yeah, I was just gonna demo that. So I added a new file in service is called New Service on because the club is set up to pick up files from service is when I run grunts and I opened Index, you can see there, the console log message came up, said I got picked up automatically. So that's sort of the rhythm that this gives you is, you know, I got a new file, I'd stick it in and do whatever, and the globs picked it up automatically. So just a little bit of automation to make sure that that goes a little smoother. Let's go next. That's just a clean up in the next again. And if you had grand file open dot Js open. You wanna close it because it's been overwritten with Grant filed out coffee and just gonna close these other things. So the coffee is a little bit tercer. Um, I just have to keep in mind that, uh, there's a couple of things. How many people are using coffee script? Yeah, one. It's not a really popular one or two. It's not a really popular language, and I don't know why it gets a pretty bad rap. And I think primarily the reason is I can only speak from my own experience. I was very anti coffee script until I was forced to use it on a project because the team actually decided to use it. And it wasn't till about three days of using it that it really kind of clicked for me. But probably one of the most useful tips for if you're wanting to investigate coffee script is setting up a workflow where you can use it. Uh, so developers don't have to think about it. Right? Um and we're gonna show how to do that. The other is a package control feature command, Um, that you can run so in sublime. If you have sublime, you can go command shift P and display coffee script. And this will select Compile the selected block of coffee scripted JavaScript. And so this is really easy to kind of a really good way to visualize, sort of what the difference is. I mean, the line endings air, the lines aren't the same, but you can kind of see the fundamental differences. Let me see if I can get them on the same line. There we go. You know, we don't have to have the Curly's. You don't have to have the brackets. It just cleans up a little bit. Thea noise in the file. So my preference actually, you know, I said I was anti coffee script has been to work with coffee script. Um, for most things that I do now, there's other things that I won't dive into. There's better resources on learning coffee script, but for config file, it makes a lot of sense. It just reduces the amount of noise. See if I can find that article. Yeah, it was Tim Branham. So if you want to read a really good article on this. He kind of makes the case for it here. If you're working in teams and you have people that are anti coffee scripts than get them to read this and maybe you could just, like, sort of sneak it in as a configuration file and then it'll sort of spread and infect itself throughout your application. No, it's it's definitely boosted my productivity.

Grunt Watch
[Autogenerated] So one thing that, um, sort of struck me as I was working through this is our workflow is pretty small, right? It's consists of grunt and Can cat. Every time we want to make a change, we have to rerun grunt. That's kind of annoying, right? Kind of _____ that we have toe do that. Luckily, there's a way for us to automate that, and it's Scranton trip watch. So if we go next and we check out what we've got here, you can see that there's a new task level and a target underneath called APP. The way that watch works. Um, actually, let's not forget to look at steps, don't want to grab this and install it, and he added it here to load it. And we also added it to our workflow. And this sort of gives you the first idea of what sequential Because we need to have watched start up because it's a long live process. It needs to be the last thing because it's gonna keep this process running and listen to the tow, the files that we watch for changes. There's a couple other features that I'd like to highlight. One is this percent syntax. This is a string interpolation. And the cool thing about grant config files is you could be self referential. So instead of duplicating, um, the fact that I wanted all of these in here, I can actually go and say, uh, grab whatever's incan cat dot after outsources stuff it in here. So this allows you to dry up your config files. We'll move it up so everyone can see it. Um, so that you can basically, you know, avoid having to create variables at the top of the file. And every time grunt runs, it will expand these, um, these interpolated strings and evaluate them against the config. At the current stage of running. There's some tasks that actually modify that configure it, run time. And so that's why it's important to understand that after you know the cat task around, if it modified it at runtime and watch how to target that, uh, interpolated value that it needed to figure out it would get the updated value. The exception to that is if the grim task is doing spawn. So if you're familiar with UNIX process model, if it's gonna spawn a child process, then it loses that context, so you would have to figure out a way to map it back. And some of the grant plug ins do that. It's now if we run, grunt, let's not run. Cat ran and we've got watching. It's just waiting there, right? And so this sort of forms the fundamental basis for our workflow. I'm gonna move this to the top of the screen on this till the bottom of the screen and what this does is it's gonna listen to any of those files for changes and then execute the compact task when that happens. So if we open up, for example, the upstate service and he put an alert, you could see that it changed. We get a nice time stamp that says, What What file changed? It re around the task, and we can see that that's working. And if we go and reload this guy in the browser, we'll see that later came up. Let's take a look at the watch task inside of node modules, Grant contribute watch tasks watch Um, and just a brief note on sort of the folder structure. This is Convention for grant Plug ins is typically to have a tasks directory that has the file, that little house sort of logic for that task. Some of these plug ins can get fairly large, and it's definitely probably best practice to split up on dhe, create multiple false small files. I have ah, really good recollection of my first discussion with my my buddy Justin from testable. And he said no project ever failed from creating too many small files, right? The projects, that failure, the ones that end up as these big monolithic things. So keep that in mind if you're gonna be creating grant plug ins, strive to really maintain small files. That being said, this one is on the largest side, like my sort of barometer for am I getting too large is like, Can I fit everything on one screen? I mean, I bumped up the font size here, but I'd ideally probably split this a little bit further. But there was. The reason I wanted to open this one is because there's a couple interesting things so we can see that they're the require system knows require system at work requiring in a couple of their dependencies gaze is ah, extracted dependency that I'm trying to remember it. Was it Sandra or sore hosts? I think he wrote. Good check. He's a pretty prolific Ono Shama Carl Robinson Young. Um, he's 1/4 grant contributor, and he's written quite a lot of Grant billions, but yeah, it's a small library that does clubbing f s dot watch. Um, So what? Pulling our dependencies again? Module dot Exports The thing that's gonna get exported when we require this the grunt run time is injected into here. Uh, and this task, we're not gonna dig into this too much, but it's using something called an event emitter in node because everything is running a sync by default. There's an event loop that happens. That's just listening for events. And so you can structure your tasks so that they will use event emitters on, and it's a really great way to decouple logic. And so now you know, there's an event that's emitted that start, and I can listen to it, and I'm gonna log some things I can listen to when it's ended. And I don't have to have all of that logic sort of nested in a sink in call back ____. So this is just one strategy to keep in mind when you're when you're architect in grant plug ins

CSS Preprocessors
[Autogenerated] so if you get if you get show, you can see all of my notes. My speaker notes, um, how many people are using a starship pre processor right now in their workflow. Which ones are you guys using? Assess. Everyone's using cess. Yeah, um, I'm gonna show you less because you already know sass. So that works out. Ah, I I opt for less purely for speed and the lack of a review dependency, especially because a lot of the tools that I work with have to support Windows. And Lennox is not an issue with ruby, but specifically windows and Ruby on windows is a real pain in the ___. So, um, I think it's good to look at other tools as well. And with the latest release of less, they're very close to feature parity. With sass on, you get the the speed benefits. I know this is more controversial for the designers that I work with. I don't know. There seems to be this religious attachment to assess that they can't shake. But, you know, it doesn't matter to me. What pre processor. You used. To be honest, the fact that you're using a pre processor is really good because I think most people aren't and there's a lot of benefits that we can get. Let's take a look at the grant file and we got a new task and a new target, and we also introduced this idea of options. Every task can have a top level key called options that you used to configure sort of global options for all the targets. You can also move that global options object down inside of each target. So if I wanted to, for example, override the AII compatibility flag for this, I could do that so I can have the parent one, and then the child target options will override that on this showcase is another way that we can tell grunt about our input output. This is a destination source mapping where the destination is the key and the source is the value. So this is another way that you can, you know, this is the compact way that you can tell Grant about what files operate on end, sort of where to stick the where to stick the output of it. Well, look at steps rate. This is another point I wanted to bring up. There will be times when you're working on a grunt work flow and you find that the plug in that you have maybe doesn't have the latest version of some dependency. And you want to, like, test out whether it's working. And so a really good strategy for doing that, um, is to just fork the project so you can see I just worked it from Grant. Contribute, lest the reason I did this was because when I was working on this a few things last week, Brunch contributes didn't have the latest version of the less compiler, which had a bunch of features that I wanted to showcase in this, uh and so, um, I have forked it. I updated the package, Jason, but you can see here I put it debated for a couple of days ago. They actually updated this anyway, so but I thought it would be a good discussion point just so that you know that you can plug, get ur Ellen here, and NPM installed will pull that dependency from get, So if you want to, like work with something that's not officially released or just like experiment with things you could do that. So that's what I did. I added it to package Jason, and then I ran in P m install. So let's run in P m install, and it should pull in that dependency from my get hub. And let's look at the file structure here. So now, instead of the style dot C s s, I have a stalled out last file and people that you saw. So I mean, it's gonna look very familiar, right? I've got one sort of main entry point for my pre processed stuff, and then I'm using at imports to import my mix and files. The mix ins are things that I'm using. There's a bunch of them in here. I think I pulled most of them from Bootstrap three's mix ins. Got less bootstrap. Three, actually, bootstrap. Since it it came out. It has supported less by default, so they have some really useful mix things that you can plug in. So let's take a look at this file. Um, because one of the benefits of implementing a pre processor is you can do things like base 64 encoded images in line in your style sheets. So if we go down Thio these guys, you can see that instead of the u R l property for background image. I'm using data dash your eye and what this does. This is a function that less calls that when it processes this, it will actually go and look for that file on the on the path encoded as base 64 then generate the right data. You are I string for the image. So if we run this now, there's, like, a whole whack of output. And the reason for that is, um and you're not Explorer nine and up. There's no size limitations on how big an image you can in line as base 64 encoded string. Uh, but, um, I e eight and lower have a limit of 32 k b. It's not an issue If you're, um, if your browser support matrix doesn't have to support, I eat. How many? How many people have to support I e eight? Yeah, it _____. It's kind of the last remaining outlier because I think I 89 is what Paul Irish classifies as an evergreen browser. Has anyone heard the term Evergreen browser? Basically, it means that it's a browser that auto updates. Right? So chrome is an evergreen browser because it transparently updates, and then you just kind of get a notification. It says, Oh, we we have to digitally this version. Um, the reason browser vendors are going to this model is to avoid the problem that we've seen with AII six and seven and eight and sort of the plague of all of these legacy browsers. So, um, this approach foreign lining can work for you if you're supporting aii eight, but just keep in mind that you're probably gonna want to not use it for images that are larger than 32 k B. Let's take a look at what this looks like in the browser. Did I leave my alert in there? I'm gonna get rid of that because that's gonna be in the way If you, um if you see a local modification, if you do get status and you wanna sort of revert because there's no revert and get you could just check out that file and that will check it out from the last known good for the last version from, um, the remote. Not that you get status. It'll be gone. And you could see that as I did that, the file changed and my watch picked it up. And after Minjae GS was created.

LESS Mixins
[Autogenerated] Let's take a look at a couple of things. Let's go to the network tab and Creme de Tools. And if you right click on the headers here, you can customize what headers you want to see. So in this case, I'm gonna get rid of time. When I wanted to see Time, which one did not want to see? I don't want to see Time Warner. What? I'm really interested in this size, because if you look at this style, she it's six megabytes, and that's definitely in. Probably not something that we want to ship to production. Um, if we take a look at the style she eats, uh, let's just go inspect an image. So now you can see normally where this would be a file path. It's the base 64 encoded version of that image, and that's what's causing our style sheet to balloon to almost six megabytes. There's two factors at play here, and there's some notes about sort of design Process. One is, uh, I didn't pre optimized these images actually extracted them from the Steam Maps folder in the game. I was on the forums and I talked to the developer and I was like, Hey, you have a fan site kit. Can I get these images? And he said, No, just go into the game and pull them out, and you can use them. But they're all like, super big PNG files s O. I didn't do any pre optimization. So if you're gonna be implementing a workflow like this four designers, it probably makes a lot more sense for smaller images like icons on. And where I work for, like this can really shine. How many people are using like sprites? Um, in their in their front and stuff. Sprites are a riel, uh, sort of improvement over manually loading images and having HDP request, reach each image. Uh, the thing that breaks down as a maintenance hassle because if you're doing a spread, you have to manage the offsets, right? Because the spread is basically just, um, you know, a tiny sliding window that's moving across one image, so you save on HDTV requests, But you kind of the tradeoff is that then you have a maintenance headache because now that the designer has to go in and tweak the offset values for left and right to move that window to the right icon. Um, that's handled somewhat by things like Compass, right, because it handles generating the sprites automatically, and you kind of just define things. Semantically is column Rohan COLUMN. But even still having Thio having to do that and then look and debug the output CSS is kind of a hassle. So the workflow that we just actually implemented at Shopify for the admin interface has been to in line all of the icon files into the style sheet, so they're like tiny little files. But then the advantage is that, um, the designers can go and use things like SPG. There's a great task that will actually take SPG and in line it as, ah, data imaged slash spg. If you see here the, uh, that part so then you get the ability to, you know, whatever your image format is, you can in line it as base 64 encoded, and SPG is great because then you don't need to have a retina already. Images right, like if you're developing for mobile, you have to have Eiko icon, and the pattern has been like to X or whatever. You have to have the multi resolution. So it doesn't look all grainy on the retina device with SPG that goes away and we'll take a look a little bit later at, uh, how that work for kind of works and how we can sort of add an optimization step to this process. But yeah, definitely. You know, the point of this was to showcase how you would get something like this to work and data. You're I in Unless I think what is compass have in line image? Is that the one that they use? I'm pretty sure we're made. That's the rails Asset Helper. No, no, no. I'm pretty sure it's a compass one, but there's an equivalent thing in in SAS. So if you want to do this since s, uh, you're not left out. The other nice thing about using a pre processor is mix ins. So now we can generate ingredients, started using this man to mix and syntax. This is less is mixing syntax. Nesting is really nice, too, so we can sort of semantically nest things and the output CSS will match that. And there's a bunch of repetition that we don't have to have for the pre processors And then there was one other thing I just wanted to show how I generated the Yeah, here we go. So you look at the bottom of the file. Um, right here I created a couple functions for so that I could drive this up because I wanted to generate, um be able to stick the name of the character on and then that have have that determine which background image showed up. And so I created this mix in or this function called based character portrait and then passing in may have overloaded the semantics of class. This is not the HTML class attributes. This is the character class in the game. So sorry about that. But yeah, So I want to say, like, dark character dot class and then assign the right portrait and all of the image files in my image folder kind of match that So here's my ranks. Here's my portrait ce So you can see that if you know, for example, back biter was pulled in there than the Oakwood CSS is gonna have dot character dot back biter portrait data. You are I was going in line the right one. And if we look at the you can see that has those two classes character and Bo master in the class attributes so that the portrait, um, gets the rate output. So this is kind of interesting because she s s didn't start as a programming language, right? But I'm kind of taking programming and functional principles and applying it. And, um, this rubs a lot of designers the wrong way, but I think it's more just one opportunity to educate people about how to reduce repetition in your code and just how to make things a little bit more maintainable. Because now, if I wanted to, you know, update this and add a new class, all that have to do is go down to the bottom here, and, you know, um, ways. The way these air split is there's a parent class, so there's a warrior and then warhawk, war leader and war master. Those are all warriors. They'll have their own associated images. But there's a parent class. So if I wanted at a new one, for example, you know my workflow would be toe create the image file, stick it in the images folder, duplicate this line, and, you know if he was called war duty or whatever, I could stick it in there. And then my build process picks that up in lines. The image. I may be modified template, but there's a whole bunch of things I didn't have to think about right. Really cool. A cool way to automate stuff. Thinking of CSS as more than just a presentation and figuring out how you can automate repetitive, repetitive tasks, I guess is the point that I'm going for there.

LESS Watch Tasks
[Autogenerated] so, yeah, pre processors. That kind of finishes off that section. But our workflow is missing a few pieces. Thio continue sort of the the automation that we want. Right now, we only have watches set up for, um, the contaminated javascript sources. We don't have a watch set up for, um, redoing the less files because we want to apply that same level of automation to our style. She files, Let's do that, kill your grunt and go next, or get crawl or check it out and get X. And I'll just leave this up because Mark was mentioning during the break that it's good to see where we were and where we're going. Um, so you can see previously were gun control less and all those notes, and the next one is we're gonna be figuring out how to watch those files for changes and using a slightly different format for the config. So the only real change here again, we're in the watch task in the less target. And the reason I keep enunciating that are over in unseating the task and the target is just because it's easy to get mixed up on the terminology and again. We're using a placeholder or a template string so that we can interpret it. Run time. And we don't have to repeat the definition for our less files. So we're gonna go into the less task access the Dev Target and grab the source key, which corresponds to our style dot last while in our, um, workflow at the bottom hasn't really changed, right? We're just doing less first, then can cat then watch. So now, if we run Grant, everything worked. And if I make this go to the bottom of the screen and this guy go to the top just so we can see if we edit that file for a change. There we go. It did the re compilation on Dhe said all of those warnings, vote images. We're gonna fix that later on. But I left it till later, Um, for optimizing those images. Rather, let's go back to the grunt file. Collapsed The innit config didn't go anywhere. I just collapsed in sublime so that we can take a look at this thing. Go back to the terminal And there was a note that I wanted to talk about here. So when I was talking about being meaningful with your target names. Um, I thought, you know, as I'm adding, these watch things that doesn't really make sense. It's really just JavaScript code that I was interested in. Um and so I changed the key name from after Jess. Just tow encapsulate that a little bit better. And now when I read the watch targets, it makes sense right there based on the type of file as opposed to some other domain level property. The other thing I changed was I went from that compact style where I had the destination as the key and the source as the value and I went to explicit with source and best. Um, and I found that this style is much easier for people to read just because it's explicit. And people often get confused when they look at the other style and they forget which one is the. I mean, if you read it, you think about it, but it just takes that extra little second when you're building it when you're reading it for your brain to kind of think, which one is the input in which ones that will put. So I just like to be explicit with that at the bottom

Grunt Documentation
[Autogenerated] Let's go take a really quick tour. Did someone have a question? Make sure I didn't override. Let's go to grant Js dot com. Um, because the grunt team did a really good job on the documentation. And as we've been looking at sort of the different ways that you can define input and output source, desk map, ings, they have probably the best resource on that. So we go to documentation. And it's one of those things developers don't like to read documentation, right? But the grant documentation is really easy to read. Uh, and it's short. So my recommendation is to spend some time just kind of going through it, even the migration guides and thinking about those things, because then you can kind of get the history of where things came from, especially if you're going to be working on a team where they maybe had a grant. Workflow, set up in 0.30 dot four is the current stable release, and there's some pretty strong, significant differences between 0.3 and 04 So reading the migration guide would would help you be better prepared if you went to a project where they were using that. So they walk you through the ground file gets in configuring tasks. Yeah, so they define it as source destination filed wrappings. And there's a couple of different ways that you can access files using that. So the compact format, um, so you can have a single source destination for mapping for target. Um, and they say it's only are typically used for read only tasks like Js hint where you're only you're not modifying any of the files, you're just consuming them to generate some sort of report. Grant. Contribute Yes. Hint is useful when you have a lot of JavaScript in your project, and especially if I ate is, ah, support concern or any of the Internet Explorer's, where a single trailing comma can cause your script to generate an error. So that's a task that you could add to your to your build that would validate that you're JavaScript is is passing jazz hands. Jazz hint. Um is a little bit more friendly version of Douglas Crawford's Just Lint, Uh, and a little bit more customizable. So that's the compact format. So if we have the Js hint task and the food target, um you know, and I and I only need source. I could do that here and source desk. So this is the compact format. Then there's an explicit files object format. So I've got the can cap task here, and I'm looking at my food target. And then I have this key files. And if you have that key in your task configuration that will clue grunt in to say that. Okay, you've got a couple of different ways or a couple of different key value map ings that map to destination source that it's gonna generate over in process. And then there's an array format. So in the above example, Files is an object literal with key and value in the array. Example. I'm gonna try and get them both on the screen at the same time, but I don't think I can, um, it's an array of object liberals with source destination map ings, and so gives you grunt gives you a couple of different ways to slice the concern of how to get the files you want. And what sort of discrete targets makes sense for this? Um, what discreet file input output map ings makes sense for this target and there's a little note on legacy formats, and I think this was from Grant 0.3, but they yeah, they've deprecate it and they don't want you to use it.

Splitting Concerns and Using Copy
[Autogenerated] sure I don't have any UN stage changes and let's go on to the next commit. So I didn't see this when I was rehearsing, but I guess this is the sheet commit because it starts with B A. That's my attempt at humor. I'm not very good at it. Let's do get show and see what we've got. One of the things that I see a lot of, um, complaints about grunt files is that they grow to be these unmanageable things, that it's very hard to understand. What is the task configuration and what is the list of files? And so a strategy that I've employed and that will take a look a little bit later at with Linemen is splitting those concerns of what files my tasks are going to use, Um, and then the configuration for those tasks. And so that's what this commit does, uh, wth e kind of rule about the grunt configures that there aren't really any rules. Aside from, um, the convention, if you're defining your task configuration so you can add whatever keys you want to the grand config that makes sense to you. And so what I've done here is I've added a files config to encapsulate that concern of where you know, these are the specific paths to the files. And then this will allow me to use those as variables for the string interpolation when grant expands those inside of the config. So our tests are going to use the files, they're going to use less files. Um, and here's the source of those less files. The only one that I care about their It's gonna use some Js files. And here's the source for those. And now if we go down, we can see that I've sort of split this as the first block of the CONFIG file is what files and the second after lion 28 here is the tasks, and then the configuration for those is a little bit cleaner because they just reference into the files. So now I can look at the cat task and I can say, Oh, it's using files dot Js that source. Um, you might argue that this this adds a little bit of cognitive overhead, but I really think that the separation makes a lot of sense, especially when you get into ah project with many lists of files. There's another really good article on decomposing grant files into sort of smaller buckets and having combinations of grant files. Uh, and I'll provide Mark with a link to that at the end, but it's a good read. But for our purposes, the first level of separation of concerns is, you know, let's make a little files bucket and then our tasks. Convicts can reference that. So now we have filed start just outsourcing the watch task and sort of there's this pattern that's repeated and predictable when people are coming to work with our grand files. So let's go to the next, leaving the sheep onto 7 11 get show. So in this commit, we're gonna add a task called Grant Can Trip copy. So if we think of our workflow, uh, with these temporary storage locations the generated folder and the distribution folder which we haven't added yet generated being for Dev distribution being for production build artifacts um, we have this problem right now in our index dot html if you open it up. Actually, I think I changed it earlier. But at the beginning it was referencing that that build time artifact has generated and that's not something we want our production code to have to do, right? That should be a configuration of our build process. So I had changed that a previous ah, few previous a few commits back and just forgot to mention it. But what we want to do with copy is sort of start setting up our workflow so that when we are running a development, it's going to mirror what is gonna happen in production. So right now, it doesn't really make sense because we're opening a static file that's not being served from a Web server, right? We're just opening index dot html on DSO. What we want to do is start shifting our workflow so that we can get to the point where we can add that server task which we're gonna do next. And so the first thing we want to do is grant can trip copy. So if we look in steps, you can see that you have a new command that we need to insult. So you can grab that command from 9 11 and we'll just do that. And if we just gonna clean up my workspace here a little bit now, If we run Grant there, you can see that the copy task ran. It's gonna move this down so everyone can see it in a copied one file. And again, if we want to verify what's happening with that, we could do that in two ways. We can actually just go into generated and see that it's there. Um, we can also, if you remember, run Grant with the verbose flag and see all of the files that it's watching for change is way at the bottom. But then you can see what it copied. So copy that index file into there, and there's a couple options that were set. This is actually another way to visualize what options are set on the task. Um, when you're working with planes, the best place to find them. It's probably back on grant jazz dot com, and if you go to plug ins, there's, ah, big list of them. But the ones that, um, we're using here are all in the contribute package. Uh, where did that start? Go? There we go. Show can trip Logan's first. So if you're sort of figuring out uh, a workflow and you're not sure about the quality of some random grant plugin out there on the Net. There's two primary metrics I used to determine the quality. One. How many stars does it have on get Hub, which is sometimes not the greatest metric? Because, you know, maybe somebody just created a plug in that a lot of people thought were cool and cargo cult it into popularity. Um, the other, probably more important metric is the number of open issues on Get Hub and, uh, how active the maintainer is. So like when the last commit buzz on by even just would go in and look at the quality of the commit messages. But that's for like, vetting plug ins that aren't part of contribute anything that's part of contributors been vetted by Ben Allman or Kyle Robinson Young or people that are part of the Grand court team. And so those plug ins are, for the most part, probably safe to introduce to your workflow. They have unit tests. They're covered very well, and they're used in a lot of places. So if you're looking for sort of ah ah, well groomed list of things you can start by looking at the contribute on grant yes dot com. And then if we go to, let's see if we can find copy, there's copy ________ links to the N. P M. Page. Actually, there's an easier way to get to this. That makes sense. And the whole thing that started me on this was looking at the options. And, um, it seems like, you know, I don't wanna have to run Grant with for both flag to sort of discover what the options of this thing are. And then at a higher level, how do I discover what the's plug ins are? And so there's a couple commands that are really useful, actually, in N P. M. If you do NPM repo and then you say, for example, if I wanted Toa look at the repositories for Grant Country a copy that'll actually open your browser to that repo. So that's pretty pretty much the fastest way to get to the documentation for those things. Um, I don't actually know why they linked to N P m Js, because if you look, it does have a copy of the docks. But I find get have just more consumable, especially because it's easier to browse the source and, uh, one of, um my my coworkers. His name's Kevin bearable his ah, his best piece of advice to me when I was stuck on a problem about looking for documentation was Just go look at the source, right? We have the source code available to us as developers. So often it's easier to just look at the source and see what's going on instead of the docks. But mpm repo is a great way to get to something. NPM search is another tool that sometimes useful. So if I wanted to search for something that did grunt and like SPG, I think I could do that. And this will search the package Jason for the keywords meta field. So if you're creating a plug in and you add appropriate keywords, then will show up in this list of results. So there's the one that I was looking for. A Grant spg Eamon down at the bottom there, Um, but just sort of a word of advice to put meaningful key names in your keywords metadata so that you can get discover ability because lots of people search for stuff like this on NPM

Custom Server Tasks
[Autogenerated] back to copy. So we set up our, um, first step and setting up our generated to basically be, um, a folder that we're going to serve from to mirror what our production environment is gonna look like in development. And so the next step, we're gonna take this to write that server task, which is a custom task. So if we go back here and go next, I can't think of any clever names for this commit shop, so I won't even try. And you can see some hints of where we're gonna go if you check out the gate log or get show, so I'll leave this up here. Um, so far, what we've been doing is integrating grant plug ins, and those have a certain AP I imposed on us that match a certain set of conventions, right? Like, um, there's, uh, the files object that you can have for your targets to configure which files work. There's the options object. Those were all sort of mandated by grunt. But there's nothing to stop us from building our own convention when we build our own tasks on. And that's what we're gonna do here. And you can see at the very bottom. Right here. Um, we jam server as the step right before watch. So we're actually gonna kick off a static Web server s so that we don't have to open that index html page anymore. Let's go take a look at what that server task looks like. Um, because this is basically a convention we established. Base is the directory that I want the static Web server to serve out of which is that generated directory where I'm putting all of my development assets. And now that we had a copy of the index, HTML is gonna be there and then Webb port just so that that's customizable if you wanted to run on a different port than 8000. So if you open up tasks and server dot Yes, What kind of go through this? I kind of deleted everything so that we can just go through it line by line instead of having toe look at the whole thing. So we called register task with the grunt run time that was injected and that basically takes two arguments. Three arguments. The 1st 1 is the name of the task. And then the 2nd 1 is description. Um, and the description is actually used when you go grunt dash, dash help so we can see a list of the available tasks S O This is useful when you go to, um, it grant Ah, project that's using grunt for the first time. And you want to really quick snapshot of the tasks you can just do Grant dash, dash help and you'll see the list of available tasks. And if people have used meaningful descriptions for their task names, then it's easy to ascertain what that thing is gonna do. So back to the server task. So we want to serve up, um, static assets basically from the generated directory. And the easiest way to do that is using something called Express. And we can pull that in by saying require express. And we'll need to go install that, um so we can just say in Yemen's ext. All express. Just gonna keep that at the top so people can see the command. So if everyone does that, it will pull down, express into your node modules holder so that when that require works, it can pull in the rate dependency, and you can see when it finished. If it was successful, it lists what version of the dependency it installed because I didn't define aversion when I didn't pay him. Install and ah, dependency, a graph that shows sort of transitive dependencies that are used by this thing. So in this case, not all of these have transitive dependencies, transitive just meaning dependencies on dependencies. So, for example, the send module has a dependency on mime at 1 to 11. So inside the sand folder, there would be a node modules folder with this, so that when send requires mime, then it would resolve that properly. So those nested node modules folders are basically the way that MPM structures dependencies. In this connect, one at the bottom has a bunch of extra transitive dependencies. So now we can require express and express is anyone use Sinatra? Um, for if you're doing Ruby development, it's basically the simplest Web server that you could get in node. Actually, that's not true. Note Has the http module built in? And if you go to the the no jazz home page and look at the example that is the simplest Web server, you can get a note um, express just adds a little bit of sugar on top of the core http and connect libraries on gives us some middle where we're not going to use too much of the middle, where because the server task is really simple. And all we really needed to do is open a Web server and serve the static assets. Right? Because that's as faras our app is concerned. That's what the production environment is going to do for this out. So I'm going to find the options, and this is a way that you can access options from the config inside of your tasks. So we had that web port option. Let me just split and pull this to the bottom. Is the Is this split? Okay? Or you guys prefer the the left and right split. I was thinking for readability. Let me try the left and right, Split. Here we go. Then. I can just shrink this a little bit because we don't need all of that there. So this is a kn attributes of the config that I want to access in my task to determine how I'm gonna start the Web server and so I can do that by calling Brent dot config dot get and it accesses. Ah kee path And it will actually traverse this key path inside of the config so you can see that server dot web dot port matches to that. And what I've done here is, if the user doesn't provide a server dot web dot port, I'm just gonna give a default one. This is a pretty common pattern that you'll see it in grunt plug ins just because the easiest way to get up on running often with them is to include the root level config for the task. Um, and it's nice if you could get out of the box running with with no options. So that's how you can provide defaults. Same with the Web root where we want to serve the the content out of. And in this case, I defaulted it to dist. But we're overriding that with generated because I want to do that here. Later on, we have a workflow that we're gonna build called the Production Simulator that doesn't do too much more, but basically will serve out of that other directory and compress assets on do all the things that you would see on production, but you'd be able to run them locally, so we'll talk a little bit more about that when we get there.

Finishing the Custom Task
[Autogenerated] one question John had waas is no useful toe front end. Uh, even if you're not using it as a server? Yep. Like so. I mean, obviously grand you can Do you know, Captain Ating JavaScript and columns left that kind of stuff, But what other kind of things are Is it useful for front end for for I don't know. I would say it's good. It's a good skill just to know, because you're probably gonna encounter it, especially if you're working with Grant because Grant runs on note right under the hood note is the engine that's running all the tasks grunt just sips has sort of an abstraction on top of it. So it definitely benefits front of developers, understand, like nodes require system and how modules workin dependencies and things like that. I know that seems more like, uh, an op C thing, but I'm coming from this at the point. Are coming at this from the point of being a friend and engineering being a disciplined right. Like we talked about front and developers and we talk about designers. Um, and I think that there's a lot more crossover between those two lately, but really engineering is like, you know, this whole core idea of taking things and figure out how to integrate. You know, a lot of what we do as friend and engineers is develop these work clothes and figure out how to integrate them, because there's certain constraints that air imposed on us by the server side environments that were in whether on Java or Ruby. Um, you know, the best example I can think of is the stuff. I just did it Shopify recently where if I didn't understand node, I wouldn't have understood how to write the grant tasks that I needed to do because a lot of grunt tasks used. Notes Cory P. I's like F s. If I want to read a file, you could do grant dot file that read. But under the hood that's using F s, which is the core node, a p I for accessing the file system. So I think, uh, I think it's it's definitely useful to know, especially if you want to be building your own custom tasks. That being said, you could probably get away with not knowing it, like if you just wanted to sort of skim the surface if all you did was integrate grant contract plug ins and just use stuff that was already out there. But if you want to do any kind of customization and write your own tasks, uh, which you will be at a certain level of complexity, that I think it's valuable to know. So the other recent question chat, which already kind of field but was asking about Is it possible to pass in arguments like court number from the command line, which I appointed? Democrats got options for that, Yes, yeah, and then I kind of made a statement that I loved actually back up with you, which is, I said, But it's not that common from what I've ever seen. Usually you have it all in Yeah, in this in this workflow. I don't do that, but I can show some examples of tasks where you can do that. What we do do is actually take the value of an environment variable and use that inside of our task. I mean, that is something that can either exist in your bash profile or from the command line. So, um, that might answer that question one way grant dot option is the other way that you would want to do that, but I agree it's definitely not common. The one thing you can do is we go back to the front file. You can see that, Um, we've got the default task. Let me bring this up so everyone can see it, which is our list of tasks. And when you run grunt, it's gonna look for that default task and run it by default. If you want to sort of debug your task configuration, you can do it with Lobos. But sometimes it's helpful to isolate to a specific unit, and you can do that from the command line. So if I wanted to just run can Cat Um, I can do that by saying Drunken Cat. And then if I have a task with multiple targets like watch, for example, it's the only one that we have that really makes sense right now. Um, I could do grant watch, but I can also access that target specifically by just put in Colin in between. So that's one way you can sort of control grant from the command line. If you wanted to have an option by like, say, watch Dash P and use a certain point. Then that's where you can use grunt dot option. So I think what you said is probably right on. I don't see a lot of grant tasks with, um, with options that you would use from the command line, because the reason being, if you think about it, the workflow that set up is such that it's typically one command that a user has to run. And then there's this whole list of tasks that get kicked off. Um, I had to make certain customization is to the workflow we did at Shopify because not every Ruby developer wanted to use on alternate asset compilation workflow. So we actually set environment variable in, um, inside of a rake task that says, If this environment variable is set, then you can kick off the asset compilation using grunt in line with the ruby stuff. But if you have it set too false than a dozen, and my preferred workflow is to manage my own asset compilation and not have the open inter leaved with with the rail server, because then I can see if a compilation failure happens in the grunt side. Um and it's not interwoven with the rail, several put. But a lot of service I developers just didn't care. They just didn't want their workflow interrupted. So that's a good point. Like when you're integrating this stuff into an organization, Um, there's gonna be the ideal approach that as a friend and developer you wantto work with, and then there's gonna be the realistic approach. And the realistic approach is probably gonna involve a lot more work because you're gonna have to make concessions or compromises to keep everyone happy. As you introduce workflow changes like this in your organization, it can have pushback. People just don't like change. People are resistant to that naturally. So I would say, you know, get by in talk to all the people who are making decisions about this stuff and then just really walk through what the impact your work flow changes we're gonna have and try really hard toe make it have a minimal impact on people so that they can keep working the way they want. If they don't need to use grunt or need to use the front and workflow, and then the people that want to can have the power in the flexibility to do it further on to that question. This is this probably as deep into notas we're going to get with this static Web server, and it's very simple. I mean, we're almost done here. Um, let me go back online. So line eight, where we're setting up at Equals Express. That's basically just saying creating a new app Instance. Uh and then the sort of guts that we need to simulate our serving environment is to serve up static assets. And there's a couple of things that I'll deconstruct here. One is this middleware called express dot static, which basically looks at all of the files in a specific folder. It'll analyze the files to serve up the correct in Miami types so that the browser doesn't think you're serving up text when you're serving up C. S s. So it just kind of takes care of that for us. If we weren't using express and we were doing it with connecting http at the lower level, we would have to do all that stuff like add manually the mind types that we wanted to support everything s o. This expresses a nice little abstraction around that process dot cwd is basically just the current working directory when we execute this command. So because we're executing grunt in this directory, that will be the value of process, dot current working directory and slash Web root. Is that configuration attribute we set which comes from base? Maybe I should have called it Webroot in here, taking my own advice on making things align with how they work in the task. I wanna keep it as a base for now, though, so that will serve our static assets. Uh, there's another middle where that express does for error handling. So if there's a problem in configuration, we can see it. Then we tell the app to listen on that web port. So 8000 by default, and then we can give some sort of useful indication that our task actually completed. Um, was there another question mark? No, uh, so we can use grunt out log, too. Do that. And then I'm returning the app in case we wanted to add any additional behavior after to the app, which is something we'll take a look at n lineman server task, which does quite a bit more than this, and it also enables a bit of a different workflow front. That log has a couple of other methods that are useful. So you could do not warren dot error. I think there's a dot Okay, as well. Which is just gives you a green message on the console so you can mix and match those as you're writing your tasks toe to see. All right, that was a lot of talking. Let's see if it actually works. So we ran Grant. Sorry, I'm gonna do that again. In case people missed it, Went back to the terminal ran Grant with our new configuration. If you get an error message, just make sure that you followed the step that we're on in steps dot MD Ah, you know what? Actually, this was the one step that I missed from putting into steps at MD. And I ran into this last night when I was rehearsing, but so you'll want to in p m install express, I think another it iss. Yeah, and I saved it as a deaf dependency, but it's not in there right now. Not your way. Anyway, if you run Grant, you should have a server running on Port 8000. Now, if you go to your browser, we got a local host. 8000. Hey, we have a Web server running, and now this is a lot closer to emulating what our production environment is gonna be, which is some Web server that's running this somewhere. Just look at our network toe. Make sure it loaded all the resources properly. Yep, there's no cash header set by default. So crumbs, I'm not gonna cash things. Hopefully. Actually, no, it will. It got a three or four not modified in the status quo there. We could probably write something that would cash bust for us automatically if we're in development. Um, I didn't write that in because my muscle memory is so bound to command shift our whenever I reload a page that I just I don't even care about cash busting anymore. At least not in development in product makes a lot of sense from a performance standpoint, but you can also do that if you hold shift and hit the reload button and then the status code and Crime Dept. Tools should change to two hundreds instead of three or four. Not modifieds. We still have that gargantuan six megabytes CSS file that we will fix shrink down a little bit later

Using Express Compress
[Autogenerated] let's go to the next commit and the commit log should look like this. The first line should say app that use expressed a compress. One of the nice things about this workflow. Um and you can see the line that we added there in the server, Uh, is that when I've been developing in this manner, I've been really striving to set up my development workflow such that it mirrors prod as closely as possible without all the headaches. And the reason for that is, if you think about work flows where, for example, we would load up all the individual files. Um, think about rails, for example, by default in the network tab, it doesn't compress assets by default. You get un compressed assets and you see on HTV request for each individual asset that's coming back from this rockets bundle, right? Um, that's okay, But the problem that I've encountered is it doesn't accurately reflect what's gonna happen in pride in Prague. There's gonna be squished into one bundle or maybe a couple of different bundles. And so what I found is moving away from that and going to a method where you serve up a single unified bundle in development. Um, gets rid of a whole class of bugs. Basically, you're integrating earlier, right? You're not waiting until the production build step to figure out if there's gonna be errors introduced by the cat nation step, which there can be depending on what libraries you're integrating. And so, as a developer, I would want to know that a lot sooner in the process, um, or process a smart place to see if if I was seeing those happen in depth. I mean, that makes a whole lot more sense. Some people say maybe this is more like something that should happen on staging environment, but I would way rather as a front and see that my JavaScript code, when squished together, is gonna fail earlier. It's just sort of this idea of failing faster. Now, this does introduce a bit of a headache, right? We've got one big fat bundle that we have to debug in, and so that's not really tractable tohave toe drip for things in that file, right? Because if I want to get to my app code, it's, you know, at line 26,000 of this bundle, it's not so bad because it's not modified, but it's nicer to be able to have the split view with all the individual files. Luckily, we can solve that, and we're going to solve that a little bit later with something called source maps, which is pretty cool stuff. But I think aligning your development environment to be closer to prod has the benefit of, you know, eliminating that class of bugs earlier. The other benefit is it's more performance. I mean, why do we squish files? JavaScript files into one unified bundle for production because it's looking less HDTV requests. The page takes less time to load. Why wouldn't we want that for our development environment just seems to make sense to me. So, you know, aside from the debugging headache that we're gonna solve later with source maps, that principle has really helped when I've been setting up these work clothes for companies to encounter those bugs at an earlier point in the integration process. So the line that we added here is sort of one of those pieces that brings us closer to what prod is going to do, and it's basically going to turn on Jesus compression for those assets So now if we're on that commit me run grunt started the server, go to the network tab and you can see content in encoding. If you don't have this header turned on, you can turn it on by right clicking on there, going to content and Cody and turning it on. I usually have this turned on just because I like to go browse states and see if they have Jesus turned on her enough because it's a performance breast. Best practice. And you'd be surprised how many Web servers don't serve Jesus assets. It's now if we hold shift or do a super reload, we can see a couple of things. The G Zip content encoding comes back, which shows us that the server is actually compressing those before it even sends them out over http. And then the size numbers have changed. So that 5.7 megabyte bundle over the wire it's actually only 4.3 maker bites. And so this is actually one of the interesting performance characteristics about, um, using base 64 encoded images specifically to the CSS. Um, we get about a 25% compression savings because base 64 strings are highly compressible with Jesus. So that's one thing to keep in mind. Um, and you know, once we get to optimizing those images a little bit later, will shrink that bundle even Maur to something more palatable. Definitely not something I would push into production. But a T least gives you the sense of how you can use this Thio really get a understanding in development for what the production characteristics of your app are gonna look like. And if you look at abdominal G s, you see that, you know, unmodified, it's 818 k b. Just adding Jesus produces it by 75%. Has pretty decent compression just turning visit bond. So there's a reason why it's a performance. Best practice.

Live Reload
[Autogenerated] so we'll go to the next commit Oh, man, I got local changes. So I'm just gonna check out my grand file, get rid of those local changes, and then we'll go next on, clear that console and get show so we can see that nice log message. Hey, there's lunch. I will keep going anyway, because this is we got 20 minutes before real lunchtime anyway. So? So one of the things that is frustrating is having to flip back and forth between your editor and your browser when you're making simple changes. Luckily, there's something called Live Reload that we can use to do that, Uh, and it is basically set up. Let's look at this steps file, see what we need to do. We don't need to install anything from MGM because the watch task Rent controlled watch actually includes live reload as a feature, but we do need to install the chrome extension. And so if you went to the next the next commit and you're opening that step stop mark down file, there's a link in there that you can grab to get the chrome extension. So let's get everyone to do that. I'll do it, too, because I don't have it. So when you go here, it's going to say This is a live reload extension. It's free. You hit that blue plus button and that's gonna have that menacing privacy warning. But if you don't like it, you can remove it after and you can see that a little pop up came up here. That said, the live reload has been added to chrome, so we can close that window now and live Reload is basically just a toggle, and the only issue I have with the U ex of it is the only way you can tell that it's working is see that tiny little dot in the corner if you click it and there's a live reload server enabled, which we're going to do in a sec, that DOT becomes black. And if it's not enabled, it becomes not black like it is right now. So it's it's Yeah, it's really small, so it's hard to see. But I mean, once you know that, then uh, then you're there. But when I installed this, I had a really hard time understanding if it was actually working or doing anything until I made a file change, so so that gets the plugin up and running. Let's go look at what the grant config was for that There's a couple things to highlight one. We added some more watches S O that if we make changes to our HTML file, those changes will be reflected in the version that's getting served up from Express in that generated folder. And we did that by adding HTML as a target custom target to the watch, uh, pointing to files dot html dot source and running that the copy task the Grant contribute copy test that we had set up. And so now if we go back up to the top, we can see files dot html dot sources just that index html. So again, another another piece of our application artifact that we need toe synchronize with the development generated folder. The other thing that we added was this. Options live, reload. True, and what that does is it will actually kick off another process in node running a live reload server on the default live reload port, and the chrome extension is set up by default so that when you click on and there's a live reload server. It looks to see if there's one running on that port, and then it'll listen to changes for that and reload your Web page when you make changes and didn't make any other changes down to bottom. No, our our task list at the bottom is still the same. So we're pre compiling less contaminating our JavaScript files, copying them over the index file over to the generated folder, _______ off that server and running watch, which also kicks off the live reload server automatically just by providing that option right there. So let's see it work. If we take front, you didn't see any kind of status message, and that's okay. I'm gonna clear my console so that we can see this happen. Um, I'm gonna move this to the bottom. I'm gonna shrink my window because I want to see the browser and my source file. And now if I open one of those jazz files like up Jess and I stick an alert in there and I save it and it kicked it off and I didn't work because I didn't have live reload, um, listening and so you didn't see anything in the console. So now if I click that button, huh? I'm anticipating this is not gonna work and said reload. But it didn't seem to work. This may just be because sometimes you have to kill Chrome in order for it to work. Let's see if we can get this working. There's the alert. There we go. Did you see it? Turn to black? We off on. But yeah, they need to improve the you exit that with, like, a bright green live reload is listening or something. So it's, um let's restart. Grunt. Just make sure in the right state, let's click it. It's good. It's listening. No, I'm gonna alert in masters rocks and there we go, my page reloaded, and I see friend and masters rocks. So for JavaScript changes, you know, debatable whether this is useful or not. The place I see this feature most desired, is by designers who are doing changes to the south sheets. So let's do that. You can see in the log. Um, it ran her watches and regenerated everything, and then the live reload kicked in and said, You know that file change, so you need to reload it in the in the environment. So let's do this and go to style. And let's change the font because that'll be really easy to see this change to Ariel and hit save and it'll kick it in and it re compiled and we saw the front change. And so where this becomes really handy is with, you know, designers who are doing rapid prototyping and they just save themselves a few keystrokes by not having hit command are to reload all the time. Uh, there is some discussion to be had around whether this makes sense from a rich client, Um, standpoint, mostly because, ah, lot of the rich client APS have state contained in between transitions between the routes, the client side roads that you have. And so, as a developer, I often don't want to use live reload because I'm going in and I'm making changes to the state of the page and that I might like, save something and see that state reflected. And if I if the browser was reloading every time I changed the file, it would blow away all that state, I'd lose it. So it's a little bit nicer to not have to worry about that. But that's where the Crumb Extension is super nice because it stopped in on if your developer, you can just toggle it off and designers can toggle it on.

Live Reload Alternative
[Autogenerated] There is another feature of how you can implement this, which is what I originally started with. So if we open up the index html, can we go to the bottom and we go to Let's let's open up those docks again using that MPM Repo Command And there was something about a snippet Hope What did I put in Gronk? In truth. Oh, right, because it's part of granted trip watch, and now for you sniff it. No watch. I will be loved. So there you can see some of the options. The default port is 357 to 9. Um, they have some examples, but what I'm looking for is the snippet that you can paste in as a script element. Here we go. Um, the only issue with this is this basically makes it impossible for developers to opt out without modifying the HTML file. So it's not as desirable. It's using a protocol lists. Um, you are I So whether you're serving up from https or HDP, it'll work. So if we plug that in to ____ before the closing body and then hit, save on and close these and I mean it's surreal. Oh, this page. Well, I gotta run. Grant, Reload this page. There we go. Let's make a file change. Oops. So it worked, even though we didn't enable the live reload plug in. Actually, that's an interesting side effect, so I didn't click this, but I just noticed that just by including that script element in the page, it enabled it in the chrome extension. Um, so if we get rid of the crumb extension Yep. I move and reload the page. Get our alert. It does work without the crime. Extension is the point I was trying to make. But I think the crumb extension is a former elegant solution just because then it stopped in for developers instead of October.

Chrome Workspaces
[Autogenerated] I've got time for one. Really Cool crumb Devils feature before we break that works in conjunction with Live Reload. I'm gonna get rid of that snippet and killed grants. I'm just gonna make sure that I don't have any already changed the style. So I'm just gonna check out this style so I don't have any changes. Let's run grunt again. Go back to local hosts. Turn on live, Reload that black dot Wentz, go to open chrome Deb tools. And if you're wanting ah, hockey To do that on a Mac, you can push command. Plus, Jay, there's a command. Plus I j does. It gets you to the console. Commend. I will also do it. You can also just look in the view menu in the developer. I command you deserve you source. So Command J is the one that is sort of committed to my memory. If you use safari, I think it's command. I Maybe that's why they have the double alias there. Let's open that up. Let's go to the elements tab. Sorry. Sources Tad, that's very so in maybe two months ago, there was a beta feature that came out to cram canary Uh, and if you're warning to beta test these features, you condone the chrome canary and check them out. They have some experiment flags enabled. Um, if you right click in the sources pain here, you'll see that this little ad folded. A workspace comes up so you can add the folder. And if we go and find that thing not Shopify expenses. Ah, code. I think I haven't upgraded to Mavericks, but I hear the finder experiences a lot better. Can anyone confirm Workshop? Let's just map that directory and then you'll see that there's this little permissions pop up that says a lowered and I So let's allow. And now I don't even need to edit and sublime If I don't want to, I could just, you know, open these things here. So let's open that app Js Let's I can't shrink that Kenny go. There we go. These little docking tabs on the side. You can customize the workspace for deaf tools. And the cool thing is, now, I can actually make changes in this file Hit command s and little persisted disc. And because I had live reload running, it just worked. So now I have like a ninja grated editor in my browser if I want, and because we have the watch tasks set up, it re compiles everything and then live reloaded Text that. So really, you can get to this workflow where you don't even leave the browser, which is kind of nice. Really, really great for prototyping things and just figuring things out on, but also just allows you to use the deaf tools features, um, like inspecting elements and tweaking the CSS, for example, uh, this guy and persist them to disk. And I think there's one other thing you have to do to get that to work, which is you know what? I didn't experiment with this a whole lot, but I think what you have to do is provide the girl and then the path to the folder. And then whenever you make a live at it in here. So, for example, if we change, there's the font. I think it's on the body. Ariel Mmm. I don't think that did it for me. Oh, right, because it's mapping back the less and I'm I'm using the the generated asset, but I know that there is a way that you can get it toe map back to the actual fall so that when you make changes in the elements panel on dhe, that's pretty cool, because, I mean, most front of developers are used to cram Deb tools anyway. And they're using this to kind of like prototype Leo changes. And so when you can get it set up that you can do all that and then have the persistence to disk because my workflow for doing this kind of stuff in the past was, uh to go in here and make changes and then, like, grab all of this and copy it and jam it into the CSS folder. And that kind of _____. So So, yeah, that's a little bit of work spaces and live Reload One of the cool, newer things. One other tip that I just actually just this morning saw you can actually run terminal now in your crime Deftones console. Um, so I can go to code work shop, and I could even run grunt from here if I wanted to, and it's got my full UNIX terminal in here. So it's like I really like the direction that the guys on the chrome developed relations team are going because they're integrating all these features so that you don't have to shift the context of switching away from your browser when you want to make changes, which is really cool. How did you determine? Oh, yeah. I'll show you that with the G eight. Good one. Hey, you go to chrome extensions. Uh, I'm just gonna find the u R l for it. There it is. That's probably gonna be hard to copy. Um, if you if you go to Twitter, I tweeted it earlier today. Twitter dot com slash d Mosher. Uh, isn't my tweet on just in time for fun and master stooling workshop terminal inside chrome Deb tools. And you can get the link there. That might be easier than trying to copy that. StarLink. Yeah, we could try that, too. Tools terminal, maybe. Yep. There it is. Devil's terminal if you just search for that. So that is pretty much all I wanted to cover before lunch. We've got some cool stuff that we're gonna do to kind of continue this workflow. Um, let's just do it really quick Overview of where our workflow is at with this grand project we, you know, started from the idea of taking ah project that had all of the javascript assets sort of as, um injected into the head. We moved to contaminating. We set up a workflow where you get a minute fied or a contaminated bundle and death. Then we added the CSS pre processing on top. We in line the images with base 64 encoding. We added a custom server tasks so that we could mirror our development environment to be closer to what's gonna be in pride. We added compressed in the express middle where so that we can see Jesup, what impact that has on her assets. And we added the copy task so we could move that index html in. And then we added watch, live, reload and a whole bunch of chrome deaf tools goodies with with workspaces and that crazy terminal thing at the ends

Grunt Clean and Grunt LESS
[Autogenerated] next or get crawl. Master, if you're using the get crawl alias, this is a pretty simple piece of our workflow, and it's maybe something we should have set up the initial start. A lot of other workflow tools like maven allow you to do something like maven clean to clean those generated and distant targets so that you can you know, as much as we want to create a robust workflow, Sometimes the state of our file system gets corrupted or whatever, and we just need a way to reset. So that's what we're gonna do here with ground control clean. So let's look at that steps file again and you can see the last one on the list there is to install Grant, contribute clean and then save it to our package. Jason, we're gonna run that. And if always good, we should see that live there. Let's go take a look at what change happened to our config. So we'll open up the grant, filed out coffee and just kind of take a look. So we only added one target. Um, clean eyes. The name of the task and the target is called workspaces, and this allows you to just provide a ray of folders or files and grant will go and remove those or empty them. Basically, when you run the clean task, we didn't make a change, too. Uh, this default workflow at the bottom. Let's move it up to the top again. So everyone can see because this is something that we don't really want as part of our automation layer. At least not in development. We would. I want this to be a test that you would run manually. And so the way that I would interact at this command is now I can just go grant clean and it's gonna clean the workspaces, and then it cleans up that generated folder. And when we get to a building the production side of this, it'll clean up the dest folder as well. Um, so this is sort of an interesting thing. You can craft a workflow that's part of these automated tasks, but then they're sort of like these one off tasks that you can create and clean is one of those. There's another one that will look at a little bit later called Image Men, which is gonna do that image optimization I talked about running a grunt test tow, take those PNG character images and optimized them so they're not so large. But yeah, just this idea of, um I've got my workflow and maybe multiple work flows that I can use, depending on different scenarios and then the ability to have sort of one shot tasks that I might just need Thio execute randomly as part of my work. Um, so we could get next. Let's just show the log. This one's pretty simple. We can get through it really easy. Um, so I mentioned earlier that I was using the fork my fork of drunken Trib less. When I have found out that they updated the last version to support 1.5 dato. I figured I'd get rid of that. Uh, and just a general note. It's, you know, forking is really good for being able to prototype things and test things out in your local environment to see if they work. But the danger in doing that and leaving it in your package, Jason, is that you diverge too far from where the sort of canonical source for that package ghost and then there's features that they add or they break backwards compatibility. And now you're relying on maybe your own package. The other issue is it's very easy to want to start a hack your own features into that project, and then just leave it in your fork. The best course of action in that regard is too. Probably submit a Paul request so you could get it merged back into the maintained package and be a good open source citizen. And then that breaks the temptation that, you know, you forked. And now you have this own special snowflake that is your own thing that totally divergence from everyone else's and becomes really hard to understand. What? The differences between the economical source and your fork. So if we check out steps, I think the only step Yeah, I didn't think there was a step actually, because, uh, we didn't make any AP I changes under the hood. If we actually open up node modules grunt. Contribute less. Look at the package. Jason, um, this is basically the line that changed it. Uh, it went from 1.5 0 dash before. So this is still the package that was installed. So if we really wanted to, uh, you know, make sure that we got the new dependency. We need to go in here and delete this folder and then, um, do an m p m install again. So I'm not gonna say that. And I think that package Jason now has the great release. It went from 0.7 about something to a 8.0. And if we just do in NPM install, we don't have to specify grant Country. Bless because MPM is smart enough to know it'll check if the versions were at match the version that's in the depository and it won't pull them down. So it should just pull in. Granted triple s, which is what it's doing here. I think the only modifications I made her just to add the spaces, and that's okay if that carries through for the Grand Files

The DIST Workflow
[Autogenerated] Let's go next. No stash. Then go next on DDE clear and you get show. So so far, we've got, you know, a deaf environment that's pretty close to simulating the production environment. But we would like to be able to take the artifacts that we output from our workflow on and have them be ready for production. Basically, the assets that were gonna work want to work with. So let's go take a look at what changed in the grant file. So the first thing is, we want to unify our CSS and compress it. Grant contribute less added an option they used to use the y u I compressor, which I believe was a ___ ajar that would compress the assets for you. But again, it kind of _____ to have to use ah workflow to, like, grunt and then shell out to another programming language. This is why I don't really like to have to shell out the ruby with Gran contribute s. I'd rather use a tool that does everything in JavaScript on. When grunt first started, that was a lot harder. A lot of the preliminary grant tasks would shell out too, you know, the existing lib or utility in another language or framework. And, um, that was frustrating because it slows down your workflow notice just so fast at doing file Io and everything. So if there's a native JavaScript solution, it's really nice. So I've changed my targets inside of less on I Have One for Dev, which basically just shoves things into that generated folder. And then I have one for dissed for distribution, and we've got a couple options one to do the clean CSS. And if we open up the video NPM repo grunt, contribute less, and we can check the notes about what clean CSS is in success. It's actually another package, says a well tested CSS magnifier. Another metric, I guess you could use to determine if it packages popular Hominy downloads on p m Js dot org's. And then I would usually go over to the actual get repo. How many stars we have? Yeah, decent number where the tests look like no unit, not my favorite. Oh, no, this is vows. Ah, a little bit different, but still more of the ex unit style test framework and ah, a little bit later, I can show um the default that we get from Grant in it when you're doing a grunt plug in and the testing framework set up with no unit on how it's, um, it's pretty crazy. I have, ah, on alternate grant plugging that I just wrote, and I kind of reworked the test framework so we'll take a look at that a little bit later. But CSS clean CSS is the module that less is using when you add the clean CSS option and then compress just removes all the white space, Um, we're gonna go and pull in from vials that les dot source, which remember we stuck in that files object in the config, and that's pointing to styled out less. And the destination is a little bit different this time. We're just basically changing the route node where this is going. So inside of the dest folder C I A. I got all the lines right. So now because we're doing that, um, we also want to add a target for copying the index that HTML So all of the artifacts that are gonna be output as part of our build process, we're gonna want to move either into generated or into dissed on, and I'm using that multiple files object. I think it was called the compact Style or just the I forget the terminology all the time. But the thing that we went over in the grunt docks, where you can use the key as the destination and the value as the source So now we're taking index html, moving it into both generated and guest whenever the copy task runs. And now we get this idea of adding to our workflow with a build command. And again, this is just using registered task. But now it'll be available to execute from the command line. So let's give that a spin and first thing, let's look a grunt, helping to see what the output is cause it's interesting when you have lists of tasks or Alias is basically what the ____ puppet shows. So now we can see we've got all of our core tasks here, but we've also got two aliases at the bottom. So the alias default, which shows all those tests and then the build alias, which does less with the distribution target on then can Cat Coppi and we've differentiated between Dev and disc now for the less tusk in the in the default alias. So if we run Grant, everything should still be working. You got a local host, And if we run grant build, I didn't do it watch because we just want this to be executed on some sort of environment, Like a continuous integration environment that's going to do this. Um, and then the artifacts live inside of dissed. So if we l s well, we can see that we have dissed and Alice minus eldest. Um, we can see that we got our CSS and our index html. We haven't taken care of JavaScript for production stuff yet. We're gonna do that next.

Minifying JavaScript
[Autogenerated] I'm just gonna check out so I don't have to stash my stash is probably getting full of stuff, just a bunch of different changes instead of stashing. If you just kind of want to reset all of the changed vase you can do, get check out and then say dot And that will just re check out all of the files if you don't want a stash. So we went next. So we've got CSS for distribution. Take care of. We moved our HTML file. We don't really have to do any processing to the HTML file. Now we get into sort of some more complex topics like unifying the JavaScript. There's a couple of things we want to do. Um, if you notice here this big green block that I'm scrolling up, there's a couple new fields that got added to the grand config. And this is all just metadata. One of the nice things about Grunt is it provides this really nice a p i for reading and config files, and it can support both the ammo if you like using animal or Jason. Um, I like Jason just because it's a little less crazy to me. than you know. But whatever you want. If I was using ammo, I would just use reedy ammo. Grendel found that re gamble there. So we're pulling in that package Jason file on. The reason for that is we have this banner and we want to actually consume some of that metadata from package Jason and admitted in a banner so that when we distribute our assets for production, they've got a nice comment block at the top that shows us like the date it was built, um, copyright information. And if we had any of the licenses, the author's maybe the company name stuff like that just sort of regular build stuff that you wanna inject into your your assets. And so here's our ugly fi configuration. The task is just called ugly Phi Tau. Load it. We called grant dot load mpm tasks at the bottom with grant contribute vilify. We're gonna add that options banner on Bennett's self referential in the In the config. It's just gonna expand an interplay toe, grab all of the banner in there, And because grunt recursive lee expands all of the template interpreters, it'll you know it'll go through and grab banner. And then I'll say, Oh, that contains a bunch more. So I need to expand all those and whatever's in the config at the time of expansion, it'll inject in. And so where do we add that we needed to add that to our build task right after King Cat so less disc takes care. CSS cat to merge Oliver job script files together and let's vilify that one man if I'd bundle and stick it out and then we just added those dependencies here. So there's that step that we can see. Let's do that so that pulls in Agua Fi. And again, this doesn't affect our build life cycle or are default life cycle workflow. It just affects the build ones. Now, if we run grant build, you see it's gonna take a few seconds magnification. You know, depending on how large your sources can take a little bit longer, and there's some options you can configure to make that smaller or the time less. Uh, if you're not concerned with, uh, performance. Um, the biggest one is probably no mangle. You can actually turn mangling of the argument names off. Let's take a look at the men if I'd bundle, and I can show you what that what I mean by that. So if we open that artifact inside of the distribution folder, there we go. So we got our banner that got injected. All of that metadata is taken from package Jason and stuck into the comment Walk of the top. Um, the other cool thing about the banner is you noticed that there was actually some programming in there. So be open because I opened the root file. Sorry. Let me do this. Uh, so inside of here, we're actually using underscore er pluck function to pick out each of the licenses and join them with a slash, um, so the template interpreters for the config. If you have this, it's just gonna inject a value. Um, if you have this, you can run any arbitrary JavaScript code that you want, so that's effectively, um, this is returning a value, but if I wanted to do this programmatically in a loop, I could do it inside of one of these blocks, you know, and whether I'm using of package licenses, this is underscore each, uh, function, license return place. Since something like that, you could do it programmatically So you've got a lot of power in the in the grand config using those template interpreters. Um, let's go back and open up that ap Minjae s. And maybe this is better to doing crump deaf tools. So let's open dissed Index, and this will open our distribution in the browser. Let's just make sure that the absolute works click around, move units, get into the editor at stats. Yep. And let's open chrome dep tools. Remember, the hockey was command option J. Let's look at the sources tab. There we go. Close that. And, um, if we hit this button down at the bottom, I'll just zoom in on it. You see the tool tip? They're pretty print. So this is useful. Um, because a lot of the time, you're gonna be ducking debugging men if I'd assets on prod and you can hit pretty print and it gives you at least some sanity in sort of indentation and white space. But it doesn't have to change the file, and you'll notice that if we go to the very bottom, none of the arguments to the strings here are not men. Ified strings can't be unified any further because Google, if I has no way to tell if they're meaningful for the application that were using the things that can be magnified effectively our arguments to functions, Um, and what this Syntex does is this is Anglers Min safe way of mapping those particular arguments when unification happens, so at runtime, when this function is called for the ER stat editor, um, the value of a will map to the scope and the value of B will map to the upstate service. And so that's how angular gets around Min ification because an angular the dependency injection works such that those names are important for resolving those dependencies. And so if you don't have this men safe structure to your anger code intellectually break when you men. If I there is a grunt task that you can get that we'll look at a little bit later that does. That step for you has sort of a pre process. But that's just ah, a point on what Agua Fication does. And so the act of transforming those argument names from like dollar scope to A and B that's called mangling the argument names, and you can turn that on and off in the in the ugly fi options. If you want

Grunt Open
[Autogenerated] So at this point, I wanted to open it up for discussion. What is missing from our workflow? That seems tedious. Anyone have any thoughts about? You know as well as we're running in developing this No typing grant to go into Dev, Are there things that we've got a lot working for us, But are the things that seem tedious to people or is it all good? Seems tedious to install NPM things. Mmm. And to have to I have all this stuff here. Just every time you add win these things, you have to install it. Yep. I mean, that's basically like every other package management strategy, right? If you're gonna add it, you need toe download it from some depository and put it locally. And then But I agree with your point about it being tedious to have to do this every time. It is kind of annoying because then there's multiple steps. And, like if I, you know, pull down a package from NPM using NPM install and then I think Oh, that's what I had to do. Was it working? I put my config in the grant config. It doesn't work. There is a solution to that, and we're gonna come to fix that one later. The one that I think is really annoying is that I have to manually open the browser to the local host 8000 every time. And that seems just like, you know, annoying to have to do that so we can automate that. And that's what we're gonna do in the next step. So if we get next and I didn't even know about this one till I started browsing some of the other grant plug ins, uh, grant files, and, uh, it's really cool. You could just find all these random plug ins and sort of the way that people combine things. And so this one's called grunt open, and it's really easy. You just passed it. Ah, task configuration called open configuration key called Open. The target is Dev and then the path of where you want to open it. And then you just jam it into your, uh, workflow wherever you want. So in this case, we've got it there at the bottom, and yeah, I mean, like I said, this is getting tedious. We're gonna fix that in the next step. Uh, and then you can see down at the bottom right before we watch we open the server. Now, uh, strict steps install grand open boom. Now, my brother has been automatically when you run, Grant and I don't have to think about it. The downside to this is if I don't close my browser than every time I run Grant, I get multiple tabs opened for that app. This also compounds. So if I do it again and have live reload turned on all I'm gonna get live reload for each three of each of those tabs. So there's some balance between you know, what you want to automate and what you think is is worth automating. But I thought that it was handy toe. Be able to have it open for your divorce flow. Just one less thing to have to manually do

Match Dependencies
[Autogenerated] So let's fix the issue of having to keep adding to this because that's kind of annoying. I mean, it's happening automatically because I staged the commits so that I was doing that. But in a normal work for would be nice toe sort of magically pick up any of the dependencies that got pulled in and not have to call Grant got loaded. PM tasks for those. So if you got next, we can do that with something called Matched Up. I see we got a whole bunch of red that's replaced by one line. The way matched up works is it analyzes the package. Jason's dependencies key and, uh, executes a filter. So in this case, we want to grab, matched up and filter all the dependencies that begin with Grant Dash and use a star to grab them. All. We can use dot for each and call grant dot load MPM tasks. And now, if we add new tasks, the only step we have to do is NPM install, and as long as they start with Grant Dash, then we don't have toe, then it'll it'll get picked up automatically. So the only step for this process uh, is to install matched up. Well, it looks like I forgot to put that step in the steppes file. We can do it anyway, because we know what it's gonna be. Match depth. Um, save this is probably more appropriate in depth because it's really only a deaf dependency. We conduce dash, dash saved up, and let's just make sure workflow still works by running grunt cool. And now, as we had more packages, um, then we don't have toe manually edit the grant filed, pick up those grant plug in. So we're adding, make sure we didn't break. It's looking good. Yeah. Couple discussion points that I thought would be interesting to bring up in relation to this, Um, the thought that is this potentially dangerous, right? Like, is, uh can this break things? Um, there's some argument to be said that this is maybe obfuscating too much, because now I have to understand what happens here. And I have to look at my package Jason, to see all the dependencies. It works for us right now, because if you look at package Jason, all of our depends. He's been begin with Grant Dash, except for matched up and we're not loading matched up as a grunt plug because it's not. We're just requiring it right here in line. So I guess when you're using something like this, you just need Thio. You know, determine whether the benefit you saved from not having to add that one more piece of convicted the ground file is worth it or whether you'd rather be explicit. It's kind of implicit. First explosive behavior. Clear my local changes and go next.

Simulating Production Assets
[Autogenerated] So now I mentioned earlier this idea of a production simulator. So that's what we're gonna do in this commit. We're gonna basically spin up our Web server with the men if I jeez, it compressed assets so that we can get some idea of what the performance characteristics, at least trauma, a network perspective. We're gonna be Let's take a look. And this is also where I mentioned being able to inject a environment very able to configure what folder we launched the server with. And so because we're using coffee script, we can use a string interpret later that's built into coffee script, which is very similar to Ruby. So this syntax here, where I've got the pound and then the bracket as long as I'm in double quotes to start coffee script is going to evaluate this and turn it into javascript. Um, when we compile, I can show you what that looks like. We go to Here we go. So he grabbed this block of code and using that command shift, p um, and we can do coffee display JavaScript. I don't know if this comes by default with sublime text, too. I think it's a package. You have to install the coffee package from package control. But now we can see it. It took that split it so he can see. And it did this drinking cat nation for us. So this is another one of the features that I really like about coffee script is you don't have to do manual strengthen cat nation. And if you're coming from python or ruby or heck, even see every other language service I like which has this feature. So it's nice to be able to have it in your in your JavaScript code. So what we're seeing here is, um, grab the value of process dot m That is the environment in which this process executed. So we can manipulate what server this thing is coming from or what, Uh, what folder? Rather, the other piece we added, is another task an alias. So for a prod simulator, we want to build first so you can actually alias lists of lists of tasks. So now it's gonna run all the all the tasks in the build, and in this way we kind of create abstractions around the workflow, which is pretty cool just to be able to do by, you know, adding a strength so we'll build for production will fire up that server and then we'll call open and then watch. And in order to get this to work, we need to add one thing to our command. Lynn. So instead of doing grunt prods, um, we now need to set that environment for able so that we can serve out of the dest folder. So let's do that. So if we do, server base equals dist. Rent prods that environment variable a set. When the process executes the value of process. Dot of dot server base will be dissed, and it should be serving out of that directory. It's gonna run ugly if I it'll open her up, still have our base 64 encoded images. Let's look at the network tab and just see what those file sizes air now so apt dot minn dot Js. If you remember, before it was like 800 k, be compressed down to 200 K B. So now it's 100 92 then Jesus brings it down to 68. So it's pretty good compression ratio, and that's all of the vendor dependencies. That's Shakeri. Olive. Angular. Underscore whatever else was in our defender dependency list down to 68 K B. If you're optimizing for mobile, that's not a great number. You want to shrink that? Hopefully even more on depending on how you want to configure cashing and granularity of cashing, you're probably gonna maybe split that between your bundle and your vendor bundle cause your vendor assets are probably not gonna change is frequently as your app assets, depending on how frequently you deploy. But this is kind of cool, because now we can, you know, with a simple command line are, uh, sequence. We can spin up the workflow to configure assets for prod and then serve out of that disk folder to kind of just get a real good idea of if unification is gonna if of litigation is gonna break her process again. This idea of integrating early so that we don't have to get to prod unsee. Here's our friend and code

Vendor JavaScript Libraries and CoffeeScript
[Autogenerated] the next one. If you notice that D s store file was showing up every time I did to get status, So I added it to the get ignore Get check out dots angle next. And so I was mentioning, May be splitting our vendor in our app code into separate bundles. And that's kind of what were the direction we're going in this committee. So now in files, um, instead of jazz source, we have jazz vendor and jazz source. Let's take a look. So now I've split my Js into the vendor bundle and the source bundle, and right now I'm still combining them in the cafes, which I do right here. But this is in preparation for delivering two separate bodies in a couple of tasks that we're going to do next. Let's just make sure that that works looks good. Oh, yeah. The other point I wanted to make about this was, um this makes a lot more sense when you think about separating the concerns of what is a vendor dependency and what is my application source? And the reason the other reason I did this is because we're gonna do our integration next and it helps to have split bundles so that we can point to the bower paths. And then it's also just visually the nice separation so that we can see these are gonna turn into power module paths and then our source paths. They're just gonna remain the same. And we have that nice visual separation. Hurry. Controversial topic Coffee script. Yeah. So what if we wanted to add coffee script compilation to our project? So this committee is huge, and it just changes to add all of the source files that were job script as copy script. So if we look at the folder, I just stuck it in the coffee folder. But this the reason I staged it in two separate commits is it's kind of useful just to be able to open up the files and see the characteristics and how they changed. If you wantto evaluate coffee script, uh, split this. So there's my original app. GS, which is 20 lines. And there's the copy script that's eight lines and that net reduction. Typically what, like this is a little more than half, but usually you see at least a 33% reduction in lines of code when going to coffee script. So that's one benefit. We're talking at lunch, and somebody mentioned that you know, there's the cognitive overhead of having to understand what the pharaoh function does or things like that. But, um, my experience, like I was relating to people, was getting to know coffee script over, You know, three days. There was a lot of W t f fs and a lot of frustration. And then after I understood sort of what it was doing, it wasn't so bad. And then having tools like being able to display the coffee script for something just right inside of sublime is really helpful than you can say. Oh, well, now I can see you that, um, let's put that up there. Now I can see that arrow means function, and the only thing is that the parameters come before the function definition. So there's that switch, and I think if we open up, get X, I'm just trying to see if I made a change to only the APP sources. Yeah, I didn't make any configuration. And then I'm pretty sure that the next commit just removes the Js sources. So next. Yep. I saw it get X flash in the background just to remove them. And the only point here being that, uh, if you're gonna write your app and coffee script, then you wouldn't commit the jazz files to repositories. But you're distributable. Artifact, if you're building a library, should probably be the compiled JavaScript. Because for coffee scripted, do you have that? I didn't know the package package package control installed. I'm actually using text, but oh, I just want to Just writing copy, scripted visit are a step. Oh, yeah. Compilation. That's going up next. Yeah, because, I mean, I don't wanna have to do this every time rate that would ____. That would be a horrible workflow. So now we only have coffee, and we can just go next.

Compiling CoffeeScript
[Autogenerated] and now we can pull in. Grant can trip coffee and spend a little bit of time talking about how to integrate this into our workflow to automate this stuff. Let's take a look in get X or you could get show if you're in your terminal. So the one thing we need to do we don't actually need to do it, but we want to do I'm just gonna open this in the in here because it's bigger. So you see, R. J s list of files went down to just the vendor dependencies on. Now we've introduced files dot coffee onda destination for where we want to introduce those sort of temporary compiled assets is in this generator folder and compiled coffee. And then we want Thio knowing that we took the paths that we had in the previous step and stuck them into this key cult compound. So knowing that the pads there still gonna be the same, it's just the er, the file names or Sylvia. Same. The globs absolutely the same. It's just the route path that changed. We're introducing an intermediary step in the compile, and the reason we do that is to set us up later for being able to generate source maps. Uh, it's just a little bit easier. So here's our coffee task configuration. I called my target compile, and I'm using that compact style, which actually gives you a few more controls, not just the source desk map ings. You can actually control the working directory that it's gonna operate in. So in this case, we want to operate in the coffee directory. That's this guy, Um, you can control what extension the compiled files are going to have. And just keep in mind that that compile target name is there's nothing special about It's just What I called it eso. We want our compiled coffee files to have dot Jess extension, and then we want them to go into wherever files dot coffee dot Guest is, which is right here, generated slash compiled coffee, and the source is going to be inside of this working directory glob. Anything with coffee because we don't really care about the order order of compilation. It's just a transform that's gonna happen. Uh, let me think. Let's check the steps while make sure I didn't miss anything, right? We're going to grab Grant contract coffee. And now when we run, grunt our absolute works. If we look at the sources, it's still JavaScript. But if we look at, um, the task here, we can look at the open and just kind of see what's going on. So it ran the coffee compile task because we added it in our workflow for Dev go down to the bottom. So we stuck it right there. So before we can catch me, we need to generate the files with coffee script and then can cat takes those and consumes them? If we look at the cat task, we can see that no longer are we doing files dot Js dot um What they call it Apple. I think in the previous commit Now we're grabbing those sort of intermediary coffee script compiled files that are in that generated folder and using that took and cat me. So that automates coffee compilation. So you don't have to think about it in our dead workflow. And I think I even added a watch. Yeah, so any files that changed inside that directory is gonna re compile them and run can cat. So our workflow kind of takes care of that. So does that kind of answer your question of how toe had a stage, this stuff so that you don't have to think about the compilation stuff. Um, and this works good for if you're experimenting with other transport, Target language is so like typescript is really popular in the dot net community. It's basically typed JavaScript. Uh, and this would work the same way for that workflow. There's also you can start using, yes, six modules Now on. There's a Google tracer compiler that would allow you to do this if you really wanted to be on the bleeding edge and start using that. My view is that I think that's great for developers that work on that stuff. But I don't think Regular Debs, we're gonna invest time into spending, you know, on the Bleeding Edge Coffee script has probably got the most critical mass as far as the transport of language on the front end. I know a lot of people are doing good stuff with typescript, but I just think it's pretty isolated to a lot of people in the dot net community of coffee. Skip, I know is used by people all over the place. Really Java, I thought, Whatever. Let's just make sure I didn't miss anything. Yeah, so we're starting to add quite a bit to this watch. And if we runner workflow with V again to get the verbose output, we can see the list of files that are being watched, and it's gonna be pretty significant. So we're watching index dot get. That's interesting. Should figure out a way to ignore that. Um, not that it matters a whole lot. Anything in coffee CSS dissed and then all of the individual files. Um, and this has some performance considerations to think about because we ran into the Sun Shopify because we've got 500 coffee script files and the compile step actually takes a few seconds to complete. And that's not acceptable from a deaf work. Little point of view. I don't wanna have to wait for my entire up to compile. Luckily, there's something called a grunt. Newer, and it's super easy to add. I could just show it to you right now. So look for Grant. You were grant. Newer is, uh, provide some time stamp cashing on the file system, and it basically just determines the last time a file was updated and whether it needs to re compile it again and super easy to add to your project, We'll we'll do it in line here. I didn't actually do it as part of this time. Step. Well, it's just try and see what happens. So we'll do. NPM installed Grant Newer Dash Dash Save Dash does, and it'll get picked up automatically cause of our match step. And now, anywhere we have the coffee task, Um, if we just pretend newer and a colon so there's that watch target that we need to touch. There's also down here Sanur coffee. We also need to modify our build task so it does it. Or you could argue that maybe you don't want it to do that optimization for build, and you just wanted to do the full compile. That's probably the better stuff. And then we also need to add the configuration for the newer task. Let's do that newer, and I think it's time stamps, and it's basically just the location of where you stick them. Let's check out the options here timestamps yet It's just a path, so let's just stick them in generated and a compilation time stamps. And I think that should work just trying to think of. If I need to add any more places, let's check it out temporarily. I'm just gonna disable open because now it's kind of annoying cause I want to see the terminal open. So if we run Grant, you can see that it pretended all of the tasks that it needed to with that flag newer. And it's now listening to watch. And if I trigger a change in one of those files, let's watch the bottom there. So if I open apt up coffee, you can see that newer, reconfigure detective only one file changed. So when that intermediary compile step happened, where we stuck our compiled output in the generated compiled target her was it compiled something or other about coffee? Um, it's only gonna have to re compile that one file and stick it in place. American Cat task still pick them all up and squishes them, so it's gonna only get the one new file. So this is ah, optimization. We added for shop. If ice workflow because, yeah, like waiting. How long does it take? I think it's like three and 1/2 seconds to compile all 500 copies. Script files, which you think isn't that bad, but for the number of times it happens during the day, we just decided optimize with this for the deaf workflow.

Beyond Grunt
Bower
[Autogenerated] Let's talk about Bauer has anyone using Bauer. James is using Bauer. I think it originated from some guys at Twitter there the lead engineers on this project and the goal with Bauer is similar to what we have in P M. To pull down packages from Node. They're intending to do the same sort of workflow for pulled on, pulling down packages that are intended to be consumed in the browser. So all of the stuff that we had in Vendor Js would be a candidate to pull in via Bauer. And they've done a good job of trying to mirror the workflow with N. P. M. But there are a few things that kind of stand out. So I mean, we've got Bauer dot Jason instead of packaged out Jason. So if you see a project and you see that power that Jason file, that's where all the dependencies live and it looks very much the same. It's got the same metadata fields, dependencies and Deb dependencies and things like that. It works the same as in p. M. You say Bauer install. It's gonna consume the packages from that Bauer Jason file and pull them down. There's config file that you can stick a dot file told our RC, and that's basically where you want the power modules to go in eyes. What I'm using it for here. Which directory? The reason being the default for Bauer is, I think, our components. And when I paired Bauer components with node modules as like, what's a component? And what's a module? And why are they different? And it just kind of confused some people on the team. So I just like, let's call it power modules And then, oh, if its power modules, it must behave the same. It snowed modules, which it kind of does effectively. It's just pulling them in off the file system. So that's why I did that. Let's look at our I think it made a bunch of modifications. Stash those because I want to add the newer stuff thio the end output of this so that you guys can have that as part of the take away from this Um next on get show. So I did two things. I got rid of the old Vendor Directory added that Power RC I took the opportunity of upgrading angular to the latest release candidate just cause I can showcase how we can pull in those dependencies of your power. So there we act the vendor, and now we're pointing to that Power Modules folder on Dhe. There's a little bit more sort of path encoding that we have to do, And that's just because of the way Bauer stores modules. Here's my Bauer Jason file. This ignore, um, key. Is is what some of us were talking about at lunch, and it's the source of a lot of confusion around power because it seems like it would be a user option. But it's not. It's ah, it's an author, a module author option. Basically, what this means is you are telling Bauer that when it installs this component, if I was publishing this thing up to power, that it can ignore all those folders and it doesn't need to pull them down. Um, the reason that this is relevant is because if we go to get, uh, I think it's Jeremy. Ask ____ and look at backbone. It doesn't have a Bower doubt Jason file, and the way Bauer works is it uses get hub as its source for pulling down dependencies and you use the Bauer Jason file to indicate that we don't need to pull down all these fellas. So when you do a bower install backbone, mine's cashed. But if you guys do that, you'll see a six megabyte chunk come down over the network, which is crazy because back bonus like a I don't know, 16 k be unified library when you pull it down. So this is the fundamental problem with Bauer, and there's something you need to be aware of. Uh, and it seems to strike me as odd, because if the Bower team recommends that you commit Bauer components to your depository, why would I ever do this with a six megabyte chunk for backbone when I don't really need it? Let's take a look inside of power modules. So I did a Bower install, and it pulled in all of these modules that I had in Battered Out Jason. So if you guys do that, our installed Is it working, pulling it down over the network for you? Anyone who is still following along. The one thing it does do is if it doesn't need to do anything, it doesn't do anything, so that's nice and now we have Ah, all of those dependencies there. Let's go back to sublime and just kind of take a look at what the package structure looks like. So we can compare it with ____ modules. So ____ models, you know, has all of our dependencies as folders at the route. Same with power. I'm gonna close after coffee. Go back up to my list where I was looking at them for a vendor. But now the one other complaint I have is there's no, um, convention yet around. Uh, you know what the file is that I need to pull in? Because if there was, then I could automate this and not have to specifically in code. Um, for example. Jake, worry if we open that one, it's Jake Arrieta Js that I wanna pull in angular. It's angular. Got yes. Um, underscores underscored gs. But this one is indexed R J s. And the reason for that is if we look in the bower, Jason, I'm actually just linking to a girl. But even though it's called extend O. J s, I don't understand why Bauer just doesn't pull it in and say, Well, it's extend Duchess inside of the extent. Extend out, yes. Folder because it index. So just a few things that air, you know, holding it back from being a really, really good package manager for Web assets. You can also use Bauer to pull in C. S S. So if you're pulling in, like, bootstrap or other components, I don't use it for that in here, But you definitely can. Let's make sure everything still works if we run Grant Super reload. Looks like it's all working. We could do a great clean and then try it, and I don't really give us the Yep. Looks good. Any questions about Bauer? Yeah, You're using a power J. R. Bauer, Jason filed to pull in what? You definitely can actually pull in your your power now. So I've got this flag private. True so that this mirrors in P. M. If you have Private Truman NPM packaged up. Jason, if you were to say NPM publish, it wouldn't push it up to N. P. M. So that it's it's not really the same. They're trying to mirror packaged up Jason, but NPM has its own sort of managed repo. For all these files, it's using couch TV under the hood. But because Bauer uses get hub like the concept of private doesn't really make much sense because, I mean, you can publish a package to Bauer, but I think when you do that, it just publishes the metadata to their central repo on. But then it uses get have as the engine for grabbing the files. So So? So a power that Jason filed for consuming or or creating natural Something to be used yet? Divinity. Just the same. Yeah. Yeah. And that is also kind of confusing for people because it's like, uh, we're using it here to consume. But you could also use it to, you know, to publish a swell. So the same with package Jason, right? Hey, Dave. Workmen. They get the slides of you, Both of them? No, I can upload them. Thio. What is it? Speaker? That cancer I put on my slides, So Okay, but I will do that. Is it okay if I do it at the end? You want me to just kick off the upload right now? Are we good? Great point, because I know a few people have asked yet we'll take a break. Next stuff, it's gonna be a template. Copulation with angular templates. Okay, so let's break 10. Just power Still. So if this was something that you were actually going to publish, is there a line even say, like, distribution file that you actually want to? I think it just uses the repo. Let's check out the bower command register just in the shower. Finally. Open source. It's already copies like this. Oh, that, Uh, that is the main field, I believe. Let's go check the paradox. I'm pretty sure it's the same as packaged Jason, though our mean I mean, yep. So you just add Maine and then the path to that file, and then, um, that's what it would use. So it works in conjunction with ignore, because this might be in some sub tree. Right? So say you say I'm gonna ignore all of these other files, and my main file is this but its existing this sub treat and the subject is also part of ignore. It will just pull the main file down when you do a bower install. So that's how you as the module author, you can control which which thing is for example, if I had a power dot Jason, or if Justin had a power that Jason in his extend repo that said it was extend, then it would pull it in his extend when we grabbed at the sink, so

Reorganizing the Application
[Autogenerated] so let's go. Next. Um, I think we exhausted all of the bower topics that we're gonna talk about. I think for the rest of this, we do keep power as the as the vendor management strategy. But this commits pretty small. The only thing it does is a line, um, all of our code inside of a nap directory, because, really, we should have sort of some way to define the source in app seems to make sense. And a lot of other tools use that moniker to sort of that bucket for where to put the application source files. And now it's clear when we come to the route that we can see sort of. The rest of this stuff is configuration related on Oliver AP source lives there. So that's the only change. Their, um I did wanna highlight what this made us have to do is pretty minimal in terms of changes. We just had to update past the things So for age to mellow lives in cap index dot html on, then less lives, an app CSS. And then for a coffee compilation in absolutes. Coffee. And I think that was about it. Uh, right when I updated Thio angular 1.2, I had to inject n g wrote because, um, they made it a split module and you have to use it as a dependency in one dot to So I did that. Grant clean Another way you can string task together is just by doing them as chains. So you can say Grant clean run. Sorry, Grant Clean default, which will kick off our so we'll do the clean first. Then it'll do our depth workflow just to make sure all our paths were still good Looks good to me. So let's go to the next one, which is template pre calm pollution. I think I'm going to stand again Mrs Shares just a little too short. So if you remember looking at our index html, all of the sections for this app are sort of in these top level dibs, which are really sort of belonged Thio the controllers and the directives that in Stan she ate them. And so one thing I thought would get to do on is good from a workflow perspective is to pre compile that stuff into the JavaScript so that we wouldn't have to remote load it if we wanted to store them in separate HTML files, and we could do that with, uh So I've added a templates directory under APP, and I've put three template files in their character selector dot html odo dot html and stat editor dot html. And, uh, they're the same that is in the index. We're just kind of moving them there as stage one of getting stuff ready to pre compile. Um, but this is a general best practice. I think when you're working with whether you're working with backbone or ember angular is to pre compile your templates. Um, it also allows you to isolate units of code so that people looking at the package or at the at the file structure in the in the APP can go in and say, Oh, I need to make changes to the character selector portion of things I can just go into templates, character, selector and make that change. So next will give us the actual grunt task to do that. And it's called grunt, angular templates. So if we NPM installed grants angular template stashed, I save. Now stick that in there for us. Let's take a look at the grant configuration, so the root config name is N G templates. That's the name of the task, uh, the key maps to the name of the angular module that these templates will be injected into anglers template cash for So if we look in coffee and ap dot coffee, you'll see that this file is loaded first, and it defines the module TVs. The banner saga dot battle planner N G. My original one was in backbone. So I just added the N g for you to note that this is angular so that key is important. A t East in so far as pre compiling for angular using N G templates, some options that we've seen for other targets of the base level that we're gonna pull these files from which is apt templates and then files source and desks familiar as we've already seen files that templates that source and compiled. So we go back up to files. They're they're so glob ing for all of the templates inside of that directory. And then again, we're going to stick it as a deaf art effect into template cash. Yes. Now, if you open index, you'll see that I replaced all of those sort of big sections with simple custom elements that you could do with angular directives. So one for the load out. One for the character selector, one for the stat editor. We've also got some new files inside of directives that correspond to each of those. Let's look at just one of them. Load out. So here's our module. We're going to restrict it to an element. We're going to load this template via this template, you, Earl. And the way angular works is when this when angular skins the dom for the element that matches this directive which is slowed out, it will check the template you, Earl. It will try to remote loaded if it doesn't exist in the template cash. And if it does exist in the template cash at this key, then it will just pull it in. And when it sees this element, it one Stan she ate a controller called the LoDo controller. Let's see if this all works. So things were looking good. We can open up to have tools. Take a look at this file and there we go. If you if you grab for template cash dot put and a quote. You'll get to the output of that that process of our build. So our key was injected properly as the module TVs stop, Battle planner and G, um, and angular has a run function that you can use to a cz part of its life cycle. You can do certain pieces of work, so in this case we inject the template cash, and we stuff the templates into there. And the key is that base path, plus the name of the file. So now those don't have to be remote loaded. And if we look in elements, you can see that those things are in there and there's the load out. There's the character selector And if you didn't want the load Oh, for example, this loaded route element to show up you could go into load out coffee, and I think you just add replace True on. I think I set up watches for the template I might not have. Let's check. Yeah, I didn't set up watches for the templates. Okay, so we can just restart, Grant no, close those other ones and open chrome deaf tools again. Look a elements and now I don't have that load out route element. I just have the element that got replaced. So it's an interesting way. Just a little comment on angular Thio encode sort of an abstraction in your markup. But the output in the browser, the compiled output is basically the stuff that goes inside. This is kind of like that backbone shell approach that we talked about with the difference that once you get inside of the template for load out, there isn't really a shell in here. You can see all of the markup that gets stuffed into there. So that's just a a side note on angular stuff, some performance considerations when you're doing this. You know, we were talking about bundle sizes and if you're gonna be in lining your templates and you have a lot like we have 450 plus and Shopify, you're gonna want to slice that, Uh, usually the best way is to kind of look at what files have a lot of action. So vendor files Js files typically don't have a lot of change. Maybe you'll upgrade like the version of a career, the version of whatever library using Once in a while, but for the most part, those bundles can be long lived in the cash on and templates, at least in Shopify. The Edmund templates are changing all the time. So I mean, we just We're not gonna get much good cashing around them anyway. And if you're working for a company that's doing lots of continuous deployments and stuff like that anyway, then I mean, it's good to have the cashing strategies in place so that when you when the activity drops, you get that good benefit from cashing. It's interesting I was in new relic plotting, sort of, uh, the traffic. And because we don't do deploys on the weekend at Shopify, that's basically when users would be getting the most benefit. But there's also a surgeon traffic on the weekend. A lot of people do working Shopify on the weekend, so customers rather so then are cashing kicks in and, you know, for the weekend we've got good cash characteristics, and then when everything gets back on Monday and deploy, start going, then all those cash bundles Aaron validated every time we deployed. So any questions about angular template pre compilation just compilation General do you guys remote? No. Originally, the Shopify admin did remote load all of its templates. But there was a significant overhead because some of the areas of the APP would remote load, like six templates. So that's likes and ex HR requests for each template, right? It just becomes a lot, especially when you've got service and points that you need a low data from, Um so we solved the template issue by bundling them at the cost of a larger payload for the user. But there was not really a noticeable decrease in customer satisfaction when that happened. And ah, yeah, so I mean, that's that's one strategy of use. It was going to say the other thing that we're looking at doing was batch ing up our service and points When you start developing a rich client up, it's very common to have many service and points and be piping a lot of ex h ours, uh, and it's you can run up against the concurrent http limit for browsers, they have ah, max number of simultaneous connections that can fire out per domain. Eso One way you can solve that is by, you know, having different domains for different service is, but that becomes logistically challenging just due to cross the main, um, origin stuff. Uh, so the best solution is really to think smart about, you know, what is what does this end point need and batch up all the data for it at the service side, and then just deliver one request with multiple keys at the top level for your Jason response? We're in the process of kind of re evaluating that right now. I'm just cleaning it up so that, you know, the ideal is that you have maybe one or two x h ours for any given page in the single page up instead of right now. It's like five or six, depending on how many service and points get hit.

Sourcemaps
[Autogenerated] source maps. This is kind of the cooler, one of the cooler features. Let's open up the steps file, I think, Yeah, this is where I started organizing the steps so that the end artifact that you guys take, you can see which steps we did it. Which parts of the talk? I think we just need to install it. Let's do that. And let's take a look at our file to see what configuration changes this implies. And so now, because we're doing the intermediary compile with coffee, we can swap park and cat task to concoct source map, which will take all of the files inside of the generated coffee compiled folder on DK captain. Eat them and merge them into ah bundle, but then also generate a source that bundle How many people, anyone deploying source maps in production? We're using them in death right now. No. Yeah, it's. There's still a lot of integration pain because a lot of the tasks like grant contribute coffee, generates source maps with a different girl at the bottom. A different pregnant than Grant could cast source map. And then there's Ugly fi, which can also generate source maps and Then you can have chains of source map so you can have an input source map from a previous compilation that you don't need to use toe. It's just it's crazy trying to get it all integrated. But so the simplest solution I've found is to not worry about coffee script source maps because debugging and coffee script is kind of hacking. Anyway, I'd rather debugging the JavaScript. Um, and cat source map is brilliant. You can drop it in and basically replace your cat task. So if you're gonna set up a workflow with with Greg can contribute cat, just swap in cat source map, there's a couple options that are good to configure. One is this source is content, and I'll show you what that looks like in the open file. Um, and then, yeah, we've got our target for cat source map the APP, and is basically for our single bundle. We want our vendor files, the the compiled coffee files and then the template files, and that is gonna make up the one bundle that we're gonna generate source maps for and stick it inside a generated slash Js slash abdomen. So now when we're on this Get open pop open from Dev Tools. And now we've got nice folders so we can debug into those individual files is gonna close these. So here's all my power modules that got pulled in and it includes the path in the in the source mapping. And here's my generated. Here's my compiled coffee so I can look at just app gs. I can insert a d ______ in here. Uh, maybe that's not a good one. Let's try this one. That's not a good one either. There we go. So now I can debug in the individual files, but they're not actually loaded. I only have one http request. So if we check out the network tab, um, let's reload. You can see it's still only loading one file. So that's pretty kick ___, because I get the performance benefit of how things are in prod in Dev. I only load one file, but I can still debug is if I had separate files with the source map Onda way That source maps work is, uh, when you look at the bottom, if you go back to sources, let me go to AP. Minjae s just closed some of these things make this bigger go all the way to the bottom. You'll see that there's this funky looking comment. This is called the source map pregnant, and it's basically just, uh on indicator to whatever is gonna consume it, that this is the girl that the source map file lives at. And this is requested on Lee. When you open chrome deaf tools so it doesn't impact performance on your production site. It's only like a developer workflow issue. And so, once you open it, then from def tools issues the HDTV request. Um, it's 1.2 megabytes right now, Um, and it got a three or four not modified. Let's see what it is. Yeah, it's still 1.2 megabytes. So because it's not getting Jesup, for some reason, that's interesting. There's probably not a inn express. There's probably not a default mime type Thio tell the compress middleware to compress maps so that support request I could make to express so that it compresses source map. Let's look at the source map file. We can open it up in, um so if you opened generated Js, don't mend out. Yes, stop map. Just stop Yeah. So open that one. Oh, no application knows how to open it. All right, if, uh, you Hee hee is my alias for sublime. Um, you could also do them if you like them or whatever. Or you could just go here and commando and browse. Do it. Let's do that. Then everyone can follow along. Yes. So it's basically just Jason and it has a version. Property there on it oration three of source maps. It's not a fully functional standard, but it's pretty close. Um, and it works really well right now, like we shifted in production in Shopify. Um, and it's already yielding benefits for our support team. So which file? The source map is four. Uh, what sources exist in this mapping file? So with their paths. And that's how chrome Deb Tools knows to expand the folder tree when you're looking at the map sources, um, and then map ings, which is just crazy encoding to map the original line numbers from the men. If I'd bundle back to the individual sources and then if we scroll all the way down, not that far. There you go. Um, the way that can cat source map works is if you turn that sources content option on, it'll actually in line all of the sources as part of sources content. So all my app sources are in lined in here as an array and each entry and the ray maps to, uh, let's go to the top maps to each one of these sources. So the first entry and sources content would be Jake worry. The second would be angular. This is not a common workflow. I haven't seen too many people ship this. I actually submitted the pole request to grant can cat source map to get sources content because I went digging in the source map spec and I saw that it was available. And I thought, Why is nobody doing this? Because the alternative is to have to load each of these individual files in your static Web server in development, and then chrome will actually make a request for each one of those when you click on it in the source map. And I'm thinking that just sounds like an integration nightmare, and I'd rather not think about it. And they already had sources content. So I was like, put two and two together, and it seemed to make a lot more sense to me to load one map file for one bundle but contain all of the source files in the map file so that you don't have further requests to the server. And if you're gonna deploy source naps in production, this makes it a lot easier to you. Just upload your one map file to the server. It's a deaf concern. Only you don't have to worry about regular users, you know, having to request that file because it only happens when you open chrome deaf tools. He's gonna check my notes. But any questions on source maps was interesting. The the pushback Originally when this feature was introduced at shop, if I was kind of struck me as funny, the 1st 1 was, Is this gonna cause a security vulnerabilities? Because people can look at our, you know, unmodified sources and see how the APA structured. And so we talked to the head of security's like, You guys are crazy like security through obscurity is not security. So what? Why would you even consider that this is a security vulnerability? Number two, the benefit that the support team gets when they have to track down stack traces is much better, because now they're not looking at a man. If I'd bundle with, like, mangled argument names, they're looking in, you know, this is what file this air originated in. So the time for developers to be able to sell problems just got a whole lot smaller. Thea other push back, which was an interesting one, was people felt like it was exposing their work to the public because anyone could go on open chrome deaf tools. And I kind of said, Well, it's javascript, It's already exposed anyway, like you could run it through an unmanned ifyour and kind of understand the characteristics of the op. So if those are some things you might, you know, encounter pushback on and maybe pushing source maps to production isn't for everyone, but it's definitely a GN awesome development, workflow improvement

Backbone
[Autogenerated] let's flip to backbone, which I think happens in _________. Uh, just make sure I don't have change is good next. And there's a bunch of steps that happened here because I didn't want to go over everything again, but we'll just kind of get the highlights. Um, the first thing is that I wanted to do this to prove that our workflow is robust enough that we could swap in an alternate framework and not have to change very much about what we've set up already. And that's pretty cool. If we look at the diff with get show, obviously the vendor dependencies, they're gonna change. Which means we're gonna need to run our install, cause those were in the bar, Jason. So you can run Bauer install right now if you want. Um, so I got rid of angular and angular wrote, and I pulled in backbone and backbone fixings with which is a view obstruction that lets you get some really good rendering helpers that the guys that test double wrote backbones Stick it, which is a two way data binding plug in for backbone. If you haven't used it. The guys from ah, New York Times I think put this one out as well on then handlebars, which is one of the popular template ing libraries that you can use a backbone views. So we, you know, normal stuff that you'd have to do if you're switching frameworks. We just dropped them into place in Bauer changed the dependencies and hip power installed. There was some load order, things that were different because I don't have directives and controllers and service is in backbone. I mean, I could create those abstractions, but they don't exist a sort of core framework features. So that went away. My templates changed from dot html to HB. Um, I think I just changed the order of that. All right, so this is the ______ Cases like how angular doesn't care about the order of things right. I could include the template, cash and angular after included the AP source, and it didn't care because it waits until the Dom is ready. It waits till all the files have been loaded to kick off the APP backbone. Because a lot of the views are statically defined, referencing a template. The templates need to come first. So that was the only thing that I had to change here, get rid of energy templates to do pre compilation cause we're not using that, and we can swap it in with handlebars. Handlebars can fix. So here's some options for that. The name space, the sort of convention around. This is JST, which is stands for JavaScript, templates on, and this is what exists in the window as a global. And that's where all the templates for backbone get stuffed wrapped True is just a configuration attribute that you can set so that handlebars compiles them the right way. And, yeah, we just have the compile and we just swapped out our source files, that template stuff source. And if I was the template stop compiled for the destination, we needed to change up our workflow just a little bit to include handlebars instead of energy templates. And then the rest is just deleting all the coffee script for the angular stuff and using, um, the backbone stuff. And in some cases, I'm just using, like a root level class object and not even a backbone. That's the battle planners. It's just a coffee skip class. The rest is backbone. Let's take a little tour of this because I want to show a couple of things. Um, this little abstraction is actually what you get from two things. One if we look in Broward out, Jason, this guy extend Js. So if you go check out extend Js on, um, Justin's get hub. So if you're working with backbone, chances are you're gonna be working with just, like name space for, you know, architecture of your app. You got a name space on the global window and extend makes it really easy to, um, give akie path and have whatever is passed as the second argument to this function. So in this case, I'm defining TBS start router, and that's a key path. And, uh, extend says, Hey, window. Does TBS exist? If so, at a member called Router and stick it on there. If TBS doesn't exist, it just creates it for you. And does it And this eliminate some of the load order headaches that you have with backbone. Because if you were to do this just with javascript, you would get an undefined error if you tried to assign a key to a value that didn't exist. So this saves you know a little bit of a loader headache and the normal keyword uses extend. But we found that this confused people when using coffee strip coffee script because you've got the extends keyword for doing prototype of inheritance from a coffee skip class. And so we thought we'd get clever and deaf eyes used in both python and ruby. And so we just created a little wrapper around it that you can see inside of this config inside of extend underscored 60. Because backbone doesn't have as many conventions around how to store and access templates, we cash the name, space path of the view using this function here. And that's on the prototype. This gets around modification. So it started as a string on it's encoded. And then what that does is if you look in backbone fixings. This is how we are basically by convention mapping, which template to load based on the name of the file. So these are just, you know, little helpers that we built up after building a bunch of backbone naps. And, you know, normally, in a backbone view, you have to define, uh, your template has sort of a top level key And then you might see something like this handlebar start, uh, compile. And, you know, if it's stored in the dom, you might have passed it in as a J. Khoury selector in some, you know, character selector dot TPL and that element contained the template. If you're storing it in, the script takes. So now we just get rid of that. And this uses the convention of what's the last fragment in here? Character selector on that little Shim goes and says, you know, app 10 places where it is and then get the sub path for that. And it basically converts this to snake case so that it can look up the template name. So just a little bit of convention that saves you having to distribute all that kind of template logical over your backbone stuff. And you can get backbone fixings. Um, which is also in here, also produced by test double. It gives you some sugar around render and the idea that you can create views and have render after methods. See if we can find an example of that. Yeah, here we go. Um, so the idea is that you know, everyone that sees backbone knows about render, uh, is sort of the place that you inject whatever into the dom. But what if you wanted to have something render after that, you'd have to manually set up that chain. So what we did with fixings was created so that any method that you prefixed with render um, gets called after the initial renders happened. So this takes care of waiting, you know, having to either differ or set time out. Zero So that the temple it exists in the dom, and it just gives you a nice little d s. L so you can say, Oh, these things all happened after the initial templates rendered. So I'm gonna render the attributes that stats overlay that we see when the when the unit is Hubbard, I'm around her some help text and the allocated stats overly. Just a nice declared of way to do that. Not much to do with work full. I just wanted to showcase a couple of things for a year if for those of you still doing backbone app development, so yeah, the original point I wanted to make was that, um we really didn't make that many changes to our grant file. You know, our core work flow is still in place. We can run the app. Oh, I didn't power. Install and PM and soul, perhaps? Yep. Grant Contrabando Bar said to come in. You can do the same things Bauer, insulin, NPM install, and then you should be able to run it with Grant. Okay, Anglers not to find. I think I need to grant clean. So I get some stale data left over. There we go. I don't know why the file system held onto those files or whatever, but and so now if we click through, um, this version is actually more full featured, so I can click on this guy can rank up in backbone. I can add some stats to reset to minimums. This because this is the first iteration of this app that I wrote, and I actually shipped it and wanted Thio posted on the game for him that I was building it for So and there's like, a little alert that pops up to say I want to remove this guy from slot three. Let's look at sources. So again, we didn't change much in our configuration, but we changed a lot in the AP source. We swapped out frameworks and we changed, like our template loading strategy. But our grant file didn't have to change to accommodate this. Really? Like we swapped handlebars for any templates, and that's really it. Just pointing to different paths shifted a couple of interdependencies empowered. Jason, we still get source maps so we can look at all of these things. So as I was working through this, I was thinking then is this gonna work? Am I gonna like, check out the next branch and things were gonna explode on? Aside from that, that sort of stale data, I was rather impressed that we could swap out a framework in the middle of our workflow workshop and not have to make too many concessions. Really? No concessions. Just changes in our grand file. So that kind of validated to me that this, you know, at least our workflow is robust enough. At least using grunt to do this kind of stuff is solid enough, you know? All right, So the question Woz about maintain ability. You're a big company, and you wanna implement door with a couple of ground plug ins? Yeah, I was ramping other developers on the process. Yeah, it's been challenging because, ah, lot of front and developers, it seems like started as either designers who are shifting rolls into developers. And really, what we're doing with this type of work flow is stuff that was traditionally done on the server side. Um, you definitely want to keep it simple and start small, like if you can find a small area that's painful to work with and just read a workflow around that on Get buy in and see people use it with the designers on the team at Shopify, I kind of asked, You know, what's your what's your ultimate dream of what you'd want to see and what they wanted was like to be able to generate image assets with SPG so that they didn't have to keep producing the retina icons for retina screens. So we started with that, and then we did in lining the images with a 64 so they didn't have to think about how to manage those image assets, and then the workflow became like Now I just dropped my SPD into this folder, and I just dropped my image into this folder, and magic happens on the other end, and they're just like once they saw that they were, they were pretty bought in. So, um, the complexity aspect, I think it's just you have to educate people and you have to. It's hard to transform a large organization fast. You need to do it slowly, incrementally. So I think that's probably the best way you can do it all at once. But I think the better approaches toe is to bring people along slowly and sort of give them the benefits of it over time, instead of trying toe make a drastic change all at once.

Yeoman Introduction
[Autogenerated] So we looked at grunt. We looked at a lot of different ways. You could integrate grim plug ins, and, uh, now I'd like to take what we have left, like an hour and 1/2 fish like to kind of blaze through Yeomin and linemen because I think that there's probably some really good stuff in the bonus topics that people want to hear. Um, and because we've already learned about Grant now, a lot of this stuff shouldn't be a mystery to you. It's basically just wrappers around grunt. So let's walk through a couple of differences. Yeoman has similar to grunt similar to N. P. M. A global command line tool that you want to install called Yo. So if you do in P M installed Dash G yo, you'll get that. And when you've run it, you'll see the dude in the top hat. I guess he's the yeoman, and you'll get, like, kind of a wizard approach to, uh, the things that you can do. Um, and some of the things that you can do with yeoman are used generators and, um, generators. If you come from, uh, project background like rails where you can scaffold out new controllers or new domain objects. For your application, you could do the same sort of thing with yeoman generators. So in this case, we're using the generator backbone in the screen shot there. There's also generator angular. There's a whole bunch of different generators that you can get on. They will do scaffolding for you, so actually scaffold out the whole project structure in the grant file and everything to get you running on, and then you can also use it to generate individual pieces to it. So I generated like pieces of the app that we're using the unit, the battle plan, her class for a router and then the unit's collection. I personally don't find generators to be too useful, uh, as you get further in the life of a project. What they're useful for is for people new to a framework, right to get a sense, for this is what the object model looks like for a backbone model, or this is how I would stumbled and angular controller or things like that. The problem I've found with generated code is that if you rely on it as a strategy, what ends up happening is, it usually gets stale pretty fast, and this is very easy to happen. So I saw this happen with human, where they had a strategy for generating that changed between releases on the back own generator. And so people that had generated code with the first revision then went and, you know, a plate up dude to the new one. And they generated code in the way that it changed broke so they couldn't, you know, interacted those things. So my preference is to recommend that people use generators a sort of, ah, learning experience, but don't rely on them to stub out individual pieces of your application. So they also support scaffolds. Eso, once you've installed either generator angular or generator backbone, then you get these top level commands available inside of Yemen. And this is what you used to scaffold out a new project structure. You kind of see it's creating all this stuff here. And here's the project structure and this shouldn't look, you know, all that unfamiliar after we've gone through all the grunt stuff right? There is a top level app directory. I called it. I am G. They called it images. I called it Js they call it scripts. I called it CSS. They call it Stiles on Dhe. Then there's some other things for Web applications and HT. Access file. If you're deploying to Apache, they've Yeoman has, ah, a lot more comprehensive sort of generators and scaffolding than some of the other libraries out there. But in that regard, it's awesome or opinionated about how you structure up. So what I've found is I don't necessarily need all that stuff, and I prefer a smaller subset when I'm gonna generate a new project on, and that's what we do with linemen. We we're still opinionated, but we're very careful about our opinions on, and we generate a much smaller payload when you can scaffold and we only have one scaffold. So that's a woman's project structure. Again. You get a grant filed out J s, which has all the task configurations, and we'll take a look at what that looks like and kind of how big it is. Um, I'm a little disappointed that they generate a Js file because, as we've seen, I like the coffee script style configuration files. Just a little cleaner and easier to read

Browserify
[Autogenerated] So if we go next, I believe that has Theo men one? Nope. It doesn't. Right. I forgot about the browser. If I want Sorry, I'm gonna jump back in time so that we can look at dependency management. I totally forgot that That's where I was going. Well, look a human next. So these are my notes on common Js. So I looked at, um, a m d a synchronous module definition. I've looked at, uh, what's coming down the pipe in Essex, which to me doesn't make a lot of sense to invest time And until they sort of worked out all the standards and that it's kind of on the bleeding edge, um, and then common Js There's another one called UMD, which is universal module definition, and it aims to be sort of all encompassing. So whether you're using a m. D or C Js or even six modules, it's supposed to provide some level of interrupt for your module system, but it doesn't um it also implies a little bit more restrictions on the tooling that you use for UMD. So, to me, Common just makes sense because as we've seen today, we've already used common Js. In all of the examples, common Js is the model system that note uses with synchronised require on module that exports for exporting functionality. So let's take a look at what our code had to change to you. So the coffee folder still exists here with all of our original sources. But I created a CGs folder, and I basically Reef acted the entire application from referencing things on the global scope to injecting dependencies explicitly, I should say, requiring expended dependencies explicitly. There's no injection happening. So before, none of these lines at the top would have been here for the battle planner class because all that stuff was just set up on the global name space. When you switch to common Js, you need to use, require and actually pull in the individual pieces. And so we can see that all of the things that are needed for this battle planner to operate our kind of encoded in this list of dependencies that I'm pulling in from the top and the location of those. And there's some interesting side effects of this one is you can instantly see the surface area of how big your application is because this is sort of one of the the primary entry points for the up. It's not really The bootstrap file is the 1st 1 It requires app dot coffee. And the way that, um, common Js works is it's gonna go through the entry point, require this, you know, go into here and then recursive lee go through all of the requires and resolve the dependencies in order to get all this stuff working. So before, for example, when I was using the global strategy in a name space, this would have been TBS stuck collections, that unit's. And now I'm not using a global strategy. I'm using the explicit CGs require. And so I could just localize this here as units and it's no longer a global. So this gives me some measure of insulation that, uh, nobody's gonna be able to clobber this object at runtime because if it exists on the name space on the global scope, there's always the risk that some third party code could come in totally trash my name space on this insulates from that a little bit, but it also comes at the cost of needing to add build configuration so that we get this working properly. Let's take a look at what the configuration was set up to do. So the one thing that changed is our list of load orders dependencies that we had with the file blobs and everything now becomes a single line because bootstrap is just that the main entry point s O. That is kind of nice that we don't have to think about that. We can point our build tool at that one bundle and say, Hey, you know, go resolve recursive Lee all these requires and generate me a bundle on the task that manages that is for the library that manages that his browser. If I The task is called Grant Browser. If I on here, I'm using that destination source mapping. So whatever I have for AP compiled is false that yesterday I mean, which are these two entries here on because we've got coffee script. Still, we don't need the grant contract coffee plugin because browser, if I has this idea of transforms that we can use on. So if we install coffee if I eyes a node module and then we tell browser if I to use that transform. It will apply the transform in line and then spit out the bundle. And it's actually pretty fast. I'm just trying to think of it. We needed to make any other changes. Can cat source map, I think, still works the same. But it's broken in this because the output from coffee if I eliminates the source map, So that's a bit of a problem. Um, and then, yeah, it was just basically swapping Can cap. We're not going cat coffee for bras. Verify. In our task life cycle, let's go see how it works. So let's install what we need to get this running, which is gonna pull down grunt browser if I and coffee if I transform and I don't think I have any Neubauer dependencies, I'll just check. So looks like ____. It's still working. Yep. And if we open from Deb Tools, so yeah, my source map things went away. It generated the source map bundle, but because the intermediary step where I was compiling the coffee script into that generated folder is no longer there, I'm using the coffee of flight transform. Then I lost that that source map generation for all those individual bundles. So let's take a look at sort of what the generated JavaScript is, what kind of characteristics it has. You can see that there's some metadata that is encoded here by the browser. If I bundle that says, you know why this dependency was required? So which file and what line it was required on? Um, And then you can see this function here that injects require and module and exports on because it's in the browser doesn't mean it's required. Yasir, MD. It's still common. Js these air just key words that are used internally by what brother? If I generates to resolve dependencies inside of a closure. And so this is what insulates us from the global scope being polluted. None of this stuff lives on the global scope anymore. And so I'm sorry. So, yeah, we've got a little bit more security about how things are structured and again, we didn't have to make too many changes to our, um, to our workflow we plugged in browser. If I, um, the biggest change, you know, as kind of makes sense was re factoring all the source files to use, um, this This actually took me quite a well, but it was an interesting exercise because it made me realize how many global dependencies I was referencing in this in this tiny little app as I went through and did it Does anyone have questions on common Js or browser? If I or how all this stuff is kind of piping together, I should mention, uh, in node when you use require for common Js you do not have to provide the file extension on and you don't have to do that either if using just JavaScript files with browser If I, um, that restriction is only applied when you're using coffee script in the coffee transform, it has to know because otherwise it thinks that you're trying to load a Js file. So if I, you know, whacked that that would be valid if it was a job script file. But because we're using coffee, I need toe be specific about the file extension. These air also relative paths. So in some cases, if I'm down inside of use, for example, where's of you? Yeah, you can see here. This one needs the config function, Max. That's point for rink. So it has to go up up a directory, so it has come back up here and grab that. But that makes it apparent that it's just purely a synchronous require that is, just traversing the file system and grabbing that so that it's loaded at the rec point when it needs it. The other thing is because there is the potential for duplication. Multiple files could be requiring multiple things. Uh, broad Verify has a deep do cliff I algorithm that removes the duplication in that would put bundle. And I haven't seen this cause any problems in my code. But I know that there was an open issue on the browser. If I get have just talked about some bugs being introduced by the de Doop algorithm because they have to basically go through and walk the dependency graph and say what's has already been included, what can I avoid? Including it twice, basically, did you have to re factor your application? Yep. So before I was doing like this, one would have said, uh, great, so that I had to do that factor to say model got exports. That is basically the only thing exported when this file is required on and then any dependencies internal like this unit. Then I had to go and required. You don't have to do at the top. You can do it in line anywhere. I just The convention is to do it at the top, but this would have been tgs dot models dot unit again referencing a global So it wasn't so much like, uh, hard to do. It was just tedious was a chore to go through and, like, you know, wack all of these deaths and replace them with macho about exports. But I was impressed with how fast the brother if I stuff, walked the tree and compiled it, even with the coffee transform. And there is a cashing coffee if I that you can add, which does the same thing that we implemented with Grant newer toe optimize so that it'll only re compile the files that have changed on disk instead of having to re compete the whole bundle so that one looks like it's pretty easy to drop in. And I think in the next commit, I fixed the source map support. Yeah, so sore snaps in. When I was first integrating this, I didn't know that there was a source map option, Ambrose verify. And it turns out that you just debug true, which is interesting because it again shows sort of the infancy of source maps. It's like in the browser if I world source maps are a debug flag that you flip on for development, but it's probably not something you'd want to push up the production. At least that's what it seems like. They're for your point is. So I was like expecting maybe there'd be a source map option like all the other tasks have. But it's debug. And so if we run this and run grant and open up sources and now our source maps should be restored. No, you got it. Reload! Here. Oh, right. Um, so there's this funky scenario where I'm using cat source map still degenerate source maps. So that's what this is because that's what can cat source map gets his input. The source maps for browse verifies transformer up here and now I can actually see that I've got coffee script, transforms working our source maps working, and I can insert a break point on here and reload. And my break point should hit. So now I can debugging coffee script if I really want to do, which is kinda cool. But again, my preferences city bugging the generated JavaScript just cause this is not quite production ready yet. They still need to fix a few issues with source maps for this to work. But it's nice that you could just have the debug flag and get the coffee script support for copy script source maps in the browser if I transform.

Yeoman Workflow
[Autogenerated] Let's jump into Yeoman, You're next. And I think this brought in a human workflow folder so we can just go into that and we're gonna have to install because these are all packages that we need in here. Uh, I think we say power installed and him and stall all those 30 four's mean, it's just pulling it from N PM's local cash on disk, which is nice. There's, like quite a few more dependencies that Yeoman pulls in because it does a whole lot more cool. Let's look at, um, that project directory. So I'm gonna kill these files and close our APP directory. And now we have a yeoman workflow directory that we can look at, which has all of the project structure as human would expect it. So we've kind of seen some of these. We've got how yeoman likes to store Bauer components in sight of app slash our components. Ah, there's an editor config that I guess is used. Thio. If your editor supports the dot editor config file, they would have some opinions about your editor. This is something I find really controversial, to be honest, because I wouldn't want somebody to change my editor settings in a scaffold that got generated But you could always delete it if you don't like it. Some get attributes, stuff the default, get ignore which we kind of set up in the groundwork Low G S and R. C. This is a configuration file you can use for Grant. Contribute yes. Hint to sort of tell it what options you care about. Um, Jake Re true would be. I think it's just flagging. Jake Reas a Global Here's Bart, Jason. This is what I added for the same dependencies that we had before. Here's the grunt file and there's a whole bunch more config that it generates. There's a lot of things that seem out of date in the human scaffold. So, like the live reload port that's already encoded in grant contribute live reload as a default. And I guess maybe they're doing something different with live reload that I'm not aware of. Here's their version of the little server test that we wrote they're using Connect, which is a node module that allows you to start up a static file server with connect out static. This one was kind of cool. Actually, I didn't know about it, but time grant. You could just mix this into at the start of your grand file, and it'll give you a lapsed time at the end of the Omen tasks. So here's our path config that their encoding a little bit differently for application and distribution. Here's their watch targets for everything that they're gonna watch for you. It looks like they're using the old live reload plug in instead of grand country watches. Live. Reload. Eso me that's a little bit out of date than handlebars to complete. Compile all of our templates. Here's connect with the port, so ours was server and Web port. There's this connect import on 9000 a test server. If you wanted to run tests, um, than the distribution server if you wanted to test your distribution, uh, here's open, which will when you run it, open your browser to the report. The jazz hint options mocha for the test runner coffee so they like. It's like the kitchen sink of conflict stuff in here. Eight. Like it's there's tons and tons and tons of stuff. Here's the server task and a bunch of conditional stuff around. If the target is dest. Other ways injected into the test run. The tests were, I guess, and here's all their sort of work flows. So there's the server workflow. Run the server, compile coffee templates, handlebars, compass. Which is why that if you're working with this on Windows, you might have problems installing this because they default to Compass, which has a dependency on SAS, which has the dependency on Ruby. Here's the test command. So they're using mocha as the default tests adapter on their build command. Let's just kind of get into the workflow and and see what works. So if we do grunt server, that's gonna do a whole bunch of stuff. I mean, it's working. The output looks the same, right? But there's just a different order of tasks and they store things in the temp directory. We put them in the generated directory. Uh, I have re be installed, so it ran compass to compile things. Um, it's got live reload running on port and or there's connect on 9000. Yeah, there's 9000 and the watches or set up the same. Let's check out the generators. I could show you how that works. I think so. If you do just yo, you get that little wizard and you can see what's going on. So there's I've installed the angular generator and the backbone generator, and I didn't install the mocha generator. It looks like they did that for me. So I'm just gonna say, Get me out of here because I don't want to do any of that on. I'm gonna say, yo, backbone model unit That didn't work. Try to remember what the command was. Thank you. Perfect. Um, I already have it existing, so I'm just gonna override it so you can see what gets generated. So if we open that file now in sublime, uh, let's just click it cause I still have the old source in here, So AP Scripts models unit. So this is like, I mean, it doesn't give you a whole lot. And the other thing that I really found confusing about this was that it stuck it on the yeoman workflow named space on the global. So it's like they generate. And then they expect that you're gonna use yeoman work flow as your global, Um And so, as I was going through, generated all of these and then, uh, worked through integrating them. And then it just proliferated throughout the whole apparatus, like window dot human workflow dot Whatever had to go in all of the places that I had had tgs dot battle planner dot Whatever. So that kind of confused me. Um, but I mean, I guess you don't have to use the generators rate. It's it's just sort of. It also doesn't really give you much, you know, like if you know how to do this, uh, you could generate that on your own pretty easily Sublime comes with, like can It doesn't take long to type that. I think there's a sublime integration you could do where he hit class and type tab, and it would generate it free and copy, script the generator's working coffee script or back our javascript as well. So I mean the apse pretty much the same. The folders of where stuff is stored is what's different, and then some of the tasks are a little bit different. Um, the task configurations, but I mean, it's just grunt under the hood. It's really just a bunch of opinions on. Howto had a manage grateful against

Lineman Workflow
[Autogenerated] next. I guess I got a that. I'm gonna go back to the root directory and then do next because get crawl has to work at the root directory. So if you try and you get a call from a subdirectory, it'll tell you you need to be in the directory. So let's look at the linemen workflow. Now we can go into line when we're CLO and PM install. Here we go. Let's open up that directory and take a look So pretty similar. The difference is we've got spec, um, for where we include a bunch of tests helpers by evil lineman originated as a project out of testable. Primarily, Justin wrote it as a way to get me to do test of a development because I was anti testing and development because it was so hard to set up. And the feedback loop was so wrong. We were doing a rich client development with the y you I did a table plugin inside of Enterprise Java application, and we're trying to test drive it and we're using the Jasmine Maven plug in. And it was like, literally run the tests and it would take, uh, you know 30 seconds to compile everything and toe get your feedback loop, and we just I was so frustrated. And so he started on this as a way to both learn node and, uh, see if we could shorten that feedback loop on test urban development. So that's included by default when you scaffold with linemen. And then the APP folder looks pretty much the same as what we built with the vanilla grande flow. So they're CSS, which can continue unless cess CSS or any combination of Image Js, which can contain coffee or Js Lyman, gives you the ability to create individual pages for your app. The the default one that it gives you is an index file, but any other template files you add in here. So whether they're HTML or HB, Lightman will generate individual HTML files in the distribution artifact. So if you want to create multiple pages, you can and then templates is kind of the top level. Um, the distinction between lineman and Yeomin is really two things. Lineman intends to be used primarily for rich client development. Yeoman has generators for that, and then, just like general Web app development, they have generators for, like, mobile specific apse. So they're trying to, like, really cover a broader range of scaffolds and generators that you want to use with linemen. It's purely focused on rich client NBC. At least that's the core of it. We have some extensions that I'll show you in a little bit the way that we can figure kind of aligns with how we set things up with grunt eso this CONFIG folder on Biff. You're familiar with rails? Ah, lot of the conventions and lineman match rails because Justin, the guy a testable, came out of a ruby background and rails background. So you have config in River Island, where all your configuration files live. It's the same in alignment, and now you can see how we split the concerns of the grunt file so we don't have a grunt file inside of config. We have one at the route that is basically just a show, and it just says, Grab the process and lineman version because we have a global that you can install within PM installed SG or a local that you can also exist, but you don't need the local and then it just delegates to look inside of configured application, which also doesn't have anything which I'll explain in a second and then files. So in this case, um, the thing that we strove to do with linemen was making ultra simple to get started. All you need to know is this is the files that make up my configuration, and that's all I really need to know to get started. If you want to dig in under the hood, you can and extend the the grant configuration on by default. You can check out what that is by looking in linemen config, application and files. So by default, you notice. At the very end here, there's an extend in files dot coffee, and there's the same thing in application. We're extending application. So what Lyman gives you, yeoman gives you sort of. Here's your massive grunt file with all of the things in it, Lineman says. What's the minimal set of things that you need to get up and running that you can extend from our defaults? So in this case, I've extended just files to override some of the defaults. Let's take a look at what the defaults look like. Um, and our defaults are just simple object liberals. So they're not a grunt objects in and of themselves, but they get merged into the grand config. So there's some convention around where to store coffee script files and what globs to look for in AP. Inspect what speck helpers to load for the test runner, which I'll show you in a sec. Some generated speck and generated spec helpers so that if you add your own files to that, it'll get merged into the spec. Helpers bundle conventions around where to start JavaScript files with all of those keys as well, and for distribution, um, conventions for where to store less and sass if you choose to enable it. CSS template ing by default that ships with both underscore templates and handlebars because handlebars is also framework agnostic, which is another design goal with linemen to remain by default framework agnostic So you can kind of get started and use whatever you want. Uh, here's what pages to look for any images, and we also do some Web font copying so that you can just drop W o FF files into the Web, wants directory, and they'll get merged into your production but a lot of radically. So the goal for doing this was really to encode the concern of what files does my application used like we talked about before? So that's the defaults and then the local one in config. It's basically just the overrides to that, so that's just something to be aware of. But the advantage to this approach that we found this, that new people getting started with this they're not overwhelmed by a massive grunt file. They've got a really small set of things that they can do, and the docks kind of out outline how the interaction between the default that's extended with your user land CONFIG works. Let's take a look at application. So here's User Landa haven't overridden anything, so I'm just getting all of the linemen default opinions, clips. And so what we do with Linemen is actually split our tasks into a couple different buckets. Um, this is pretty common to something like, maybe in, for example, so we have common life cycle tasks that things that are gonna happen in both development and when you're preparing for distribution. Eso coffee script compilation less basically ah, lot of this stuff that we set up for the grunt work flow, but just categorized inside of this common bucket. And then things that only happen in death, like _______ off the server and running watch, and then things that that only happened in distribution. And then a whole bunch of sort of the default task configurations basically pointing to all the files, this stuff that we configure it in in the vanilla, um, front project. So this should all look pretty familiar. I'll cover the test run in a sec, but what we also do is generate test bundles for anything that you put inside the spec directory. So if you're familiar with our speck on the re beside, you can just drop your coffee files or jazz falls in there and they get merged into the spec bundle automatically. So there's lots of stuff in the defaults. Uhm, and you get it all and you can override it if you want to. The user land can figs, so let's look at the workflow for a lineman instead of running grunt. We have a command line called Lyman, so you'll want to NPM install minus G lineman to get that, and I have the _____ problems. I need toe suit to make me a sandwich. And now I can do Lyman run, and that starts up in sort of executes, grant and run runs through the common in the Dept. Tasks. So we've encoded the the idea of those tests into lineman run. And if you want to see how it looks, um, by default, it doesn't do the open that we added to our custom flow. So there we go, the AP, still working in Lineman. Nothing has really significantly changed about this. It's just that our config got a whole lot leaner on the user side because Lyman comes out of the box with those defaults, abstracted away into the node modules folder, and we can extend them and override them if we want, but we don't have to by default.

Lineman Spec and Build
[Autogenerated] The other tool that we have is lineman Speck. So while I'm and run is running on watching and regenerating that asset bundle, you can run lineman speck, and it will kick off the test runner. Uh, oops. I need to go. Yeah, I need to go into line, man. Workflow to run that That's right. In line and run again and go into another terminal session. Leave lineman run running. And you learned in spec that's gonna kick off something called test. Um, test, Um, is a really nice test runner. Kind of in the same being his karma. Um, but the interface is a little simpler. They give you this nice, little tiny, gooey. And if you notice it actually spun up a chrome instance at at the test import with a randomized string at the back here on. If I had tests in the spec holder, those would actually be executing on dhe to kill that. You can take you, uh, in the terminal there. The other command that you get is lineman build. And this is what generates our production. Ready Assets runs ugly fi does all the things you want. Pre compile the templates and then, if you look, we have the distribution folder with their artifacts that are ready to go to our Web server. So Lyman run Finally build Lyman Spec. Where Lyman running lineman Specter kind of intended to be used together. Let's look at the scaffold for linemen because we took a look at that human one. So if I just go to a new directory and I say linemen knew, uh, friend and masters, that's it. It completes pretty fast because it's just copying in the scaffold and it gives you some instructions, um, about how to work with it. So if we go into front and masters and line and run, we also built it for speed optimally, eh? So that it didn't take a long time either scaffold on any project or to run the specs. So if I do line inspect now, there's some default specs that you get with the scalpel, and we should Did I go into the wrong wanted to the wrong folder? Ah, and I've got one test running and it's sitting there. And so the watch integration that we have set up is kind of like doing continues integration, but for testing the development on your workstation. So now if I shrink this guy just like that and let's pull him like that in the corner and let's open up I'm gonna kill this just to get creative Some extra stuff. Um, let's open up this thing. Put him in the other corner. Let's open that test file. I think it's hello. Um, so the idea is that you would match your production source. So this is a really simple one that just adds hello to the document body and verifies that there's a JST template compiled. This is just sort of a hello world test example. But if we open the test file hello spec. This is using something called Jasmine given there's gonna make this a little bit bigger. Uh, we like coffee script for testing just because it reduces the amount of Robo city. We like our spec patterns for testing. And so a lot of this is informed by that. And are all of these plug ins were written by Justin from test double on. I learned a lot of the TDD sort of stuff that I know from him on from a bunch of the other testable guys. But the idea is, as I change this, then I get, you know, instant feedback that that test is feeling. So it's integrating against that. I can look in the terminal and I can see that that's failing. Um, if I wanted to, for example, integrate across a large number of browsers, I can go into config slash spec dot Jason. And this is what configures the test runner to open and multiple browsers. So if we go to launch in Dev and I say Firefox and let's just kill it and start up again There it opened fire, Fox and chrome and it's gonna integrate against all those browsers at the same time. Karma can do this too. Um, the the test amu is nice because it gives you these little tabs that you can switch back and forth between to see the output. And if I didn't want any of those two pop up, you know, I could swap out to Phantom, um for running Headless Lee. Let's do that. You'll need Phantom just installed in available on your path. That's the only requirement tease, Phantom. And now it's just gonna run headless. Lee, I don't even need a browser, so I can, you know, do my TV, the workflow where I've got this thing and I know what the value should be s So let's make it green again. Boom at screen. So were, you know, using the watches intelligently to build these spec bundles and the source bundles to really improve the level of feedback. And what happens when you have this really fast feedback loop when you're doing TV is that development becomes a lot more enjoyable. I mean, when you're not spending your time waiting for things to compile, it's just so much more fun Fund to do development. So Jasmine, given lets you describe things with Given one and then Syntex. It's modeled after our respect, given on a given, basically maps to if you've used jasmine maps to before, each and judgment. So any given statement will run before all of the subsequent statements. Um, when and then basically map to Jasmine's its statement. So if you see specs in there like it should do this, that's what when and then do andan. They have some sugar about assertions, so that you know, if you don't like using the expect style assertions. You could do something like this, and that's valid as well enough and make it fail. Then you get a little bit more sugar in the output message, and you don't have to use the expect style assertions. If you don't want to. The expect style assertions just come with Jasmine by default.

Test-Driven Development Questions
[Autogenerated] I'm gonna go and jump into just a couple of the linemen templates that we make. So Yeoman has scaffolds and generators. We don't do cogeneration because we don't necessarily agree with it. Sorry, there's a question in school. What's the question? So if we were to use lineman with angular, would we not using yours building know? So, um, that's actually just what I was gonna go into. Um, So if we go to get hub and like a test double, we have templates. So instead of scaffolds, we have sort of, uh, using these NBC frameworks with quality test driven development in mind. What's a sort of good example? And so we have these different templates, this one for anger. When for mber one for backbone, one for Batman on Ben. We have a couple others, so let's take a look at the linemen. Angular template. Uh, so if you want, you can clone it. By doing that, you can snag it from the kid, huh? Buehrle? Um so I already have it checked out, so I'm just gonna go to there and let's open it up and take a look. Um, so you can use CONFIG files as coffee or JavaScript, just like Grant. So here's my files, and it's a pretty minimal set because it's again only the extensions that I'm making to the linemen defaults s. So we're going to use energy templates to generate that template. Cash. Um, here's my load. Order for things because it's angular. I don't care about anything except having a yearly loaded first for vendor. And then anything else in this case for vendor were only loading. Angular 1.20 angular wrote an angular resource and underscore. And then an app again, because it's angular. We also don't have too many concerns around load order, so we can just load up and then the globs tipple, anything else in, uh, and then the only other one was less because, um, we do SAS or C s s bitey vote. So I just set up the paths to pull in that file. Did I even have vendor? Let me check. Yep. So vendor can be like images CSS or JavaScript or coffee script. Andi, I'm just saying I only wanted normalize and then foundation, which is what I use for the angular in the backbone template. So let's take a look at how this works so we could do a line and run and linemen speck. And then we'll I don't know why. It's not remembering my angular template. And I think there's nine tests that I wrote. Yeah, so nine test examples that I wrote. If you wanted to write tests using Jasmine given and not use karma and not use any other testing framework basically the test, Yeah, absolutely. Yep, it's all in here. So let's look at, uh, let's look at the the tests that are running. Um, So there's tests for basically the simple areas of the app The controller. If that logs you in, um, and some directives that do some things let's take a look at the AP and then maybe that will make more sense. State 1000. Um And so, by default, what we do with the templates is just give you a minimal set of features that you might wantto implement in one of these frameworks. So, like log in, for example, I can take whatever I want in here and hit, enter and log in. And then I think I have to turn on x HR logging. Yeah, let's Let's go do that again. There we go. So you can see the X HR fired in Crime Dept. Tools there for Lagos. And I could take whatever I want and you log in and I have some directives that show this working and then I can log out and it makes opposed to Lago. So the question was, What's the Tesco would look like? So let's look at that controller speck on guy Have examples in Jasmine given in coffee script and in regular Js. So if you don't want to use coffee script, all the templates have spec examples in any of those Look at the jasmine given one. So given our module of app, which is where this angular AP lives given we need to inject these dependencies for our system under test to work, we're gonna create a new scope. We're gonna create a spy, which is Jasmine's way of saying I'm gonna, uh, mark out this thing under test, and then I'm gonna listen to it to make some assertions on it. Then we're gonna Instead, she ate the lock and controller with the scope that we created and, um, unauthentic ation service in a location, which is what that controller needs in variant is a way of in jasmine given seeing, no matter what happens, this should always happen for any of the subsequent specs. And so that in variant will basically run, Uh, all the time after each one of the test suites and the describe block runs. So given there's, uh, this angular http mocking framework where you can say ht to you back end when the Post comes for log in with the Scopes credentials. I wanna respond with the 200 then I'm gonna call log in, which is the method on that controller, and then flush out the request. This is all angular, specific, test mocking set up on. Then just make an assertion on my redirect method that it was called with the right path. So logging controller should redirect you home so you can see that then can also contain a string which kind of gives you a little bit more, uh, inline semantics for reading this. Given when, then this should happen. Expect that to happen? That's that's really what the semantics of this are. Let's open the controller under test so you can see exactly what's happening here. Stop you for just a sec. Sure. Yeah. More particular question was, if you're using linemen, should you not use karma, then? No, you can swap it in. You'll just basically need to remove the spec task from Lyman's defaults. And you can do that in application. Uh, the straight one. Okay, open throwing one there. That's better. So the way that we handle extending from the default config is that you can sort of just merge those keys in to find them. If you want to just remove tasks like in this case, we don't need can cat. We don't need handlebars, and we don't need JST for the linemen. Angular template. So we just remove those. There's probably a point at which it makes more sense to, uh, just start with a vanilla grande config. But for most of our cases, a lot of the configuration that we find between these different frameworks it's just like small Delta's between the default config and how we either add or remove tasks. All this stuff is is available in the linemen documentation, so it shows you how you can change the order of tasks. So in the distribution phase. I've pretended Endymion, which is the minute fication safe pre processor for angular andan. The common phase I pretended, Angie template so that that runs first. And then I've also upended cat source map to replace King cat with cat source map so they would get the source maps. So all of the things that I showed you in the vanilla Graham workflow are things that we've built into all the angular or all the linemen templates and that config files air typically a lot smaller and basically just did the deltas between the defaults and what you want to change to support your specific framework. That's the idea. Does that answer the question so you can use karma through? You just don't move that yet. We just ripping this back taxes right now you're just using pure vanilla testing test. Um, eyes the runner Jasmine is testing framework, and then our helpers are loaded inside a speck. Coppers. So why do you like testament instead of, um, mostly Because testing is a lot lighter weight than karma. Um, and the configuration file is ultra simple. Like that is all you have. If you've seen the karma configuration file. I could get pretty gnarly. So it seems like the test. Um, author. His name's Toby __. He's done a really good job with just keeping it small and tightened, focused on get It supports a lot of the same integrations that you can get with with karma so you can run your tests on sauce labs. You can run them on. What's the other one? That's popular browser. Stack a lot of these integration platforms where you can run against, like, e multiple versions of our young Windows on Mac on Lennox on things like that, and you just add different configuration files.

End-to-End Testing
[Autogenerated] another note on testing. So you see this speck folder here. In the case of the linemen, angular template. There's this idea of and inspects so something that traditionally might be done in the realm of cucumber on the ruby side, where you're actually spinning up a physical browser to run the app and make assertions against it with a mock back in. We do that with Protractor, which is Thea Giller teams framework for doing and two in testing. It's basically request replaced the angular scenario runner on. So if you're doing angular development, we include protractor in the alignment angular template. So let me show you how that works. So I'm to start lineman, run and you need a couple of things you need. Chrome Driver. If you're on a Mac, you can brew. Install chrome driver, and that will get you dependency you need. Chrome Driver is an alternative runner for selenium is Web Driver, which originally worked with Fire fox. But it spins up chrome so it's a lot faster. And then the other thing you'll need is ah, selenium standalone server. So I think if you do brew, install selenium Standalone server that will pull down a jar file that you can execute. So those two things, those were the only external dependencies. You need to run this task with linemen. And so now, if I start up the selenium stand alone server, this is where mine lives. I just haven't alias, so they don't have to type this monstrous thing all the time. Um, so when you brew, install selenium server stand alone, this is where it puts it at least 2.32 dot 35 jar. And I'm gonna start it up on port 4444 which is the default. And this just sits in the background and it's ah, Web driver host so that you can connect any test suite to it on. It'll just sit there listening. So I'm gonna take him, just kind of put him out of the way, and we'll go back in here and now we can say lineman grunt so we can delegate out to grunt for tasks that aren't part of the linemen life cycle. But if you just want to run individual to rent task, you can still do that. And one that we've created is spec U T E So when I hit this, it's found the selenium server and it actually fired up that server and it was hard to see. But I'll do it again. Um, and it ran my app in a browser and made assertions against it so that I could verify, sort of at a higher level of reality what's actually happening. Let's see. There we go. There it pops up, logs in It hits, Ah, books End point in the APP, which I can show you. I think it's list of books. It hits this one. It makes some assertions about it, and the goal with these types of tests is really to get a high level of fidelity in the test. And so there's a huge cost to doing this right to getting a back end. Spun up Thio running the tests in the browser, too, you know, instrument in cliques and things like that. So when you think about the cost of that, you really want to keep this number of tests minimal. You get a lot of assertion value about the character six of your app from this kind of a test, but you definitely don't want to write over assertive tests because then they become very brittle and they don't allow for re factoring. So in this case, the minimal assertion that I can verify that the log in is working is when I go to the slash root these air like protractor d s l methods that just delegate down to a selenium Web driver stuff. So if you're used to selenium Web driver, you'll be at home pretty much with protractor. And then I have, you know, described when a user logs and so given I'm gonna look for ah protractor element that matches credentials, start user name, which is what the angular model is bound to there. Then I'm gonna send keys, Ralph. So I'm gonna fill in the user name field with Ralph and then the password field with William. Then we're gonna click log in, and then I'm going to expect that the message that appears on that second page if we go there, so let's log in. Not going to say my password. The message is mouse over these images to see a directive that work, which you conceive being verified there. That's like a minimal assertion. But if you think about all the integration points that that is verifying. There's a ton of stuff being verified to determine that my APP works as I expect it to. And so really, that's, you know, that's the goal of integrating, um, that protractor into this workflow. And so a lot of the times with the With lineman's templates, we really strive to have, like a full stack architecture for you. No test driving, not just unit testing, but also into in testing the linemen. Angular template is the only one that we have in tow and testing for all the other ones have unit testing. But there's not a lot of decent frameworks out there for doing into in testing anglers pretty superior in that regard. And that protractor just really works well for that. So the other thing that you might be wondering is, how is this actually working? You're seeing X, Hrs fire to the log in right, But I don't really have a back end. Um, one thing we've found is that when you're developing a rich client, ap ah, lot of the initial place that this starts is at the server side with, like, an inside out approach. So people think about what service is doing need to make this happen. And they start at the service layer and then they build up to the you and then they build that toe Where can consume the service is. And we found that it works better if you do it outside in. If you start with the u I. And you have a framework like linemen where you can build the entire U Y without needing a back end, and the way that we do that is with a tiny little file inside config called server. And this is different in that, um, it's not responsible for serving up the static assets, but it allows us to stub ode R a p I as a friend and developer So we can say this is what I want my a p I to look like And the thing that we've seen happen is Front and Dev's take this and go with it because they know how to like um, you know, stuff about Jason. And if you teach them the little tiny express J S. D. S. L like Apt Outpost. It's very similar to Sinatra. They can go and stumbled a lot of the X ray Charles that need to happen and lineman by default. If you have these in your server Js, it will intercept requests that are made and return them right from this little serving stub. The other cool thing is that ah, so that works for prototyping and that gets people up and running Thio build outside in don't even need a back end.

Push State Simulation
[Autogenerated] the other cool thing that we do this if we look in application, um, we've got pushed state simulation by default in the server. So if you notice when I'm here, I'm not at the hash. Right, which is the default if you don't have pushed state enabled an angular you get the hash bang. So we've got pushed State simulation enabled. So let's go. Turn that off. I think it's an abduct Js j s router. Right. So this is how you turn on push state mode for angular. You say location provider dot html five mode. True. So I'm gonna comment that out, and I'm gonna go to application and I'm gonna turn server, push state off. So let's restart, linemen. Andi, you'll see that it's serving up the static assets that have generated on 40,000. Um, but now if I reload so now it's in. Not in html five Mod bond. The reason this is cool is one of the common complaints we've heard from people doing this kind of app. Development is while there's the S e o concern, right? If I have an external facing app, how do I get to go to work Um What what if I don't want that hash in my girl? And so this was like, out of response. We had a client project where they were just adamant that they didn't want a building up like this if that hash was in the URL. So we're like, OK, well, let's just built a little push State simulator. Then you can flip the config on. You can configure your client side up, whether it's backwater, angler or whatever, and I've got, you know, happy you or else and doesn't have the hash in it. And it's using pushed eight under the hood. Um, so that's another sort of quality of life thing that we added two linemen. Um, And then the inevitable conclusion that you can draw from this is Well, if I've got a little fake server stubbing a p i n points, how hard would it be to plug in a back end so that I could actually have the two talking to each other and I could build my decoupled back in on top of my d couple of front and on top of my back end? And so we actually allow that to a swell with something called a P I proxy. So in here, if we said a p I proxy enabled, I think enabled true port, you know, 4000. So if I had a rail server running on port 1,044,000 any requests that didn't exist inside of server? Because those are the stubbed ones. So you can have a combination of requests inside of server. Um, any requests that come through here and don't get caught and returned? Go through that that server running on port 4000 so I can show you a demonstration of that with, uh, the linemen Batman template that I've been working on. And I've got a really rails out that it can spend up. So this is just a standard rails for application. That one of the guys that shop if I was working on to make a foosball ladder. So if I do bundle exact real server, we'll get that up and running on Port 4000 on. Let's open this up so we can take a look at the configuration. Ah, not that. Cheerio. So we're using push State. We've got the AP. I proxy turned on so that we can forward requests. The only caveat is that you need to have a pretty fixed to your a p I so that Lyman knows howto intelligently wrote. Otherwise it wouldn't be able to determine which requests should go to the A P I in which shouldn't. But it turns out that pretty fixing your a p I is somewhat of a best practice when you're designing an AP I anyway. So that's why we built it like this. So now if I start up, lineman with linemen, run um, the other thing. You see this output. So we sprock singing AP requests with a P I to locals for 1000. We just added that log message so that you see it booting up and you can see simulating html five foot state serving up, generated in next HTML for all other unmatched paths on and kicked off the little static file server on 8000. Now, if I go to 8000 I can see my foosball ladder and my static assets are actually being served up by lineman. If I reload and you can see all my ex HR, they're going through a P I and those are actually going through the rails and coming back. And so now you know, if you want to integrate and you want to run like, say, you're doing this with the linemen angular template, anyone actually run those high fidelity tests against your back end. You can do that. You slip on the A P R proxy, you run Lineman's Becky to be and Lyman run and you run your back end, and then you can verify that your end to end, you know, from back and two front and is working as it should be. So that's really the goal with linemen. And that's why I say it's well aligned to building rich, rich Web applications in this matter. Have a question. So you're talking about, you know, in the simulating actual five push state. Yeah, with helps with Seo. Somehow it doesn't help with, you know, the concern that continue serving off the index that no matter what, that's right. Yeah, specific concern was that it just changes pound yet whatever too. Well, I mean, that's respectively What pushing does right? Yeah, It's just I thought you mentioned something. I didn't know that concern from the product owner was We can't build a nap like this if it's external facing, if it has the hash in the world and that's all he cared about. And so to get around that way built the push State simulator. The whole concern of S E. O is completely different. Because if you're building an app that's external facing like that, uh, some tool recently that that's supposed to be oh, for you and your dad, I hope you're Yeah. What? What's your thoughts on that? Um, it's interesting. The pushback I've heard from people is like, Do I really wanna be running phantom toe? Render my HTML and everything because that's what it does on the back end is it pipes the request it detects. If this if a Google bought or like a search engine, um uh, hits your website, then it'll render the content on the service side and then serve it up to the search. But but for everyone else, they get the rich calling a nap served up, so it's interesting they actually just updated their Web page two. I'm not sure if that's because they're getting where there's tons of interest in this kind of thing, though, when they No, you can go to the example and, uh, see you at the bottom. It says you're currently being the JavaScript version of the site. Click here to switch to the pre rendered version. And so now this was completely served up from the server side. So the idea is that if you had a rich client up where you were using push state than search engines that are calling your page, regardless of whether you have pushed it enabled would get the full content from Phantom and then the rest of the clients they don't care about S E O. Right. If it's just a user, then they're going to get the full single page up experience. So I haven't tried pure rendered audio, but I'm interested. Ah, lot of the apse that I build in this manner are not public facing, and I think to be honest, building rich client NBC Epps, until this problem is solved, makes a lot more sense for things that are behind, you know, an admin log in or something so that it's not crawl able by a search search indexers. So Shopify admin is basically the prime example of that, right? Like It's a big, fat, single page app, but it's right behind a name in Log in so it doesn't have any S e o implications. Nobody said Oh, you know, I don't want to revote Google indexing When we were building this thing so and I know most search engines you can actually you could use cream bread nor just isolated, like just run it. And then you actually submit their results to the search engine. You don't necessarily have running all the time. That's true. It can spend up on man or something like that. Yeah. Yeah, just put it like varnish or something. Yep. Generated one. Yep. And attach it especially. It's varnished, Just yeah, whatever the HDTV request is, Barney? Yeah, absolutely. So I think that there's a ton of really cool innovation in this space, and I think the people that are thinking about this stuff are solving it because what I've seen is writing ups in this method is way more enjoyable than writing traditional full page reload request response websites with like, rails or whatever back and you're using So

Integrating With Rails
[Autogenerated] another question question from Chet From a deployment point of view. Yeah. Uh, how does this work? Full integrate with rails, acid pipeline and employment frameworks. So you talked about earlier, but yep, I can I'll show you how it works for Shopify, actually. So in Shopify Um, you can run lineman run And we've basically replaced the asset pipeline for just the admin portion of Shopify so I can run lineman run and it will. It's got a bunch of great tasks. So here's all our image optimization stuff. Here's generating inline Batman templates for a view store Grant SPG icons to do the SPG stuff. Sascha's all the designers like, says, coffee script, blah blah, blah. Um, and then that's sort of when you're running and development, you run rails like you normally would, and you'll leave this running and it does. Static asset compilation. Um, for deployment. You just run lineman build and we have a couple of things. This is going to run through the full gamut of tasks. We had to write a custom tasks to generate asset fingerprints the same way that the rails asked. Pipeline does, which turns out it's really easy. It's just an empty five hash of the file contents on. And then we inject the fingerprints into the rails manifest and are deployed. Process basically says, I'm gonna do all the rails asset pre compilation for the legacy areas of the APP because our single page app lives inside over rails up, which is an ideal to me I'd really liketo move it out to its own repo. Then there's other integration problems that happened there. But for now we're basically, you know, the deploy step runs the legacy rails Asset Pipeline runs our step, which completes in about 30 seconds, like it just finished their andan. You can see there it's just jamming the assets into public assets on the shop. If I deploy process takes those uploads. The manifesto s three and we've gotta cdn configured. So those just go up to s three as well. So the task to do that if you're doing rails integration, I open sourced it. It is called grunt Rails Asset Digest. So if you want to grab that, it's very specifically tailored to if you have to work with a single page app that is stuck inside of rails up assets but it should be general enoughto kind of work with, um, it gets our linemen build task. It gets executed by Capistrano for deploy. And so there's some docks here you can see here. This is basically taken from Shopify, so assets compress, runs, rails, assets compress. Then we compile with linemen, which just shells out on runs. Lineman build on and then we upload. So does that answer the person's question? It was also a gem called That's Pretty That's supposed to replace the acid with Cool. Yeah, but then you're running node with Ruby, Sort of. I mean, you're shelling out to run node from Ruby. Yeah, half pipe A Let's see. That's pretty general. Half a privy, Jim. Oh, Joe Fiorini wrote it, But dependencies view Bauer Grant. Yes. So maybe this will integrate easier. But we did. We did it with Shah, provide us with linemen and basically just grant under the hood, right, customizing the ground tasks to integrate at the right point, get killed the server. So that's a lot of stuff to digest. We've got, like, 15 minutes left. I just kinda wanted to use the last 15 minutes toe Ask if people had other questions or clarification on anything. I was I was looking at the Jasmine. No, because we just because because we're testing in the client side, we just lose the jasmine dot Js and test him actually takes care of doing that for us when it runs. So that's another nice thing. You don't have to worry about the life cycle of that. Um, did you get any questions on the chat? A couple of, um, we're actually just a follow up question. He's asking what would probably be the direct half to integrate with rails. The most direct path asset. I I think, approach that we took right. Just letting rails assets run by default and modifying the manifest after it runs on, then just dumping folders into public assets. Because most rails deploy strategies involved looking at public assets to deter neither what to upload to a CD en or if you're just serving at a public assets when you deploy to like heroic or something, then you could just dump him in there. That seems to be the most straightforward. I mean, maybe you guys, do you have any thoughts on anything else? Because the way that we did it in Shopify was we blacklisted one folder from Asset Accomplish in which you could do in config dot r b Um, And then when the rails ask that pre compilation runs, it just it's exempts that folder and all sub folders from doing any asset free compilation and then lineman runs and does the optimize bill path, you know, doing these other things for us. So the integration wasn't that painful at all? Um, basically, just dumping them into public assets and modifying the manifest. If you look at, uh, you can see there, we just basically upended lines to the end. And the grim task has is smart enough to know that if the acid hasn't changed, if the MD five hasn't changed, it doesn't touch the manifest on. We've got unit tests around that. Because we didn't we wanted to make sure that there were no integration problems, because the biggest risk is that you inject an entry into the manifest for an asset that doesn't exist. And then you get a rails asset not pre compiled area when you go to production, which really _____. So do you have any examples of running a house? Uh, they're Adios. Manny did a block post specifically about that, actually, uh, making maven Grant Meritus. So he's got a really good article on this. So if you want to integrate grunt into your maven workflow, he goes through this in depth and covers it.

Unit Testing Grunt Plugins
[Autogenerated] I'm in a swell show this cause this is the thing that I was most happy with building in the last couple of days. Um, actually, it was Yeah, it's this guy. So I mentioned, um, unit testing grant plug ins is really, really painful. So I'm gonna show you what that looks like by default and started the approach that I took to get it to a little more sane place. So if we say Grant in it, um, Grant plug in. I guess I should make a folder first. Um, no unit current testing him, Grant, innit? Grant plug in, run through a little bit of a wizard. The best current plugin ever. I like that where it lives. So that's gonna scaffold me out a basic grunt plug in. So it gives me a grant file with sort of the default tasks and no unit set up to run the way that this works is it splits the concern of setting up the system under test, which is really the grant configuration inside of the grunt file. So you can see here. It generated me a target node unit. Grant plug in testing demo. Um, and so The idea is you set up the system under test by configuring grunt in here on. Then you might have some files that are gonna be operated on with the grunt plug in, like I'm gonna output default options to from test fixtures testing. So if we look inside the test holder, there's a fixed years and we got testing. And if we run, look down at the bottom. You can see that the default task if we run Grant is just in to test. So did you Grant? I need to mpm install now If you run Grant. So there it basically runs the grunt tasks in line with those targets. And then node unit makes assertions about the output files, but it's kind of funky. I was talking with James about this because you have to look into places to really understand what's going on. You have to look in the grant file, which is basically your system under test, sort of. It's like 1/2 of the system under test, and then the other piece you need to look in his actual no d n a test file. So if we look here, we can see like you know, default options and custom options. So these were like different tests that you might write to verify. But the only thing that's in here is assertions about Thea quit. So it's like grunt runs with the configuration in the grunt file. And then this makes assertions about the output, and it just becomes very hard to read because you don't have all the context of the system under test localized in one place. So that's what note unit does on. And it's very I don't know, x unit style you have. You know, this giant option that is the test suite on one set up method that runs before all of them. If you need Thio that you can do And you know how many assertions you expect? Ah, very sort of limited vocabulary for expressing tests. Well, so what I did was I spent a good day trying to figure out how in the heck I was gonna test my rails. Asset Digest plug in. In a way, that was a little bit more scene. Let's take a look at the ground file. Um and, uh, my friend Justin from test double. He was working through a client doing some note consulting, and he was like, Well, I've got all these really good patterns for testing with Jasmine and all my plug ins that I like in the browser, but I want to be able to do the same thing and note. So he released this bundle called Grant Jasmine Bundle that you can drop into a note project and then you contest all of your note code with many jasmine note, which exports the Jasmine browser global into nodes global s so that it works the same way as it does in the browser is as it doesn't note. So now you contest like the same as you do in the browser at least the way that we like to test, um, in note code. So that's, um, Grant Jasmine bundle. And so the only thing that you need to do in this case is, you know, grab jasmine bundle and PM, install it, uh, and then initialize the spec config with many jasmine. No, to show the colors. That's just so the terminal output is nice. So let's take a look at this spec now. So now I have a grunt file. Um, and all it does is parse out an option. So this is how you can pass command line options with Grant So you could say grant dot option config or, you know, bail with without anything. And the way that works is we can look at the speck. So I pull in the grant library. That's kind of the thing. The engine that I'm gonna use to run this thing spawned because I'm gonna spawn a child process to execute my system under test, which is basically just gonna run the grunt task. These were just some helpers so that I can stop both the input and output. Ah, and then an expand so I can expand file gloves. Then I created this tiny little function that is actually going to spawn a grant task with the config that I pass inside of my test. And so now I can localize the system under test all inside of here. So the way this test works to test this, I'm gonna stub boat ah, workspace path, which is spec temp public assets. Because that's where this plug in is expecting to operate, or at least generator output on. Then after each, I'm gonna clear it. Those air just jasmine conventions with before each and after each And these tiny little functions that I created are just, you know, pulling from the grunt file a p I and I just the idea was to create this little de eso before each make the directory workspace path just so that it's very easy to read so we can describe Rails Asset Digest. So given I have these entries in the rails asset manifest already, um, and then I have some manifest entries that I'm gonna ad or generate from my task. Then maybe I have some stale manifest entries with, like, an old Shaw. So those are the three sort of scenarios for the system under test that I want to verify. Then I can stuff about my grand config. So here's the task Name rails Asset Digest. I called s UT for system under test. This is a pattern that I learned from the guys that testable, uh and we're gonna pass some options of the path that we want to work with Is that path that we stubbed out temp public assets and now we have the files. So I if you look inside of spec Common rails Pop project. You can see that this basically mirrors what the task is gonna operate on. So again, we've localized the context of how the test is gonna operate inside of that folder. Um so now we can see that we've got a couple contexts in which this test executes or which this task executes. So if we have a manifest with previously generated rails asset pipeline entries, here's the existing manifest. The nice thing about coffee script is you can do multi line strings just with the triple quotes. Let me go back and show you that. So it does. Does the string concatenation over multiple lines and adds the slash and for you So it's really easy to see. You know, this is what a rails asset manifest looks like. It's got that header at the top with three lines, and then I've got those entries that I created in the variable at the top. And then I haven't expected Manifest, which is basically gonna be given that task and fig and my entries that existed in the folder. This is what I expected to look like. So I'm gonna write out the manifests that its existing, which basically is like after the rails past that three compilation is run. I'm gonna run that grunt test rails assets. I just pass it in the config and pass it a done call back. And this is the way that you could do a sink testing inside of Jasmine or mini jasmine node. Rather. And so when I read in after the task has run, then I should expect that the written equals my expected. So that, to me, is a lot better at understanding the system under test. Because now I don't have to look in the node unit file, and I don't have to look in the grunt file to really understand all of the pieces. And I could go look through the rest of these tests and say, You know, Well, now I have a manifest with old entries from a previous task. So here's my stale manifest entries. Um, and then when I run this, I should expect that those stale, manifest entries get updated with the new ones. So to me, this is a much superior way to test a grunt plug in. Because I can I can see what the config exchanging, uh, and then I can see with the The initial value in the expected value is all in the context of the test. There's one where I actually tweak it. So here we normalized the asset path by adding a trailing slash because somebody changed the config file on that broke our deployed process. And I was like, Wow, that's really brittle. So, uh, you know, saw that fail wrote a test around it, made it pass and then pushed up to N p. M. On. Then we've got, uh, Travis integration for running these tests on Get Hope. I'll show you that it's really easy. Tell Travis you want node. Tell it what Scripture run Grant spect you to be, which is part of that task that you get with the Grant Jasmine bundle on, Ben. Just install the grants, Eli. And so now if you look on get, you can see every time I do it. Push. I've got continuous integration on get hub and you could set that up for you with any get help Depository. So but I I really, you know, was happy with how this turned out because it lets me test in the way that I really like to test the way that the test double guys really like to test. And, uh, it localizes all the context of what this task is doing and the scenarios that it's used in in the test file. So So if you want to test your grant plug ins and you want to use this style and you like it, you can use JavaScript to I mean, here's what Jasmine given looks like in JavaScript. It's a lot more of her, Bos because the givens air basically wrapped in function calls. That's what those arrows are. I mean, but you can do it. But it really shines in _____ script, especially when you think about sort of creating little D. S. L's to really express the test, the system under test much better. And that's all open. Get him. I'll add all this stuff to the links that I've created that Justin blast you guys with even more stuff. I have some other links that I can give you a swell so stuff that we didn't cover today

Writing a Blog With Lineman
[Autogenerated] So my block is at blogged out. Dave mo dot com. And did anyone have their blood on Post Rhys or anyone here of post arrest? Before it was a blogging platform that originated out of Gary Tan. And I forget who else from San Francisco And they they got bought out and I had my blah gone there for the longest time. And, uh, I had kind of moved from WordPress, too. Posters and then I was like Posters is great. I can post vlog posted by sending an email to post that poster's dot com, And it was super easy And the template. This is what the template gave you from Post Rhys. And then they got bought out there like we're shutting it all down and I said, That's it, I'm done. I'm not hosting my blogger on somebody else's platform that's gonna get bought out and shut down. And, uh, Justin souls from testable wrote this tiny little blogging engine called a grunt markdown blawg. And so that's what using lineman eyes what it does. So if we look at AP instead of pages, we have posts. And so all my posts are in mark down so super easy toe, you know, go in and work with, um and they support for the generated with a grunt plugging called marked, actually, not even a grandpa. And it's a node module called Marked, which allows you to do mark down, plus embed snippets of HTML in it. So it's really cool. And when I do lineman run, it's gonna chew through all those things and really quickly, you know, generate me. Um, my blawg. So now if I got a local host, there's my blawg, uh, with no database and nothing but mark down. And it generates, like the previous links for you, it generates like archives so that you can look at all the posts you posted. I mean, it's really simple, but so I took the poster's theme and poured it into this. It took me like an afternoon, downloaded my archive, Um, so you can grab this on my get. How about david? Slash the name of this? I'll put it in the links. And, uh, here's the templates. Here's my wrapper. It's just using underscore templates on dhe again because underscore templates just use javascript. You can execute arbitrary JavaScript. Uh, Justin created the idea of a yield kind of similar to year be so This looks very similar to your B, but it's all JavaScript and underscore. And here's my individual tempeh template for a post so you can execute arbitrary JavaScript. Thio sort of decide what links should show up. This is showing that newer and older link on the right and the left. It's just basically going through and determining this at runtime when it when it generates the pages. So it's pretty cool, just more JavaScript. So if you want to grab that, you check out the package. Jason. It's based on Lyman on Grant Mark Down Block and underscore. Those were the only dependencies. And the other thing that's cool. His i d we get push Roku. We have alignment build pack that will automatically push this to Hiroko and deploy it for you. So we've kind of got integration sort of into end, so it'll fetch the bill pack or the linemen build pack. It runs lineman, build on the server, and then it ports all the assets into Apaches Public directory for your little Hiroko app. So if you want to get a block up and running. This is like the fastest way to do it in my experience. And then you fully control the experience. You can set up a block on her Roku for free. I haven't paid anything for mine yet. For comments, I added Discuss. You don't have to add comments. Some people think comments are evil, but I got some good response to some of the screen casts that I produced. So the even more meta the linemen documentation we built with linemen as well. So we've really, um, taken to dog food ing it and trying to make it work in his many different areas as possible. So I mean, you could build a blob with it. You can any kind of workflow you can think of. Um, the linemen lived template. I didn't show that one, but I mentioned it. So this is where you want Thio. Use lineman to generate that distributable artifact for your project. So Ajay Kori plug in, for example, or something like that. So one that I used the linemen live template for is called Jasmine on Lee and Jasmine on Lee lets you add a dot only to it or a describing jasmine and Jasmine when it's running, the tests will only run that test. So it's a really fast way to isolate to a single test case if you want to, just from right in your you know, your editor. So let me show you that really quick. Uh, today, yeah, connects him to date. It's an idea Lymon run. There's no static Web server or anything. It's just watching because the workflow for developing the library is sort of this fast has been on Lee So again, Lymon, run! Let me speck! And I've got five tests for Jasmine only, um, that run just verifying that it works based on the jasmine environment, you can actually see the DOT reporter at the top. Here is, uh, three of those air. Great, because I have some It not only is it described that only that limit the system or the test run, so this is all it's verifying. And so when I'm ready to distribute this thing, then I can just do let me build and I get dissed slash Jasmine dash only dot men. And if I open that, there's my distributor Well, with the header that we put in the version so really fast wayto to produce a library and because it's using the linemen conventions. What I found is I move from Project Project, and we found more ways to use Lineman for things, but the workflow remains the same. So I lime and run and I'll I'm inspect when I'm developing. I lineman build to distribute. I don't have to think hard about it. And so I go to these other projects that we've written in the past with sort of different methodologies. And now I've been re factoring the Malta use linemen because it's just so much easier to go in and jump into a project like, Oh, this is a lineman project I'm not run line would build. You know I can. It's really easy to get started with it. And it's the same folder structure, so you know it's got that convention approach where if I want to add specs, I just dropped the minute I dropped helpers in, and I have to think about it. The there's a couple settings for lineman lib by default. We don't include vendor dependencies in the open bundle because technically, if you're writing a J. Khoury plug in you're gonna write tests against something that is using Jake worry in the system under test so that you can verify it. But I don't want my hope. What to include Jake worry. So by default, we don't include those. But if you did want to, you could set that to true. And then it would bundle all the vendor dependencies before your plug independency and squish them together for a distributable artifact. So I can't take credit for Lineman Justin and the guys that testable did it Kick ___ job. I've done a bunch of contributions. Might have mostly been on the on the lineman templates like I did the angular template in the backbone template and the Batman template. Justin did the ember template, and then he did the blogger engine and then the lib template. And it's just kind of going crazy now because we find so many different ways toe use it. So it's been super fun

Wrap-up
[Autogenerated] any questions from the chat or smart make comments? I Yeah, I've just been talking with him. They're just, uh you know, like, for novices. I definitely need to have you back to do another workshop. Cool. First thing I was saying that 90% of this is new to me. Another before saying the same thing for them. Well, yeah. And, uh, sorry. Father says, uh, earlier, back when your last five minutes made the entire workshop more than worth it. So for the angle, like for the testing stuff or Oh, yeah, it was. They're also saying that this is yeah, to work jobs. Consecutive weeks would be great, but yet it's a lot of stuff to throw Monday. I It was crafting this stuff last night. And to be honest, I was having, like, anxiety attacks, that I didn't have enough material. In retrospect, I you know, I probably could have split this over two days. There's a lot of stuff, but when I got to the bonus section, I was like, Oh, this is the stuff I really want to show. But you really need the context of late grunt and everything to see how this all works, and then you get to the abstraction like linemen and Yeomin, and it's like, No, no, I can take this and replicate it really fast to different work flows for different scenarios, and that's where the true power comes in. So I'm glad that the last five minutes of that section made it worthwhile, because that's the stuff that I'm really excited about is, you know, granted school and everything. But I really love when you I can take something like that and build on top of it and build an abstraction that just makes you so much more productive at what you do. So yeah, and they're saying that Yeoman was kind of more trouble than it was worth it. Absolutely. This approach is more lightweight coming to the metal. Oh, and then John says it's been very useful. I'm hoping we can use this work well in our current application development, or at least aspect of it. And people are definitely I'm gonna go over the examples and Charlie Incorporated, Yeah, yeah, there's a lot to dig into. I'm gonna the one thing I have to do tonight on, but I will make sure I remember to do this is, I mean, add a couple more commits to this to move, um, the top level or like everything else into a folder called Grunt Work Flow. So then it's very clear to see what's the yeoman. Where Flo, What's the line workflow? What's the groundwork? Flow? And then just kind of clean up the repo of it. But then I'll create it just with all the girls for stuff that I talked about. I've also got links to screen casts that I've produced that the guys from testable have produced on JavaScript testing. They're definitely the masters of that stuff. I just I learned from them and I was like, Wow, you guys air, You're awesome. So Justin and ah, bunch of other people that testable have been producing screen casts, and it's all free and up on YouTube, so I'll put links to that stuff. People wanna dive in and look more about, like, Jasmine given and sort of this methodology of testing that that they're using. Yeah, And then, uh, mind says, uh, the hard part is actually getting it implemented at work? Yep. Convincing others that it's worth returning. Yep. Yeah, I mean, So my experience joining shop. If I if I would go back, I would do things differently. In the 1st 3 weeks, I basically paired with a guy on the admin team, and we basically tour the Shopify Admin out of the Rails Asset Pipeline and then wrote our own tasks like the Grunt Rails Asset Digest and then integrated a bunch of other tasks to figure out how to get it into the workflow. But it made significant change, an alert organization in a small amount of time. And there was a lot of pushback actually deployed the first iteration of our workflow and took down Shopify for 20 minutes in my 1st 3 weeks. So it was a bit of a trial by fire, but it turned out to not be my fault, thankfully, but yeah, if I was gonna have any advice for somebody wanted to make these kind of radical changes. Maybe, um, take it a bit slower and make sure that you get buy in from the right. People like solicit for feedback about what people want in a workflow, like what's lacking in their work floor right now, and then solve those smaller problems first instead of trying to just be like here. I'm gonna change this over wholesale, which is what I did. If I could go back and fix it. But it was also worth the experience I got toe. I got to see the scale at which Shopify operates. And it was insane having a Web app go down where? You know, I think the throughput on average is like 50,000 requests per second on seeing the error logs like start flooding in and having to fix it. It was that got my adrenaline going, but yeah, in general, you know, definitely get buy in and and make small changes incrementally toe integrate this stuff.

