Course Overview
Course Overview
[Autogenerated] Hello, everyone. My name is David Tucker and welcome to the course. Advanced get techniques. I'm a cloud consultant that helps organizations plan, build and implement custom software solutions in the cloud. And I have over 15 years of experience in software, architecture and development. Now, software developers can often see source control as simply a system that must be used rather than a tool that enables efficiency. But in this course advanced get techniques, you will learn how to optimize and automate your workflow with git by leveraging some of its advanced capabilities. First, we will review the configuration of get, and then we will review how multiple repositories could be interconnected using get sub modules. Next, we will leverage the tools within. Get that, help us find defects within our code. And finally, we will implement both client and server side hooks toe optimize both individual and team work clothes. When you're finished with this course, you will have the skills to leverage the advanced capabilities of get that make you and your team more efficient in whatever software you are creating

Configuring Git
Overview
[Autogenerated] welcome to the course. Advanced get techniques. I'm excited that you're here to learn even more about get and how you can integrate it into your workflow. Initially, we're gonna be talking here about configuring, get and utilizing the power of gets configuration system. Now let's talk first about a fictional company, Global Man tics because they, too, are looking to use get at a deeper level. So first of all, what they're looking to do is configure Newgate installs for the developers. They want to be able to follow a set of best practices, and they want to be sure that everyone is set up for success. With that. They also want to enable code reuse through common repositories, so common code they use across multiple projects that want to be sure they're using get in the proper way to pull that into the new projects that they create. They also are developing a local workflow for running tests and lynching per commit. So they catch those things before they even end up on the build server. They also want to enforce a commit message template on the server so that every commit the developers make references a ticket within their ticketing system. And ultimately they want to enable their developers toe work more efficiently with git. So here, in this initial module, here's what we're gonna cover toe work towards those goals. First of all, we're gonna be reviewing the structure of gets configuration files. Then we'll be modifying. Get configuration four common tasks. Then we'll be reviewing get attributes and their use will be implementing a clean and smudge filter within. Get which will leverage get attributes.

Git Configuration Structure
[Autogenerated] so the first step in understanding how to configure get is understanding its configuration structure. So, first of all, let's talk about get configuration. So get does provide a robust configuration system, and you can configure both standard and custom configuration values across multiple levels of your installation. Let's first talk about those levels and let's give an example. So to begin with on your machine, you might have a depository. Let's say you actually have multiple repositories, but ultimately those repositories air under your user account on that machine and on the exact same machine, you could have another user account that has other repositories in it, and then over all of that, you have the actual get installation on that computer. Now let's see how that ties into the get configuration levels. So, first of all, we have three different levels, primarily first, we have the repositories, which is known as the local level. Then we have the user account or global level, and then finally we have the get installation or system level and configuration values are evaluated from the repositories up, so get config will use what is in the repositories, and if it doesn't find a value there. It will bubble up to the global setting. And if it doesn't find something there, it will ultimately bubble up to the system level setting. Now let's talk about the git Config locations. Now I'm using an example here from my machine, which is a Mac, and in this case you can see here where the repositories get configures found it is actually in the get directory of your depository and then for Global. It's under my user in dot get config and then for the system. It is actually under user, local, etc. And then get config. All this said, even on a Mac, it is going to be dependent on the method you chose to install. Get on your machine. Now let's look at a sample git config file. So here, within a git config file, you'll see that you have sections, and in some cases you even have a qualifier on a section. But, for example, will look first at the user section, and this contains two keys being name and email and then the values for those specific settings. And so this holds true for every use of get convict that you will see whether you're talking about local, global or system level configuration. So let's look at how you set a git config value. So you would actually specify within each of these, the qualifier on what level you want to save it as and in all three cases here, I'm choosing to set the user, which is the section and then the name, which is the actual key for the setting, followed by the value, which in this case is David Tucker. So I'm first setting the local value. This would be the value that is set within the repositories. Then I'm setting the global value and then I'm sitting here, the system value now, you wouldn't need to set all three if you simply set this at the system level or at the global level, it would evaluate, no matter what repositories you're using. However, if you ever wanted to have a different name within a different repositories, you could choose to set that at the local level. Let's talk about common configuration settings that you would configure for Get on your machine. First of all, we have identity settings, and that's what we just saw. This is where you would configure your name and email address. Then you have the file editor. So maybe you're a total command line pro, and you want to use vim or e max for your primary editor. Or maybe for you. You're very familiar with V s code or sublime tax, and you want to use those for your editor. Those air, some examples of things you can configure, and the same holds true for the merged tool. Also, you can configure terminal color output whether you want to include it or not, and even customize the colors that it uses also command aliases. So if there are certain commands that you perform over and over again, you can create aliases so that you can execute those commands more easily. Next, let's look at how we view our config values. So from any point on your machine, you can run, get config list, show origin, and this will show you all config values and also it will show you in which file there to find. So if you run this command within a depository, it will show you those that are configured for the repositories as well as for the global value for your user and for the system value. So at any point, if you want to see what get configures evaluating four specific setting, you can simply run, get config and then pass in the actual setting that you want to evaluate, and it will return what the value is for you at that point. Now let's look next how we remove git config values because there are times that maybe we've entered in a customization at our repositories level that we want to remove. Or maybe there's a setting that we've set globally that we don't wanna have set globally. So at any point you can run, get config, passing the level and then say unset and then tell it what you wanted toa unset in this case, user dot name. You can also edit the CONFIG files directly, so without even having to do it through the command line, you can simply run, get config global and edit, and it will launch this in your default file editor. You also can remove an entire section of config by simply running git config global and then remove section and then pass in the section that you want to remove now It's important to note here that get config is not the only configuration that changes how get works. In addition to gets configuration, there are environment variables that also affect how get works. However, in most cases, these air more advanced to use cases that you would be modifying environment variables. Four. Your first step should always be toe leverage git config to modify the default behavior.

Configuring a Git Installation
[Autogenerated] So next we're going to be configuring a get installation. So let me tell you what will be configuring over the course of this demo. First of all, we will need to review the current configuration settings so we know where we're starting from. Then it will be configuring a first time get installation for use, so we'll look at it just as if you were starting from scratch. He then will be configuring the editor def and merge tools. And then we'll be utilizing local config four different identity settings to demonstrate the different configuration levels. So I realized that for many of you, one of the first things you did when you installed get was to set your identity values were gonna walk through that again here and look specifically at how we're setting those values. So the first appear is we're going to set the name. No. In this case, if you notice we're using the global level, this means it will apply to any repositories for the current user. You'll also notice here that we're setting the user category and the name of value. Next, we need to set the email address in this case. Will say that I am one of the developers at Global Mantex. So we'll say in this case that for any repositories at I have under this user account that I'm going to be using my global Mantex dot com e mail address. However, we also will later on in this clip, walk through the process of how we would customize this for a specific repositories. Now that we have that added in. The next thing we need to do is we need to create a sample repositories that we can work in. Now that we've added in a sample repositories, we can now review all configuration. So we're going to run the git CONFIG list command and pass in show origin. So with this, we're now able to see every current git config value that is being evaluated all the way from the system level, which we see at the top, then through the global level and then after the global level, we see the specific repositories settings that are included, and we can see here that our identity settings have been set globally within the users slash David Tucker get config file and let's say that I'm not going to be editing this as David a global Mantex dot com Let's say this specific repositories is a personal project that I'm going to be working on. I can choose here to update the email address specifically for this repositories, and in this case, I've set this to be the local scope. But if we look here at our configuration list, we can see that we're currently evaluating this locally. Within the repositories, we can also see that if we run, get config user, not email. Now, the next thing we need to do is we need to configure the standard tools that we want to leverage for editor for our def tool and for our merged tool. And this will heavily rely on git config to make these settings work. Now I'm gonna choose to leverage V s code for all of these. So the first step to making this work is that I need to set globally the setting for core DOT editor and in this case, I'm going to use V s code, which is just code from the command line, and I'm going to specify that it would open a new window each time. This is executed and that it waits to return until the editor is closed. So in this case will go ahead and enter this configuration value, and then we can actually test that it works. By editing our global CONFIG file, we can see here now that V s code has launched and it's launched with our configuration file. And this global configuration file includes the identity settings that we set previously. If we need to, we can make any changes to this and save it, and this will then be reflected in our global config. So in this case, we're going to choose to set the diff tool that we want to leverage. So I'm going to paste in value here that will allow us to use V s code for that as well. So now that I've pasted this in, we're going to save the file and then we'll close the editor. Now, the next step is for us to test out Our def tool in this case will make a change to our read me file. And then we'll open our def tool. We'll see here that it does open up V s code on the left. We have the original value on the right. We have the modified value for this file, and we can see that it is properly showing us the diff between the two. Now, close the editor. Now, the next step is for us to actually set the merge viewer. So in this case will go back and edit our global CONFIG file well paced in the value for Emerge config. And then we'll save our CONFIG file. Well, then, close the editor Now. Next, we're gonna walk through steps so that we can actually create a merge conflict. And now that we've ended up in a situation where we have emerged conflict, we can now run, get merged tool. We'll see that that now opens V s code and were able to in this case, except either the current change, incoming change or both changes in this case will accept the incoming change. We can save the file, and then we can close the editor next we can commit. And in this case I'm purposely not gonna pass in the message through the command line by simply hitting. Get commit. We'll see the editor come up. This allows us to editor commit message from within V s code because it set as our default editor. I'll save the file and clothes. And now we can see we've solved our merge utilizing our merged tool. Now, the next step we can take in making our use of get even more efficient is weaken set aliases inside of get config. So one of the commands that I use a good deal and get is the status command. So in this case, instead of having to type get status every time I want to get the status, I simply want to be able to type, get S t and have it returned the status we can accomplish this utilizing config values. Now here I am setting an alias and we can see here that it is an alias because it is included within the alias category. And in this case, the value that we pass in is the shortened version of the command which is S t. And then we can see the full version of the command after status now, simply by typing, get s t were able to get our status command back. We can also build on top of our aliases. So another command that I leverage. And to be honest, I actually leverage it more than get status is get status and then by passing in the short argument. So here, by utilizing git config, we can pass in an alias for S s or short status. And in this case, we can pass in S T, which is the alias that we just defined previously and then pass in dashed a short now we can utilize the short status which in this case returns nothing because we don't have any modified files. And the more that you work with git config you want to actually create an alias for how you edit your global, your local and your system config? So in this case will utilize an alias for E G C, which stands for edit global Config, and this will call get config. It'll pass in the global option, then dash E to edit it within our editor. Now we can simply type in get e g c. Now this opens up the config file and we can see at the bottom of the config file. Where are alias? Values have been set. Now here we can choose to pass an even more aliases that will allow us to work more efficiently within the system. So I've pasted in options here for editing the local config, editing the system config checkout branch, commit and amend. We can now save this file and closed the editor. Now, from this point forward, I will not be using the alias is in this course. This is simply because if someone doesn't watch this specific clip, I don't want them to be lost on what commands I'm executing. So while in this course I'll be using the full versions of the commands. I encourage each of you to figure out the aliases that can make you most efficient when your leverage and get on the project you're working on.

Git Attributes
[Autogenerated] So now that we've talked about get configuration and how we can use it to change how get functions, we're now gonna talk about a different aspect of configuration, which enables us to configure how get deals with specific files and that's called get attributes. Now there's two different ways that get really can handle dealing with files differently. The first is get ignore, and this is what allows us to determine files in which get will simply ignore and not include within the repositories. But then we also have get attributes, and this allows us to set specific configuration values for how specific files or groups of files are handled. So at a high level, get attributes are placed on a file or a collection of files within a depository, and it dictates how this file is handled. Now, in some cases, different get hosts may offer specific functionality that leverages these attributes. So let's talk about some common use cases. Forget attributes. First of all, you can configure line endings in files with get attributes. You also can specify files that are binary versus files that are not. You also can enable large binary foul support with get L F s. You also can exclude files from the exported version of a repositories, and you can specify clean and smudge filters, which will talk more about in just a minute. So let's look at a sample, get attributes file. So here is an example file from within a repositories and you can see first we're setting it to auto detect the line endings for specific files. You can also see here that we are setting the specific file. Such a JPEG files and P and she files are binary files. Now, as a note, in most cases, you don't have to specify this yourself. Get does a great job detecting and determining what is binary. However, if you ever run into a situation where it is not handling it properly, you can choose to set that specifically within the get attributes file. You can also see an example here of using get LF s for storing zip files with inner repositories and this again is dependent on your host support. Forget LF s and we also have an example here where we're using the export ignore a tribute to set that value for our test directory. So it is not included within the exported version of the repositories. But let's talk next about a more complicated example, utilizing something called Get clean and smudge filters. So, first of all, within any project, you're going to have a staging process. When you have files that are ready to be committed, you're going to have your working directory, which are the files that you're choosing to work with, and then you're gonna have this staging area. So once things are ready to push into the repositories, now, we can choose to define inside of our get attributes, file a filter and in this case, were choosing to specify a filter just on the Java script files within our repositories. And there are two functions for this filter. One is smudge and one is clean. So let's say, for example, we have an A P I ke that is present within our job. A script files, and we want to remove that so it's not stored in our repositories. We can choose in this case to use the clean and smudge filter to make that happen. So let's look at what would happen to these files first of all, because this is a JavaScript filter are read Me file would be passed through without going through the filter. However, our job script files would pass into the clean filter, and this function would remove references to our specific AP ____, and then we would see it go from the clean into the staging area. However, this is just the staging process. We would need to have the reverse of this happened in the checkout process, and that's what this much filter will do. So first, within our checkout process, we would see the Read me file continue to pass through, just as it did before. So next we would see are JavaScript files moved through the smudge filter, and this would take the default placeholder that we put in place and then replace it with the specific AP I ke. And we would then see the proper values reflected within our working directory. And this is just another example of what can be accomplished by utilizing get attributes. So next we're gonna walk through the process of implementing specific get attributes within a git repositories, and using a clean it's much filter is one of the attributes that will include

Using Attributes in Git
[Autogenerated] So next we're gonna walk through the process of actually utilizing attributes within. Get so over the course of this demo, here's what we're gonna do. First, we're gonna be adding in a get attributes file for a new repositories, and then we'll be implementing exit dips for image files. Then we'll be excluding files from release packages on Get Hub and then we'll be adding a clean. It's much filter to hide secret values within a repositories. So let's dive in. So first as a prerequisite, we're going to be leveraging the exit tool from the command line to help performed. If files on our images now, for this to work, you will need tohave the exit tool installed on your machine. You can look in the exercise files that are included within this module to get instructions on how to install that on your machine. So first we're gonna create a repositories that we can work in. Once we create a repositories, we're now gonna populate it with both a read me file and an index dot Js file. And next we need to add in our get attributes file. Next, we'll go in and edit our get attributes file. And so next we're going to define a get a tribute for J Peg files within our repositories, telling them to use the exit strategy for performing deaths will Now go ahead and save our file. Next, we need to define how we're going to leverage the exit tool from within our git config. And we're going to choose to set this globally. So next by using this command were able to now specify how get config is going to utilize the exit strategy and what tool it is gonna be leveraging, which in this case will be the exit tool we're now gonna add. These two are repositories and commit. I'm now gonna open the exercise files for this module. I'm going to choose to go into the original image folder and I'm going to copy one dot j Peg and then we'll move this over into our repositories. Now that I've moved that over, I'm now going to add that into the repositories. Now that I've committed that, I'm going to open up again. The exercise files for this module and from within the exercise files I'm now gonna navigate to modified image. I'm going to copy this version of one dot jpeg into our repositories, and we'll choose to replace the existing image from here. We can now run, get def. When we do, we'll notice that we're able to see the diff between the exit on the old version of the file and the new version of the file. And in this case, if we continue to scroll down. So in this case, among other things, you'll notice that the image, width and height is different between the new and old versions of the file. The new version of the file is an optimized version of the image that is smaller both in terms of size and file size. We can now clothes out of the diff. So next I'm gonna open up the exercise files for this module again. I'm gonna take the test directory that is included, and I'm going to copy it. I'm now going to pace that within the repositories. Now what we want to do with this is we want to configure get attributes so that within get hub, our tests directory is not included within the export of files. So to make this work, we first need to include our test directory. So well, now navigate back to the terminal and will add this to the repositories. Next will commit it. Now, the next step is that we need to add in our origin. I've created a depository on get hub specifically for this. So I'm gonna choose to add this in. Now that we've added in the remote, I'm gonna push the master branch to Origin. Now that we've successfully pushed, I'm going to add a tag in. At this point, I'm gonna follow semantic version ing standards and we'll call this 0.0 point one. Now we'll push that specific tag toe origin. Next, I'm gonna navigate to my repositories on get hub. We can see now that get Hub has been populated with the files that we've added into our repositories. I'm going to choose to select the releases option. From here, we can see our release for 0.0 point one. I'm gonna next used to download the zip file and here we can see within the export for our tag. 0.0 point one. All of the files that are in our repositories, including our get attributes file are included within the downloaded zip for the release. So next let's leverage get attributes to change that I'll navigate back over to the terminal. Next, we'll actually navigate to our get attributes file from within our get attributes foul we're going to add in two new lines. So the first line that we added puts an attribute of export ignore on anything that begins with a dot in the repositories, which would include our get attributes file. And next I've added in the same attributes on the test directory. So if this works properly, once we push this tag toe origin with the updated commit, we should see that the release would not include those files. So let's go ahead and save our get attributes file. So next we'll commit these changes. Then we'll add a tag, and then we'll push the tack. Now that that tag has been pushed, we will now navigate over to get Hubbell, and we can see now on the releases page. We now have a release for 0.0 point two. I'll click on the ZIP file and now we can see that the files for this specific release on Get Hub on Lee include the files that we wanted to. We have excluded the get attributes file along with the test directory, and so next will navigate back over to the terminal. And so next we're gonna be implementing are clean and Smudge filter, as we discussed in the previous clip. So our first step here will be to edit our index dot Js file. So from within this file, we want to include some sample code, and this sample code won't do anything, but it'll simply be an example of what we could implement with real code. So in this case, we have a pretend a p i ke. You can see it listed here, and we're going to say that to make some A P. I call. We need to pass in this AP ____. But here's the issue. We don't want this secret to end up within our repositories, so this becomes a good use case for leveraging a clean. It's much filter. Well, go ahead and write our index dot Js file. So justice. When we were creating the exit strategy for how we would handle dips for images, we defined the specifics of that within git, config and then we simply told specific files to use it within our get attributes file, and the same will be true for the clean and smudge filter. Now, in this case, we're going to use said to simply replace one value and put in a place holder. So our real AP I ke will be replaced by that place holder. So let's go ahead and implement the clean and smudge filters within the local level of git config. And so now that we've added both of those filters in both the clean and smudge filter, we're now ready to utilize get attributes to specify what files it needs to act on. And so now we specified this so that the clean it's much filter will work with each Java script file within the repositories. When we go through the staging process will see it run the clean filter, and then when we see it run the check out process, it'll run this much filter. Now that we have this in place, let's save our get attributes file Next will commit our get attributes file. Next, we're gonna push this to master, then we'll navigate over to get up. So from here within our repositories weaken now navigate to the index dot Js file. And when we navigate to the file, we can see that our actual AP ____ has been replaced by the placeholder for secure a p i ke. So, by using the clean and smudge filter, were able to have the real value locally while having a different value on the remote version of the repositories. So over the course of this demo, we've been able to utilize get attributes for several things. First of all, we have configured images to use the exit tool to performed ifs. Then, in addition to that, we were able to exclude specific files from the exported version of our depository using the export ignore attribute. Then we were able to use a clean. It's much filter to help protect secret values within our repositories, from ending up on a remote

Summary
[Autogenerated] So over the course of this module, we have looked at several different ways that we can configure get Now, let's look specifically of what we've been able to cover. First of all, we reviewed the structure of gets configuration files. We examine the three different levels that get config works within. Initially, we have the local level, which handles the repositories that you're in. Then we looked at the global level, which is what is for the specific user account that you're using. And ultimately we look at the system level, which covers the specific get installation that you're using. And then we modified get configuration for common tasks first for things like our identity settings are naming our email. But then we went deeper and looked at how we set our merged tool and our def tool to be V s code. And then we also looked at how we can use aliases to make ourselves more efficient by taking common get commands that we leverage and creating a shortened version of them. And then we reviewed get attributes and their use. We talked about how you can leverage get attributes for things like setting line endings on files. And then we also talked about how you can use it to perform things like using a different diff strategy, which we use the exit tool to perform def on two different versions of an image, and we also used get attributes to specify within get hub what should and should not be included within the exported version of a tag. And then we utilize both get config and get attributes to implement a clean and smudge filter within. Get we utilize, said to replace a sensitive AP ____ and put a placeholder in place before it ended up in a remote repositories. And then, when we checked it back out, it was able to then replace that value with the real AP ____.

Utilizing Git Submodules
Overview
[Autogenerated] So in this module of the course, we're gonna be walking through how you leverage get ___ modules. Let's take a minute and review what we're trying to solve for global Mantex. First of all, they are looking to configure new get installs for their developers, and we covered several aspects of configuration in a previous module. But they're also looking to enable code reuse through common repositories, and we're gonna be utilizing get sub modules to make that happen within this specific module. They're also looking to develop a local workflow for running tests and lynching per commit, as well as enforcing a commit message template on the server. They're also looking to enable developers toe work more efficiently. So over this module, let's talk about what we're going to accomplish. First of all, we're gonna be reviewing sub modules and their support within get, Then we'll be configuring, get to better use sub modules will be adding a sub module to a project, removing a sub module from a project, working with nested sub modules and reviewing best practices for utilizing sub modules as a team

Understanding Git Submodules
[Autogenerated] So next we're gonna tackle the process of understanding, get sub modules and what they provide. Let's first talk about different ways that we can utilize code from other get repositories. And remember, our goal here is that we could have shared repositories that can be used across projects. The first approach is you can leverage a package manager, one that specific for the technology that you're working in. This could be a solution, like in PM or Newgate or Ruby gems. The next approach is utilizing something called Get sub Trees. Now this is an emerging approach, and it does leverage a command Get sub tree. However, we also have get sub modules and get some modules are the most common approach for integrating other repositories, and it is the approach that's been around the longest, and so we're going to choose to focus on get sub modules. So for a quick definition, hey, get sub module is just a construct within get That enables you to keep a separate git repositories as a subdirectory within an existing repositories. So this enables you to effectively keep two separate repositories linked together within a project. So let's see how this plays out. So here we have our normal get repositories, and within this we're gonna have our working copy, and all of this exists within our repositories. But then we can look to integrate a separate repositories. In this case, we have sub module A, and this is held under a directory, external slash, sub module A. And then we could have another one, even some module B, and this one would be an external slash. So much will be. But then it goes even deeper than this because you can also have nesting. So we could even potentially have to separate sub modules that exist under sub module A. So with this being the case, let's talk through a few facts about get sub modules. First of all, utilizing sub modules does add complexity, especially when you're working with the team. So you want to be sure that you understand the guidelines that you need to follow, and we'll be covering those in more detail later on. Within this module next package, managers should be leveraged if possible. Package managers have scripted many aspects of taking specific versions of a get repositories, making them available in an easy way to include within one of your projects. There will be much more additional work if you choose to go the sub module route over the package manager round. However, sub modules are the fully supported way to include other repose into your project, And sub modules as mentioned are the most common manner to include other repositories and you'll see this approach leveraged in many open source projects. So let's next look at how you add a sub module. So get does have a sub module sub command that you can leverage. And in this case, we're going to pass in the ad command to that and then pass in the repo that we want to add, followed then by the directory that we want to live in within our current depository. Now there is a file that gets created the first time we had a sub model, which is our dot Get modules file. Now, this file will be checked in to our remote, and this is what allows us to then share this with other members of our team that are gonna be leveraging the same get sub modules because in this case, there is a process with some modules where it will take this information and then integrated in with the config for your repositories. Now you'll notice this looks much like the configuration files that we covered in a previous module, and that is very true. Much of this will get integrated in within your get configuration for your specific repositories, but for each sub module, two pieces of data are included. First, the path within the current depository and in the U. R L for the remote that we're pulling it from. Let's look next and how you clone a repositories that has some modules in it. So if you pull down a depository that has some modules, you can utilize clone Justus you have before. But next, you'll need to admit the sub module, and by doing that, you'll then integrate that in with the config for your local repositories. Once you do that, you can run the Update Command, which will actually grab the content of the reference for the specific commit of that sub module. Then we can talk about how you actually remove a sub module from a repositories. Now there are two different approaches you can take if you just want to temporarily remove it. You can use the D N a command, and that will remove it. But you can also go back and in it again at a later time. You also can permanently remove it by running the D N a command, followed by get R M and then committing your repositories with that change. Now let's talk about a few facts of working with gets up modules. First of all, sub modules are truly their own repositories. So that means once you change into that directory, you're utilizing the config of that repositories you're committing to that specific repositories. And when you push your pushing the contents of that repositories. So it's very important when you're working with sub modules to know what director you're in and what repositories or working with now. Sub modules do not track to a branch, but rather to a specific commit Now. This is to your advantage. You can make sure that someone else doesn't have the ability to change the code that is included in your project because you have to update explicitly if you want to include the new code for your sub module. Now, as mentioned sub modules can also contain other sub modules, and while that adds some complexity will walk through that also in a later clip. In addition, you can edit an update your sub modules within your project, just as you would any other normal repositories.

Adding a Submodule to a Project
[Autogenerated] So next we're gonna walk through the process of adding a sub module to a project over the course of this demo here, specifically, what we're gonna cover, first of all, will be verifying our version of Get. We do need to be sure we have the correct version because gets a module support has changed slightly in certain releases. Then we'll be adding a sub model to a project. Then we'll be configuring. Get to better work with some modules as there are some small changes we can make that will help your interaction with get. Then we'll be updating a sub module and finally will be removing a sub module. So let's dive in. So as mentioned, we want to be sure that we verify the version of Get that we're leveraging now, here on my local machine I'm using get version 2.22. Now there are changes that have been made some significant changes to sub model support within get 1.751 point 78 and even to 780.7. So we want to be sure that you're using at least version 2.7 to be following along with this clip now, the next thing we're gonna do is we're going to make a repositories at we can leverage for this clip. Now, the next thing we're going to do is we're going to create a directory external, and this will be a directory where we will store the sub modules that we will add to this project. Next, we're going to actually run our get sub module, add command. And in this case, we're telling it to pull down the gate hub depository that I'm referencing. And we're telling it that it needs to store it in the external slash example Dash sub module directory. Now that we've added that in, we can now navigate to that directory. Once we do, we can see that it has pulled down the contents of that specific repositories. Well, now navigate back up to the parent repositories from here, we can now take a look at the get modules file that was included because we ran the get sub module, add command and we can see here that it does define a sub module within the directory external slash example dash sub module. Now it also includes the girl that I passed in that it is actually pulling the repositories from. And so next I'm going to run, get status. Now we can see here that there are two different files that are included. The first is get modules, which this is the file that we just looked at. The other is a reference to the specific commit of the repositories for our sub model. Now, this doesn't give us a ton of information about the sub module. So because of that, we can choose to set a different get configuration setting that will give us more information when we run, get status when we're leveraging some modules and this configuration setting is status dot sub module summary. So we'll set this value to true, and then we'll run. Get status again Now, Once we do this, we'll be able to see here that we do have some module changes that need to be committed. It even lets us know the specific commit that were actually referencing in what the commit message was for that specific commit. So next we'll go ahead and add both of these and then we'll commit, and that is a configuration that allows us to also get some module summaries when we're doing dips on our repositories. So we want to be sure that we set this value as well. So next I'm going to navigate outside of this specific repositories, and then I'm going to use the file protocol of get, and I'm actually going to clone the repositories that we just created. Next. I'm gonna change into the clone of our depository from here, will list the contents, and we can see that we do have the same files that we had previously. But next we will change into our external slash example Dash sub module directory. And when we do, we can see that there are no files currently within this directory. And this is because there are some additional steps that will need to perform. To be sure that we have fully initialized our sub module, we'll navigate back to the parent module and then from here we will first run, get some module in it, and next we'll actually update our sub module to pull down the code. Next will change back into our sub module directory, and we can now see that the files have populated from our sub module. So next we'll talk about how we update the reference for our sub module. So in this case at global Mantex, let's say that we want to leverage the specific beta branch off this shared repositories at we're pulling in as a sub module. In this case, we would first need to fetch after we fetch. Just like any normal repositories, we can check out a different branch. In this case, we'll check out the Beta branch. We will then change back into our parent directory and from here will run, get status. When we do, we can see that we do have new commits for our sub module. So next we will add and commit by updating this too. Now, leverage Debate. A branch of the same model that we pulled into our project now next will walk through the process of deleting the sub module from our project. The first step will be for us to DEA net the specific sub module. Now, at this point, we could choose to go back in and re innit that sub module so it's not removed permanently from our repositories. However next we will actually run. Get our M. Now. If we do this. We can now run, get status and part of what it's letting us know here is there is no longer a get depository at the location where it was previously. We've modified our get modules file, which has removed the module that we had previously included and it has deleted our sub module. Next from here will finalize this by committing toe are repositories. Now that we've done this, we've successfully shown how we can add update and then ultimately remove a sub module from a git repositories.

Using Submodules with Teams
[Autogenerated] So in this clip, we're gonna be walking through how you utilize sub modules with teams. So let's take a look at what we're gonna cover in this demo. First of all, we're going to be leveraging nested sub modules because the moment you start pulling in some modules, many of those some modules will have sub modules underneath them. Then we're gonna be understanding team considerations for sub modules. Now, this is critical, and this is where some of the complexity comes in in using sub modules, then will be editing a sub module in place. And then finally, we will be pushing to remote with sub modules. So first, we're going to clone a repositories that has sub modules and actually has nested sub modules. Now, if we follow the path that we took in the last clip, we would need to first clone it and then go into a sub module directory, initialize and update it, and then we would need to go into if that's a module had more sub modules. We would need to do that again for each of those now, this could be quite time consuming. If you had a repositories that had a lot of sub modules. However, in this case, get provides a command that does all of this for us. And we accomplish this by passing in the recursive option to get clone. This will go through each of the tree of sub modules and it will perform both initialization and updating on each of those. And we can see here that we're pulling in a lot of different sub modules within this repositories. So let's change into our repositories directory now. From here, we want to take a look at our get modules file. And here we can see within our parent repositories, we have to sub modules. The first is external slash repo one, and the second is external slash repo, too. Now, we also want to take a look at the sub modules that are included within each of these sub modules. And we can do that by leveraging a command called get sub module for each. So what we're going to do is we're going to pass in a command which will be the same command we used to look at our get modules file here will pass that in for each of the sub modules and so it will simply go and run this command within each of our sub modules. And we can see first here with our external slash repo one. It has to sub modules and then for external repo to it has one sub module underneath it. Next, we're going to talk about when working as a team, how we integrate the changes that our team members have made into our repositories. So the first step is going to be the same as if we were working without sub modules, and that's just using get pool. Now the next step is a little different because let's think about what could happen here with our sub modules. First of all, it's possible we could have some of our teammates delete sub modules. We could have them bring in new sub modules. We could even have them change a sub module. So let me explain what I mean by that within our get modules file when we initialize it, it integrates in that into our local config. But it's possible that we could have one of our teammates even change the remote u R l fora repositories. Let's say, for example, that they cloned 1/3 party library. They now have their own version of it to make specific edits, and now they want a reference that repositories. So because of that, we need to sink our configuration with our get modules file, and we need to do that recursive Lee. And so we're going to use the get sub module sink Command to sink our config with to get modules file, and we're using the recursive option so it will navigate the tree of sub modules for us. So first of all, it's possible that our sub modules have been updated, and they're now pointing to a different commit. It's also possible that we have new sub modules, as we mentioned earlier. So first we need to initialize any new sub modules, and then we need to make sure that we're updating each of our sub modules now. Fortunately, get also provides this within a single command and here we're going to use get some module update, bypassing in both ian it and recursive options. So it's important to note here that there are three distinct steps that were taking when we're working in a project with sub modules, and these three steps need to be taken every time we're pulling in changes from our team members first get pull, then gets a module sink recursive and finally get some module update and knit recursive you could even create your own alias utilizing what we learned previously about get configuration so that each of these could be performed by passing in a single command. Now, next, we're gonna talk about how we edit our sub modules and make sure that those changes can make it to our team members. So I'm gonna next change into one of the directories for one of our sub modules. So in this case, we are still tracking against master. But in most cases, that's not going to be the case. We're going to be referencing a specific commit, and we're going to assume that the sub module that we're working with probably has its own ongoing development life cycle. So we're probably not going to be on the head of a specific branch. So we need to make a decision here. We need to make a decision about what branch we're going to track against for this change that we're going to make. So in this case, I'm going to choose to check out Master and the next I'm gonna go ahead and pull and performer re base. And now we're gonna make the changes within our sub module. And so in this case, I'm going to choose to upend a value to our read me file. Now, next, I'm going to commit this within the sub module. Now, just remember, we have to think about the directory that were in Currently we're in the directory for one of our sub modules, So we're going to commit this to the sub module now. I'm purposely not going to push this now because I want to highlight one of the risks that can exist. I'm gonna now navigate back up to the parent depository. So if we run, get status, we can see here that there are new commits and so we need to go ahead and commit from this repositories from the parent repositories to pick up on the new reference to the sub module. And so, in this case, I'm gonna go ahead and commit that. Now let's think about what happens if I were to push this right now. If I were to push it. We would be referencing a commit that I haven't pushed from the sub module into the sub modules remote. And so by doing so, I would in essence, break that sub module for each of my teammates because they wouldn't be ableto update the sub module to the commit that it's referencing. So we want to avoid this now. We could go through and manually check each of the sub modules every time we want to push, but chances are we would miss it. Luckily, since get 2.7, there is a config value that will go through and detect when you're doing a push in the parent depository to see if any of the child's sub modules have commits that haven't yet been pushed, and it will push them for you. And so we're gonna go ahead and set this config value, and we're going to set it globally because we want to do this by default, moving forward. Once we have that in place, we can now push and you can see here that we have pushed both our sub module, which in this case was example sub module one as well as the parent depository which was the example nested sub module repositories. So throughout this clip, we have first been able to deal with nested sub modules. When we have been cloning a repositories, we have then covered how we integrate changes from our team and how we push out changes to our team utilizing get some modules.

Summary
[Autogenerated] So now we've made it through our focus on get sub modules, and we've covered quite a lot from the beginning. We first looked at sub module support within get. We gained an understanding of what sub modules are, why we would use them in what some of the challenges could be. We then configured, get to better use sub modules. We updated things like how get status and def handle sub modules. We also made sure that we recur star sub modules when we're doing pushes. Then we added a sub module to a project. We removed a sub module from a project and we worked with nested sub modules, for example, how we use the recursive option with clone so that we can handle initialization and updating of all of the sub modules when we clone a repositories that includes sub modules. And then we also reviewed best practices for utilizing sub modules. As a team, we talked about how when you're leveraging sub modules as a team and you're doing pull statements, you need toe. Also sink your configuration for sub modules as well as performing an update, and in it recursive lee across all of your sub modules.

Implementing a Git Workflow
Overview
[Autogenerated] in this module, we're gonna be walking through how we implement a git workflow and taking many of the concepts that we've learned so far and piecing them together. So let's quickly review Global Mantex, the fictional company that we have been following throughout this course Here is what they're looking to do. First of all, they're looking to configure Newgate installs for the developers and we talked about in the first module how you leverage git config to optimize different aspects of how individuals leverage get. They also want to look at enabling code reuse through common repositories which we solved through looking at get sub modules. But now we're gonna look at two aspects within this module, first of all, developing a local workflow for running tests and limiting per commit, as well as enforcing a commit message template on the server. We're also going to look at enabling developers to work more efficiently, and we'll be covering that in a later module. So here, over the course of this module, here's what we're gonna be focusing on. First of all, we'll be reviewing client side and server side, get hooks and will be utilizing client side. Get hooks to perform pre commit tests. And then we'll be leveraging server site. Get hooks to enforce a commit message template. Then we'll be creating a custom get command toe, automate repetitive steps.

Introduction to Git Hooks
[Autogenerated] So next we're going to talk about get hooks and get hooks are one of the features of Get that allow you to optimize aspects of workflow. So let's talk about what get hooks are. So First of all, a get hook is a predefined script that is executed in response to a specific action that has occurred within your git repositories. Now, generally, we bring these down into two different groups. We first have client side hooks and these air hooks that would run on your machine with your version of the repositories based on things that you do to your depository. So next we have server side hooks and these air scripts that execute on the get server to a different set of events. That may happen. So let's look at the overall get hooks process. First of all, we're going to divide down the middle between client and server. Let's start by looking at the client's side, so this will include some but not all of the areas for integrating get hooks. So, first of all, we're going to look at pre commit now. This happens after the user chooses to commit, but in this case, the commit message. Template hasn't yet been generated. Then we have prepare commit message. And in this case, we do have a commit message that has been generated, and we can choose to customize it at this point. Then we have commit message, and this is where the user has entered in there. Commit message. And we could in this case, choose to either accept or reject that message, and then we have post commit. Now any of the get hooks that start with Post are generally just used for notifications because in this case, the action has already been completed. The committee has already been made, but if you wanted to tie this into some notification system, you could do it through post commit. Now, at this point, we're now going to say that we have pushed things from our client to the server to our remote. Now the first area forget hooks that we see is pre received. Now pre receive receives all of the refs that are being updated so you could have many. They're being pushed from the client to the server, and you could choose in this case to examine each of those and reject that push that is coming into the server. You also have update Now update will get called per ref that gets pushed to the server so you'll get a chance to look at each of them individually, and you could choose to reject some of those that are coming in. And just as with Post commit, we also have a post received, which also would be focused for notifications after things have been pushed to the server. Now let's talk for a minute about client side. Get hooks. First of all, clients I'd get hooks are designed to improve workflow for developers that are using the repositories. Now. I note this here that this is designed to improve workflow and not to enforce policy because you cannot enforce policies because the users have their own version of the repository and they can reconfigure those and adjust those. They could even completely remove those get hooks. Now it's often leverage to run pre commit checks against code. So if you want to do just some simple checks of code before it leaves your developers machine, this is one of the ways that we would leverage clients. I'd get hooks. Now let's look at some of the common use cases. First of all, we have things like lynching files, checking to be sure that the files that the developer is going to commit meet the standards for your organization running tests. So actually _______ off an execution of the test suite to make sure that we're not injecting code that breaks the tests, verifying things like No. Two DUIs and committed code. So we have different ways that we can look at the content of those files and make sure that the developer is not breaking any of the best practices that we have defined. We can also use them for preparing a commit message so potentially providing a template that our users can then go in and edit and in some cases even cleaning up files after specific actions. So if there is some sort of compilation, depending on the language that were in that we would need to perform before we actually push, we could then go through, for example, and clean up some of those artifacts once that has completed. Now let's talk next about server side get hooks. So these are different because, unlike client side hooks, server side hooks can enforce team policies because our developers don't have the ability to go in and edit the server and change what those scripts are. So, first of all, when we're looking at the different opportunities to inject our get hooks, if we want to reject pushes overall based on overall policies, we would use pre receive if we want to look at individual branch pushes, this is where we would leverage update and for notifications and hooks after the commit. This is where we would use Post received. So for server side get hooks, here are some common use cases. We have things like enforcing a commit message format because in some cases organizations want to be sure that developers are referencing a ticket in their ticketing system with every commit. It could also include enforcing user identity information, making sure that they're using their corporate email address as the identity to push this to the server, enforcing the signing of tags and or commits. Now there's a lot of talk around whether or not there is value and actually signing commits. But some organizations want to enforce that, and that's something that you can do with server side get hooks. You can also block access for specific I P addresses, and you can even block specific file extensions.

Implementing Client-side Hooks
[Autogenerated] So next we're going to be implementing client side Get hooks. So over the course of this demo, here's what we're gonna do. First, we'll be verifying our version of get again because there are some things we will be leveraging that require a specific version of Get Well, then be reviewing a sample project with testing and lynching integrated into it. We will then create a pre commit hook to run tests and talent are files will then update config to include hooks within the repositories. So first, I'm going to check the version of Get that I'm using. Now I'm on get version 2.22. Now, in this case will be using a config variable that is only available and get version 2.9 and later. So I'm fine here. You should be passed version 2.9 as well. Next, we're gonna be cloning a sample. JavaScript Project depository. Now that we have that in place, we're going to change into the directory now from here were first going to run in P. M installed to pull in some of the project dependencies. Now I'm gonna open this in V s code now from here. I'm gonna go in and view the terminal. Now, the first thing that we need to do is make sure that our index dot Js file is executed. Next, we're going to run this script, and the script is a relatively simple one. It will simply calculate all of the prime numbers between one and the number that we pass in. So in this case will choose to pass in 100 and we can see that it found 25 prime numbers between zero and 100. Now, the next thing we're going to do is we're going to highlight the different capabilities that we have built into this repositories. So first, we do have a test suite that is configured in packaged up Jason so we can run in P m test. And when we do, we see that we do have to passing tests, its first test to be sure that it is returning 25 primes between zero and 100. And then we're checking to be sure that it is returning the correct prime numbers. Now, the next thing I want to highlight is that we also have lynching integrated into this repositories and So in this case, we can run in P M Ron lint and will now use E s lint to check over the files that we pass in. Now, in this case, we have no lynching errors. Now, the next thing we're going to do is we're gonna navigate to settings for V s code so that we can see our dot get directory inside of the editor. Now, chances are for whatever tool you're using to editor code, you'll need to make this adjustment as well. So from here, I'm going to search for exclude. And then I'm going to make this a workspace setting. I'm going to remove the globe pattern that includes the dot get directory. Now we'll see that our dot get directory has shown up well, now close settings. Now, next, I'm going to open the dot get directory, and I'm going to open the hooks directory from within here. We can see that there is a pre commit dot sample file. This is the file that we're going to be using. Now. The pre commit file is one again that gets executed before we actually commit the file. And even before the commit message is generated. So in this case, we're going to use this to run both the tests and the lint ing prior to committing. And we will rename this and I'm going to remove the dot sample from the end of the file. Now, the next thing I'm going to do is I'm going to close the terminal, all then highlight and delete everything that's currently in this file and will now add in some additional logic that will enable us to run both the tests and the lynching. So, first of all, I've specified that this needs to exit with a non zero status. If any of the following scripts fail now, that's critical here because the way that get hooks communicate with get is based on that status code. So if anything fails, even the lynching or the test it needs to return a non zero status code that way, get will know that this failed and we should not accept to commit. Next, I'm gonna open back up the terminal, and from here I'm going to close our dot get directory, and I'm going to navigate to index dot Js. Now I'm going to add an extra tab in Now, this should cause Linton to fail because that's not where we would want this tab. So I'll save this file. And then now I'll try to commit this. And when we do, we can see that there is an error. The lynching air does come up, and it lets us know that we cannot commit Now. Next, I'll reset the repositories to get rid of this change. Now, next, I'm going to navigate in the lib directory to find primes dot Js. Now, this is the function that is actually being tested by the test suite. So in this case, I'm going to change. Instead of returning the output, which would include the prime numbers that it has detected, I'm going to return a fixed array. Well, now, save the file. Now from here will now try to commit this change as well. And now we can see that we do have a failure. In this case, we're not returning the correct primes and we're not returning the correct number of primes. So we have failed our tests and because of that, it is failing to let us commit. So in this case will now go back in and we will reset the repositories. Now All of this has worked well so far, except there's a problem. Our dot get directory is our config for our repositories. This is not information that is going to get populated for any of the members of my team. Luckily, get provides a config option, and it's been around since. Get 2.9 that allows us to use a different directory within the repositories, historic at hooks. So I'll go ahead and set this value and this is core dot hooks path, and I'm going to set this to be dot get hooks. So next I'm going to actually make this directory, and then I'm going to move the pre commit file into that directory now just isn't note here. This file is already executed ble, But if you're creating this file from scratch, you want to take the extra step to be sure that you do make it execute a ble before you actually attempt to commit. Now the next thing I'm going to do is I'm going to navigate back into my index dot Js file. I will add in a few misplaced tabs again, I'll save the file and now I'll attempt to commit this, and in this case we do see that it failed yet again. So in this case, this failed not because of a hook in our dot get directory, but because of a hook within our dot get Hooks directory. And that is a directory that will be included within our depository. And as long as our teammates have the correct config value set for where they're get hooks directory is, it will automatically integrate in with the get hooks that we have created.

Implementing Server-side Hooks
[Autogenerated] Now that we've implemented client side hooks, we're now going to transition to implementing server side hooks. So over the course of this demo, we will first be cloning a bear repositories to enable testing of server side get hoax. Then we'll be creating a pre receive hook to verify the commit message format, then will be amending commits so that we can enable pushing with the correct format. So 1st 1 of the challenges that can exist when you are testing your server side hooks is effectively being able to test that on your local machine. Now the first thing we're going to do is we're going to clone a depository, but we're going to clone it as a bear repositories, and this will allow us to simulate the remote on our local machine. And so, in this case, we have cloned the bear repositories into example, get remote. Next, we're going to clone another version of the repositories. That is not a bear version, but we're going to clone it from this version that we just cloned. And this will be our local copy of the repositories, and in this case, we're going to use to get file protocol, but we will be able to leverage this just like we would if we had cloned a repositories from a get host like Get Hub Now First, let's change into our example Get remote directory. And in this case, if we list the directory, you'll see that we're basically inside of the normal dot get directory for a repositories. However, since a bear repositories does not have a working copy in this case, the CONFIG directory is the root of the repositories. Next, we're going to create a file for pre Receive because we want to use the pre receive hook point to be able to reject any push that includes commits that don't follow our desired commit template. And what we want to do here is we want to leverage our ticketing system. And let's just say that are ticketing system something like Jiro are other solutions out there has a key for each issue, and in this case the key includes letters and then a dash and then numbers. This allows us to find a specific number within our ticketing system Now, because of this, we want to be sure that all of our developers have a ticket that is associated with each of their commits. So first we will create our pre received file. Then we need to make sure that it is executed. Next, we're gonna go in and edit this file now from here, we're going to drop in code that will allow us to check for this format. So at a high level, first, we have a regular expression and we've included the letters G s, P four, Global Man Tick standard project, and then we have a dash, and then it can include any number of numbers after that. Now, this is the format that we're going to be looking for within each of the commits. Now, this specific version of this is a modified version that comes from some platform samples that get hub makes openly available. Now, in this case, we're going to check with each of the refs that get included because remember, when we're using the pre receive hook, we're going to be getting one or more refs. They're gonna be pushed at a time. But in this case, if it doesn't meet the regular expression, we're going to reject the push to the server. So now that we have this in place will now save the file. So we're now going to change into our local repositories. In this case will choose just to edit a sample file. We'll just choose, get ignore. Well, then say that we want to ignore the V s code directory. Well, now save the file. Now that we've made that change, we're going to commit that change. Now we're ready to actually push to the server now again because we're using the file protocol were actually going to be pushing it just to the other repositories. That is our bare repositories that we checked out first. So next I'll push, and we can see here that we do have an air that comes back. It lets us know here that it was rejected because a specific commit is missing the global Mantex Jura issue key, which in this case as an example we're saying is GSP Dash 123 So, to make this work, we're gonna have to actually go in and amend our commit. Now we're going to choose to add in our issue key First will say that this is our ticket. Well, then save this and we'll close the editor. Now that we've amended, our commit will not push and we can see now that our push has been accepted. Now, this is just the beginning of what you can do utilizing server side, get hooks. So if you're interested in learning more about server side get hooks and seeing Maur examples of how they work and even learning how to set up your own get server, you can see another course that I've authored here on plural site get administration.

Creating Custom Git Commands
[Autogenerated] So one aspect of improving your workflow with git revolves around automating things that normally take multiple steps. And we're going to leverage a feature of get, which is custom get commands to do just that. So over the course of this demo, here's what we're gonna be doing. First, we will be creating a directory to store custom commands for our user. Well, then, make sure that that directory is in the path variable. And then we will create a custom command that combines multiple get commands in tow one. And then ultimately we will run and verify our custom command. So first, we need to create a directory for our user to store our custom get commands. In this case, we're gonna call that get Dash scripts. Next will change into this directory. Next, we're going to add it a sample file. In this case, we'll just call this get dash test script and you'll notice that every command that we create needs to start with git and then dash. So inside of this file, we're just going to include an echo statement. This will allow us to test and make sure that this custom script is working next. We need to make sure that this file and any of our custom get commands are executed. Now from here, The next step is that we need to make sure that our get scripts directory is in the path variable for our user. So in this case for me, this is going to involve me putting this into my Z s h r c. Because I'm using I'm Dizzy s h as opposed to bash. Now, if you're using Bash, which is the default on Mac, you can simply run this and drop this into bash profile. Now, you will need to update this directory to be the specific directory for your user. I'll go ahead and put this back in, and then I'll hit. Enter now. The next step is I need to actually source this value, and this will actually pick up on that path. Variable. Now, next. If everything works properly, I should be able to run, get, and then pass in as the sub command the name of my custom command. So in this case, get and then test script. Now, as I mentioned, any get custom command in terms of the file needs to start with Get Dash and it will only work if this is on the path. And we can see here that we do see the echo statement indicating that the test script worked. So our custom get command is working just fine. But now we're gonna create one that we actually will use now, if you remember previously when we talked about working with sub modules, there were three different steps that we needed to integrate when we were looking to pull down commands for a depository that contains sub modules. In this case, we're goingto automate those steps into one custom get command, and in this case, we're going to call it, get some pool I'm going to paste. And what will be the logic that we will be automating for this particular custom? Get command. So first you'll notice that I'm using Bash, and then I'm going to call get pole. This will allow us to pull changes from the remote. Then I'm going to call get sub module sink recursive, and this is what will allow us to sink our config in the local repositories with any changes that have come in from one of our direct sub modules or any of the child's of modules. And then finally, we're going to call get sub module update and it recursive, which is what will update the sub modules to the correct commit. And if they haven't yet been initialized, it will initialize them. And we can perform all of those across the entire sub module tree Recursive Lee, I'll now save the file now from here, the next step is I need to make sure this particular file is executed. Next, I'm going to clone the same module that we leverage before that Integrated, get some modules. And next I'm going to change into that directory. Now that I'm in that directory, I'm going to now use our new custom, get command, get simple, and we can see that it has walked through each of the three different steps that we included within our custom Get command

Summary
[Autogenerated] So here we have walked through multiple ways for how we can implement and then ultimately improve our overall get workflow. Let's quickly review what we've covered. First of all, we reviewed client side and server side Get hooks. We learned that client side get hooks, actually execute on the machine where our local repositories is and the server side get hooks, execute on the remote server. We then utilise client side get hooks to perform pre commit tests. And we verified in this case that we could both run tests and lynching as a part of that process and that those commits were rejected if either of those processes failed. And then we utilize server side get hooks to enforce a commit message template because we know that global Mantex wants to ensure that developers are referencing a ticket for every commit they make. We included this change and because it is a server side, get hook, we can use it to actually enforce a policy for our developers. And then we created a custom get command toe automate repetitive steps. In this case, we looked at the situation where we are dealing with sub modules inside of a repositories. And when we want to pull down a new code, we want to ensure that we're pulling it down, sinking our config and then ultimately updating and if need be, initializing the sub modules within our project.

Finding Bugs with Git
Overview
[Autogenerated] So in this module we're going to be using git and one of the tools provided by get to help find bugs within our repositories. But first, let's quickly review Global Man Ticks, the fictional company that we have been following throughout this course they were first looking to configure. Newgate installs an able code reuse, developed a local workflow for running tests and Linton Per commit and enforcing a commit message template on the server. And currently through the previous modules, we have been able to meet all of those needs. Next, we're going to talk about enabling developers to work more efficiently and one of the key aspects of any development. Workflow is finding bugs, and so we're going to see the tools that get provides to help us with that process. So first of all, in this module, we will be reviewing to get bisect tool and its capabilities then will be utilizing. Get bisect to manually determine when bad code was injected within our repositories, and then ultimately we will be utilizing get bisect toe, automatically determine when bad code was injected

Using Git Bisect
[Autogenerated] So next we're going to talk about how you leverage the get bisect tool to help find the point at which bad code was injected into your project. But let's first review some general version control benefits. First of all, version control doesn't able us to see a history of the entire project. We can see what changes were made to what files and when they were made. We also conceive specifically who made them. We can know which developer committed a specific line of code now. Because of that, with any good version control system, we can identify the point at which bad code was injected into an application. We simply need to spend time reviewing all of the logs. We can try to determine where a problem is happening and then try to track down changes that have happened to that specific project. However, with this being said, this can be horribly inefficient. This can take a good deal of time. Now get provides a tool that will help us in this process, and that tool is called get bisect, so get bisect is a tool that is included with get that enables you to specify I start and in commit and then either manually or automatically determine the point of failure within that range of commits. Let's see how this plays out. So let's say that we have a sample depository and these are all commits within this repositories, and we know that at this point code was working correctly. However, by the time it got to the end, code was not working correctly. So we need to determine where within this range that bad code was injected into the project. So first we'll call this code working correctly, commit our good commit and we'll call the code not working correctly, commit our bad commit now. First get bisect will identify a commit near the middle. It will know in this case that this one is not working correctly. And so because of that, it knows that the commit must happen before this point. It's then going to go back and search, and we can see here that there is now a good commit happening here and then it will continue to proceed, and we'll see here that there is another good commit, which means that by the process of elimination that we're going to have a first bad commit identified here. Now this is the power of get bisect and that it helps guide you through this process, either manually or automatically, which will talk more about in the next clip. Now let's look at how you enter bisect mode. You simply need to run, get by ___, start and then specify both the good and bad commits like we mentioned previously. Now next, we need to classify the commits that get bisect takes us to as either good or bad, and that is simple as just entering, get bisect good or get bisect bad. But as I mentioned, there is an automated way that it can help guide us through this process. So if we have a command that will test our code from within our repositories, weaken, simply utilize, get bisect, run and then specify what command it needs to run. And as long as that command will use the status code to correctly indicate whether or not something passed or failed, we can then use this to determine when our first bad commit WAAS. Now, whether you're using the automated or manual process when you are finished, you need to call get bisect reset, and this will allow us to exit out of bisect mode and we can now go fix the code that we found.

Detecting Bad Commits with Git Bisect
[Autogenerated] So next we're going to utilize get bisect to detect bad commits within our repositories. So over the course of this demo, we will first utilize get by ___ manual mode to find wind. Bad code was injected, but then will be integrating. Get bisect with test to automatically find a bad codecommit. So the first thing we need to do is clone the example Java script project that we used within a previous module. Next, we're going to change into that directory from here. The next step is we need to run in P m. Installed to pull down the project Dependencies. Next, we'll check out a branch, I'll call, get fetch and then we'll check out the bisect branch from here. We're going to run our index dot Js file now just a za reminder. This file allows us to pass in a number, and that number is the max and we'll find prime numbers up to the max value. Now, in this case, I'm going to run up to 100 and when we do, we'll see that it found 15 primes between zero and 100. But that actually is incorrect. We should be finding 25 primes between zero and 100. So we know that there is a problem in our code and we can verify that by actually running in P M test and we can see here that we have four different failures. We have no test passing and all failing. Next, we need to look at the commits that have been made into this branch. So we have one commit here, which is breaking the fine primes dot Js logic. Now, this is the committee ultimately that we won't get bisect to find for us. We're going to specify the commit for updating our getting nor file as our good commit. Because we know it was working at this point and we'll utilize the add more tests, commit to be the commit where this is our bad commit because we know that this is a point where it was no longer working. So I'm gonna go ahead and exit out of here and we'll go ahead and inter get Bisek mode now from here, our next step is to specify are good commit then we need to specify are bad commit now we've currently entered get bisect mode and get bisect is waiting for us to determine whether or not the current commit that we're on is good or bad. We contest this by simply running our index dot Js file. In this case, we can see that it is returning 15 primes instead of 25. So we know that we still are bad now. Next were actually on the committee where it is breaking. And so in this case, we're going to run our index dot Js file again and we can see that it is still returning the incorrect value. So we'll specify this commit is bad. And it lets us know then that this is the first bad commit. It has done the analysis and it is determined that this is the point where the bad logic was injected. We can now run get show. From here, you can see that there was a single line that was passed in. In this case, it is cutting the max value in half from the max value that is being passed into the function. So we know that this is the logic that caused it to break. So now I'm gonna exit out of get show now. Once we're done to exit out of get bisect. We simply need to run, get bisect. Reset. Now we have exited out of Get Bisek mode. Now the next step is we're going to inter get bisect mode again and in this case, instead of using the manual process, we're going to use the automated process. But our first step is still the same. We need to specify are good commit and we need to specify are bad commit now in this case, we're going to use get bisect and we're going to tell it to run our test suite and it can run our test suite by running in p m test. It now went through the process and it landed at the same conclusion that the breaking the fine primes dot Js logic commit was indeed the one where the bad code was injected. Now, some of you might be worried if you don't have tests at the point when you think that the bad code was injected. However, if you include tests that are not a part of your repositories, they will not be wiped out when get by ___, which is between different commits and so in that case, you can still use the automated process as long as you keep those tests that you're using to validate whether or not a commit is good or bad out of the repositories for the time being.

Summary
[Autogenerated] So let's quickly review what we were able to cover in this module. First of all, we reviewed the get bisect tool and its capabilities. We talked about how this is a needed addition to a version control system in that it can help you find the point at which bad code was injected into our repositories. We then looked at how we can utilize the get bisect tool to manually determine when bad code was injected. We were able to manually test each point that get bisect, put us into and then determine if that commit was either good or bad. But then we utilize get bisect, automatically determine when bad code was injected by giving it the ability to run our test suite and take the results of that test suite to determine whether or not each commit was good or bad. But let's look at all of the advance get techniques we have covered over this entire course. First of all, we've looked at get configuration, and I hope that you've seen that there are several areas throughout the course where we utilize different get configuration values to make our work with get more efficient. We've also looked at get attributes and we've looked at ways that we can specify get to work differently with one file, depending on certain conditions that we set. We also have looked at get sub modules which give us the ability to integrate shared repositories into our projects and then effectively allow our teams to collaborate on the shared projects. And then we have get hooks and get hooks. Enable us to optimize areas of our workflow. We can do things like making sure that we're limiting and running our tests before we commit to the repositories. We then looked at custom get commands, and in this case we implement it a custom command that enabled us to use all of the steps needed when we're pulling down a project that is using sub modules. And then finally, the get bisect tool that we covered here in this module that Maur effectively enables us to find when bad code was injected into our projects. I hope these get techniques serve you well as you go out and implement them within your projects.
